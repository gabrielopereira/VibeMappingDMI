"year","title","abstract","journal","doi"
"2017","Fake news, post-truth and media–political change","Media researchers may well experience a degree of difficulty in relating to the strident arrival of ‘post-truth’ and ‘fake news’ as key markers of the current media–political situation, the focus both of countless commentaries in newspapers and magazines and a spate of new books. After all, questions about the contingency and precariousness of what is publicly circulated as the ‘truth’ have long been central to research across both the cultural studies’ and the more sociological strands of international media inquiry. Similarly, the idea of news involving a good measure of often deliberately counterfeit information, as a result of journalistic practices themselves or the strategies of deception used by sources, is very familiar too. It is perhaps necessary to note the difference between the ‘post-truth’ label and ‘fake news’ despite the lines of interconnection. ‘Post-truth’ is a self-consciously grand term of epochal shift (trading heavily on assumptions about an ‘era of truth’ we apparently once enjoyed). As Philip Schlesinger (2017) recently pointed out in this journal, despite its limitations, its rise as an idea ‘has signalled a perception of change both in how the public domain is constituted and in the conduct of major protagonists in the media-political sphere’ (p. 603). A change does indeed seem to be occurring but the more tightly that the focus is placed on the political sphere, perhaps the less the sense of shock that should be delivered by the phrase given the long and amply documented history of strategic deception here. ‘Fake news’, however, seems a snappy identifier of a kind of a fraudulent media product (the negative judgement and the sense of intention are even stronger than","",""
"2018","I do not believe you: how providing a source corrects health misperceptions across social media platforms","ABSTRACT Social media are often criticized as serving as a source of misinformation, but in this study we examine how they may also function to correct misperceptions on an emerging health issue. We use an experimental design to consider social correction that occurs via peers, testing both the type of correction (i.e., whether a source is provided or not) and the platform on which the correction ocratcurs (i.e., Facebook versus Twitter). Our results suggest that a source is necessary to correct misperceptions about the causes of the Zika virus on both Facebook and Twitter, but the mechanism by which such correction occurs differs across platforms. Implications for successful social media campaigns to address health misinformation are addressed.","",""
"2018","The agenda-setting power of fake news: A big data analysis of the online media landscape from 2014 to 2016"," This study examines the agenda-setting power of fake news and fact-checkers who fight them through a computational look at the online mediascape from 2014 to 2016. Although our study confirms that content from fake news websites is increasing, these sites do not exert excessive power. Instead, fake news has an intricately entwined relationship with online partisan media, both responding and setting its issue agenda. In 2016, partisan media appeared to be especially susceptible to the agendas of fake news, perhaps due to the election. Emerging news media are also responsive to the agendas of fake news, but to a lesser degree. Fake news coverage itself is diverging and becoming more autonomous topically. While fact-checkers are autonomous in their selection of issues to cover, they were not influential in determining the agenda of news media overall, and their influence appears to be declining, illustrating the difficulties fact-checkers face in disseminating their corrections. ","",""
"2018","The small, disloyal fake news audience: The role of audience availability in fake news consumption"," In light of the recent US election, many fear that “fake news” has become a force of enormous reach and influence within the news media environment. We draw on well-established theories of audience behavior to argue that the online fake news audience, like most niche content, would be a small subset of the total news audience, especially those with high availability. By examining online visitation data across mobile and desktop platforms in the months leading up to and following the 2016 presidential election, we indeed find the fake news audience comprises a small, disloyal group of heavy Internet users. We also find that social network sites play an outsized role in generating traffic to fake news. With this revised understanding, we revisit the democratic implications of the fake news crisis. ","",""
"2018","How People Weave Online Information Into Pseudoknowledge"," Misinformation has found a new natural habitat in the digital age. Thousands of forums, blogs, and alternative news sources amplify fake news and inaccurate information to such a degree that it impacts our collective intelligence. Researchers and policy makers are troubled by misinformation because it is presumed to energize or even carry false narratives that can motivate poor decision-making and dangerous behaviors. Yet, while a growing body of research has focused on how viral misinformation spreads, little work has examined how false narratives are in fact constructed. In this study, we move beyond contagion inspired approaches to examine how people construct a false narrative. We apply prior work in cognitive science on narrative understanding to illustrate how the narrative changes over time and in response to social dynamics, and examine how forum participants draw upon a diverse set of online sources to substantiate the narrative. We find that the narrative is based primarily on reinterpretations of conventional and scholarly sources, and then used to provide an alternate account of unfolding events. We conclude that the link between misinformation, conventional knowledge, and false narratives is more complex than is often presumed, and advocate for a more direct study of this relationship. ","",""
"2019","Political Elites' Use of Fake News Discourse Across Communications Platforms","“Fake news” has become a global term since Donald Trump’s election as President of the United States. President Trump adopted what we describe as a “discourse of fake news” to attack and discredit news media and political rivals, which is suggested to have been reproduced by politicians in other national contexts. This article investigates whether Australian politicians adopt a fake news discourse. To do so, data are gathered over six months after Trump’s election from four political communications fora : parliamentary debates, social media (Facebook and Twitter), press, and politicians’ websites. We find fake news discourse is predominantly the domain of conservatives. Frequent users employ fake news discourse to delegitimize primarily the media, but also political opponents. Australian politicians’ use of fake news discourse is rare, but it is amplified by news media. Concerningly, it is seldom contested. We argue this has negative consequences for public debate and trust in media and political institutions.","",""
"2019","(Re)constructing Professional Journalistic Practice in Mexico: Verificado’s Marketing of Legitimacy, Collaboration, and Pop Culture in Fact-Checking the 2018 Elections","Although fact-checking websites for political news such as FactCheck.org, Politifact, and ProPublica are common in the United States, they are new in Mexico. Using textual analysis, this study examines the strategies used by Verificado 2018, a crowdsourced political fact-checking initiative generated during the largest election in Mexican history by news organizations, universities, and tech companies. Verificado 2018 emphasized legitimacy, collaboration, and critical humor to promote and engage users in fact-checking and viralizing reliable information.","",""
"2019","Where ‘fake news’ flourishes: a comparison across four Western democracies","ABSTRACT How does the content of so-called ‘fake news’ differ across Western democracies? While previous research on online disinformation has focused on the individual level, the current study aims to shed light on cross-national differences. It compares online disinformation re-published by fact checkers from four Western democracies (the US, the UK, Germany, and Austria). The findings reveal significant differences between English-speaking and German-speaking countries. In the US and the UK, the largest shares of partisan disinformation are found, while in Germany and Austria sensationalist stories prevail. Moreover, in English-speaking countries, disinformation frequently attacks political actors, whereas in German-speaking countries, immigrants are most frequently targeted. Across all of the countries, topics of false stories strongly mirror national news agendas. Based on these results, the paper argues that online disinformation is not only a technology-driven phenomenon but also shaped by national information environments.","",""
"2019","FAKE NEWS DURING NATURAL DISASTER: INFORMATION FLOW, NEWS PRACTICES AND FACT-CHECKING IN INDONESIA","After an earthquake and tsunami struck Palu city and its surrounding areas in Indonesia on September 28, 2018, fake news were rampantly circulated on online platforms. To address lack of studies on how fake news during natural disaster is handled through working process of news and fact-check professionals in Indonesia, this study aims to examine how fake news during natural disaster were handled by news and fact-check professionals in Indonesia.&#x0D; Primarily built from multilevel analyses of Hierarchy of Influences Model (HOI), this study analyzed four dimensions that shaped news information. Key codes for this study are under individual factors (i.e. personal trait and professional value), routine (i.e. information gathering, information processing, information distribution and fact-checking), organizational factors (i.e. editorial policies and organizational culture) and social institution (government and third party fact-checking organization).&#x0D; Through a mixed-method approach, web-observation examines the information flow of selected Palu fake news cases to provide overview on development of each case, including responses from government, media, fact-check organizations and the public. Next, in-depth interview will examine how news professionals from both traditional news media and web-only news media along with how third party fact-checkers handled Palu fake news.&#x0D; Theoretically, this study expands HOI’s multilevel applications to investigate how news and fact-check professionals in Indonesia handled Palu fake news. Practically, the findings will shed light for news and fact-check professionals to assess and improve their practices in handling fake news. This work-in-progress research will finish data collection in March 2019, followed by data analysis in April.&#x0D;  ","",""
"2019","Big Data and quality data for fake news and misinformation detection"," Fake news has become an important topic of research in a variety of disciplines including linguistics and computer science. In this paper, we explain how the problem is approached from the perspective of natural language processing, with the goal of building a system to automatically detect misinformation in news. The main challenge in this line of research is collecting quality data, i.e., instances of fake and real news articles on a balanced distribution of topics. We review available datasets and introduce the MisInfoText repository as a contribution of our lab to the community. We make available the full text of the news articles, together with veracity labels previously assigned based on manual assessment of the articles’ truth content. We also perform a topic modelling experiment to elaborate on the gaps and sources of imbalance in currently available datasets to guide future efforts. We appeal to the community to collect more data and to make it available for research purposes. ","",""
"2019","Listening to lies and legitimacy online: A proposal for digital rhetorical listening","As people scream past each other in an increasingly polarized public sphere, fake news emerges as problem for reception on the Internet. While scholars have posited rhetorical listening as a strategy to bridge these differences in off-line spaces, it has not been fully explored online. Online spaces are becoming increasingly salient and important to theorize though, since polarized groups often communicate and miscommunicate on the Internet. Using the fake news that circulated in the wake of the shooting at Marjory Stoneman Douglas High School in Parkland, Florida as a case study, I demonstrate some of the complications for rhetorical listening that arise through algorithms, interfaces, and performances that perpetuate the spread of fake news. As such, I call for more robust digital listening practices and theories that account for complications of the Internet. I conclude that individuals, platforms, and institutions can all actively promote rhetorical digital listening practices. However, we also need to think about other motivations besides ignorance for spreading fake news.","",""
"2019","Spreading Disinformation on Facebook: Do Trust in Message Source, Risk Propensity, or Personality Affect the Organic Reach of “Fake News”?"," There is considerable concern about the propagation of disinformation through social media, particularly for political purposes. “Organic reach” has been found to be important in the propagation of disinformation on social networks. This is the phenomenon whereby social media users extend the audience for a piece of information: interacting with it, or sharing it with their wider networks, greatly increases the number of people the information reaches. This project evaluated the extent to which characteristics of the message source (how trustworthy they were) and the recipient (risk propensity and personality) influenced the organic reach of a potentially false message. In an online study, 357 Facebook users completed personality and risk propensity scales and rated their likelihood of interacting in various ways with a message posted by either a trustworthy or untrustworthy source. Message source impacted on overall organic reach, with messages from trusted sources being more likely to be propagated. Risk propensity did not influence reach. However, low scores on trait agreeableness predicted greater likelihood of interacting with a message. The findings provide preliminary evidence that both message source and recipient characteristics can potentially influence the spread of disinformation. ","",""
"2019","Sourcing and Automation of Political News and Information During Three European Elections"," Voters increasingly rely on social media for news and information about politics. But increasingly, social media has emerged as a fertile soil for deliberately produced misinformation campaigns, conspiracy, and extremist alternative media. How does the sourcing of political news and information define contemporary political communication in different countries in Europe? To understand what users are sharing in their political communication, we analyzed large volumes of political conversation over a major social media platform—in real-time and native languages during campaign periods—for three major European elections. Rather than chasing a definition of what has come to be known as “fake news,” we produce a grounded typology of what users actually shared and apply rigorous coding and content analysis to define the types of sources, compare them in context with known forms of political news and information, and contrast their circulation patterns in France, the United Kingdom, and Germany. Based on this analysis, we offer a definition of “junk news” that refers to deliberately produced misleading, deceptive, and incorrect propaganda purporting to be real news. In the first multilingual, cross-national comparison of junk news sourcing and consumption over social media, we analyze over 4 million tweets from three elections and find that (1) users across Europe shared substantial amounts of junk news in varying qualities and quantities, (2) amplifier accounts drive low to medium levels of traffic and news sharing, and (3) Europeans still share large amounts of professionally produced information from media outlets, but other traditional sources of political information including political parties and government agencies are in decline. ","",""
"2020","My Reality Is More Truthful Than Yours: Radical Right-Wing Politicians’ and Citizens’ Construction of “Fake” and “Truthfulness” on Social Media—Evidence From the United States and The Netherlands","Although a growing body of literature has provided important insight into the conceptualization and consequences of mis- and disinformation, we know little about the construction of communicative (un)truthfulness online. Because (partisan) attributions of dishonesty and inaccuracy may influence citizens’ political opinions, and because accusations of fake news can be used to delegitimize political opponents and the media, it is important to understand how politicians and citizens construct different versions of (un)truthfulness. We specifically look at how (radical) right-wing populist politicians and citizens attribute antimedia and anti-elite sentiments in digital media settings. Against this backdrop, this article relies on two qualitative content analyses in the United States and The Netherlands to understand how discourses around (1) the epistemic status of facts and (2) inaccurate and (3) dishonest information are constructed by (radical) right-wing populists and citizens participating in Facebook discussions. The results provide important insights into the resonance of the expression of (un)truthfulness with perceptual screens and hostile media perceptions.","",""
"2020","Combating misinformation online: re-imagining social media for policy-making","Social media have created communication channels between citizens and policymakers but are also susceptible to rampant misinformation. This new context demands new social media policies that can aid policymakers in making evidence-based decisions for combating misinformation online. This paper reports on data collected from policymakers in Austria, Greece, and Sweden, using focus groups and in-depth interviews. Analyses provide insights into challenges and identify four important themes for supporting policy-making for combating misinformation: a) creating a trusted network of experts and collaborators, b) facilitating the validation of online information, c) providing access to visualisations of data at different levels of granularity, and d) increasing the transparency and explainability of flagged misinformative content. These recommendations have implications for rethinking how revised social media policies can contribute to evidence-based decision-making.","",""
"2020","Fake news as an informational moral panic: the symbolic deviancy of social media during the 2016 US presidential election","ABSTRACT A persistent story about the 2016 US presidential election was the preponderance of fake news stories on social media, and on Facebook in particular, that had no basis in fact but were wholly concocted to quickly amass clicks that could be converted into advertising revenues. This study steps outside of arguments about the spread or efficacy of fake news to instead interrogate its symbolic dimensions and its meaning for both journalism and the larger system of political communication. To conceptualize the role of fake news as a particular symbol, this paper approaches the journalistic condemnation of fake news as an ‘informational moral panic.’ This concept builds off Cohen’s classic formulation of moral panics as public anxiety that a particular social threat will lead to declining standards. The ability to define a phenomenon as an informational moral panic is an exercise in cultural power that ascribes deviancy to particular actors while validating others. In the case of fake news, the anxiety is not so much directed toward a particular group but aimed at the larger transformation of informational spaces made possible by social media. An examination of journalists’ responses in the US press during November 2016 reveals four domains of focus ‒ production, platform, subsidy, and consumption – each with its own narratives of blame and remedy. Fake news becomes a particular signifier that condenses broader concerns surrounding the eroding boundaries of traditional journalistic channels, click-driven news, the extension of mediated voices, and the growing role of social media in news distribution.","",""
"2020","Fake news practices in Indonesian newsrooms during and after the Palu earthquake: a hierarchy-of-influences approach","ABSTRACT The viral dissemination of fake news threatens news organizations in Indonesia, with many social media users exhibiting a decrease in their trust of traditional media, as well as limited digital literacy. To investigate fake news during natural disasters, this mixed-methods study examines information patterns and journalistic practices of three news organizations during the 2018 Palu earthquake and tsunami. First, online observations of disaster-related fake news cases on social media provide insights into how fake news was handled by three types of news media. The results show that when fake news concerned factual scientific evidence, news organizations unanimously used the government statements to debunk disinformation. In contrast, political or religious fake news had long lifecycles of polarized debates between pro-government groups and opponents. Using the Hierarchy-of Influences Model, in-depth interviews showed that individual-level journalistic professionalism mattered when tackling fake news reports, with some local practices differing from Western journalism approaches. At the routine level, news professionals treated the government as the authority to debunk controversial, high-risk fake news by presenting news only after official clarifications, while independent media tended to present balanced reports with diverse views. Additionally, interviewees revealed that organizational policies in relation to media types greatly influenced the handling of fake news practices in Indonesian newsrooms.","",""
"2020","Fake news and the discursive construction of technology companies’ social power"," In the research and commentary around ‘fake news’, there has been growing attention to the way the phrase evidences a growing field of technology industry critique, operating as a shorthand for understanding the nature of social media companies’ power over the public sphere. This article interrogates elite and popular discourses surrounding ‘fake news’, using the tools of critical discourse analysis to show how public commentary constitutes a discursive field that renders tech industry power intelligible by first defining the issue of fake news as a sociotechnical problem, then debating the infrastructural nature of platform companies’ social power. This article concludes that, as commentary moves beyond a focus on fake news and critiques of technology industries grow more complex, strains of elite discourse reveal productive constraints on tech power, articulating the conditions under which limits on that power are understood as legitimate. ","",""
"2020","You are fake news: political bias in perceptions of fake news"," Although the rise of fake news is posing an increasing threat to societies worldwide, little is known about what associations the term ‘fake news’ activates in the public mind. Here, we report a psychological bias that we describe as the ‘fake news effect’: the tendency for partisans to use the term ‘fake news’ to discount and discredit ideologically uncongenial media sources. In a national sample of the US population ( N = 1000), we elicited top-of-mind associations with the term ‘fake news’. Consistent with our hypothesis, we find evidence that both liberals and conservatives freely associate traditionally left-wing (e.g. CNN) and right-wing (e.g. Fox News) media sources with the term fake news. Moreover, conservatives are especially likely to associate the mainstream media with the term fake news and these perceptions are generally linked to lower trust in media, voting for Trump, and higher belief in conspiracy theories. ","",""
"2020","Caution: Rumors ahead—A case study on the debunking of false information on Twitter"," As false information may spread rapidly on social media, a profound understanding of how it can be debunked is required. This study offers empirical insights into the development of rumors after they are debunked, the various user groups who are involved in the process, and their network structures. As crisis situations are highly sensitive to the spread of rumors, Twitter posts from during the 2017 G20 summit are examined. Tweets regarding five rumors that were debunked during this event were manually coded into the following categories: rumor, debunking message, uncertainty about rumor, uncertainty about debunking message, and others. Our findings show that rumors which are debunked early and vehemently by official sources are the most likely to be stopped. When individuals participate in the process, they typically do so by sharing uncommented media content, as opposed to contributing user-generated content. Depending on the conditions in which a rumor arises, different network structures can be found. Since some rumors are easier for individuals to verify than others, our results have implications for the priorities of journalists and official sources. ","",""
"2020","‘Fake news’ as infrastructural uncanny"," In this article, we examine how the social disturbance precipitated by ‘fake news’ can be viewed as a kind of infrastructural uncanny. We suggest that the threat of problematic and viral junk news can raise existential questions about the routine circulation, engagement and monetisation of content through the Web and social media. Prompted by the unsettling effects associated with the ‘fake news’ scandal, we propose methodological tactics for exploring (1) the link economy and the ranking of content, (2) the like economy and the metrification of engagement and (3) the tracker economy and the commodification of attention. Rather than focusing on the misleading content of junk news, such tactics surface the infrastructural conditions of their circulation, enabling public interventions and experiments to interrogate, challenge and change their role in reconfiguring relations between different aspects of social, cultural, economic and political life. ","",""
"2020","Discipline and promote: Building infrastructure and managing algorithms in a “structured journalism” project by professional fact-checking groups"," News organizations have adapted in various ways to a digital media environment dominated by algorithmic gatekeepers such as search engines and social networks. This article dissects a campaign to actively shape that environment led by professional fact-checking organizations. We trace the development of the Share the Facts “widget,” a device designed to give fact-checks greater purchase in algorithmically governed media networks by driving adoption of a new data standard called ClaimReview. We show how “structured journalism” gave journalists a language for the social and technical challenges involved, and how this infrastructural technology mediates between fact-checkers, audiences, and platform companies. We argue that this standard-setting initiative exhibits both promotional and disciplining facets, offering greater distribution and impact to journalists while also defining their work in specific ways. Crucially, in this case, this disciplining influence reflects internal professional-institutional agendas in an emerging subfield of journalism as much as the demands of platform companies. ","",""
"2020","Cognitive Biases in Link Sharing Behavior and How to Get Rid of Them: Evidence from the 2019 Spanish General Election Twitter Conversation"," After a few years focusing on issues such as electoral prediction through social media data, many analysts turned their attention toward fake news spreading and misinformation. A coherent next step in elections research through social media data would be identifying what makes communities and individuals less open to manipulation. Misinformation is not simply bad or false information but selective information circulated among isolated and unconnected groups. Here, I will discuss common cognitive biases in link sharing behavior and its effects on politically shaped communities in the Twitter public debate on the 2019 Spanish general election campaign. Finally, I will present and discuss some data-driven mechanisms that may contribute to the mitigation of mass manipulation. ","",""
"2020","Reluctant to Share: How Third Person Perceptions of Fake News Discourage News Readers From Sharing “Real News” on Social Media"," Rampant fake news on social media has drawn significant attention. Yet, much remains unknown as to how such imbalanced evaluations of self versus others could shape social media users’ perceptions and their subsequent attitudes and behavioral intentions regarding social media news. An online survey ( N = 335) was conducted to examine the third person effect (TPE) in fake news on social media and suggested that users perceived a greater influence of fake news on others than on themselves. However, although users evaluated fake news as socially undesirable, they were still unsupportive of government censorship as a remedy. In addition, the perceived prevalence of fake news leads audiences to reported significantly less willingness to share all news on social media either online or offline. ","",""
"2020","Mobilizing Users: Does Exposure to Misinformation and Its Correction Affect Users’ Responses to a Health Misinformation Post?"," Misinformation spreads on social media when users engage with it, but users can also respond to correct it. Using an experimental design, we examine how exposure to misinformation and correction on Twitter about unpasteurized milk affects participants’ likelihood of responding to the misinformation, and we code open-ended responses to see what participants would say if they did respond. Results suggest that participants are overall unlikely to reply to the misinformation tweet. However, content analysis of hypothetical replies suggests they largely do provide correct information, especially after seeing other corrections. These results suggest that user corrections offer untapped potential in responding to misinformation on social media but effort must be made to consider how users can be mobilized to provide corrections given their general unwillingness to reply. ","",""
"2020","Nudge Effect of Fact-Check Alerts: Source Influence and Media Skepticism on Sharing of News Misinformation in Social Media"," This study extends the nudge principle with media effects and credibility evaluation perspectives to examine whether the effectiveness of fact-check alerts to deter news sharing on social media is moderated by news source and whether this moderation is conditional upon users’ skepticism of mainstream media. Results from a 2 (nudge: fact-check alert vs. no alert) × 2 (news source: legacy mainstream vs. unfamiliar non-mainstream) ( N = 929) experiment controlling for individual issue involvement, online news involvement, and news sharing experience revealed significant main and interaction effects from both factors. News sharing likelihood was overall lower for non-mainstream news than mainstream news, but showed a greater decrease for mainstream news when nudged. No conditional moderation from media skepticism was found; instead, users’ skepticism of mainstream media amplified the nudge effect only for news from legacy mainstream media and not unfamiliar non-mainstream source. Theoretical and practical implications on the use of fact-checking and mainstream news sources in social media are discussed. ","",""
"2020","Real Talk About Fake News: Identity Language and Disconnected Networks of the US Public’s “Fake News” Discourse on Twitter"," This article studies “fake news” beyond the consumption and dissemination of misinformation and disinformation. We uncover how the term “fake news” serves as a discursive device for ordinary citizens to consolidate group identity in everyday political utterances on Twitter. Using computational linguistic and network analyses, we demonstrate that over the period of 2016–2018, there is an uptrend in the use of identity language in US Twitter users’ discussions about “fake news,” manifested by the increased frequency of group pronouns in combination with issues and sentiments that boost one’s ingroup and derogate the outgroup. Furthermore, as opposed to the conventional wisdom that “fake news” is a right-wing term, we uncover two disconnected retweet networks surrounding liberal and conservative opinion leaders. Like-minded individuals selectively amplify ingroup messages to claim the power to define falsehood and make group-serving blame attributions. We discuss the theoretical implications of our findings and offer new directions for future research on “fake news,” misinformation, and disinformation. ","",""
"2021","Media Trust Under Threat: Antecedents and Consequences of Misinformation Perceptions on Social Media","Public concern over misinformation has reached worrying levels in recent years. This phenomenon stimulates a climate of information uncertainty under which individuals may also question high-quality information that is needed to sustain meaningful political debates. To address this issue, this panel study investigates antecedents of perceived misinformation exposure on social media and its consequences for media trust. We take a novel approach by examining 3 key factors that might lead to heightened perceived misinformation exposure (PME) among social media users: (1) their political knowledge, (2) their partisan strength, and (3) network characteristics. Even more importantly, we find that PME decreases media trust, and that this effect was especially pronounced among individuals with low political knowledge.","",""
"2021","The Effects of Message Order and Debiasing Information in Misinformation Correction","Misinformation continues to influence inferences even after being discredited, making it extremely difficult to completely erase its detrimental effects. With a two-wave online experiment, this research tested how the effectiveness of misinformation correction is influenced by (1) whether correction is presented before or after misinformation and (2) whether correction is accompanied by a message that enhances the coherence between misinformation and correction message. The results showed that a correction was most effective when it was delivered after the misinformation and with a debiasing message. These effects persisted at least one week after the initial exposure to the correction. The results were consistent with the Knowledge Revision Components (KReC) framework and the schemata-plus-tag model of negation comprehension. The findings also provided a comprehension-based explanation to previous findings from meta-analysis regarding the order of presentation of misinformation and corrective messages. Practical implications for misinformation correction practices are discussed.","",""
"2021","Comparative Approaches to Mis/Disinformation| Motivations for Sharing Misinformation: A Comparative Study in Six Sub-Saharan African Countries","In most African countries, “fake news,” politically motivated disinformation, and misinformation in the media were common occurrences before these became a preoccupation in the Global North. However, with a fast-growing population of mobile users, and the popularization of apps such as WhatsApp, misinformation has become much  more pervasive across the continent. Researchers have shown that perceived exposure to false information is high in some African countries, and yet citizens often share made-up news intentionally. This article explores the motivations and contributing factors for sharing misinformation in six sub-Saharan African countries. Our analysis of 12 focus groups with university students reveals two common motivations: civic duty and fun. The sharing of political (dis)information was uneven, but common among students with high levels of self-reported political engagement. We also present an array of cues used to determine credibility, which often determines the shareability of information. Cross-national differences are also discussed.","",""
"2021","Special Section on Comparative Approaches to Mis/Disinformation Introduction","From misleading news articles around elections in Brazil and the United States to mob lynchings fueled by false social media messages in India to made-up stories about COVID-19 vaccination, a deluge of disinformation and misinformation is affecting various aspects of citizens' lives around the world. Although there is an increasing number of research papers dealing with disinformation or misinformation, a majority of these have focused on the United States. This Special Section on comparative approaches to mis/disinformation features conceptual and data-informed articles with international and global perspectives on the prevalence, impact, and diffusion of mis/disinformation in different countries. Articles selected for the Special Section provide new theoretical and empirical contributions to existing bodies of knowledge whether focusing on one country or offering comparative perspectives involving multiple countries. The articles, individually and collectively, offer important scholarly and policy implications for studying and combating mis/disinformation around the world.","",""
"2021","“One Big Fake News”: Misinformation at the Intersection of User-Based and Legacy Media","This article explores audiences’ online reactions to public service broadcasting content manipulations. Drawing on a case study of Israeli televised content, we discuss the role user comments play in mediated calls for media literacy and civic awareness, allowing audiences to gather and discuss the impact of misinformation and fake news on culture, civic participation, and trust in public service media and other democratic institutions. We show how online mediated spaces that are considered aggressive and counterproductive should also be understood as facilitators of calls against misuse of public resources and manipulations spread in society. We thus suggest that alongside legacy mainstream media, user comments can become part of the solution for the prevalence of disinformation in our current digital media ecosystem.","",""
"2021","Online disinformation in the run-up to the Indian 2019 election","ABSTRACT This essay examines the role of disinformation in the Indian general election of 2019. The findings are presented against the background of previous work on the role of digital media in Indian politics. The essay uses 25 in-depth interviews among ordinary Indians to probe their level of awareness about so-called ‘fake news’. It also examines their behavior in seeking news and sharing political information and their views about the digital campaign strategies of leaders and parties. The interviewees were concerned about the increasing role of religious extremism online. Yet they were also strongly aware of the role of disinformation campaigns and had strategies for working around being misled by information shared on social media. The essay concludes by assessing how disinformation and online extremism are likely to have affected the 2019 election, and makes comparisons with Modi's election in 2014 and with other leaders.","",""
"2021","Fake news as fake politics: the digital materialities of YouTube misinformation videos about Brazilian oil spill catastrophe"," This article investigates misinformation chains – fake news and clickbait – related to the 2019 oil spill along the coast of Northeast Brazil. A link between the intensive use of misinformation on YouTube and the environmental impact of digital media and algorithmic performativity has been found by analyzing videos about the 2019 Brazilian oil spill. A total of 591 YouTube videos were extracted based on a search for the hashtags ‘oleononordeste’, ‘vazamentopetroleo’, and ‘greenpixe’. The data thus obtained suggest that most of the corpus (80.37%) consists of misinformation, of which 65.82% (389 videos) is clickbait and 14.55% (86 videos) fake news. YouTube misinformation videos produced around 1.42 MtCO2e, the equivalent of burning 3.30 barrels of oil. We argue that misinformation chains increase pollution and carbon footprint as a result of at least three factors: (a) the extra energy cost of feeding algorithms; (b) increased algorithmic resistance to the visibility of journalistic information; and (c) undermining public debate about environmental catastrophes in favor of private interests (fake politics). ","",""
"2021","Disinformation after Trump"," Disinformation research surged in the wake of the 2016 U.S. Presidential Election of Donald J. Trump. This essay reviews three book-length contributions published in 2020 and 2021. In doing so, I try to identify key developments in the field of disinformation research, and to contemplate next steps that may be of specific interest to readers of this journal. First, researchers are increasingly moving beyond a narrow obsession with technology in explaining and addressing disinformation. Second, not all authors reviewed here are convinced of the efficacy of media literacy education and fact-checking. Finally, considering limitations of the books reviewed here, I highlight the need for studies on marginalized communities and the Global South, as well as the potential of an embodied approach that may benefit a number of current perspectives on disinformation. ","",""
"2021","THE LIMITS OF FACT CHECKING: EIGHT NOTES ON CONSENSUS REALITY","In this study, we review the literature on fact-checking and the         empirical evidence contending that it can correct prior knowledge and false information. We         posit that the growing fact-checking industry is detached from the mis – disinformation         landscape and outline eight fundamental problems with fact-checking revolving around         epistemology, implementation, bias, efficacy, ambiguity, objectivity, ephemerality, and         criticism. We discuss these shortcomings in relation to the establishment of fact-checking         agencies across the world and their role in national elections in the United Kingdom, United         States, Malaysia, and Brazil. The article concludes with a discussion on the extent to which         fact-checking may be effective against false information in a context where consensus         reality has been super-imposed by individual reality.","",""
"2021","‘FAKE NEWS’ AND OTHER PROBLEMATIC INFORMATION: STUDYING DISSEMINATION AND DISCOURSE PATTERNS","Encompassed by the disputed term ‘fake news’, a variety of overtly or covertly biased, skewed, or falsified reports claiming to present factual information are now seen to constitute a critical challenge to the effective dissemination of news and information across established and emerging democratic societies. Such content – variously also classifiable as propaganda, selective reporting, conspiracy theory, inadvertent misinformation, and deliberate disinformation – in itself is not new; however, contemporary digital and social media networks enable its global dissemination and amplification, by human and algorithmic actors (Woolley &amp; Howard 2017), ordinary users and professional agents, outside of, in opposition to, or sometimes also in collusion with, the mainstream media (Shao et al. 2017; Vargo et al. 2017). Various political, commercial, and state actors are suspected to have exploited this ‘fake news’ ecosystem to influence public opinion, in major votes ranging from the Brexit referendum to national elections, and/or to utilise discourse around ‘fake news’ to generally undermine trust in media, political, and state institutions. This panel brings together a number of perspectives that combine systematic, large-scale, mixed-methods analysis of the empirical evidence for the global dissemination of, engagement with, and visibility of problematic information in public debate with the study of the public discourse about ‘fake news’, and the operationalisation of this concept by politicians and other societal actors to downplay inconvenient facts or reject critical questions. In combination, its five papers present a substantive collection of innovative approaches to the ‘fake news’ concept, exploring the dissemination of problematic information itself at larger and smaller scales as well as examining the operationalisation of the idea of ‘fake news’ in pursuit of specific ideological aims. This produces a new and more comprehensive picture of the overall impact of ‘fake news’, in all its forms, on contemporary societies.","",""
"2021","SOCIAL MEDIA USE, TRUST AND TECHNOLOGY ACCEPTANCE: INVESTIGATING THE        EFFECTIVENESS OF A CO-CREATED BROWSER PLUGIN IN MITIGATING THE SPREAD OF MISINFORMATION ON        SOCIAL MEDIA","Social media have become online spaces where misinformation abounds and spreads virally in the absence of professional gatekeeping. This information landscape requires everyday citizens, who rely on these technologies to access information, to cede control of information. This work sought to examine whether the control of information can be regained by humans with the support of a co-created browser plugin, which integrated credibility labels and nudges, and was informed by artificial intelligence models and rule engines. Given the literature on the complexity of information evaluation on social media, we investigated the role of technological, situational and individual characteristics in “liking” or “sharing” misinformation. We adopted a mixed-methods research design with 80 participants from four European sites, who viewed a curated timeline of credible and non-credible posts on Twitter, with (n=40) or without (n=40) the presence of the plugin. The role of the technological intervention was important: the absence of the plugin strongly correlated with misinformation endorsement (via “liking”). Trust in the technology and technology acceptance were correlated and emerged as important situational characteristics, with participants with higher trust profiles being less likely to share misinformation. Findings on individual characteristics indicated that only social media use was a significant predictor for trusting the plugin. This work extends ongoing research on deterring the spread of misinformation by situating the findings in an authentic social media environment using a co-created technological intervention. It holds implications for how to support a misinformation-resilient citizenry with the use of artificial intelligence-driven tools.","",""
"2021","FRAMING COVID-19: HOW FACT-CHECKING CIRCULATES ON POLITICAL         FACEBOOK","This abstract compiles the results of a research on how the political         framing of fact-checking posts about Covid-19 may influence their circulation on Facebook.         Our research is based on a dataset of 460 fact-checking posts published on politically         aligned Brazilian Facebook pages/groups. We used frame analysis to discuss how these posts         share fact-checking links. Our results point to the right-wing affiliated groups/pages         sharing more fact-checking than left-aligned ones, but using framing strategies to subvert         fact-checking content to support their beliefs.These results show that fact-checking does         circulate on political Facebook groups/pages that share disinformation (and they circulate         on right-wing and conservative ones), but it is used to reinforce their discourse, rather         than debunk it.","",""
"2021","CONTENT MATTERS, FAKE OR NOT: MEDIA CONTENT INFLUENCE ON PERCEIVED         INTERGROUP THREAT","We investigate how consumption of media content leads to change in         perception of an outgroup, and how is such change affected when the content is presented as         false. 403 Israeli participants filled out a questionnaire measuring realistic and symbolic         threat towards EU asylum seekers (EUAS). after 10-14 days, participants read an article         about EUAS. Group 1 read a positive article, group 2 read a negative article and group 3         read the same negative article, followed by a disclaimer notifying that fact-check websites         found the facts in the article misleading and false. Group 4 read a neutral report and a         control group did not read an article. A follow-up questionnaire measured perceived threat         towards EUAS again, as well as participant’s evaluation of the articles. The finding show         that media content has an immediate effect on perceived threat towards EUAS, and the         relevant perceived threat emphasized in each article was significantly changed in the         direction of the article (positively/negatively). The change was similar in the case of the         negative article presented as a fake article. Further analysis shows that participants         evaluated the fake article similarly to the negative article which was not presented as         fake. Apparently, in each group the evaluation of the article (reliability, professionalism,         convincingness, or objectivity) significantly correlated with participant prior perceived         threat towards EUAS. It seems that prior attitude serves as a lens through which media         consumers evaluate content, and the question of whether the facts are true becomes         negligible compared to one’s own inclination and beliefs.","",""
"2021","Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation"," Misinformation about the novel coronavirus (COVID-19) is a pressing societal challenge. Across two studies, one preregistered ( n1 = 1771 and n2 = 1777), we assess the efficacy of two ‘prebunking’ interventions aimed at improving people’s ability to spot manipulation techniques commonly used in COVID-19 misinformation across three different languages (English, French and German). We find that Go Viral!, a novel five-minute browser game, (a) increases the perceived manipulativeness of misinformation about COVID-19, (b) improves people’s attitudinal certainty (confidence) in their ability to spot misinformation and (c) reduces self-reported willingness to share misinformation with others. The first two effects remain significant for at least one week after gameplay. We also find that reading real-world infographics from UNESCO improves people’s ability and confidence in spotting COVID-19 misinformation (albeit with descriptively smaller effect sizes than the game). Limitations and implications for fake news interventions are discussed. ","",""
"2021","Knowing when to act: A call for an open misinformation library to guide actionable surveillance"," The design and reporting of data-driven studies seeking to measure misinformation are patchy and inconsistent, and these studies rarely measure associations with, or effects on, behaviour. The consequence is that data-driven misinformation studies are not yet useful as an empirical basis for guiding when to act on emerging misinformation threats, or for deciding when it is more appropriate to do nothing to avoid inadvertently amplifying misinformation. In a narrative review focused on examples of health-related misinformation, we take a critical perspective of data-driven misinformation studies. To address this problem, we propose a curated and open library of misinformation examples and describe its structure and how it might be used to support actionable surveillance. We draw on experiences with other curated repositories to speculate on the likely challenges related to achieving critical mass and maintaining data consistency. We conclude that an open library of misinformation could help improve the consistency of data-driven misinformation study design and reporting, as well as provide an empirical basis from which to make decisions about how to act on new and emerging misinformation threats. ","",""
"2021","Four years of fake news: A quantitative analysis of the scientific literature","Since 2016, “fake news” has been the main buzzword for online misinformation and disinformation. This term has been widely used and discussed by scholars, leading to hundreds of publications in a few years. This report provides a quantitative analysis of the scientific literature on this topic by using frequency analysis of metadata and automated lexical analysis of 2,368 scientific documents retrieved from Scopus, a large scientific database, mentioning “fake news” in the title or abstract.&#x0D; Findings show that until 2016 the number of documents mentioning the term was less than 10 per year, suddenly rising from 2017 and steadily increasing in the following years. Among the most prolific countries are the U.S. and European countries such as the U.K., but also many non-Western countries such as India and China. Computer science and social sciences are the disciplinary fields with the largest number of documents published. Three main thematic areas emerged: computational methodologies for fake news detection, the social and individual dimension of fake news, and fake news in the public and political sphere. There are 10 documents with more than 200 citations, and two papers with a record number of citations.","",""
"2021","Mixed findings in directly replicated experimental studies on fake news","Fake news mimics the look of legitimate news articles even if it does not mimic the standards of journalistic reporting. An increase in fake news has developed along with heightened concern about the veracity of news information, which has been highly politicized as fake news. These problems suggest whether standards of journalistic reporting can overcome the mimicry of real news, and whether the public can correctly identify real news. Here we ask two research questions. Does source information about the news article or its presentation influence the perception that a news article is fake news? What factors influence the perception of fake news? We conducted directly replicated experimental studies that presented four news articles to four subject pools. We show that source information and presentation have limited influence on participants’ judgments of a real news article as fake. Among those who evaluated the articles as fake news, our results show that the less participants thought the article presented a fair, balanced, evidence-based view, the more likely they were to judge it as fake news. These findings warrant discussion about the purpose of news organizations and news reporting as well as about how evidence and fairness work in news information.","",""
"2021","The disconcerting potential of online disinformation: Persuasive effects of astroturfing comments and three strategies for inoculation against them"," This study is the first to scrutinize the psychological effects of online astroturfing in the context of Russia’s digitally enabled foreign propaganda. Online astroturfing is a communicative strategy that uses websites, “sock puppets,” or social bots to create the false impression that a particular opinion has widespread public support. We exposed N = 2353 subjects to pro-Russian astroturfing comments and tested: (1) their effects on political opinions and opinion certainty and (2) the efficiency of three inoculation strategies to prevent these effects. All effects were investigated across three issues and from a short- and long-term perspective. Results show that astroturfing comments can indeed alter recipients’ opinions, and increase uncertainty, even when subjects are inoculated before exposure. We found exclusively short-term effects of only one inoculation strategy (refutational-same). As these findings imply, preemptive media literacy campaigns should deploy (1) continuous rather than one-time efforts and (2) issue specific rather than abstract inoculation messages. ","",""
"2021","A systematic literature review on disinformation: Toward a unified taxonomical framework"," The scale, volume, and distribution speed of disinformation raise concerns in governments, businesses, and citizens. To respond effectively to this problem, we first need to disambiguate, understand, and clearly define the phenomenon. Our online information landscape is characterized by a variety of different types of false information. There is no commonly agreed typology framework, specific categorization criteria, and explicit definitions as a basis to assist the further investigation of the area. Our work is focused on filling this need. Our contribution is twofold. First, we collect the various implicit and explicit disinformation typologies proposed by scholars. We consolidate the findings following certain design principles to articulate an all-inclusive disinformation typology. Second, we propose three independent dimensions with controlled values per dimension as categorization criteria for all types of disinformation. The taxonomy can promote and support further multidisciplinary research to analyze the special characteristics of the identified disinformation types. ","",""
"2021","Dysfunctional information sharing on WhatsApp and Facebook: The role of political talk, cross-cutting exposure and social corrections"," In this study, we investigate dysfunctional information sharing on WhatsApp and Facebook, focusing on two explanatory variables—frequency of political talk and cross-cutting exposure—and potential remedies, such as witnessing, experiencing, and performing social corrections. Results suggest that dysfunctional sharing is pervasive, with nearly a quarter reporting sharing misinformation on Facebook and WhatsApp, but social corrections also occur relatively frequently. Platform matters, with corrections being more likely to be experienced or expressed on WhatsApp than Facebook. Taken together, our results suggest that the intimate nature of WhatsApp communication has important consequences for the dynamics of misinformation sharing, particularly with regard to facilitating social corrections. ","",""
"2021","Correction Experiences on Social Media During COVID-19"," Despite a wealth of research examining the effectiveness of correction of misinformation, not enough is known about how people experience such correction when it occurs on social media. Using a study of US adults in late March 2020, we measure how often people witness correction, correct others, or are corrected themselves, using the case of COVID-19 misinformation on social media. Descriptively, our results suggest that all three experiences related to correction on social media are relatively common and occur across partisan divides. Importantly, a majority of those who report seeing misinformation also report seeing it corrected, and a majority of those who report sharing misinformation report being corrected by others. Those with more education are more likely to engage in correction, and younger respondents are more likely to report all three experiences with correction. While experiences with correction are generally unrelated to misperceptions about COVID-19, those who correct others have higher COVID-19 misperceptions. ","",""
"2022","Review essay: fake news, and online misinformation and disinformation","The attempted over-turning of the result of the 2020 US presidential election involved the proliferation of multiple online conspiracy theories and fake stories, and culminated in the assault on the US Congress while it was in the process of validating the electoral college count on 6 January 2021. This represented the apotheosis of the growth of misinformation and disinformation in the USA from around the middle of the previous decade. Social media is commonly assumed to be culpable for this growth, with ‘the news’ and current affairs deemed the epicentre of the battle for information credibility. This review begins by explaining the key definitions and discussions of the subject of fake news, and online misinformation and disinformation with the aid of each book in turn. It then moves on to focus on the following themes common to all three books as a means of attempting to provide a comprehensive analysis of the subject at hand: the use of memes and ironic content; the globalisation of misinformation, disinformation and fake news, and the impact on democratic societies; the limitations of media literacy approaches.","",""
"2022","When viruses and misinformation spread: How young Singaporeans navigated uncertainty in the early stages of the COVID-19 outbreak"," Guided by the frameworks of uncertainty management and sensemaking during crises, this study examined how young adults in Singapore managed uncertainty around the COVID-19 outbreak. Through a series of eight focus group discussions involving 89 young adults, we found that participants experienced uncertainty about the outbreak, especially when it comes to how they should protect themselves. They managed this uncertainty in two ways: while some engaged in information seeking, others engaged in information scanning. Those who did not actively seek information did not avoid it either, with some of them finding it impossible to avoid information about COVID-19, as it comes up in their routine social media use and offline conversations. Understanding COVID-19 as an illness that does not threaten young people, our participants noted only minimal disruptions to them. Instead, they were more concerned about their parents and older family members, whom they considered as more vulnerable. ","",""
"2022","Why do so few people share fake news? It hurts their reputation"," In spite of the attractiveness of fake news stories, most people are reluctant to share them. Why? Four pre-registered experiments ( N = 3,656) suggest that sharing fake news hurt one’s reputation in a way that is difficult to fix, even for politically congruent fake news. The decrease in trust a source (media outlet or individual) suffers when sharing one fake news story against a background of real news is larger than the increase in trust a source enjoys when sharing one real news story against a background of fake news. A comparison with real-world media outlets showed that only sources sharing no fake news at all had similar trust ratings to mainstream media. Finally, we found that the majority of people declare they would have to be paid to share fake news, even when the news is politically congruent, and more so when their reputation is at stake. ","",""
"2022","Health-related fake news on social media platforms: A systematic literature review"," This review aims to (a) investigate the characteristics of both the research community and the published research on health-related fake news on social media platforms, and (b) identify the challenges and provide recommendations for future research on the subject. We reviewed 69 journal articles found in the main academic databases up to April 2021. The studies extracted data mainly from Twitter, YouTube, and Facebook. Most articles aimed to investigate the public’s reaction to fake health information, concluding that health agencies and professionals should increase their online presence. The articles also suggest that future work should aim to improve the quality of health information on social media platforms, develop new tools and strategies to combat fake news sharing, and study the credibility of health information. Nonetheless, those in control of the platforms are the only ones which can take effective measures to ensure that their users receive reliable information. ","",""
"2022","PM Me the Truth? The Conditional Effectiveness of Fact-Checks Across Social Media Sites"," People use multiple social media daily. Some platforms feature public interactions like Facebook, others emphasize private communications such as Line. Although misinformation is rampant on all platforms, literature on fact-checks (FC) focuses primarily on public ones. This article provides an integrated psychological model and argues that FC is less effective on private platforms. People expect to encounter “unwelcome” FCs (incongruent with their beliefs) on public platforms, but selectively approach the “welcome” FC on private platforms. An experiment ( n = 601) and a national survey ( n = 1060) were implemented to test these hypotheses in the 2020 Taiwan Presidential Election. The experiment shows that respondents prefer FC on Line, which helps their party, but prefer FC on Facebook which disadvantages their party. The survey shows that consuming FC with more private platform usage has lower media literacy, while is the opposite on public platforms. Future work should focus on both FC and how it is consumed. ","",""
"2022","Fact-Checking the Crisis: COVID-19, Infodemics, and the Platformization of Truth"," During the onset of the COVID-19 pandemic, various officials flagged the critical threat of false information. In this study, we explore how three major social media platforms (Facebook, Twitter, and YouTube) responded to this “infodemic” during early stages of the pandemic via emergent fact-checking policies and practices, and consider what this means for ensuring a well-informed public. We accomplish this through a thematic analysis of documents published by the three platforms that address fact-checking, particularly those that focus on COVID-19. In addition to examining what the platforms said they did, we also examined what the platforms actually did in practice via a retrospective case study drawing on secondary data about the viral conspiracy video, Plandemic. We demonstrate that the platforms focused their energies primarily on the visibility of COVID-19 mis/disinformation on their sites via (often vaguely described) policies and practices rife with subjectivity. Moreover, the platforms communicated the expectation that users should ultimately be the ones to hash out what they believe is true. We argue that this approach does not necessarily serve the goal of ensuring a well-informed public, as has been the goal of fact-checking historically, and does little to address the underlying conditions and structures that permit the circulation and amplification of false information online. ","",""
"2022","“My People Already Know That”: The Imagined Audience and COVID-19 Health Information Sharing Practices on Social Media"," This article examines how imagined audiences and impression management strategies shape COVID-19 health information sharing practices on social media and considers the implications of this for combatting the spread of misinformation online. In an interview study with 27 Canadian adults, participants were shown two infographics about masks and vaccines produced by the World Health Organization (WHO) and asked whether or not they would share these on social media. We find that interviewees’ willingness to share the WHO infographics is negotiated against their mental perception of the online audience, which is conceptualized in three distinct ways. First, interviewees who would not share the infographics frequently describe a self-similar audience of peers that are “in the know” about COVID-19; second, those who might share the infographics conjure a specific and contextual audience who “needs” the information; and finally, those who said they would share the infographics most frequently conjure an abstract audience of “the public” or “my community” to explain that decision. Implications of these sharing behaviors for combatting the spread of misinformation are discussed. ","",""
"2022","The Roles of Worry, Social Media Information Overload, and Social Media Fatigue in Hindering Health Fact-Checking"," Health misinformation has become a salient issue on social media. To lower the risk of health misinformation, fact-checking matters. However, most existing studies investigated fact-checking from the journalism angle, while little is known about how information-seekers’ social media use affects their fact-checking behaviors. Also, it remains unclear how individuals’ health worry is associated with health fact-checking. Based on the O-S-O-R model, this study explored the underlying mechanism through which health worry and social media might hinder users’ fact-checking. Specifically, with a two-wave panel survey conducted in China during the COVID-19 pandemic, this study showed that individuals’ worry about COVID-19 increased social media information overload, which resulted in social media fatigue that could reduce health fact-checking. Also, the direct relationship between worry and fact-checking was not significant, but was completely mediated by social media information overload and social media fatigue. The findings demonstrate the negative roles of worry and social media in inhibiting users’ fact-checking behaviors. Important theoretical and practical implications for promoting effective fact-checking are discussed. ","",""
"2022","Fighting Fire With Fire? Relegitimizing Strategies for Media Institutions Faced With Unwarranted “Fake News” Accusations"," Empirical accounts point to the increasing weaponization of the “fake news” label—or unwarranted fake news accusations—by politicians to deflect critical reporting and delegitimize media outlets and achieve political ends. While research has begun unpacking the implications of such attacks, little attention has been paid toward avenues to counter them. Drawing upon the literature on misinformation and crisis management research and through an experimental survey ( n = 1,460), this study explores strategies that media outlets can employ to protect themselves against unwarranted “fake news” accusations—specifically through various denial and attack responses. Results show that denial strategies significantly increase respondents’ belief in the initial critical report, increase support of the media while conversely decreasing support of the politician. While variants of more offensive attack strategies also led to these anticipated effects, simple denials were found to be more effective in protecting the legitimacy of the media outlet. This suggests that such strategies can constitute a simple first-level measure through which institutions can undertake to challenge unfounded fake news accusations. ","",""
"2023","Misinformation","","",""
"2023","Persuasive strategies in online health misinformation: a systematic review","ABSTRACT A proliferation of a variety of health misinformation is present online, particularly during times of public health crisis. To combat online health misinformation, numerous studies have been conducted to taxonomize health misinformation or examine debunking strategies for various types of health misinformation. However, one of the root causes – strategies in such misinformation that may persuade the readers – is rarely studied. This systematic review aimed to fill this gap. We searched Web of Science, Scopus, PsycINFO, and Communication and Mass Media Complete for studies published between 2011 and 2021 on 29 May 2021. Peer-reviewed studies that discussed persuasive strategies in online misinformation messages were included. Of 1,700 articles identified, 58 were eligible and 258 persuasive strategies were extracted. Following the affinity diagraming process, 225 persuasive strategies in online health misinformation were categorized into 12 thematic groups, including: fabricating narrative with details, using anecdotes and personal experience as evidence, distrusting government or pharmaceutical companies, politicizing health issues, highlighting uncertainty and risk, inappropriate use of scientific evidence, rhetorical tricks, biased reasoning to make a conclusion, emotional appeals, distinctive linguistic features, and establishing legitimacy. Possible antecedents for why and how these persuasive strategies in online health misinformation may influence individuals were discussed. The findings suggest that media literacy education is essential for the public to combat health misinformation.","",""
"2023","Degrees of deception: the effects of different types of COVID-19 misinformation and the effectiveness of corrective information in crisis times","ABSTRACT Responding to widespread concerns about misinformation’s impact on democracy, we conducted an experiment in which we exposed German participants to different degrees of misinformation on COVID-19 connected to politicized (immigration) and apolitical (runners) issues (N = 1,490). Our key findings show that partially false information is more credible and persuasive than completely false information, and also more difficult to correct. People with congruent prior attitudes are more likely to perceive misinformation as credible and agree with its positions than people with incongruent prior attitudes. We further show that although fact-checkers can lower the perceived credibility of misinformation on both runners and migrants, corrective messages do not affect attitudes toward migrants. As a key contribution, we show that different degrees of misinformation can have different impacts: more nuanced deviations from facticity may be more harmful as they are difficult to detect and correct while being more credible.","",""
"2023","Perceived prevalence of misinformation fuels worries about COVID-19: a cross-country, multi-method investigation","ABSTRACT Data suggests that the majority of citizens in various countries came across ‘fake news’ during the COVID-19 pandemic. We test the relationship between perceived prevalence of misinformation and people’s worries about COVID-19. In Study 1, analyses of a survey across 17 countries indicate a positive association: perceptions of high prevalence of misinformation are correlated with high worries about COVID-19. However, the relationship is weaker in countries with higher levels of case-fatality ratios, and independent from the actual amount of misinformation per country. Study 2 replicates the relationship using experimental data. Furthermore, Study 2 demonstrates the underlying mechanism, that is, perceived prevalence of misinformation fosters the belief that COVID-19 is spiralling out of control, which in turn, increases worries. Our findings suggest that perceived prevalence of misinformation can have significant psychological effects, even though audience members reject the information as being false.","",""
"2023","The sharing of disinformation in cross-national comparison: analyzing patterns of resilience","ABSTRACT Although the problem of disinformation is on the rise across the globe, previous research has found that countries differ in the extent of widespread disinformation. In this study, we examine the willingness to disseminate disinformation across six countries (Belgium, France, Germany, Switzerland, the U.K. and the U.S.). We use a model by Humprecht et al. (2020) to study to what degree various systemic-structural factors influence individual behavior and contribute to resilience to disinformation. We draw on uniformly collected primary survey data and use regression analyses to examine which factors may explain citizens’ decisions to not further propagate disinformation. The results of our cross-national study show that resilience factors are country-specific and are highly dependent on the respective political and information environments. While in some countries extreme ideology weakens resilience, in others low education can have such an effect. Cross-national resilience factors include heavy social media use, the use of alternative media, and populist party support. We discuss what kind of tailored measures in combating online disinformation are needed to improve social resilience across different countries.","",""
"2023","THE WEIRD GOVERNANCE OF FACT-CHECKING: FROM WATCHDOGS TO CONTENT MODERATORS","In this work, we chart the multiple conflicts between stakeholders in the pursuit of a common standard for fact-checking outside Western Industrialized Educated Rich and Educated (WEIRD) countries, a problem that sits at the center of the institutional mission of fact-checkers as watchdogs of politicians and enforcers of content moderation. We apply reflexive thematic analysis to a set of interviews with 37 fact-checking experts from 35 organizations in 27 countries to catalogue the methods employed by fact-checkers and the pressures they contend with in non-WEIRD countries. In contrast to the one-size-fits-all approach to community guidelines implemented by social platforms worldwide, our results show that the asymmetric relationship with platform companies compels fact-checkers to adjust their methods and strategies to account for the political and cultural dimensions driving mis- and disinformation in their local contexts. Our findings detail three ways through which social platforms impinge on the scope, values, and institutional mission of non-WEIRD fact-checking organizations. As we argue, the platformization of non-WEIRD fact-checkers entails a convoluted process in which social media platforms gradually nudge fact-checkers into becoming part of the content moderation industry, a shift that runs counter to the democracy-building values underpinning the fact-checking movement. We conclude with a discussion of our findings and recommendations for content moderation both in WEIRD and non-WEIRD contexts.","",""
"2023","WHEN FACT-CHECKING IS NOT WEIRD: CHALLENGES IN FACT-CHECKING BEYOND THE WESTERN WORLD","Fact-checking has rapidly achieved a pivotal role in regulating the public debate globally. Reports show that the fact-checking industry is becoming more diverse, operating across more cultures and languages of recent. However, literature on fact-checking beyond the West is still forthcoming, as empirical research is disproportionally focused on the US. In this paper, we seek to catalog the many different forms of organizing and implementing fact-checks beyond the de facto standard found in Western industrialized countries, where fact-checking streams from journalistic verification practices. We analyzed 37 semi-structured, in-depth interviews with fact-checkers from 35 organizations operating in 27 non-WEIRD (Western, Educated, Industrialized, Rich, and Democratic) countries in Africa, Asia, Latin America, and Eastern Europe. The interviews were conducted in three different languages (English, Portuguese, and Spanish) between March and November of 2021. Interview data was transcribed and translated for downstream analyses using thematic clustering in N-Vivo. Findings show that non-WEIRD fact-checkers endure similar challenges to those reported in Western fact-checking organizations. These challenges are identified through an analysis of seven types of challenges common to non-WEIRD fact-checking organizations, which are associated with and speak to institutional, infrastructural, political, methodological, social, cultural, and linguistic dimensions. We concluded that while fact-checkers are relentless in promoting democratic values worldwide, the standards that support the industry may vary substantially around the world, particularly where truth-seeking practices evolved detached from notions of democracy, truth, and journalistic integrity.","",""
"2023","FACT CHECKING THE PANDEMIC IN THE GLOBAL SOUTH: CORRECTION STRATEGIES BY LATIN AMERICAN AND AFRICAN META FACT CHECKERS","Much of the professional fact-checking activities that were once conducted by political journalists and news media during electoral periods or political debates, or what Luengo and Garcia-Marin (2020) call fact checking of top-down claims, now focus on assessing dis/misinformation emerging from social media users, or bottom-up claims. Between 2019 and 2021, the number of fact-checking organizations rose substantially in three key regions of the world (Asia: 35 to 75; Africa: 9 to 19; and Latin America: 18 to 38) (Stencel &amp; Luher, 2021). To further address the recognised need for bottom-up fact checking, Meta recently added 28 fact-checking organizations to their funded partnership program (Facebook, 2021) and opened up access to their detection and engagement measurement tools (Full Fact, 2020). This new fact-checking infrastructure has made the geopolitics of dis/misinformation more visible globally because fact checkers can monitor online spread in near real time. This study investigates the Facebook communication of domestically produced fact checks of Covid-19 vaccine misinformation by Meta’s third party fact checkers. Specifically, we investigate the Covid-19 vaccine fact checks that Meta-affiliated fact checkers in the so-called Global South have selected and how they are packaged for dissemination on Facebook.","",""
"2023","UNRAVELING DISINFORMATION: EXAMINING THE HUMAN INFRASTRUCTURE OF MISINFORMATION IN BRAZIL THROUGH THE LENS OF HETEROMATION","In recent years, major technology companies have taken much of the public blame for this reality, given their algorithms facilitate the sharing of—and sometimes even promote—falsehoods. This, however, misses a key reality; social media, search engines, and messaging services are not fully automated technologies. Rather, they are heteromated: they are reliant on participatory humans to serve their economic goals. Focusing on users, and on the sharing, rather than the origination, of disinformation, we connect theories of heteromation with those surrounding the Human Infrastructure of Misinformation (HIM) with the express purpose of contributing to a more holistic understanding of how and why misinformation is so prevalent online.","",""
"2023","Michael Polányi’s fiduciary program against fake news and deepfake in the digital age","AbstractThis paper argues that Michael Polányi’s account of how science, as an institution, establishes knowledge can provide a structure for a future institution capable of countering misinformation, or fake news, and deepfakes. I argue that only an institutional approach can adequately take up the challenge against the corresponding institution of fake news. The fact of filtering news and information may be bothering. It is the threat of censorship and free speech limitation. Instead, I propose that we should indicate reliable information with a trademark and news signing-approved information and brand equity. I offer a method of creating a standard for online news that people can rely on (similar to high-quality shopping products).","",""
"2023","Toward an integrated framework for misinformation and correction sharing: A systematic review across domains"," Although misinformation and correction sharing is a topic that spans various domains and disciplines, the ultimate aim of such research is to better understand how to reduce misinformation sharing while motivating correction sharing in an increasingly decentralized and dispersed informational landscape. This review aims to (a) provide a systematic and structured overview of empirical studies on both misinformation sharing and correction sharing, as differentiated phenomenon, by examining article elements such as theoretical lenses, methodologies, topics of research, and (b) collect and organize factors predicting both misinformation sharing and correction sharing into an integrated model, which provides the foundation for an interdisciplinary framework of misinformation sharing and correction sharing. A total of 64 relevant empirical articles published before October 2021 were identified for analysis. Finally, a discussion regarding the academic and practical implications of this study, and gaps in the literature aim to provide direction for future research. ","",""
"2023","Fact-checking, reputation, and political falsehoods in Italy and the United States"," This article develops a reputational theory of political falsehoods. Politicians are motivated by the desire to build a positive reputation, therefore, they will be more likely to deliver false statements (incurring the risk of being fact-checked) when the potential benefit outweighs the cost. This happens as new elections come closer, since the electoral benefit of falsehoods increases along with the probability of being checked too late (after the election day). Politicians are less likely to issue falsehoods in detailed statements and in scripted communication, since the reputational cost is higher because such falsehoods would be considered intentional. Conversely, the stronger trust that voters attribute to politicians on issues they own, allows politicians to lie on such topics. Statistical analysis of almost 8000 statements released by politicians and assessed by fact-checkers, in the United States and Italy (2007–2018), supports the hypotheses. The results hold irrespective of party affiliation. ","",""
"2023","Believing and sharing misinformation, fact-checks, and accurate information on social media: The role of anxiety during COVID-19"," The COVID-19 pandemic went hand in hand with what some have called a “(mis)infodemic” about the virus on social media. Drawing on partisan motivated reasoning and partisan selective sharing, this study examines the influence of political viewpoints, anxiety, and the interactions of the two on believing and willingness to share false, corrective, and accurate claims about COVID-19 on social media. A large-scale 2 (emotion: anxiety vs relaxation) × 2 (slant of news outlet: MSNBC vs Fox News) experimental design with 719 US participants shows that anxiety is a driving factor in belief in and willingness to share claims of any type. Especially for Republicans, a state of heightened anxiety leads them to believe and share more claims. Our findings expand research on partisan motivated reasoning and selective sharing in online settings, and enhance the understanding of how anxiety shapes individuals’ processing of risk-related claims in issue contexts with high uncertainty. ","",""
"2023","Asymmetric adjustment: Partisanship and correcting misinformation on Facebook"," Across two studies, we test two of Facebook’s attempts to fight misinformation: labeling misinformation as disputed or false and including fact checks as related articles. We propose hypotheses based on a two-step model of motivated reasoning, which provides insight into how misinformation is corrected. For study 1 ( n = 1,262) and study 2 ( n = 1,586), we created a mock Facebook News Feed consisting of five different articles—four were actual news stories and the fifth was misinformation. Both studies tested (a) the effect of misinformation without correction, (b) Facebook’s changes to its platform, and (c) an alternative we theorized could be more effective. The findings, in line with the two-step model of motivated reasoning, provide evidence of symmetric party effects for the belief in misinformation. In both studies, we find partisan differences in responses to fact checking. We find modest evidence that our improvements to Facebook’s attempts at correcting misinformation reduce misperceptions across partisan divides. ","",""
"2023","Digital false information at scale in the European Union: Current state of research in various disciplines, and future directions"," Digital false information is a global problem and the European Union (EU) has taken profound actions to counter it. However, from an academic perspective the United States has attracted particular attention. This article aims at mapping the current state of academic inquiry into false information at scale in the EU across fields. Systematic filtering of academic contributions resulted in the identification of 93 papers. We found that Italy is the most frequently studied country, and the country of affiliation for most contributing authors. The fields that are best represented are computer science and information studies, followed by social science, communication, and media studies. Based on the review, we call for (1) a greater focus on cross-platform studies; (2) resampling of similar events, such as elections, to detect reoccurring patterns; and (3) longitudinal studies across events to detect similarities, for instance, in who spreads misinformation. ","",""
"2023","Peer correction of misinformation on social media: (In)civility, success experience and relationship consequences"," Misinformation often involves sensitive topics, and individuals may attempt to correct their peers using uncivil tones. We examined the effect of civil versus uncivil corrections on the perceived success of the correction and the reported relationship consequences. We used three-wave panel data consisting of 1513 participants in the first wave, and followed 686 individuals who participated in all three waves. Our results indicate that demographic variables were important predictors of the frequency and tone of correction. Furthermore, individuals reported an equal number of successful and unsuccessful correction experiences. Importantly, we found that more frequent civil correction was associated with a higher likelihood of success, and a successful correction experience was associated with positive relationship outcomes. In contrast, uncivil correction was associated with negative relationship consequences. In addition, individuals with higher appraisal literacy and those correcting close ties were more likely to report successful correction experiences. ","",""
"2023","Fake News and the Web of Plausibility"," This article explores the presentation of fake news, the most salient kind of disinformation, focusing neither on its text-based content nor its image-based form, but instead on its overall aesthetic composition—and how and why that composition contributes to the proliferation of disinformation. It begins with an analysis of “real news”—the genre that fake news attempts to copy—and its reliance on what Gaye Tuchman calls the “web of facticity” to communicate “good” information. It then turns to examine how fake news uses the logic of graphic design to exploit features of the web of facticity to create a “web of plausibility”—the web of facticity’s evil twin—to generate momentum for circulation through the analysis of several specific aesthetic features of the news genre. The conclusion offers some possible ways that this sort of perspective can better equip us to help stop the spread of disinformation. ","",""
"2023","Why Do People Share Political Information and Misinformation Online? Developing a Bottom-Up Descriptive Framework"," Social media users are key actors in the spreading of misleading or incorrect information. To develop an integrative parsimonious summary of social media users’ own accounts of motives for sharing political information, we conducted: (1) a literature review of motives for personally sharing false information as reported by social media users and (2) qualitative research concerning these motives using an innovative, ecologically valid method. Based on our findings, we developed a pool of items evaluating social media users’ motives for sharing false political information, which we then tested and analyzed the dimensionality of in (3) a pre-registered questionnaire-based study to identify key clusters of users’ own accounts of motives for sharing both true and false political information. The current findings show that there are distinct sets of motives people report for their misinformation sharing behavior: prosocial activism, attack or manipulation of others, entertainment, awareness, political self-expression, and fighting false information. Also, these sets of motives are associated with variables known to predict sharing misinformation, and some of these sets predict social media users’ self-reports of having shared misinformation in the past. Our findings highlight and elaborate on users’ motives that reflect a concern with “making things better” and acting in a manner that is beneficial to society as a whole, and suggest that different interventions may be required to combat misinformation sharing driven by different motives. A potential set of 18 items that could be used in questionnaires measuring motivations for sharing political news online is described. ","",""
"2023","Misinformation on Misinformation: Conceptual and Methodological Challenges"," Alarmist narratives about online misinformation continue to gain traction despite evidence that its prevalence and impact are overstated. Drawing on research examining the use of big data in social science and reception studies, we identify six misconceptions about misinformation and highlight the conceptual and methodological challenges they raise. The first set of misconceptions concerns the prevalence and circulation of misinformation. First, scientists focus on social media because it is methodologically convenient, but misinformation is not just a social media problem. Second, the internet is not rife with misinformation or news, but with memes and entertaining content. Third, falsehoods do not spread faster than the truth; how we define (mis)information influences our results and their practical implications. The second set of misconceptions concerns the impact and the reception of misinformation. Fourth, people do not believe everything they see on the internet: the sheer volume of engagement should not be conflated with belief. Fifth, people are more likely to be uninformed than misinformed; surveys overestimate misperceptions and say little about the causal influence of misinformation. Sixth, the influence of misinformation on people’s behavior is overblown as misinformation often “preaches to the choir.” To appropriately understand and fight misinformation, future research needs to address these challenges. ","",""
"2023","Developing Misinformation Immunity: How to Reason-Check Fallacious News in a Human–Computer Interaction Environment"," To counter the fake news phenomenon, the scholarly community has attempted to debunk and prebunk disinformation. However, misinformation still constitutes a major challenge due to the variety of misleading techniques and their continuous updates which call for the exercise of critical thinking to build resilience. In this study we present two open access chatbots, the Fake News Immunity Chatbot and the Vaccinating News Chatbot, which combine Fallacy Theory and Human–Computer Interaction to inoculate citizens and communication gatekeepers against misinformation. These chatbots differ from existing tools both in function and form. First, they target misinformation and enhance the identification of fallacious arguments; and second, they are multiagent and leverage discourse theories of persuasion in their conversational design. After having described both their backend and their frontend design, we report on the evaluation of the user interface and impact on users’ critical thinking skills through a questionnaire, a crowdsourced survey, and a pilot qualitative experiment. The results shed light on the best practices to design user-friendly active inoculation tools and reveal that the two chatbots are perceived as increasing critical thinking skills in the current misinformation ecosystem. ","",""
"2023","Studying the Downstream Effects of Fact-Checking on Social Media: Experiments on Correction Formats, Belief Accuracy, and Media Trust"," Repeated exposure to misinformation not only reduces the accuracy of people’s beliefs, but it also decreases confidence in institutions such as the news media. Can fact-checking—journalism’s main weapon against misinformation—worsen or ameliorate distrust in journalists and the media? To answer this question, we conducted two pre-registered experiments in Chile (total N = 1,472) manipulating message and receiver factors known to regulate the persuasiveness of fact-checks: transparency elements, arousing images, and political alignment. The results of both studies show that, across message formats, fact-checks are similarly effective at reducing people’s misperceptions. However, these positive effects on belief accuracy come at a cost: Compared to control groups, users exposed to political fact-checks trust news less and perceive the media as more biased, especially after reading corrections debunking pro-attitudinal misinformation. We close with a discussion of the theoretical and practical implications of these findings. ","",""
"2023","One Dose Is Not Enough: The Beneficial Effect of Corrective COVID-19 Information Is Diminished If Followed by Misinformation"," The World Health Organization (WHO) released a series of mythbuster infographics to combat misinformation during the COVID-19 infodemic. While the corrective effects of such debunking interventions have typically been examined in the immediate aftermath of intervention delivery; the durability of these corrective effects and their resilience against subsequent misinformation remains poorly understood. To this end, we asked younger and older adults to rate the truthfulness and credibility of 10 statements containing misinformation about common COVID-19 myths, as well as their willingness to share the statements through social media. They did this three times, before and after experimental interventions within a single study session. In keeping with established findings, exposure to the WHO’s myth-busting infographics—(a) improved participants’ ratings of the misinformation statements as untruthful and uncredible and (b) reduced their reported willingness to share the statements. However, within-subject data revealed these beneficial effects were diminished if corrective information was presented shortly by misinformation, but the effects remained when further corrective information was presented. Throughout the study, younger adults rated the misinformation statements as more truthful and credible and were more willing to share them. Our data reveal that the benefit of COVID-19 debunking interventions may be short-lived if followed shortly by misinformation. Still, the effect can be maintained in the presence of further corrective information. These outcomes provide insights into the effectiveness and durability of corrective information and can influence strategies for tackling health-related misinformation, especially in younger adults. ","",""
"2024","Misinformation’s missing human"," From pandemics to political campaigns, online misinformation has become acute. In response, a plethora of interventions have been offered, from debunking and prebunking to fact-checking and labeling. While the technical efficacy of these “solutions” are debatable, I suggest a more fundamental failure: they rely on a humanlike caricature, a rational and ethical figure who only needs better facts to disavow misguided misinfo practices. Instead I argue that misinformation studies must incorporate a more holistic human. Drawing from the broader humanities, this article conceptualizes the actually-existing human who can be emotional, factional, and bigoted – all qualities instrumentalized and amplified by online media. Reinserting this missing figure reintroduces agency and antipathy into misinformation studies. Misinformation is not something done to innocent subjects who merely need to be educated, but is an active practice shaped by identity and sociality that reflects the contradictions and frictions intrinsic to human nature. ","",""
"2024","Online misinformation and everyday ontological narratives of social distinction"," Most research into online misinformation has investigated its direct effects—the impact it may have on citizens’ beliefs and behavior. Much less attention has been paid to how citizens themselves make sense of misinformation as a broader social problem. We integrate theories of narrative, identity, cultural capital, and social distinction to examine how people construct the problem of misinformation and their orientation to it. We show how people engage in everyday ontological narratives of social distinction. These involve making a variety of discursive moves to position one’s “taste” in information consumption as superior to others constructed as lower in a social hierarchy. This serves to enhance social status by separating oneself from misinformation, which is presented as “other people’s problem.” We argue that these narratives have significant implications not only for citizens’ vigilance toward misinformation but also their receptiveness to interventions by policymakers, fact-checkers, news organizations, and media educators. ","",""
"2024","Disinformation and strategic frames: Introducing the concept of a strategic epistemology towards media"," Efforts to raise awareness about foreign disinformation might accidentally increase distrust towards legitimate media. We argue that state discourse on disinformation is comparable to strategic framing in journalists’ coverage of political events, and that it might imbue audiences with cynicism. Furthermore, in contrast to an experimental paradigm that depicts disinformation audiences as passive, we suggest that news consumers actively appropriate and produce content themselves. Conceptualising media content as ‘strategic’ rather than sincere might influence audiences to share and produce media content strategically. This Machiavellian tendency leads to similar effects on bias as motivated reasoning. Most accounts of motivated reasoning assume that limits of psychological processing are the reasons for biased judgements of what is true and fake, however, we argue that biases can also be due to culturally acquired second-order beliefs about knowledge. To explain this, we build on ideas about ‘folk epistemology’ and propose the term ‘strategic epistemology towards media’. Resistance-building efforts against disinformation risk promoting such a strategic epistemology towards media and this can have harmful effects on democratic dialogue. To avoid this, educational interventions should be premised on social epistemology rather than experimental psychology. ","",""
"2024","De- and recoding algorithmic systems: The case of fact checkers and fact checked users"," With the recent development of debunking on social media as a dominant agenda, fact checkers have increasingly used machine learning (ML) to identify, verify and correct factual claims, as ML promises the scaling of fact checking practices. However, it also places a new actor in between the fact checkers and the fact checked users. In this paper, we conducted a contrasted analysis of how fact checkers and fact checked users understand, evaluate and act towards the algorithmic system and the data flows in Meta’s Third-Party Fact-Checking Program: We did ethnographic fieldwork in the fact checking newsroom and interviewed and did protocol analysis with the fact checked. For both professional users and end users, the algorithmic system is experienced as a black box in which they have limited insight, and their sense-making practices happen based on the data and metrics that are made visible to them. In the paper, we draw on and expanded theory on decoding algorithms by not only exploring how the two user groups engage in decoding the algorithmic system, but also actively engage in forms of recoding by attempting to adapt or modify the algorithmic system to better fit within their cultural and social context, which is characterised by both varying epistemic cultures and societal positions. While the fact checkers from their hegemonic (sometimes negotiated) position understand the program as a (sometimes stupid) tool and primarily engage in passive acts of recoding, fact checked users, from their oppositional position, understand the program as an unpredictable censoring machine and engage primarily in more active acts of recoding. Based on the analysis, we end the paper with a discussion in which we argued for understanding data reflexivity as highly relational and processual. ","",""
"2024","Sowing “seeds of doubt”: Cottage industries of election and medical misinformation in Brazil and the United States"," We conducted ethnographic research with 31 misinformation creators and consumers in Brazil and the United States before, during, and after a major election to understand consumption and production of election and medical misinformation. This study contributes to research on misinformation ecosystems by focusing on poorly understood “micro-influencers” who create misinformation in peer-to-peer networks. We detail four key tactics that micro-influencers use. First, they disseminate “gray area” content rather than expert-falsified claims, using aesthetic and rhetorical tactics to evade moderation. Second, they post in small, closed groups where members feel predisposed to trust content. Third, they target consumers’ emotional and social needs. Finally, they post high volumes of short, repetitive content to plant “seeds of doubt” and build trust. We discuss the implications these micro-influencers have for misinformation interventions and platforms’ efforts to moderate misinformation. ","",""
"2024","The limits of live fact-checking: Epistemological consequences of introducing a breaking news logic to political fact-checking"," This article analyses the novel form of live political fact-checking, as performed by the Norwegian fact-checking organisation Faktisk.no during the Norwegian parliamentary election campaign in 2021. The aim of the study was to investigate the epistemological consequences of introducing a breaking news logic to political fact-checking. Through methods of participatory observation, interviews and textual analysis, the study finds that Faktisk.no used several strategies to bridge the ‘epistemic gap’ between the logics of breaking news and political fact-checking. Combined, these strategies pushed the live fact-checking towards a confirmative epistemology, implying that the live political fact-checking confirmed (1) knowledge already believed to be true and (2) hegemonic perspectives on what constitutes important and reliable information. The findings thereby point to a potential reorientation of political fact-checking from being a critical corrective of political elites to confirming the perspectives and knowledge base of the same elites. ","",""
"2024","Perceiving AI intervention does not compromise the persuasive effect of fact-checking"," Efforts to scale up fact-checking through technology, such as artificial intelligence (AI), are increasingly being suggested and tested. This study examines whether previously observed effects of reading fact-checks remain constant when readers are aware of AI’s involvement in the fact-checking process. We conducted three online experiments ( N = 3,978), exposing participants to fact-checks identified as either human-generated or AI-assisted, simulating cases where AI fully generates the fact-check or automatically retrieves human fact-checks. Our findings indicate that the persuasive effect of fact-checking, specifically in increasing truth discernment, persists even among participants without a positive prior attitude toward AI. Additionally, in some cases, awareness of AI’s role reduced perceived political bias in fact-checks among Republicans. Finally, neither AI-generated nor human fact-checks significantly affected participants’ feelings toward or their perceptions of the competence of the targeted politicians. ","",""
"2024","<i>Disinforming the unbiased</i>: How online users experience and cope with dissonance after climate change disinformation exposure"," The emergence of disinformation challenges today’s democracies. Selective exposure research assumes that psychological biases cause people to turn to attitude-reinforcing disinformation, though studies indicate that this only holds true for small niches of online audiences. However, when online, unbiased users as well may encounter disinformation, which for them appear to be attitude-challenging. How unbiased online users experience and cope with dissonance triggered by this, and whether this affects their pre-existing attitudes, has hardly been explored. This research gap is addressed using the polarized topic of climate change as an example. An experimental research design is applied combining stimulus exposure, survey research, eye tracking, and interviews ( n = 50). The findings indicate that unbiased users are not entirely resistant to disinformation influence. However, attitude effects could not be fully explained by selection behavior but instead through different feelings and strategies of coping with dissonance and patterns of performing online information searches. ","",""
"2024","People believe misinformation is a threat because they assume others are gullible"," Alarmist narratives about the flow of misinformation and its negative consequences have gained traction in recent years. If these fears are to some extent warranted, the scientific literature suggests that many of them are exaggerated. Why are people so worried about misinformation? In two pre-registered surveys conducted in the United Kingdom ( Nstudy_1 = 300, Nstudy_2 = 300) and replicated in the United States ( Nstudy_1 = 302, Nstudy_2 = 299), we investigated the psychological factors associated with perceived danger of misinformation and how it contributes to the popularity of alarmist narratives on misinformation. We find that the strongest, and most reliable, predictor of perceived danger of misinformation is the third-person effect (i.e. the perception that others are more vulnerable to misinformation than the self) and, in particular, the belief that “distant” others (as opposed to family and friends) are vulnerable to misinformation. The belief that societal problems have simple solutions and clear causes was consistently, but weakly, associated with perceived danger of online misinformation. Other factors, like negative attitudes toward new technologies and higher sensitivity to threats, were inconsistently, and weakly, associated with perceived danger of online misinformation. Finally, we found that participants who report being more worried about misinformation are more willing to like and share alarmist narratives on misinformation. Our findings suggest that fears about misinformation tap into our tendency to view other people as gullible. ","",""
"2024","Fake thumbs in play: A large-scale exploration of false amplification and false diminution in online news comment spaces"," This study explores how disinformation can dampen general users’ expressions of opinion online. In the context of a proven disinformation case in South Korea, this study analyzes externally validated click-logs of 1389 fake accounts and more than a million logs of 45,769 general users in a highly popular web portal. Findings show that the inflated visibility of anti-governmental opinions in the manipulated comment space was incongruent with the overall political tone that general users had spontaneously encountered from the broader media ecosystem beyond the manipulated space. Subsequently, this opinion “climate” incongruence decreased the likelihood of commenting in the manipulated space. The study concludes that false amplification (of the opinions that the manipulators promote) and false diminution (of general users’ political expressions) work in tandem to create a distorted opinion environment. ","",""
"2024","Not who you think? Exposure and vulnerability to misinformation"," Is exposure to false information necessary for misbelief? In this article, we consider the possibility that certain individuals hold misinformed beliefs without encountering misinformation, thus questioning for whom exposure to “fake news” is most deleterious. Using a pre-registered experiment on a diverse sample of 1079 US respondents, we find that the young, those with low information literacy, and those with high trust in government tend to hold mistaken beliefs, even without exposure to misinformation. Because these groups are already misinformed, eventual exposure to fake news does little to influence their misperceptions. Instead, misinformation exposure affects the elderly, those with high information literacy, and those with low trust in mainstream media the most. These results suggest that research focused on correcting misperceptions should avoid studying how certain characteristics correlate with misbelief only in misinformation’s presence. ","",""
"2024","Global misinformation trends: Commonalities and differences in topics, sources of falsehoods, and deception strategies across eight countries"," In a quantitative content analysis of 3,154 debunking articles from 23 fact-checking organizations, this study examines global misinformation trends and regional nuances across eight countries in Europe and Latin America (UK, DE, PT, SP, AR, BR, CL, and VZ). It strives to elucidate commonalities and differences based on political and media system indicators. Notably, countries with a substantial online presence of far-right parties avoid disclosing (fake) ordinary accounts to evade engaging in inauthentic coordinated actions. While entirely fabricated stories are infrequent, they stand out in Brazil and Spain, the two countries with higher political polarization. Despite variations, aggregated forms of fabrication (invented, manipulated, imposter, or decontextualized content) are more prominent in Latin America due to high social media use for news and low reliance on public media. Conversely, in Europe, countries are more impacted by misleading (cherry-picked, exaggerated, and twisted) information. ","",""
"2024","Let’s verify and rectify! Examining the nuanced influence of risk appraisal and norms in combatting misinformation"," Mounting concerns about COVID-19 misinformation and its insidious fallout drive the search for viable solutions. Both scholarly and practical efforts have turned toward raising risk appraisal of misinformation and motivating verification and debunking behaviors. However, individuals remain reluctant to verify and correct misinformation, suggesting a need to develop persuasion strategies to motivate such behaviors. Therefore, with an experiment of 256 participants recruited from Amazon MTurk, this study examines how effectively norm-based messages improve positive behavioral intentions during the COVID-19 pandemic. Findings suggest that among individuals with high perceived severity of misinformation, exposure to both descriptive and injunctive norms about verification reduced their intention to rectify misinformation. However, both descriptive and injunctive norms about debunking misinformation increased intentions to engage in preventive behaviors. By probing the “self–other” discrepancy and the “trade-off effect” of risk appraisal, the study further reveals that the perceived severity of misinformation merits in-depth exploration in future research. ","",""
"2024","User agency–based versus machine agency–based misinformation interventions: The effects of commenting and AI fact-checking labeling on attitudes toward the COVID-19 vaccination"," This study aimed to examine the effects of commenting on a Facebook misinformation post by comparing a user agency–based intervention and machine agency–based intervention in the form of artificial intelligence (AI) fact-checking labeling on attitudes toward the COVID-19 vaccination. We found that both interventions were effective at promoting positive attitudes toward vaccination compared to the misinformation-only condition. However, the intervention effects manifested differently depending on participants’ residential locations, such that the commenting intervention emerged as a promising tool for suburban participants. The effectiveness of the AI fact-checking labeling intervention was pronounced for urban populations. Neither of the fact-checking interventions showed salient effects with the rural population. These findings suggest that although user agency- and machine agency–based interventions might have potential against misinformation, these interventions should be developed in a more sophisticated way to address the unequal effects among populations in different geographic locations. ","",""
"2024","Correcting vaccine misinformation on social media: Effect of social correction methods on vaccine skeptics’ intention to take COVID-19 vaccine"," This study identifies the effect of six social correction methods on vaccine skeptics’ intention to take COVID-19 vaccine. In April–May 2021, we conducted a 3 (corrector on Twitter: ordinary person vs medical doctor vs nurse) × 2 (correction strategy: priming vs rebuttal) + 1 (control: misinformation only) between-subjects online experiment with 569 vaccine skeptics in the United States. Results show that exposure to priming-based corrections performed by a corrector, regardless of their expertise, is positively associated with intention to take COVID-19 vaccine if the information shared by the corrector is perceived to be trustworthy. This is evident among those with high or moderate vaccine skepticism. What is only evident among those with moderate vaccine skepticism is that exposure to corrections using priming (any corrector) or rebuttal (ordinary person or medical doctor) is positively associated with intention to take COVID-19 vaccine if the respondents perceived that the corrector was an expert. ","",""
"2024","A systematic literature review of the motivations to share fake news on social media platforms and how to fight them"," This review aims (a) to investigate the motivations to share fake news on Social Media Platforms (SMPs) according to the Self-Determination Theory (SDT); (b) to identify the solutions to fight these motivations and the agents in charge of implementing them; and (c) the user’s role in this process. We reviewed 64 journal articles published up to April 2022. Misinformation belief and entertainment stood out as the most cited intrinsic motivations, while self-promotion, conspiracy theory, and political ideology were the most cited extrinsic motivations in the reviewed literature. The main solutions to fight fake news spreading on SMPs are improving users’ digital literacy, refining interventions, rating headlines, and sources, and promoting users’ engagement to consume content sustainably. These interventions should be adopted by four agents: governments, SMPs, civil society, and private health organizations. However, the role of SMP users themselves is critical in this process. ","",""
