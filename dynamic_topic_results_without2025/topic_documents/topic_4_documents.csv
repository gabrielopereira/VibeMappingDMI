"year","title","abstract","journal","doi"
"2002","""""Universal Data Elements,"""" or the Biopolitical Life of Homeless Populations","This article explores the development of the Homeless Management Information Systems program by the U.S. Department of Housing and Urban Development. Launched in 2001, the program mandates data collection by homeless social service agencies receiving federal funds. The program is examined in terms of broader responses to the """"electronic turn"""" in social work. The generative capacities of database management systems are understood as producing surveillance at a register other than the individual subject often presumed in political theories of social control as well as surveillance studies of information technologies. The article argues that we must move toward an understanding of homeless management as a biopolitical enterprise, rather than only a disciplinary one. A discussion of how the HMIS program produces a homeless population as an object of knowledge and plane of intervention provides an understanding of the significance of HMIS for homelessness in the U.S. as well as for surveillance studies more broadly.","",""
"2004","Compelled Disclosure of Scientific Research Data","Federal legislation requires that research produced with federal funding be available to the public under the Freedom of Information Act. I raise a concern that this power might be used to harass scientists. The goal of data sharing, however, is important, and should be facilitated through electronic data archiving.","",""
"2006","Knowledge and governance in the digital age: The politics of monitoring planetary life","Planetary phenomena, such as global climate change and transborder disease transmission, are increasing subject to monitoring aided by advances in surveillance and data processing technologies. The most powerful governments of the world, especially the United States, are building monitoring systems they can control. Communities and activists around the world face a fundamental choice: become involved in shaping those systems so they better serve the needs and interests of the world’s population or build their own independent, unofficial monitoring systems.","",""
"2008","Sense.us: Towards a more social ‘social visualization’","The present research analyses the ‘social visualization’ tool Sense.us, a commercial interactive Web application in which U.S. Census data are being visualized. Sense.us was developed as a tool for social data exploration and interaction, in which it would be worthwhile to pay attention to the socio-cultural values that have driven the collection and categorization of the underlying U.S. Census datasets. It is argued that closer attention to value-driven U.S. Census statistics would greatly enhance the social appeal of Sense.us, and would be a logical next step in the development of online social visualization tools. In order to allow for explicit socio-cultural values of statistics in online visualizations, three strategies are offered: pro-active annotation; more attention to visual aesthetics; and, a tighter integration of user profiles and represented data.","",""
"2009","SOCIOLOGY OF EXPECTATION AND THE E-SOCIAL SCIENCE AGENDA","This paper explores the relevance of sociology of expectation in conceptualizing some of the tensions emerging in the UK context from the attempts to engage communities of social scientists, anthropologists and colleagues in cognate disciplines with e-social science. As the uptake of e-science proceeds fast in many scientific domains – from genetics to physics, from biology to clinical medicine – many social scientists and scholars in cognate disciplines remain apparently unaware or unimpressed by the promises of linking up large-scale data sets of fieldwork, and having access to the new tools and technologies that are being developed to cope with this scaling up of data set size. Science and Technology Studies (STS) has theorized technological innovations, and highlighted how they come packaged with expectations of their applications, their benefits and sometimes their risks. Future scenarios are projected in which a technology is integrated with society at large and with representations of everyday life. In line with an STS approach, instead of debating the likelihood of possible scenarios, this paper calls for uncovering the values and preferences that are implicitly inbuilt in the visions of the proponents of e-social science. It is only once these are rendered explicit that one can begin to explore the extent to which these values are shared across sections of the research community, or the extent to which they may be specific of certain stakeholders only. The process, it is argued, ultimately allows for a more transparent debate, and a negotiation of which values end up being up-taken in research policy and why.","",""
"2010","Expanding the Possibilities of Deliberation: The Use of Data Mining for Strengthening Democracy with an Application to Education Reform","Deliberation is important for strengthening democracies and enhancing the legitimacy of public policy. However, deliberation has been constrained by limits of time, space, and human capacities for listening and processing information. In this article, the authors discuss a new technology-based tool and show how it can help to partially remove these constraints. Although the Internet already provides the means to deliberate without the need to meet at the same place and time, its conjunction with data mining solves the “large numbers deliberation dilemma” that arises when large amounts of data have to be processed. The author's proposal adapts particular data-mining techniques, which simulate the learning process of a human brain with almost infinite relational capacities. The methodology was applied in a real-world case of Chilean education reform and demonstrated its potential effectiveness.","",""
"2010","Barriers to Interorganizational Information Sharing in e-Government: A Stakeholder Analysis","Government agencies often face trade-offs in developing initiatives that address a public good given competing concerns of various constituent groups. Efforts to construct data warehouses that enable data mining of citizens’ personal information obtained from other organizations (including sister agencies) create a complex challenge, since privacy concerns may vary across constituent groups whose priorities diverge from agencies’ e-government goals. In addition to privacy concerns, participating government agencies’ priorities related to the use of the information may also be in conflict. This article reports on a case study of the Integrated Non-Filer Compliance System used by the California Franchise Tax Board for which data are collected from federal, state, and municipal agencies and other organizations in a data mining application that aims to identify residents who under-report income or fail to file tax returns. This system pitted the public good (ensuring owed taxes are paid) against citizen concerns about privacy. Drawing on stakeholder theory, the authors propose a typology of four stakeholder groups (data controllers, data subjects, data providers, and secondary stakeholders) to address privacy concerns and argue that by ensuring procedural fairness for the data subjects, agencies can reduce some barriers that impede the successful adoption of e-government applications and policies. The article concludes that data controllers can reduce adoption and implementation barriers when e-government data mining applications rely on data shared across organizational boundaries: identify legitimate stakeholders and their concerns prior to implementation; enact procedures to ensure procedural fairness when data are captured, shared, and used; explain to each constituency how the data mining application helps to ensure distributive fairness; and continue to gauge stakeholders’ responses and ongoing concerns as long as the application is in use.","",""
"2010","The dangers of Webcrawled datasets","This article highlights legal, ethical and scientific problems arising from the use of large experimental datasets gathered from the Internet - in particular, image datasets. Such datasets are currently used within research into topics such as information forensics and image-processing. This paper strongly recommends against webcrawling as a means for generating experimental datasets, and proposes safer alternatives.","",""
"2010","Home Truths","This article interrogates the shifting ethical contours of research on contemporary childhood and family living. I reflect on increases in ethical regulation and the role of ethics review panels. Drawing on original data from empirical research I examine some of the ethical issues that arise in studies of family life with particular attention to qualitative mixed methods research and the use of psychosocial approaches. I propose that multilayered in-depth approaches require us to consider carefully ethical standpoints, affecting how we thread together individual and/or family case studies. Unsettling stories in research on emotional–social worlds refine our understandings of 'harm' and 'distress' and reconfigure ideas of 'responsible knowing'. Qualitative mixed methods research situates 'messy', conflicting and unfavourable data as part of ordinary parenthood, reformulating ethical and epistemological dilemmas for researchers of personal lives.","",""
"2011","Open data: Empowering the empowered or effective data use for everyone?","This paper takes a supportive but critical look at “open data” from the perspective of its possible impact on the poor and marginalized and concludes that there may be cause for concern in the absence of specific measures being taken to ensure that there are supports for ensuring a wide basis of opportunity for “effective data use”.  The paper concludes by providing a seven element model for how effective data use can be achieved.","",""
"2012","INTRODUCTION","‘e-Social Science’ refers to a new generation of digital and computational tools and methods for conducting social science research. As a label, it will no doubt become obsolete, the ‘e-’ will be dropped and these tools and methods will be as little noticed as the everyday use of computers now is. While the label is still with us, however, it helps to highlight issues that are arising with the increasing use of these tools and methods, and make the most of a window of time to attempt to tackle them, while they remain novel. The most pressing issues relate to the legal and ethical aspects of data in digital form and the computational processing of data. This is the focus of the current special issue. ‘e-Science’ generally was associated with the establishment of grid computing as a resource for facilitating computationally expensive research in the natural sciences, but since the late 1990s when the grid began to emerge as a new technology for science, here have been two important changes. First, cloud computing has emerged as a viable alternative to grid computing. Secondly, a panoply of digital and computational methods has been developed in social and human sciences. Qualitative methods in social research are now as digital as in any other field, since data in text, audio and video form are now overwhelmingly gathered and stored, using digital means. Increasingly, computational methods are being used for the analysis and interpretation of qualitative and quantitative data. Extensive data archives and repositories, accessed via the Internet, are facilitating data reuse to an extent that was unimaginable even a decade ago and enormous volumes of new data are generated continuously in an environment of ubiquitous and pervasive computing. In addition, social researchers are turning their attention to the analysis of social behaviour which is mediated or made possible by the Internet, possibly the most ubiquitous presence of information technology in our daily lives. Social media such as Facebook and Twitter provide fascinating new ways of accessing information about social behaviour. Finally, all of these modes of obtaining data necessitate new modes of analysis and","",""
"2012","THE ETHICAL WORK THAT REGULATIONS WILL NOT DO","Ethical concerns in e-social science are often raised with respect to privacy, confidentiality, anonymity and the ethical and legal requirements that govern research. In this article, the authors focus on ethical aspects of e-research that are not directly related to ethical regulatory framework or requirements. These frameworks are often couched in terms of benefits or harms that can be incurred by participants in the research. The authors shift the focus to the sources of value in terms of which benefits or harms are understood in real social situations. A central claim of this paper is that the technologies that are used for research are not value neutral, but serve to reinforce some values at the expense of others. The authors discuss databases, modelling and simulation, network analysis as examples of technologies which affect the articulation of values. A view of e-social science as a techno-scientific constellation of researchers, technologies and society, in which values are always already embedded, is put forward as a basis for a view of ethics as reflexive and active engagement, conducted with awareness. Methodological pluralism and proactive openness are also proposed as responses to this view of the ethical dimensions of e-social science.","",""
"2012","CRITICAL QUESTIONS FOR BIG DATA","The era of Big Data has begun. Computer scientists, physicists, economists, mathematicians, political scientists, bio-informaticists, sociologists, and other scholars are clamoring for access to the massive quantities of information produced by and about people, things, and their interactions. Diverse groups argue about the potential benefits and costs of analyzing genetic sequences, social media interactions, health records, phone logs, government records, and other digital traces left by people. Significant questions emerge. Will large-scale search data help us create better tools, services, and public goods? Or will it usher in a new wave of privacy incursions and invasive marketing? Will data analytics help us understand online communities and political movements? Or will it be used to track protesters and suppress speech? Will it transform how we study human communication and culture, or narrow the palette of research options and alter what ‘research’ means? Given the rise of Big Data as a socio-technical phenomenon, we argue that it is necessary to critically interrogate its assumptions and biases. In this article, we offer six provocations to spark conversations about the issues of Big Data: a cultural, technological, and scholarly phenomenon that rests on the interplay of technology, analysis, and mythology that provokes extensive utopian and dystopian rhetoric.","",""
"2012","ETHICAL IMPLICATIONS OF LIFESTYLE MONITORING DATA IN AGEING RESEARCH","Lifestyle monitoring systems, intelligent proactive systems incorporating passive monitoring capabilities and allowing contemporaneous remote access to data promise potential benefits to service providers, service users and their carers and families and those engaged in ageing research. Research to date has focused primarily on technical issues, generally at the expense of detailed consideration of the ethical issues raised by these systems. The paper, which is based on a literature review, identifies ethical issues and questions for researchers around: informed consent; working with people who are cognitively impaired; surveillance and the passivity of monitoring; processes of care and using and linking lifestyle monitoring data. It concludes by emphasizing the importance of all parties exploring and discussing the tradeoff between potential benefits to multiple stakeholder groups and actual costs to the individual.","",""
"2012","DATA PROTECTION, FREEDOM OF INFORMATION AND ETHICAL REVIEW COMMITTEES","Effective interpretation of, and compliance with, data protection and freedom of information law across the range of administrative and educational activities undertaken in a UK higher educational institution are tasks which, over a decade after the passage of the legislation, remain fertile ground for disagreement, misunderstanding and poorly conceived institutional policymaking. For social science researchers, the issue is further complicated by the need to simultaneously interpret and implement research ethics guidelines promulgated by diverse external bodies: the Research Councils, subject-specific research associations and other cross-disciplinary special interest groups. The cascade of new information communication technologies (ICTs) available to the social science researcher completes a triangle of policy variables and uncertainties for both researchers and institutional research scrutiny bodies. The aim of this article is threefold: first, to examine some of the issues raised by the application of data protection and freedom of information law to research in the social sciences, with a particular eye to the impact of ICTs; second, to discuss how the interplay between legal rules, ethical guidelines, and institutional regulation is developing; and finally, to suggest some potential ways forward.","",""
"2012","CONSTRUCTING THE LABYRINTH: The impact of data protection on the development of ‘ethical’ regulation in social science","Through a historical examination of the UK case over the past 40 years, this article argues that, although not drafted with such activities specifically in mind, the growth of legal initiatives protecting personal information have exerted a powerful and under-recognized impact on how social science is ‘ethically’ regulated. This impact has been both direct and indirect. At an indirect level, data protection law has encouraged the development of ‘self-regulation’ by learned societies, research institutions and funding bodies including, most importantly, the recent expansion of the remit of Research Ethics Committees within UK universities. Additionally, interpretations of the 1984 and, even more so, 1998 Data Protection Acts have resulted in the direct imposition by Universities as data controllers of key limitations on research projects. Thus, the infiltration into social science of governance models developed in medical research does not constitute the only important factor in explaining the increase, and shape, of regulation in this area. Legal changes have also been critical. In sum, data protection has helped fuel a radical shift away from a liberal regime based on a high valuation of individual academic autonomy to a much more constrained one where academics are often placed in a formally subordinated position vis-à-vis their institutions and subject to a labyrinth of restrictions and controls.","",""
"2012","The danger of big data: Social media as computational social science","Social networking Web sites are amassing vast quantities of data and computational social science is providing tools to process this data. The combination of these two factors has significant implications for individuals and society. With announcements of growing data aggregation by both Google and Facebook, the need for consideration of these issues is becoming urgent. Just as Web 2.0 platforms put publishing in the hands of the masses, without adequate safeguards, computational social science may make surveillance, profiling, and targeting overly accessible.&#x0D; &#x0D; The academic study of computational social science explains the field as an interdisciplinary investigation of the social dynamics of society with the aid of advanced computational systems. Such investigation can operate at the macro level of global attitudes and trends, down to the personal level of an individual’s psychology. This paper uses the lenses of computation social science to consider the uses and dangers that may result from the data aggregation social media companies are perusing. We also consider the role ethics and regulation may play in protecting the public.","",""
"2013","Viktor Mayer-Schonberger and Kenneth Cukier, Big Data: A Revolution That Will Transform How We Live, Work and Think","Viktor Mayer-Schonberger and Kenneth Cukier’s Big Data: A Revolution That Will Transform How We Live, Work and Think unveils the future possibilities of building on the analysis of vast amounts of data. Hypothetical correlation goes out the window, and the new methodology behind datafication opens new possibilities for companies and governments in the 21 century. The authors explain the importance of this data-driven approach, how messiness trumps exactitude, and the unlimited potential for many of data completeness. They also illustrate how searches on Google open new possibilities, but caution of the dark future of shattered privacy that could prevail as depicted in movies like Minority Report.","",""
"2013","The Functionality of Social Tagging as a Communication System","If the 1990s was all about the information superhighway and the network society, then the first 10 years of the 21st century is perhaps best described as the decade of data. Actors in different enterprises worked feverishly to develop innovative database and data mining technologies for institutional goals such as marketing, social networking, and scientific discovery. These researchers and data entrepreneurs follow an emerging belief that gathering and mining massive amounts of digital data will give objective insight into human relations and provide authentic representations for decision-making. On the surface, the technologies used to mine big data have the appearance of value-free and neutral inquiry. However, as information entrepreneurs use database and data mining technologies to purposively organize the social world, this seeming neutrality obfuscates domain assumptions and leaves cultural values and practices of power unexamined. We investigate the role of communication and social shaping of database and data mining technologies in the institutional context of genome science to understand how various stakeholders (scientists, policy makers, social scientists, and advocates) articulate racialized meanings with biological, physical, and big data. We found a rise in the use of racial discourse that suggests race has a genetic foundation.","",""
"2013","Neurodata and Neuroprivacy: Data Protection Outdated?","There are a number of novel technologies and a broad range of research aimed at the collection and use of data drawn directly from the human brain. Given that this data – neurodata – is data collected from individuals, one area of law which will be of relevance is data protection. The thesis of this paper is that neurodata is a unique form of data and that this will raise questions for the application of data protection law. Issues may arise on two levels. On a legal technical level, it is uncertain whether the definitions and mechanisms used in the data protection framework can be easily applied to neurodata. On a more fundamental level, there may be interests in neurodata, particularly those related to the protection of the mind, the framework was not designed to represent and may be insufficiently equipped, or constructed, to deal with.","",""
"2013","Home made big data&amp;#8253; Challenges and opportunities for participatory social research","Why should big data be the purview of only national governments, corporations, and (sometimes) academics? Many Web communications and other electronic traces are made by people as part of their everyday lives, and many of these same producers of big data have questions they want to answer about their own lives. This paper suggests some ways of thinking about big data in the context of questions people are trying to answer for themselves and their communities. It then takes an initial glance at conversations on Reddit to see how users draw on evidence, and concludes by arguing that there is space for home–made big data.","",""
"2013","Undermining ‘data’: A critical examination of a core term in scientific inquiry","The term ‘data’ functions as a powerful frame for discourse about how knowledge is derived and privileges certain ways of knowing over others. Through its ambiguity, the term can foster a self–perpetuating sensibility that ‘data’ is incontrovertible, something to question the meaning or the veracity of, but not the existence of. This article critically examines the concept of ‘data’ within larger questions of research method and frameworks for scientific inquiry. The current dominance of the term ‘data’ and ‘big data’ in discussions of scientific inquiry as well as everyday advertising focuses our attention on only certain aspects of the research process. The author suggests deliberately decentering the term, to explore nuanced frames for describing the materials, processes, and goals of inquiry.","",""
"2013","Making big data, in theory","In this paper, I explore four conceptual interventions that can contribute to the “big theory” sorely needed in regard to big data. This includes temporality and the possibilities of “dated theory,” the implicit histories of the meta- prefix shaping notions of metadata, “the dialectic of surveillance and recognition,” and questions of interpretation understood in terms of “rotted data” and “thick data.” In developing these concepts, I seek to expand frameworks for addressing issues of time, context, and power. It is vital that a vibrant theoretical discussion shape emerging regimes of “big data,” as these regimes are poised to play an important role regarding the mutual constitution of technology and society.","",""
"2013","A critical reflection on Big Data: Considering APIs, researchers and tools as data makers","This paper looks at how data is ‘made’, by whom and how. Rather than assuming data already exists ‘out there’, waiting to simply be recovered and turned into findings, the paper examines how data is co–produced through dynamic research intersections. A particular focus is the intersections between the application programming interface (API), the researcher collecting the data as well as the tools used to process it. In light of this, this paper offers three new ways to define and think about Big Data and proposes a series of practical suggestions for making data.","",""
"2013","The big head and the long tail: An illustration of explanatory strategies for big data Internet studies","This paper discusses how the advent of big data challenges established theories in Internet studies to redevelop existing explanatory strategies in order to incorporate the possibilities offered by this new empirical resource. The article suggests that established analytical procedures and theoretical frameworks used in Internet studies can be fruitfully employed to explain high–level structural phenomena that are only observable through the use of big data. The present article exemplifies this by offering a detailed analysis of how genre analysis of Web sites may be used to shed light on the generative mechanism behind the long–tail distribution of Web site use. The analysis shows that the long tail should be seen as a tiered version of popular top sites, and argues that downsizing of large–scale datasets in combination with qualitative and/or small–scale quantitative procedures may provide qualitatively better understandings of macro phenomena than purely automated, quantitative approaches.","",""
"2013","Faster than the speed of print: Reconciling ‘big data’ social media analysis and academic scholarship","The promise of ‘big data’ has generated a significant deal of interest in the development of new approaches to research in the humanities and social sciences, as well as a range of important critical interventions which warn of an unquestioned rush to ‘big data’. Drawing on the experiences made in developing innovative ‘big data’ approaches to social media research, this paper examines some of the repercussions for the scholarly research and publication practices of those researchers who do pursue the path of ‘big data’–centric investigation in their work. As researchers import the tools and methods of highly quantitative, statistical analysis from the ‘hard’ sciences into computational, digital humanities research, must they also subscribe to the language and assumptions underlying such ‘scientificity’? If so, how does this affect the choices made in gathering, processing, analysing, and disseminating the outcomes of digital humanities research? In particular, is there a need to rethink the forms and formats of publishing scholarly work in order to enable the rigorous scrutiny and replicability of research outcomes?","",""
"2014","The big data divide","This article extends the notion of a “big data divide” to describe the asymmetric relationship between those who collect, store, and mine large quantities of data, and those whom data collection targets. It argues that this key distinction highlights differential access to ways of thinking about and using data that potentially exacerbate power imbalances in the digital era. Drawing on original survey and interview findings about public attitudes toward collection and use of personal information, it maintains that the inability to anticipate the potential uses of such data is a defining attribute of data-mining processes, and thus of the forms of sorting and targeting that result from them.","",""
"2014","Advertising, Big Data, and the Clearance of the Public Realm: Marketers' New Approaches to the Content Subsidy","This article addresses implications for democracy of two interconnected developments involving big data and the media. One is the targeting of consumers for advertising by marketers and the new data-capture industry that supports them. The other involves the transformation of advertisers’ approach to subsidizing media content production. We describe these developments and consider their consequences for democratic life, drawing on classical and recent democratic theory (Paine, Dahl, Mouffe, Rosanvallon). We conclude that big data’s embedding in personalized marketing and content production threatens the ecology of connections that link citizens and groups via information, argumentation, empathy, and celebration as members of a shared social and civic space. Unless challenged, these developments risk eliminating the connective media necessary for an effective democracy.","",""
"2014","Big Data, Big Questions| The Big Data Divide","This article extends the notion of a “big data divide” to describe the asymmetric relationship between those who collect, store, and mine large quantities of data, and those whom data collection targets. It argues that this key distinction highlights differential access to ways of thinking about and using data that potentially exacerbate power imbalances in the digital era. Drawing on original survey and interview findings about public attitudes toward collection and use of personal information, it maintains that the inability to anticipate the potential uses of such data is a defining attribute of data-mining processes, and thus of the forms of sorting and targeting that result from them.","",""
"2014","Living on Fumes: Digital Footprints, Data Fumes, and the Limitations of Spatial Big Data","Amid the continued rise of big data in both the public and private sectors, spatial information has come to play an increasingly prominent role. This article defines big data as both a sociotechnical and epistemic project with regard to spatial information. Through interviews, job shadowing, and a review of current literature, both academic researchers and private companies are shown to approach spatial big data sets in analogous ways.  Digital footprints  and  data fumes , respectively, describe a process that inscribes certain meaning into quantified spatial information. Social and economic limitations of this data are presented. Finally, the field of geographic information science is presented as a useful guide in dealing with the “hard work of theory” necessary in the big data movement.","",""
"2014","Big Data, Big Questions| This One Does Not Go Up To 11: The Quantified Self Movement as an Alternative Big Data Practice","Big data is often seen in terms of powerful institutions managing the actions of populations through data. This ethnography of the Quantified Self movement, where participants collect extensive data about their own bodies, identifies practices that go beyond simply internalizing predetermined frameworks. The QS movement attracts the most hungrily panoptical of the data aggregation businesses in addition to people who have developed their own notions of analytics that are separate from, and in relation to, dominant practices of firms and institutionalized scientific production. Their practices constitute an important modality of resistance to dominant modes of living with data, an approach that we call “soft resistance.” Soft resistance happens when participants assume multiple roles as project designers, data collectors, and critical sense-makers who rapidly shift priorities. This constant shifting keeps data sets fragmented and thus creates material resistance to traditional modes of data aggregation. It also breaks the categories that make traditional aggregations appear authoritative. This enables participants to partially yet significantly escape the frames created by the biopolitics of the health technology industry.","",""
"2014","Big Data, Big Questions| Metaphors of Big Data","Metaphors are a common instrument of human cognition, activated when seeking to make sense of novel and abstract phenomena. In this article we assess some of the values and assumptions encoded in the framing of the term  big data , drawing on the framework of conceptual metaphor. We first discuss the terms  data  and  big data  and the meanings historically attached to them by different usage communities and then proceed with a discourse analysis of Internet news items about big data. We conclude by characterizing two recurrent framings of the concept: as a natural force to be controlled and as a resource to be consumed.","",""
"2014","Metaphors of Big Data","Metaphors are a common instrument of human cognition, activated when seeking to make sense of novel and abstract phenomena. In this article we assess some of the values and assumptions encoded in the framing of the term big data, drawing on the framework of conceptual metaphor. We first discuss the terms data and big data and the meanings historically attached to them by different usage communities and then proceed with a discourse analysis of Internet news items about big data. We conclude by characterizing two recurrent framings of the concept: as a natural force to be controlled and as a resource to be consumed.","",""
"2014","Big Data, Big Questions| A Dozen Ways to Get Lost in Translation: Inherent Challenges in Large Scale Data Sets","As noted by the late Susan Leigh Star, technoscientific research always involves simplification and standardization. In recent years, the collection and analysis of large-scale data sets (LSDS) have become the norm. These are often convenience samples analyzed by data mining techniques. Moreover, these data are often used as the basis for public and private policy and action. At the same time, the term “large-scale” suggests completeness, while ease of collection and analysis suggest that little else need be done. Both tend to crowd out other interpretations; hence understanding their limits should be of the utmost concern. This article discusses a number of the issues of concern that arise out of the necessary but potentially problematic simplifications/standardizations found in LSDS.","",""
"2014","Big data: a revolution that will transform how we live, work, and think","Howard, P. (2006). New media and the managed citizen. New York: Cambridge University Press. Lathrop, D., & Ruma, L. (Eds.). (2010). Open government: Collaboration, transparency, and participation in practice. Sebastopol, CA: O’Reilly. Noveck, B. S. (2008). Wiki-Government: How open-source technology can make government decisionmaking more expert and more democratic. Washington, DC: Brookings Institution Press.","",""
"2014","Big and broad social data and the sociological imagination: A collaborative response"," In this paper, we reflect on the disciplinary contours of contemporary sociology, and social science more generally, in the age of ‘big and broad’ social data. Our aim is to suggest how sociology and social sciences may respond to the challenges and opportunities presented by this ‘data deluge’ in ways that are innovative yet sensitive to the social and ethical life of data and methods. We begin by reviewing relevant contemporary methodological debates and consider how they relate to the emergence of big and broad social data as a product, reflexive artefact and organizational feature of emerging global digital society. We then explore the challenges and opportunities afforded to social science through the widespread adoption of a new generation of distributed, digital technologies and the gathering momentum of the open data movement, grounding our observations in the work of the Collaborative Online Social Media ObServatory (COSMOS) project. In conclusion, we argue that these challenges and opportunities motivate a renewed interest in the programme for a ‘public sociology’, characterized by the co-production of social scientific knowledge involving a broad range of actors and publics. ","",""
"2014","Official statistics and Big Data"," The rise of Big Data changes the context in which organisations producing official statistics operate. Big Data provides opportunities, but in order to make optimal use of Big Data, a number of challenges have to be addressed. This stimulates increased collaboration between National Statistical Institutes, Big Data holders, businesses and universities. In time, this may lead to a shift in the role of statistical institutes in the provision of high-quality and impartial statistical information to society. In this paper, the changes in context, the opportunities, the challenges and the way to collaborate are addressed. The collaboration between the various stakeholders will involve each partner building on and contributing different strengths. For national statistical offices, traditional strengths include, on the one hand, the ability to collect data and combine data sources with statistical products and, on the other hand, their focus on quality, transparency and sound methodology. In the Big Data era of competing and multiplying data sources, they continue to have a unique knowledge of official statistical production methods. And their impartiality and respect for privacy as enshrined in law uniquely position them as a trusted third party. Based on this, they may advise on the quality and validity of information of various sources. By thus positioning themselves, they will be able to play their role as key information providers in a changing society. ","",""
"2014","Big Data solutions on a small scale: Evaluating accessible high-performance computing for social research"," Though full of promise, Big Data research success is often contingent on access to the newest, most advanced, and often expensive hardware systems and the expertise needed to build and implement such systems. As a result, the accessibility of the growing number of Big Data-capable technology solutions has often been the preserve of business analytics. Pay as you store/process services like Amazon Web Services have opened up possibilities for smaller scale Big Data projects. There is high demand for this type of research in the digital humanities and digital sociology, for example. However, scholars are increasingly finding themselves at a disadvantage as available data sets of interest continue to grow in size and complexity. Without a large amount of funding or the ability to form interdisciplinary partnerships, only a select few find themselves in the position to successfully engage Big Data. This article identifies several notable and popular Big Data technologies typically implemented using large and extremely powerful cloud-based systems and investigates the feasibility and utility of development of Big Data analytics systems implemented using low-cost commodity hardware in basic and easily maintainable configurations for use within academic social research. Through our investigation and experimental case study (in the growing field of social Twitter analytics), we found that not only are solutions like Cloudera’s Hadoop feasible, but that they can also enable robust, deep, and fruitful research outcomes in a variety of use-case scenarios across the disciplines. ","",""
"2014","Big Data, social physics, and spatial analysis: The early years"," This paper examines one of the historical antecedents of Big Data, the social physics movement. Its origins are in the scientific revolution of the 17th century in Western Europe. But it is not named as such until the middle of the 19th century, and not formally institutionalized until another hundred years later when it is associated with work by George Zipf and John Stewart. Social physics is marked by the belief that large-scale statistical measurement of social variables reveals underlying relational patterns that can be explained by theories and laws found in natural science, and physics in particular. This larger epistemological position is known as monism, the idea that there is only one set of principles that applies to the explanation of both natural and social worlds. Social physics entered geography through the work of the mid-20th-century geographer William Warntz, who developed his own spatial version called “macrogeography.” It involved the computation of large data sets, made ever easier with the contemporaneous development of the computer, joined with the gravitational potential model. Our argument is that Warntz's concerns with numeracy, large data sets, machine-based computing power, relatively simple mathematical formulas drawn from natural science, and an isomorphism between natural and social worlds became grounds on which Big Data later staked its claim to knowledge; it is a past that has not yet passed. ","",""
"2014","Big Data and the brave new world of social media research"," The recent Facebook study about emotional contagion has generated a high-profile debate about the ethical and social issues in Big Data research. These issues are not unprecedented, but the debate highlighted that, in focusing on research ethics and the legal issues about this type of research, an important larger picture is overlooked about the extent to which free will is compatible with the growth of deterministic scientific knowledge, and how Big Data research has become central to this growth of knowledge. After discussing the ‘emotional contagion study’ as an illustration, these larger issues about Big Data and scientific knowledge are addressed by providing definitions of data, Big Data and of how scientific knowledge changes the human-made environment. Against this background, it will be possible to examine why the uses of data-driven analyses of human behaviour in particular have recently experienced rapid growth. The essay then goes on to discuss the distinction between basic scientific research as against applied research, a distinction which, it is argued, is necessary to understand the quite different implications in the context of scientific as opposed to applied research. Further, it is important to recognize that Big Data analyses are both enabled and constrained by the nature of data sources available. Big Data research is bound to become more widespread, and this will require more awareness on the part of data scientists, policymakers and a wider public about its contexts and often unintended consequences. ","",""
"2014","The emerging role of Big Data in key development issues: Opportunities, challenges, and concerns"," This paper presents a review of academic literature, policy documents from government organizations and international agencies, and reports from industries and popular media on the trends in Big Data utilization in key development issues and its worthwhileness, usefulness, and relevance. By looking at Big Data deployment in a number of key economic sectors, it seeks to provide a better understanding of the opportunities and challenges of using it for addressing key issues facing the developing world. It reviews the uses of Big Data in agriculture and farming activities in developing countries to assess the capabilities required at various levels to benefit from Big Data. It also provides insights into how the current digital divide is associated with and facilitated by the pattern of Big Data diffusion and its effective use in key development areas. It also discusses the lessons that developing countries can learn from the utilization of Big Data in big corporations as well as in other activities in industrialized countries. ","",""
"2014","Data and life on the street"," What does the abundance of data and proliferation of data-making methods mean for the ordinary person, the person on the street? And, what could they come to mean? In this paper, we present an overview of a year-long project to examine just such questions and complicate, in some ways, what it is to ask them. The project is a collective exercise in which we – a mixture of social scientists, designers and makers – and those living and working on one street in Cambridge (UK), Tenison Road, are working to think through how data might be materialised and come to matter. The project aims to better understand the specificities and contingencies that arise when data is produced and used in place. Mid-way through the project, we use this commentary to give some background to the work and detail one or two of the troubles we have encountered in putting locally relevant data to work. We also touch on a methodological standpoint we are working our way into and through, one that we hope complicates the separations between subject and object in data-making and opens up possibilities for a generative refiguring of the manifold relations. ","",""
"2014","Big Data, new epistemologies and paradigm shifts"," This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities, and assesses the extent to which they are engendering paradigm shifts across multiple disciplines. In particular, it critically explores new forms of empiricism that declare ‘the end of theory’, the creation of data-driven rather than knowledge-driven science, and the development of digital humanities and computational social sciences that propose radically different ways to make sense of culture, history, economy and society. It is argued that: (1) Big Data and new data analytics are disruptive innovations which are reconfiguring in many instances how research is conducted; and (2) there is an urgent need for wider critical reflection within the academy on the epistemological implications of the unfolding data revolution, a task that has barely begun to be tackled despite the rapid changes in research practices presently taking place. After critically reviewing emerging epistemological positions, it is contended that a potentially fruitful approach would be the development of a situated, reflexive and contextually nuanced epistemology. ","",""
"2014","Big Data from the bottom up"," This short article argues that an adequate response to the implications for governance raised by ‘Big Data’ requires much more attention to agency and reflexivity than theories of ‘algorithmic power’ have so far allowed. It develops this through two contrasting examples: the sociological study of social actors used of analytics to meet their own social ends (for example, by community organisations) and the study of actors’ attempts to build an economy of information more open to civic intervention than the existing one (for example, in the environmental sphere). The article concludes with a consideration of the broader norms that might contextualise these empirical studies, and proposes that they can be understood in terms of the notion of voice, although the practical implementation of voice as a norm means that voice must sometimes be considered via the notion of transparency. ","",""
"2014","Big Data ethics"," The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. ","",""
"2014","Big Data and Small: Collaborations between ethnographers and data scientists"," In the past three years, Heather Ford—an ethnographer and now a PhD student—has worked on ad hoc collaborative projects around Wikipedia sources with two data scientists from Minnesota, Dave Musicant and Shilad Sen. In this essay, she talks about how the three met, how they worked together, and what they gained from the experience. Three themes became apparent through their collaboration: that data scientists and ethnographers have much in common, that their skills are complementary, and that discovering the data together rather than compartmentalizing research activities was key to their success. ","",""
"2014","After the crisis? Big Data and the methodological challenges of empirical sociology"," Google Trends reveals that at the time we were writing our article on ‘The Coming Crisis of Empirical Sociology’ in 2007 almost nobody was searching the internet for ‘Big Data’. It was only towards the very end of 2010 that the term began to register, just ahead of an explosion of interest from 2011 onwards. In this commentary we take the opportunity to reflect back on the claims we made in that original paper in light of more recent discussions about the social scientific implications of the inundation of digital data. Did our paper, with its emphasis on the emergence of, what we termed, ‘social transactional data’ and ‘digital byproduct data’ prefigure contemporary debates that now form the basis and rationale for this excellent new journal? Or was the paper more concerned with broader methodological, theoretical and political debates that have somehow been lost in all of the loud babble that has come to surround Big Data. Using recent work on the BBC Great British Class Survey as an example this brief paper offers a reflexive and critical reflection on what has become – much to the surprise of its authors – one of the most cited papers in the discipline of sociology in the last decade. ","",""
"2014","Complementary social science? Quali-quantitative experiments in a Big Data world"," The rise of Big Data in the social realm poses significant questions at the intersection of science, technology, and society, including in terms of how new large-scale social databases are currently changing the methods, epistemologies, and politics of social science. In this commentary, we address such epochal (“large-scale”) questions by way of a (situated) experiment: at the Danish Technical University in Copenhagen, an interdisciplinary group of computer scientists, physicists, economists, sociologists, and anthropologists (including the authors) is setting up a large-scale data infrastructure, meant to continually record the digital traces of social relations among an entire freshman class of students ( N &gt; 1000). At the same time, fieldwork is carried out on friendship (and other) relations amongst the same group of students. On this basis, the question we pose is the following: what kind of knowledge is obtained on this social micro-cosmos via the Big (computational, quantitative) and Small (embodied, qualitative) Data, respectively? How do the two relate? Invoking Bohr’s principle of complementarity as analogy, we hypothesize that social relations, as objects of knowledge, depend crucially on the type of measurement device deployed. At the same time, however, we also expect new interferences and polyphonies to arise at the intersection of Big and Small Data, provided that these are, so to speak, mixed with care. These questions, we stress, are important not only for the future of social science methods but also for the type of societal (self-)knowledge that may be expected from new large-scale social databases. ","",""
"2014","Big Data, data integrity, and the fracturing of the control zone"," Despite all the attention to Big Data and the claims that it represents a “paradigm shift” in science, we lack understanding about what are the qualities of Big Data that may contribute to this revolutionary impact. In this paper, we look beyond the quantitative aspects of Big Data (i.e. lots of data) and examine it from a sociotechnical perspective. We argue that a key factor that distinguishes “Big Data” from “lots of data” lies in changes to the traditional, well-established “control zones” that facilitated clear provenance of scientific data, thereby ensuring data integrity and providing the foundation for credible science. The breakdown of these control zones is a consequence of the manner in which our network technology and culture enable and encourage open, anonymous sharing of information, participation regardless of expertise, and collaboration across geographic, disciplinary, and institutional barriers. We are left with the conundrum—how to reap the benefits of Big Data while re-creating a trust fabric and an accountable chain of responsibility that make credible science possible. ","",""
"2014","Big Data in the 1800s in surgical science: A social history of early large data set development in urologic surgery in Paris and Glasgow"," “Big Data” in health and medicine in the 21st century differs from “Big Data” used in health and medicine in the 1700s and 1800s. However, the old data sets share one key component: large numbers. The term “Big Data” is not synonymous with large numbers. Large numbers are a key component of Big Data in health and medicine, both for understanding the full range of how a disease presents in a human for diagnosis, and for understanding if one treatment of a disease is better than another treatment or better than just leaving the patient on his or her own without therapy. In this paper, we examine the first considerations of Big Data in medicine in Paris in the early 1800s when urologic surgeon Jean Civiale collected the first large numbers. Civiale collected the large numbers to defend the efficacy of his urologic instrument, the lithotrite, and the surgical procedure he developed, lithotrity, for the removal of bladder stones compared with earlier, more invasive surgical approaches. We examine how large numbers were adjudicated in social decision-making in the Académie des sciences, Paris, when a dispute arose among French urologic surgeons about the importance of large numbers in surgical science. After Civiale’s successful defense of his instrument and procedure in Paris, we examine how his approach to Big Data (large numbers) impacted data collection by George Buchanan in his use of the procedure at the Royal Hospital Infirmary in Glasgow. ","",""
"2014","It’s time to scale the science in the social sciences"," The social sciences are at a remarkable confluence of events. Advances in computing have made it feasible to analyze data at the scale of the population of the world. How can we combine the depth of inquiry in the social sciences with the scale and robustness of statistics and computer science? Can we decompose complex questions in the social sciences into simpler, more robustly testable hypotheses? We discuss these questions and the role of machine learning in the social sciences. ","",""
"2014","On minorities and outliers: The case for making Big Data small"," In this essay, I make the case for choosing to examine small subsets of Big Data datasets—making big data small. Big Data allows us to produce summaries of human behavior at a scale never before possible. But in the push to produce these summaries, we risk losing sight of a secondary but equally important advantage of Big Data—the plentiful representation of minorities. Women, minorities and statistical outliers have historically been omitted from the scientific record, with problematic consequences. Big Data affords the opportunity to remedy those omissions. However, to do so, Big Data researchers must choose to examine very small subsets of otherwise large datasets. I encourage researchers to embrace an ethical, empirical and epistemological stance on Big Data that includes minorities and outliers as reference categories, rather than the exceptions to statistical norms. ","",""
"2014","Emerging practices and perspectives on Big Data analysis in economics: Bigger and better or more of the same?"," Although the terminology of Big Data has so far gained little traction in economics, the availability of unprecedentedly rich datasets and the need for new approaches – both epistemological and computational – to deal with them is an emerging issue for the discipline. Using interviews conducted with a cross-section of economists, this paper examines perspectives on Big Data across the discipline, the new types of data being used by researchers on economic issues, and the range of responses to this opportunity amongst economists. First, we outline the areas in which it is being used, including the prediction and ‘nowcasting’ of economic trends; mapping and predicting influence in the context of marketing; and acting as a cheaper or more accurate substitute for existing types of data such as censuses or labour market data. We then analyse the broader current and potential contributions of Big Data to economics, such as the ways in which econometric methodology is being used to shed light on questions beyond economics, how Big Data is improving or changing economic models, and the kinds of collaborations arising around Big Data between economists and other disciplines. ","",""
"2014","What difference does quantity make? On the epistemology of Big Data in biology"," Is Big Data science a whole new way of doing research? And what difference does data quantity make to knowledge production strategies and their outputs? I argue that the novelty of Big Data science does not lie in the sheer quantity of data involved, but rather in (1) the prominence and status acquired by data as commodity and recognised output, both within and outside of the scientific community and (2) the methods, infrastructures, technologies, skills and knowledge developed to handle data. These developments generate the impression that data-intensive research is a new mode of doing science, with its own epistemology and norms. To assess this claim, one needs to consider the ways in which data are actually disseminated and used to generate knowledge. Accordingly, this article reviews the development of sophisticated ways to disseminate, integrate and re-use data acquired on model organisms over the last three decades of work in experimental biology. I focus on online databases as prominent infrastructures set up to organise and interpret such data and examine the wealth and diversity of expertise, resources and conceptual scaffolding that such databases draw upon. This illuminates some of the conditions under which Big Data needs to be curated to support processes of discovery across biological subfields, which in turn highlights the difficulties caused by the lack of adequate curation for the vast majority of data in the life sciences. In closing, I reflect on the difference that data quantity is making to contemporary biology, the methodological and epistemic challenges of identifying and analysing data given these developments, and the opportunities and worries associated with Big Data discourse and methods. ","",""
"2014","Governing the Wild: Databases, Algorithms, and Population Models as Biopolitics","This essay draws on interviews with conservation biologists to reflect on two interrelated aspects of the in situ – ex situ divide and its increasing integration: database systems and population management models. Specifically, I highlight those databases and software programs used by zoos in ex situ conservation settings, and the parallel, traditionally distinct, in situ databases and risk assessment models. I then explore the evolving technologies that integrate wild-captive databases and population models and, in particular, emerging metapopulation and meta-model approaches to small population management. My central argument is that, while still viewed by many as separate, the in situ and ex situ projects—and their respective elaborate administrative structures and models of calculation—are, in practice, increasingly bleeding into one another. The stories I tell here about the efforts to save the red wolf from extinction reveal the complexities of this integration. I also document how—in this process—a tiny group of experts translates data into algorithmic formats to generate standardized risk calculations that are meant to apply both universally and objectively. Applying Foucauldian and STS insights to the field of conservation biology, I argue, finally, that surveillance and biopolitics work hand-in-hand in this context to enable a comprehensive, effective, and unitary management of nonhuman population life, or “viability”.","",""
"2014","When big data meets dataveillance: the hidden side of analytics","Among the numerous implications of digitalization, the debate about ‘big data’ has gained momentum. The central idea capturing attention is that digital data represents the newest key asset organizations should use to gain a competitive edge. Data can be sold, matched with other data, mined, and used to make inferences about anything, from people’s behavior to weather conditions. Particularly, what is known as ‘big data analytics’ — i.e. the modeling and analysis of big data — has become the capability which differentiates, from the rest of the market, the most successful companies. An entire business ecosystem has emerged around the digital data asset, and new types of companies, such as analytical competitors and analytical deputies, are proliferating as a result of the analysis of digital data. However, virtually absent from the big data debate is any mention of one of its constitutive mechanisms — that is, dataveillance. Dataveillance — which refers to the systematic monitoring of people or groups, by means of personal data systems in order to regulate or govern their behavior — sets the stage and reinforces the development of the data economy celebrated in the big data debate. This article aims to make visible the interdependence between dataveillance, big data and analytics by providing real examples of how companies collect, process, analyze and use data to achieve their business objectives.","",""
"2014","Datafication, dataism and dataveillance: Big Data between scientific paradigm and ideology","Metadata and data have become a regular currency for citizens to pay for their communication services and security—a trade-off that has nestled into the comfort zone of most people. This article deconstructs the ideological grounds of datafication. Datafication is rooted in problematic ontological and epistemological claims. As part of a larger social media logic, it shows characteristics of a widespread secular belief. Dataism, as this conviction is called, is so successful because masses of people — naively or unwittingly — trust their personal information to corporate platforms. The notion of trust becomes more problematic because people’s faith is extended to other public institutions (e.g. academic research and law enforcement) that handle their (meta)data. The interlocking of government, business, and academia in the adaptation of this ideology makes us want to look more critically at the entire ecosystem of connective media.","",""
"2014","Engineering the public: Big data, surveillance and computational politics","Digital technologies have given rise to a new combination of big data and computational practices which allow for massive, latent data collection and sophisticated computational modeling, increasing the capacity of those with resources and access to use these tools to carry out highly effective, opaque and unaccountable campaigns of persuasion and social engineering in political, civic and commercial spheres. I examine six intertwined dynamics that pertain to the rise of computational politics: the rise of big data, the shift away from demographics to individualized targeting, the opacity and power of computational modeling, the use of persuasive behavioral science, digital media enabling dynamic real-time experimentation, and the growth of new power brokers who own the data or social media environments. I then examine the consequences of these new mechanisms on the public sphere and political campaigns.","",""
"2014","In the realm of Big Data ...","In 2008, Chris Anderson (2008), at that time the Editor–in–Chief of Wired, proposed that in the age of the petabyte, there was no longer any need for the scientific method, nor for models or theories. Although it might be contended that this was more provocation and journalistic hubris than formal or substantiated claim, the issue was taken up and has gathered momentum ever since. Indeed within a year or so of Anderson’s article, and a series of rejoinders published on the Edge Web site, ‘The Age of Big Data’ was being heralded, and the measure had increased from petabytes to exabytes, zettabytes, and yottabytes. Diebold (2012) usefully distinguishes between Big Data ‘the phenomenon’, ‘the term’, and ‘the discipline’; arguing that the phenomenon ‘continues unabated’, the term is ‘firmly entrenched’, and the discipline is ‘emerging’. In what follows we focus initially on the term and the phenomenon, but our main objective is to argue that it is critical that there is general understanding of the emerging discipline. In particular we aim to justify the assertion that in the age of Big Data the ability to be able to develop abstractions and concepts is at least as important as it was previously; perhaps even more so. Moreover that these skills and techniques need to be understood and available to all of us in an era where we are all analysts and researchers at least to the extent of our use of the internet and its potential for affording search and investigation of online resources. We seek to offer some critical insights into these activities — modeling, conceptualizing, and theorizing — by comparing and contrasting Knowledge Discovery from Data (KDD) with the Grounded Theory Method (GTM). The former a technical orientation, that although predating Big Data, lies at the heart of the emerging tools and techniques. The latter a widely used approach to qualitative research aimed at developing conceptual models ‘grounded in the data’.","",""
"2014","Active players in a network tell the story: Parsimony in modeling huge networks","One of the methodological and logistic problems of network research is the challenge of big data. Dynamics and network qualities are not as easy to extrapolate as averages and distributions. The numbers are huge, and traditional sampling doesn’t solve the problem. What if, by using a small sub–group of the members of a population, we could understand the nature of the network connecting them? For instance, what if we could draw network analysis conclusions, such as predicting the outbreak and evolution of an epidemic, without measuring the entire network of individuals? Christakis and Fowler (2010, cited in Wilson, 2010) found a unique group of users that could predict an epidemic days before its peak in the relevant population.This study continues their work. Instead of exploring millions of online social activities, we suggest investigating the active users (as we define them) in their community and using their activity logs to build a partial network. This network of intensive users can depict the dynamics of a huge social network, in our case Yahoo! Answers intensive activities.Barabási, et al. (2002) explored the connection between topology and network size on real–life networks. Twelve years later, our online Q&amp;A social network study reached the same findings and conclusion: the partial network has several basic topological parameters that correlate with activity parameters of the entire social network and, hence, make it suitable for depicting the dynamic parameters of the huge network.Since exploring online social lives is so interesting and time consuming, we believe that our findings can help the investigation of huge social networks. We call for further investigation of these findings and their implications.","",""
"2015","Spreadsheets and the Violence of Forms: Tracking Organisational and Domestic Use","  IntroductionWith its capacity for modelling and “what if” logic, the spreadsheet operates as a media of beginnings and possible futures. It has proved indispensable in organisational life and labour, its failures the stuff of enduring legend about the Global Financial Crisis and the excesses of Wall Street. Indeed, the “European Spreadsheet Risk Interest Group” maintains an archive devoted to cataloguing public “horror stories” of legal actions, business failure and government enquiries due to errors in spreadsheet calculations (EuSpRIG Horror Stories). One such tale of spectacular failure occurred in 2012 when a coding error was revealed in a spreadsheet formulae used by economists Kenneth Rogoff and Carmen Reinhart to argue for the implementation of harsh austerity measures following the GFC. The spreadsheet purported to demonstrate that when debt levels exceed 90% of the size of GDP then national economies cease to grow, thereby justifying the reduction of public infrastructure and services. To substantiate the argument the data mapped worldwide national levels of debt for the period 1945-2009. However, the authors mistakenly omitted key countries from their spreadsheet – those from the start of the alphabet namely Australia, Austria, Belgium, Canada and Denmark. When these countries were included, the data showed economies can actually grow despite high levels of public spending (Yglesias). As Mike Konczal explains, the “core empirical points providing the intellectual foundation for the global move to austerity in the early 2010s was based on someone accidentally not updating a row formula in Excel”.In this paper I track the history and affect of spreadsheet use across organisational and domestic settings. Expanding upon the insights of Lisa Gitelman, JoAnne Yates and Ben Kafka, who focus on paperwork’s materialities to excavate the labour of bureaucratic media, I report on the early findings of a project exploring the role of the spreadsheet in everyday life. One of the interesting threads I pursue is how the spreadsheet becomes imbricated in the contours and vicissitudes of the home managing and recording its daily practices. Although spreadsheet applications have been extensively studied in business and engineering literatures there has been scant attention paid in the fields of cultural studies, media or, surprisingly, software studies and media archaeology. In the journal Computational Culture where one expects to see finely grained analyses of the algorithms and design decisions underpinning the spreadsheet it has not turned out to be a major concern. This isn’t to say that spreadsheets are omitted from discussions exploring the materiality of digital culture particularly from those interested in institutional life and “evil media” (Fuller and Goffey) but these are often references in passing to broader arguments. As this paper shows, the pervasive nature of spreadsheet use often eclipses its central role in our lives. In order to counter its ubiquity, to make visible its cultural impact, we need to focus on the material conditions from which it emerges and the specificities which shape its use. So I begin with a brief history of the spreadsheet format framed by legal questions of intellectual property and the ways in which these regimes enable its distribution. We then see how it operates to manage risk in relation to personal data management and the Quantified Self both in the organisation and at home. Cutting across these various sites and practices is an interest in how the spreadsheet acts “violently”, how its banality and familiarity belie its ability to generate affective intensities and real material impact. What does it mean to talk of the violence of forms? By this phrase I want to bring to the surface the ways in which forms and other administrative media operate as tools of governance. The spreadsheet in particular extends Yates’s argument in Control through Communication that the history of organisational paperwork is a story of disciplinary systems inaugurated by the circulation of internal documentation. In the early 20th-century workplace, memos, forms, tables, and circulars emerged to produce new hierarchies of managerial control through the downward communication of rules and procedures and the upward flow of reports. Recording and regulating labour, this often overlooked category of communication was instrumental in the move to quantify and monitor people’s activities at work (Yates). With properties of tabulation and calculation the spreadsheet operates discursively, it constrains emotions and bodies in particular ways. Spreadsheet HistoryThe precise beginnings of the spreadsheet program are difficult to pinpoint. Of relevance here is the distinction between spreadsheets on mainframe, timesharing computers of the 1960s to 1970s and the software developed for the Personal Computer (PC) since the 1980s. Is there a direct lineage stretching from the computerised accounting programs designed by Richard Mattessich to the VisiCalc program written by Dan Bricklin and Bob Frankston in 1979? Reacting to such a chronology, Frankston states that “Mattessich is creating his own myth” elaborating that he “completely misses the point”: I don't begrudge him his work in accounting in the 60's [sic] but it had not the slightest influence on VisiCalc. It was one of many online financial programs. I worked on some systems while at Interactive Data in the 60's and 70's. But VisiCalc was not an accounting program at all, it just made it possible for people to do accounting.This distaste for accounting is echoed by Frankston’s co-creator Dan Bricklin who explains the original name for the program, “Calcu-ledger” was rejected because it carried too many connotations of bookkeeping (Bricklin, Dan Bricklin's Web Site). Instead, VisiCal, short for Visual Calculator, speaks to its genesis in a Harvard lecture theatre where sitting as a student, Bricklin imagined “if only we had a blackboard” on which one “could erase a number and write a new number in, and everything would recalculate” (Bricklin, """"How""""). VisiCalc is widely thought to have been the first “killer app” in that it enabled the extensive commercial success of Apple II. Questions of law play a significant role for understanding the history and use of spreadsheet programs. One of the early mainframe based software systems LANPAR (LANguage for Programming Arrays at Random) was unsuccessful in its original application for patent approval when lodged in 1970. Its developers, Rene Pardo and Remy Landau, faced twelve years of appeals before it was granted in a landmark case of 1983 only to be reversed in 1995 (Power). Also billed as the first electronic spreadsheet by its authors, LANPAR invented the “Forward Referencing &amp; Natural Order Recalculation” algorithm. Unlike the earlier programs or some that would follow such as VisiCal, this feature allowed spreadsheet cells to automatically recalculate rather than rely on manual refresh. In other words, the program would use a “topological sort” to calculate values of spreadsheet cells that were dependent on other cells for their totals. During this period LANPAR spreadsheet software was licensed for use by a number of large companies including Bell Canada, AT&amp;T and General Motors (Pardo). Patent law does not generally protect mathematical calculations. Since an algorithm is a set of instructions rather than a tangible invention it doesn’t meet a crucial principle of patent law that protects creations which perform specific functions. As many commentators have noted, software occupies a curious border position: while the code is simply a string a numbers it is also executable, a process that produces or invents. Software is not included within the US patent legislation and case law since the 1960s has seen intense commercial and cultural clashes unfold over what patentability means. Title 35 of the US Code grants patents to: “whoever invents or discovers any new and useful process, machine, manufacture, or composition of matter, or any new and useful improvement” (USC 35). The test for patentability requires that the invention must be “novel” and “non obvious”, that is a patent won’t be granted if the product or process is already available to the public nor if its use is obvious to anyone with an “ordinary skill” in the area to which the patent pertains. Rights were exercised for computer software through other measures of intellectual property such as copyright and trademark but in the early days of software development when Pardo and Landau wanted to register their program, code was considered un-patentable. A series of decisions by the US Supreme Court during the 1980s, known as the “Patent-Eligibility Trilogy cases”, established that a software patent claim could not be dismissed “simply because it uses a mathematical formula, computer program, or digital computer” (Place). These precedents granted their patent for “Process and apparatus for converting a source program into an object program” (Pardo et al.). Sadly, their luck did not hold out. Armed with a newly minted patent, Pardo and Landau instigated an unsuccessful law suit for patent infringement in 1989 against Lotus and Microsoft who had themselves by now developed spreadsheet software. Lotus 123 was created by Mitch Kapor and Jonathan Sachs and released in January 1983 to operate on the IBM PC, its key innovations being the introduction of macros, graphical charts and database capabilities. As the program VisiCalc had achieved with Apple II, Lotus 123 dramatically increased sales of the IBM and is one of the first software programs to run a television advertising campaign (Barker). Lotus overtook spreadsheet sales of VisiCalc who were generating $12m annually, and recorded $53 million in the first year of the program launch, ensuring it dominated the spreadsheet market through the 1980s. Although Microsoft had a spreadsheet program called Multiplan, it was Excel released for Mac in 1985 and for Windows in 1987 that outsold Lotus 123 maintaining market share throughout the 1990s and 2000s (Clarke). Running in the background as a counterpoint to this success is the court battle of Pardo and Landau. In a sense the authors of the LANPAR program were caught up in a broader legal stoush of the time as their patent claim bounced between two opposing statutory bodies who could not agree about the scope of software patentability. Routinely, applications were rejected by the US Patent and Trade Mark Office (USPTO) and then reversed and granted by the United States Court of Customs and Patent Appeals (USCCPA) (Magri and Ellul). At stake for Pardo and Landau was whether they could prove their invention was patentable and further that they met the statutory test for “non-obviousness”. Rejecting their initial patent claim the USPTO found that being an algorithm disqualified it from protection: The courts above us have consistently said that a claim directed in its entirety to an algorithm is nonstatutory. An algorithm is defined ... as a procedure for solving a given type of mathematical problem. (In re Pardo)The USPTO then dismissed a subsequent application by Pardo and Landau on the basis that the invention would be obvious to anyone skilled in the area facing the same problem the LANPAR software solved. After years of litigation, the patent was finally granted by the USCCPA who reversed the original rejection citing recent decisions, mentioned above, making algorithms patentable. These matters weren’t in direct contention in the $300 million law suit that Pardo and Landau filed against Lotus and Microsoft. Instead they lost due to inequitable conduct. Unfortunately it was shown these developers had misled the original patent office, failing to disclose their business relationships with witnesses whose testimony they used to argue that Lotus infringed their patent. In losing the case the patent was found unenforceable (Chisum). Debates about the definition and scope of software patents continue apace. Fears about its expansion and the prevalence of non-practicing entities, or “patent trolls” coalesced in the recent US Supreme Court case Alice Corp. v. CLS Bank International which considered software patent eligibility, one of the first to do so since the “Patent-Eligibility Trilogies” three decades earlier. Although critics of the decision, denying the patent, argued the judgement should have gone further in guidance on computer patents, many endorsed its continued limits to algorithm patentability (Free Software Foundation). Reading spreadsheet history through these legal frames reveals the complex material, social and economic meshwork (Ingold) in which software applications emerge. I now explore the consumption practices and ecologies of spreadsheet use across organisational and domestic contexts to make visible the ways in which this bureaucratic media plays out in our everyday lives. Spreadsheet Risk in the Organisation Managing risk is a central narrative in contemporary culture for financial markets, commercial organisations and government institutions. Our world seems constantly threatened by ecological, military and informational crises; our personal lives facing pervasive emotional and medical danger (Van Loon). Operating within and often constitutive of these discursive and material fields, the spreadsheet anticipates risk through its algorithmic capacity for modelling and forecasting but it also instantiates that risk with its high propensity for error. This double logic is what gives the spreadsheet its urgency as a unit of analysis through which to understand organisational conditions of labour and regulation. Recognising the crucial social and economic function played by spreadsheets, the European Spreadsheet Risks Interest Group (EuSpRIG) formed in 1999 as a collaboration between university researchers, professional associations and industry practitioners in order to “address the ever-increasing problem of spreadsheet integrity” (History). Error detection, regulation and resolution are notoriously difficult to achieve in spreadsheet research. One of the leading reports shows that spreadsheet errors are “pandemic” since 88% of spreadsheets examined contained miscalculations. A study conducted by Coopers and Lybrand revealed that 91% of spreadsheets are in error with a similar figure appearing in the audit run by KMPG (Panko). It is estimated that 1% - 5% of cell formulae contain errors (Gabbay). Spreadsheet risk is difficult to mitigate because of the lack of definition (categories applied vary from typing errors to incorrect cell formula); differences in error detection software used; and disparity in samples (spreadsheets tested in the laboratory as against those operational in the field) (Powell, Baker and Lawson). These inaccuracies have material implications when understood in relation to the prevalence of spreadsheets to fulfil corporate auditing obligations. As Panko argues, 95% of US firms rely on spreadsheets for their financial reporting methods. Spreadsheet error, risk and misuse had a direct impact on the collapse of the global financial system in 2008 (Croll). Spreadsheets rarely operate in isolation. One study reports that only 12% of use in businesses is limited to a single person with 48% routinely sharing with others (Baker et al.). Since few people password protect these documents, cumulative revision is common. In fact, spreadsheet design predominantly occurs in ad hoc ways: an unofficial or beta version then becomes “part of an established business process” (Baker et al.). A vivid illustration is provided by the California Amplifier Company who was found guilty of fraud by the US Securities and Exchange Commission (SEC) in 2004. The financial director of the company Barry Kusatzky “hid at least $7.8 million in expenses by fabricating financial statements, falsifying the company's books and records.” The SEC found that his “fraud went undetected because of the company's lack of adequate internal controls” since the financial statements of California Amplifier were “generated from a spreadsheet maintained by Kusatzky on his own desktop computer” kept “wholly separate from the company's accounting system” (SEC). Before Kusatzky, however, there was Enron. Here we see the violence of forms enacted as corporate malfeasance when nearly a quarter of its workforce, some 4,000 people, lost their jobs and life savings in the company’s spectacular collapse. The downfall of Enron, how it became synonymous with corporate corruption, was driven by a byzantine spreadsheet reporting system that gave an inaccurate picture of capital and risk by understating its liabilities and overstating its equity and earnings (Moncarz et al.).What this shows is that the spreadsheet, along with third party applications such as Dropbox and Gmail, form a vast network of shadow IT within organisations. In response to the complexity of financial disclosure and a slew of high profile fraud cases, the Sarbannes-Oxley Act was introduced into US law in 2002 with Section 404 “Management Assessment of Internal Controls” requiring publically listed corporations to reveal their monitoring procedures. Established to implement the Act, the Public Company Accounting Oversight Board (PCAOB) sets out standards including how risk is audited, the consistency of financial statements and the controls for independent assessment (PCAOB). Since the law was enacted hundreds of guidelines have been produced to achieve compliance. Providing such guidance, PricewaterhouseCoopers recommends business run an inventory of all spreadsheets to record file name, description, author and the “frequency and extent of changes to the spreadsheet”. Developing robust policies to guard against financial mismanagement is to be applauded. But such recommendations miss a key point about the ways in which grey literature and informal economies operate (Lobato and Thomas). With particular reference to the function of shadow IT systems, organisations may well decry their popularity through terms of use policies but undeniably many rely substantially on this media. In other words, spreadsheet “risk” viewed through the lens of management policies ignores the micro practices in everyday work cultures to which we now turn.Spreadsheets and the Quantified SelfRecent scholarship has pointed to the ways in which self-tracking, personal data management and the “quantified self” reconfigure bio-politics opening up new forms of agency while also widening the reach of surveillance devices (Daly; Jethani; Lupton). Wearable technology, locative media and a rapidly expanding constellation of applications and software – such as Fitbit and Evernote – underpin the auditing and archiving of personal consumption, activity and location. At the same time, burgeoning algorithmic cultures and technologies are also finding valency in the workplace where productivity is increasingly measured and evaluated (Chong; Gregg; McCosker and Milne). Forming a significant node in the media ecology of personal data analytics, the spreadsheet has, again, been somewhat ignored. Yet it plays a crucial role in the governance of self as it regulates and records bodily health and illness. In the final section of this paper I explore the personal and social uses to which the spreadsheet is put for recording and sharing the practices of daily life. Alongside new and emerging applications, the spreadsheet is used extensively by the Quantified Self movement (QS), a community founded by Gary Wolf and Kevin Kelly in 2007 to provide “self knowledge through numbers” (Kelly). Its popularity is in part because so many tracking applications make it easy to export information in a spreadsheet or as a CSV file. Katie McCurdy, for example, identifies the spreadsheet as her favourite self-tracking software explaining how she has been recording her health data for three years in an effort to manage her autoimmune disease. In this spreadsheet she registers symptoms, triggers and medications, making the information available through the website and presentations at the “QS Meet up Groups” (Ramirez). For Greg Kroleski, spreadsheets are a resonant method for representing longitudinal evidence of personal life. Registering his time over a six year period, he tabulates it into eight categories: “Survival, Labor, Spirit, Mind, Expression, Body, Social, Distractions and Transport”, uploading the spreadsheet as a Google doc and requesting comment (Ramirez). And in his book Experience Curating How to Gain Focus, Increase Influence, and Simplify Your Life Joel Zaslofsky is messianic in his praise of spreadsheets to “outsource memory”. As he explains, “everything that you experience from books to blog posts, to conversations to recipes … any experience you have can be curated.” Not only can it be recorded for personal retrieval purposes, the spreadsheet also grows your “curating currency” converting your experiences into “social, financial, spiritual and intellectual capital.” Interestingly, while endorsing the monetisation of “experience curating” Zaslofsky distances himself from the QS movement which he argues demands too much labour in capturing data rather than living life. Instead, his method requires only 0.1% of a person’s time to achieve (Zaslofsky). Discussions such as these are part of extensive narratives about human memory and its socio material support (Barnet; van Dijck) together with wider debates about the institutional processes of digital heritage policy development. These conversations also feed into research about Personal Information Management which examines the software and devices we encounter and must negotiate in our professional and domestic spaces. The lessons of paper, its ‘affordances’ (Sellen and Harper) seem particularly important here as office filing systems expand to incorporate ever increasing stacks of digital and physical data. In one study, modes of caching and retrieval across the “tree structure” of Windows were compared with those deployed as “filing and piling” using cabinets and desks to illuminate the different organisational strategies in play (Trullemans and Beat). The findings point to an increasing reliance on meta systems, such as spreadsheets or proprietary apps like Mendeley, to consolidate and retrieve information stored across a range of geographically dispersed analogue and digital locations. Is a particular book or document to be found at home or in the office? Such results chime with the initial findings from a research project exploring the role that media – social, technical, personal, broadcast—plays in home renovation and building practices. The study, funded by university and industry bodies through the Australian Cooperative Research Centre for Low Carbon Living aims to map the media ecologies through which people gather information about sustainable modes of renovation and, crucially, how these sites are shared and accessed (Hulse and Podkalicka). While we know something of the way media, in the form of lifestyle and property TV, contributes to the meanings people ascribe to their domestic space (Ouellette and Hay; McElroy; Andrews; Weber), work has not yet drilled down to the material specificities of consumption. In response, this project, with which I am involved, is running a national survey of home renovators to canvas such topics as how media helps to find and engage building practitioners, what media is accessed to plan a renovation; what sites are used to spark inspiration and ideas; and what media is used to document, record and share progress of the renovation project. In this latter category, we have been interested to see how high spreadsheets rank – second only to photographs – as the media of choice for recording renovations. Other methods reported in the survey include sketches, videos and blogs. Although evidence scraped from a variety of renovation forums and websites indicates unsurprisingly that spreadsheets are regularly relied upon for budget purposes in builds and renovations, what is still to be explored and suggestive from our study is how these functions might be complemented by other more novel uses. ConclusionAs a ubiquitous media product, the spreadsheet contours our everyday practices of work and home. It registers our financial dreams, charts our bodily experiences and records the hours we work yet this very ubiquity can often hide it from critical sight. In this paper I have sought to bring to the foreground the many ways that the spreadsheet materially impacts on patterns of digital consumption by exploring its beginnings and historical development and by showing how the program itself functions to model social and economic futures. Particularly in relation to risk management I argued that the spreadsheet operates according to a double logic. While its software makes forecasting and prediction easy it can actually bring about disastrous consequences due to its high incidence of error. Tales abound of “cut and paste” mistakes that enable fraud and deceptive business practices causing widespread financial violence and harm. Yet such incidents must be seen within the context of shadow IT economies used by the very same organisations that would censure others for incorrect spreadsheet usage. If its affective reach is felt across global financial markets, it also figures at the intimate, domestic level as the spreadsheet is used for self-tracking strategies to capture personal data about health and the spaces we inhabit. Stitching together diverse sites of labour and leisure, bureaucracy and home, the spreadsheet has been a vital expression of social and economic life for decades. What then accounts for its relative invisibility in media and cultural studies? Part of the problem is that the spreadsheet, like email, is at once indispensable and reviled, its banality obscuring its significance as an object of study and the irritations it provokes easily dismissed as the inevitable, routine experiences of a bureaucratic life. In this capacity for generating affect and material impacts, however, the incomprehensible form, the annoying “reply all” office email and the impossible to navigate spreadsheet demand attention. Acknowledgments I thank the two anonymous referees for their very helpful feedback.ReferencesAndrews, Maggie. Domesticating the Airwaves: Broadcasting, Domesticity and Femininity. London: Continuum, 2012.Baker, Kenneth, Lynn Foster-Johnson, Barry Lawson, and Stephen G. Powell. “A Survey of MBA Spreadsheet Users.” Spreadsheet Engineering Research Project. Tuck School of Business. 2006. 9 Aug. 2015 ‹http://faculty.tuck.dartmouth.edu/images/uploads/faculty/serp/survey_paper.pdf›.Barker, Colin. “So Farewell Then Lotus 1-2-3, Spreadsheet Extraordinaire.” ZDNet 2 Oct. 2014. 9 Aug. 2015 ‹http://www.zdnet.com/article/so-farewell-then-lotus-1-2-3-spreadsheet-extraordinaire/›.Barnet, Belinda. Memory Machines: The Evolution of Hypertext. London: Anthem Press, 2013.Bricklin, Dan. Dan Bricklin's Web Site 9 Sep. 2014. 15 May 2015 ‹http://www.bricklin.com/history/saiidea.htm›.———. “How the Electronic Spreadsheet Revolutionized Business.” Interview with Robert Siegel. NPR Planet Money 27 Feb. 2015. 15 May 2015 ‹http://www.npr.org/2015/02/27/389585340/how-the-electronic-spreadsheet-revolutionized-business›.Chisum, Donald. “Best Mode Concealment and Inequitable Conduct in Patent Procurement.” Santa Clara High Technology Law Journal 13.2 (1997): 277–319.Chong, Ming Ki, Jon Whittle, Umar Rashid, Chee Siang Ang, Rebecca Whiting, Helen Roby, Petros Chamakiotis, and Gillian Symon. “Methods for Monitoring Work-Life Balance in a Digital World.” Socio-Technical Practices and Work-Home Boundaries. Toronto: ACM, 23 Sep. 2014. 15 May 2015 ‹http://www.drjonbird.e-vps.net/workhomeboundaries/papers/Chong.pdf›.Clarke, Gavin. “Lotus 1-2-3 Turns 30: Mitch Kapor on the Google before Google.” The Register 26 Jan. 2013. 15 May 2015 ‹http://www.theregister.co.uk/2013/01/26/mitch_kapor_lotus_123_anniversary/›.Croll, Grenville. “Spreadsheets and the Financial Collapse.” Proceedings of the European Spreadsheet Risks Interest Group (2009): 145-161. ‹http://arxiv.org/ftp/arxiv/papers/0908/0908.4420.pdf›.Daly, Angela. “The Law and Ethics of 'Self Quantified' Health Information: An Australian Perspective.” International Data Privacy Law 5(2) (2015):144-155. European Spreadsheet Risks Interest Group (EuSpRIG). “Horror Stories.” 15 May 2015 ‹http://www.eusprig.org/horror-stories.htm›.———. “History.” ‹http://www.eusprig.org/history.htm›.Frankston, Bob. “RE: VisiCalc History.” Message to Daniel Power. Email. 15 Apr. 1999. 15 May 2015 ‹http://dssresources.com/history/frankston4151999a.html›.Free Software Foundation. “US Supreme Court Makes the Right Decision to Nix Alice Corp. Patent, But More Work Needed to End Software Patents for Good.” 19 June 2014. 15 May 2015 ‹https://www.fsf.org/news/fsf-statement-on-alice-corp-v-cls-bank›.Fuller, Matthew, and Andrew Goffey. Evil Media. Cambridge: MIT Press, 2012.Gabbay Nir. “Controlling Critical Spreadsheets.” Proceedings of the 6th Israel Association for Information Systems (ILAIS) Conference. Haifa: University of Haifa, 2 July 2012. Eds. Daphne Raban, David Bodoff, and Irit Hadar. Sagy Center for Internet Research.Gitelman, Lisa. Paper Knowledge: Toward a Media History of Documents. Durham: Duke, 2014.Gregg, Melissa. Work's Intimacy. Cambridge: Polity, 2011.Hulse, Kath, Aneta Podkalicka, Esther Milne, Gavin Melles, Tomi Winfree, Shae Hunter and Aggeliki Aggeli. “Media and Communication Strategies to Achieve Carbon Reduction through Renovation of Australia’s Existing Housing.” Low Carbon Living CRC. 9 Aug. 2015. ‹http://www.lowcarbonlivingcrc.com.au/research/program-3-engaged-communities/rp3021-media-and-communication-strategies-achieve-carbon›.Ingold, Tim. Being Alive: Essays on Movement, Knowledge and Description. New York: Routledge, 2011.In re Pardo and Remy Landau. Appeal No 81-619. United States Court of Customs and Patent Appeals (USCCPA), 5 Aug. 1982.Jethani, Suneel. “Mediating the Body: Technology, Politics and Epistemologies of Self.” Communication, Politics &amp; Culture 47 (2015): 34-43.Kafka, Ben. The Demon of Writing: Powers and Failures of Paperwork. New York: Zone Books, 2012.Kelly, Kevin. “What Is the Quantified Self?” Quantified Self, 5 Oct. 2007. ‹http://quantifiedself.com/2007/page/3/›.Konczal, Mike. “Researchers Finally Replicated Reinhart-Rogoff, and There Are Serious Problems.” Next New Deal, Blog of the Roosevelt Institute, 16 Apr. 2013. 4 Oct. 2015 ‹http://www.nextnewdeal.net/rortybomb/researchers-finally-replicated-reinhart-rogoff-and-there-are-serious-problems#.UW14rDQo2L4.twitter›.Lobato, Ramon, and Julian Thomas. The Informal Media Economy. Cambridge: Polity, 2015.Lupton, Deborah. “Self-Tracking Modes: Reflexive Self-Monitoring and Data Practices.” Social Science Research Network, 19 Aug. 2014. 15 May 2015 ‹http://ssrn.com/abstract=2483549›.Magri, Rochelle, and Tonio Ellul. “Malta: Patenting and Copyright of Software - with Particular Reference to Maltese Law, EU Law and US Law.” Mondaq Business Briefing 9 Aug. 2011. ‹http://www.mondaq.com/x/141936/IT+Internet/Patenting+And+Copyright+Of+Software+With+Particular+Reference+To+Maltese+Law+EU+Law+And+US+Law›.McCosker, Anthony, and Esther Milne. “Coding Labour.” Cultural Studies Review 20.1 (2014): 4-29.McElroy Ruth. “Property TV: The (Re)making of Home on National Screens.” European Journal of Cultural Studies 11.1 (2008): 43-61.Moncarz, Elisa S., Raul Moncarz, Alejandra Cabello, and Benjamin Moncarz. “The Rise and Collapse of Enron: Financial Innovation, Errors and Lessons.” Accounting and Administration 218 (2006). 5 May 2015 ‹http://www.redalyc.org/pdf/395/39521802.pdf›.Ouellette, Laurie, and James Hay. Better Living through Reality TV: Television and Post-Welfare Citizenship. Malden: Blackwell, 2008.Panko, Raymond. “What We Know about Spreadsheet Errors.” Journal of End User Computing 10.2 (1998): 15-21.Pardo, Rene. “Personal Homepage.” n.d. ‹http://www.renepardo.com/›.Pardo et al., assignee. “Process and Apparatus for Converting a Source Program into an Object Program.” Patent 4,398,249. 9 Aug. 1983.Place, Anthony. “The Evolution of Patenting Software.” James Cook University Law Review 12 (2005): 11–32.Powell, Stephen, Kenneth Baker, and Barry Lawson. “Errors in Operational Spreadsheets.” Journal of Organizational and End User Computing 21.3 (2009): 24-36. Power, Daniel. “A Brief History of Spreadsheets.” 30 Aug. 2004. 15 May 2015 ‹http://www.dssresources.com/history/sshistory.html›. PricewaterhouseCoopers. “The Use of Spreadsheets: Considerations for Section 404 of the Sarbanes-Oxley Act.” July 2004. ‹http://www.spreadsheetdetective.com/main/PwC-SpreadsheetsSoX.pdf›.Public Company Accounting Oversight Board (PCAOB). “Auditing Standard No. 5: An Audit of Internal Control over Financial Reporting That Is Integrated with an Audit of Financial Statements.” 15 Nov. 2007. 15 May 2015 ‹http://pcaobus.org/Standards/Auditing/Pages/Auditing_Standard_5.aspx›.Ramirez, Ernesto. “QS15 Conference Preview: Katie McCurdy on Symptom Tracking with Spreadsheets.”Quantified Self. 6 May 2015. 15 May 2015 ‹http://quantifiedself.com/2015/05/qs15-conference-preview-katie-mccurdy/›.Ramirez, Ernesto. “Greg Kroleski: Six Years of Tracking My Time.” Quantified Self. 27 Feb. 2015. 15 May 2015 ‹http://quantifiedself.com/2015/02/greg-kroleski-six-years-tracking-time/›.Rogoff, Kenneth, and Carmen Reinhart. “Growth in the Time of Debt.” Cambridge MA: National Bureau of Economic Research, Jan. 2010. 15 May 2015 ‹http://www.nber.org/papers/w15639›. Securities and Exchange Commission v Barry Richard Kusatzky. Civil Action No. 1:04CV00700 (JGP) (D.D.C.) 28 Apr. 2004. 15 May 2015 ‹https://www.sec.gov/litigation/admin/34-49630.htm›.Sellen, Abigail, and Richard Harper. The Myth of the Paperless Office. Cambridge: MIT Press, 2002.Trullemans, Sandra, and Beat Signer. “From User Needs to Opportunities in Personal Information Management: A Case Study on Organisational Strategies in Cross-Media Information Spaces.” IEEE/ACM Joint Conference on Digital Libraries (2014): 87-96.United States Code (USC). Title 35. Part II. Chapter 10 › § 101, “Inventions Patentable.” Legal Information Institute, Cornell University. ‹https://www.law.cornell.edu/uscode/text/35/101›. Van Dijck, José. Mediated Memories in the Digital Age. Stanford: Stanford University Press, 2007.Van Loon, Joost. Risk and Technological Culture: Towards a Sociology of Virulence. London: Routledge, 2002. Weber, Brenda. Makeover TV Selfhood, Citizenship, and Celebrity. Durham: Duke University Press, 2009.Yates, JoAnne. Control through Communication: The Rise of System in American Management. Baltimore: Johns Hopkins University Press, 1989.Yglesias, Matthew. “Is the Reinhart-Rogoff Result Based on a Simple Spreadsheet Error?” Slate Money Box 16 Apr. 2013. 15 May 2015 ‹http://www.slate.com/blogs/moneybox/2013/04/16/reinhart_rogoff_coding_error_austerity_policies_founded_on_bad_coding.html›.Zaslofsky, Joel. “Outsource Your Memory &amp; Curate Your Life with Joel Zaslofsky.” Interview with Roderick Russell.  Remarkably Human Radio. n.d. 15 May 2015 ‹http://remarkablyhuman.com/outsource-memory-curate-life-joel-zaslofsky›.  ","",""
"2015","Bigger sociological imaginations: framing big social data theory and methods","Making effective use of big social data requires us to frame that work in useful ways, ways that draw connections between new methods and a long history of social methods and theories. In particular, the key questions of big social data – those of relating observations of features at scale to practical outcomes for individuals and groups – are core sociological questions. We need to develop a new, bigger sociological imagination that allows us to incorporate big social data rather than reinventing the wheel. That requires careful mining of our methodological and theoretical history, along with a reexamination of the ways in which we collect and use our data.","",""
"2015","The Contexts of Control: Information, Power, and Truck-Driving Work","This article examines the implications of electronic monitoring systems for organizational information flows and worker control, in the context of the U.S. trucking industry. Truckers, a spatially dispersed group of workers with a traditionally independent culture and a high degree of autonomy, are increasingly subjected to performance monitoring via fleet management systems that record and transmit fine-grained data about their location and behaviors. These systems redistribute operational information within firms by accruing real-time aggregated data in a remote company dispatcher. This redistribution results in a seemingly incongruous set of effects. First, abstracted and aggregated data streams allow dispatchers to quantitatively evaluate truckers’ job performance across new metrics, and to challenge truckers’ accounts of local and biophysical conditions. Second, even as these data are abstracted, information about truckers’ activities is simultaneously resocialized via its strategic deployment into truckers’ social relationships with their coworkers and families. These disparate dynamics operate together to facilitate firms’ control over truckers’ daily work practices in a manner that was not previously possible. The trucking case reveals multifaceted pathways to the entrenchment of organizational control via electronic monitoring.","",""
"2015","Reflections on Big Data: ‘Just because it is accessible does not make it ethical’"," Drawing from observations in China and from world history, this is a reflection on boyd and Crawford’s provocation on social problems related to Big Data, especially ‘Just because it is accessible does not make it ethnical’. ","",""
"2015","Debating Big Data","‘Big Data’ has become a flashpoint in conversations in a range of disciplines across the humanities and social sciences. As advances in computational methods expand the terrain of the measurable, the identifiable, and the knowable, they also raise thorny questions around the politics and ethics of academic research. In an era marked by the thoroughgoing digitalization of virtually every domain of our lives, changes in how information about human behavior is gathered, circulated, and made sense of both unsettles and reinforces existing power dynamics. This Special Crosscurrents Issue aims to spark a debate on ‘Big Data’ from the disciplinary location of ‘media and communication studies’ and more specifically, the emergent field of digital media studies. Our starting point is danah boyd and Kate Crawford’s (2011) important article, ‘Critical questions for Big Data’, in which they reflect on ‘what all this data means, who gets access to what data, how data analysis is deployed, and to what ends’ (p. 3). We asked our contributors to draw on their own research on different aspects of digital and global media as a way to respond to one of more of the issues that boyd and Crawford identified – the definition of knowledge, claims to objectivity and accuracy, context and meaning-making, access to data, and ethics and accountability. Moving well beyond the domain of social media, this collection of essays shows that the story of Big Data is part of a long-standing debate about methods and approach in","",""
"2015","The nice thing about context is that everyone has it"," In their ‘Critical Questions for Big Data’, danah boyd and Kate Crawford warn: ‘Taken out of context, Big Data loses its meaning’. In this short commentary, I contextualize this claim about context. The idea that context is crucial to meaning is shared across a wide range of disciplines, including the field of ‘context-aware’ recommender systems. These personalization systems attempt to take a user’s context into account in order to make better, more useful, more meaningful recommendations. How are we to square boyd and Crawford’s warning with the growth of big data applications that are centrally concerned with something they call ‘context’? I suggest that the importance of context is uncontroversial; the controversy lies in determining what context is. Drawing on the work of cultural and linguistic anthropologists, I argue that context is constructed by the methods used to apprehend it. For the developers of ‘context-aware’ recommender systems, context is typically operationalized as a set of sensor readings associated with a user’s activity. For critics like boyd and Crawford, context is that unquantified remainder that haunts mathematical models, making numbers that appear to be identical actually different from each other. These understandings of context seem to be incompatible, and their variability points to the importance of identifying and studying ‘context cultures’–ways of producing context that vary in goals and techniques, but which agree that context is key to data’s significance. To do otherwise would be to take these contextualizations out of context. ","",""
"2015","Big data interfaces and the problem of inclusion"," A commentary on ‘Critical Questions for Big Data’ and the projection in the article of how ‘limited access to big data creates new digital divides’. Pressing questions are indeed proliferating around not only what the actual relationship is between data and real world user behavior but also around defining what the very practices, knowledge sets, legal and technological infrastructures, and social norms are that guide the work of big data as a field itself. But how much of a difference does it make for academics and academic institutions to gain access to big data when the logics of commerce and commercial enclosure around data management, collection, and use are what increasingly get privileged? ","",""
"2015","Deconstructing the cloud: Responses to Big Data phenomena from social sciences, humanities and the arts"," The era of Big Data comes with the omnipresent metaphor of the Cloud, a term suggesting an ephemeral and seemingly endless storage space, unhindered by time and place. Similar to the satellite image of the Whole Earth, which was the icon of technological progress in the late 60s, the Cloud as a metaphor breathes the promise of technology, whilst obfuscating the hardware reality of server farms and software infrastructure necessary to enable the proliferation of (big) data. This article presents projects from the fields of humanities, social sciences and the arts that formulate a response to Big Data and its human and automated practices, from data analytics dashboards to critical reflections on smart technologies and objects. ","",""
"2015","Scaling down"," While “scaling up” is a lively topic in network science and Big Data analysis today, my purpose in this essay is to articulate an alternative problem, that of “scaling down,” which I believe will also require increased attention in coming years. “Scaling down” is the problem of how macro-level features of Big Data affect, shape, and evoke lower-level features and processes. I identify four aspects of this problem: the extent to which findings from studies of Facebook and other Big-Data platforms apply to human behavior at the scale of church suppers and department politics where we spend much of our lives; the extent to which the mathematics of scaling might be consistent with behavioral principles, moving beyond a “universal” theory of networks to the study of variation within and between networks; and how a large social field, including its history and culture, shapes the typical representations, interactions, and strategies at local levels in a text or social network. ","",""
"2015","The literary uses of high-dimensional space"," Debates over “Big Data” shed more heat than light in the humanities, because the term ascribes new importance to statistical methods without explaining how those methods have changed. What we badly need instead is a conversation about the substantive innovations that have made statistical modeling useful for disciplines where, in the past, it truly wasn’t. These innovations are partly technical, but more fundamentally expressed in what Leo Breiman calls a new “culture” of statistical modeling. Where 20th-century methods often required humanists to squeeze our unstructured texts, sounds, or images into some special-purpose data model, new methods can handle unstructured evidence more directly by modeling it in a high-dimensional space. This opens a range of research opportunities that humanists have barely begun to discuss. To date, topic modeling has received most attention, but in the long run, supervised predictive models may be even more important. I sketch their potential by describing how Jordan Sellers and I have begun to model poetic distinction in the long 19th century—revealing an arc of gradual change much longer than received literary histories would lead us to expect. ","",""
"2015","Known or knowing publics? Social media data mining and the question of public agency"," New methods to analyse social media data provide a powerful way to know publics and capture what they say and do. At the same time, access to these methods is uneven, with corporations and governments tending to have best access to relevant data and analytics tools. Critics raise a number of concerns about the implications dominant uses of data mining and analytics may have for the public: they result in less privacy, more surveillance and social discrimination, and they provide new ways of controlling how publics come to be represented and so understood. In this paper, we consider if a different relationship between the public and data mining might be established, one in which publics might be said to have greater agency and reflexivity vis-à-vis data power. Drawing on growing calls for alternative data regimes and practices, we argue that to enable this different relationship, data mining and analytics need to be democratised in three ways: they should be subject to greater public supervision and regulation, available and accessible to all, and used to create not simply known but reflexive, active and knowing publics. We therefore imagine conditions in which data mining is not just used as a way to know publics, but can become a means for publics to know themselves. ","",""
"2015","Lost in a random forest: Using Big Data to study rare events"," Sudden, broad-scale shifts in public opinion about social problems are relatively rare. Until recently, social scientists were forced to conduct post-hoc case studies of such unusual events that ignore the broader universe of possible shifts in public opinion that do not materialize. The vast amount of data that has recently become available via social media sites such as Facebook and Twitter—as well as the mass-digitization of qualitative archives provide an unprecedented opportunity for scholars to avoid such selection on the dependent variable. Yet the sheer scale of these new data creates a new set of methodological challenges. Conventional linear models, for example, minimize the influence of rare events as “outliers”—especially within analyses of large samples. While more advanced regression models exist to analyze outliers, they suffer from an even more daunting challenge: equifinality, or the likelihood that rare events may occur via different causal pathways. I discuss a variety of possible solutions to these problems—including recent advances in fuzzy set theory and machine learning—but ultimately advocate an ecumenical approach that combines multiple techniques in iterative fashion. ","",""
"2015","Big Data and the danger of being precisely inaccurate"," Social scientists and data analysts are increasingly making use of Big Data in their analyses. These data sets are often “found data” arising from purely observational sources rather than data derived under strict rules of a statistically designed experiment. However, since these large data sets easily meet the sample size requirements of most statistical procedures, they give analysts a false sense of security as they proceed to focus on employing traditional statistical methods. We explain how most analyses performed on Big Data today lead to “precisely inaccurate” results that hide biases in the data but are easily overlooked due to the enhanced significance of the results created by the data size. Before any analyses are performed on large data sets, we recommend employing a simple data segmentation technique to control for some major components of observational data biases. These segments will help to improve the accuracy of the results. ","",""
"2015","Three fallacies of digital footprints"," “Digital footprints” is an attractive, useful, and increasingly popular metaphor for thinking about Big Data. In this essay, I elaborate on this metaphor to highlight three relatively basic fallacies in the way we tend to think about Big Data: first, that they contain information on complete populations, or “ N = all”; second, that they contain recordings of naturalistic behavior; and third, that they can be understood devoid of context. ","",""
"2015","Big Data and <i>The Phantom Public</i>: Walter Lippmann and the fallacy of data privacy self-management"," In 1927, Walter Lippmann published The Phantom Public, denouncing the ‘mystical fallacy of democracy.’ Decrying romantic democratic models that privilege self-governance, he writes: “I have not happened to meet anybody, from a President of the United States to a professor of political science, who came anywhere near to embodying the accepted ideal of the sovereign and omnicompetent citizen.” Almost 90 years later, Lippmann’s pragmatism is as relevant as ever, and should be applied in new contexts where similar self-governance concerns persist. This paper does just that, repurposing Lippmann’s argument in the context of the ongoing debate over the role of the digital citizen in Big Data management. It is argued that proposals by the Federal Trade Commission, the White House and the US Congress, championing failed notice and choice privacy policy, perpetuate a self-governance fallacy comparable to Lippmann’s, referred to here as the fallacy of data privacy self-management. Even if the digital citizen had the faculties and the system for data privacy self-management, the digital citizen has little time for data governance. We desire the freedom to pursue the ends of digital production, without being inhibited by the means. We want privacy, and safety, but cannot complete all that is required for its protection. If it is true that the fallacy of democracy is similar to the fallacy of data privacy self-management, then perhaps the pragmatic solution is representative data management: a combination of non/for-profit digital dossier management via infomediaries that can ensure the protection of personal data, while freeing individuals from what Lippmann referred to as an ‘unattainable ideal.’ ","",""
"2015","In defense of forensic social science"," Like the navigation tools that freed ancient sailors from the need to stay close to the shoreline—eventually affording the discovery of new worlds—Big Data might open us up to new sociological possibilities by freeing us from the shackles of hypothesis testing. But for that to happen we need forensic social science: the careful compilation of evidence from unstructured digital traces as a means to generate new theories. ","",""
"2015","Inflated granularity: Spatial “Big Data” and geodemographics"," Data analytics, particularly the current rhetoric around “Big Data”, tend to be presented as new and innovative, emerging ahistorically to revolutionize modern life. In this article, we situate one branch of Big Data analytics, spatial Big Data, through a historical predecessor, geodemographic analysis, to help develop a critical approach to current data analytics. Spatial Big Data promises an epistemic break in marketing, a leap from targeting geodemographic areas to targeting individuals. Yet it inherits characteristics and problems from geodemographics, including a justification through the market, and a process of commodification through the black-boxing of technology. As researchers develop sustained critiques of data analytics and its effects on everyday life, we must so with a grounding in the cultural and historical contexts from which data technologies emerged. This article and others (Barnes and Wilson, 2014) develop a historically situated, critical approach to spatial Big Data. This history illustrates connections to the critical issues of surveillance, redlining, and the production of consumer subjects and geographies. The shared histories and structural logics of spatial Big Data and geodemographics create the space for a continued critique of data analyses’ role in society. ","",""
"2015","Between technical features and analytic capabilities: Charting a relational affordance space for digital social analytics"," Digital social analytics is a subset of Big Data methods that is used to understand the social environment in which people and organizations have to act. This paper presents an analysis of eight projects that are experimenting with the use of these methods for various purposes. It shows that two specific technological features influence the work with such methods in all the cases. The first concerns the need to distribute choices about the structure of data to third-party actors and the second concerns the need to balance machine intelligence and human intuition when automating the analysis. These features set specific conditions for knowledge production, and the paper identifies two opposite approaches for engaging with each of these conditions. These features and approaches are finally combined into a two-dimensional affordance space that illustrates how there is flexibility in the way project leaders interact with the features of the data environment. It thereby also shows how digital social analytics come to have different affordances for different projects. ","",""
"2015","Big Data and historical social science"," “Big Data” can revolutionize historical social science if it arises from substantively important contexts and is oriented towards answering substantively important questions. Such data may be especially important for answering previously largely intractable questions about the timing and sequencing of events, and of event boundaries. That said, “Big Data” makes no difference for social scientists and historians whose accounts rest on narrative sentences. Since such accounts are the norm, the effects of Big Data on the practice of historical social science may be more limited than one might wish. ","",""
"2015","Big Data and central banks"," This commentary recaps a Centre for Central Banking Studies event held at the Bank of England on 2–3 July 2014. The article covers three main points. First, it situates the Centre for Central Banking Studies event within the context of the Bank’s Strategic Plan and initiatives. Second, it summarises and reflects on major themes from the event. Third, the article links central banks’ emerging interest in Big Data approaches with their broader uptake by other economic agents. ","",""
"2015","Big Data and reality"," DNA sequencers, Twitter, MRIs, Facebook, particle accelerators, Google Books, radio telescopes, Tumblr: what do these things have in common? According to the evangelists of “data science,” all of these are instruments for observing reality at unprecedentedly large scales and fine granularities. This perspective ignores the social reality of these very different technological systems, ignoring how they are made, how they work, and what they mean in favor of an exclusive focus on what they generate: Big Data. But no data, big or small, can be interpreted without an understanding of the process that generated them. Statistical data science is applicable to systems that have been designed as scientific instruments, but is likely to lead to confusion when applied to systems that have not. In those cases, a historical inquiry is preferable. ","",""
"2015","Datafication and empowerment: How the open data movement re-articulates notions of democracy, participation, and journalism"," This article shows how activists in the open data movement re-articulate notions of democracy, participation, and journalism by applying practices and values from open source culture to the creation and use of data. Focusing on the Open Knowledge Foundation Germany and drawing from a combination of interviews and content analysis, it argues that this process leads activists to develop new rationalities around datafication that can support the agency of datafied publics. Three modulations of open source are identified: First, by regarding data as a prerequisite for generating knowledge, activists transform the sharing of source code to include the sharing of raw data. Sharing raw data should break the interpretative monopoly of governments and would allow people to make their own interpretation of data about public issues. Second, activists connect this idea to an open and flexible form of representative democracy by applying the open source model of participation to political participation. Third, activists acknowledge that intermediaries are necessary to make raw data accessible to the public. This leads them to an interest in transforming journalism to become an intermediary in this sense. At the same time, they try to act as intermediaries themselves and develop civic technologies to put their ideas into practice. The article concludes with suggesting that the practices and ideas of open data activists are relevant because they illustrate the connection between datafication and open source culture and help to understand how datafication might support the agency of publics and actors outside big government and big business. ","",""
"2015","Small decisions with big impact on data analytics"," Big social data have enabled new opportunities for evaluating the applicability of social science theories that were formulated decades ago and were often based on small- to medium-sized samples. Big Data coupled with powerful computing has the potential to replace the statistical practice of sampling and estimating effects by measuring phenomena based on full populations. Preparing these data for analysis and conducting analytics involves a plethora of decisions, some of which are already embedded in previously collected data and built tools. These decisions refer to the recording, indexing and representation of data and the settings for analysis methods. While these choices can have tremendous impact on research outcomes, they are not often obvious, not considered or not being made explicit. Consequently, our awareness and understanding of the impact of these decisions on analysis results and derived implications are highly underdeveloped. This might be attributable to occasional high levels of over-confidence in computational solutions as well as the possible yet questionable assumption that Big Data can wash out minor data quality issues, among other reasons. This article provides examples for how to address this issue. It argues that checking, ensuring and validating the quality of big social data and related auxiliary material is a key ingredient for empowering users to gain reliable insights from their work. Scrutinizing data for accuracy issues, systematically fixing them and diligently documenting these processes can have another positive side effect: Closely interacting with the data, thereby forcing ourselves to understand their idiosyncrasies and patterns, can help us to move from being able to precisely model and formally describe effects in society to also understand and explain them. ","",""
"2015","Facing Big Data: Making sociology relevant"," Working with computational methods and large textual analysis has been challenging and very rewarding—with all the ups and downs that doing empirical social research entails. In my contribution, I relate some research experiences and reflect upon data construction and the links between theory, data, and methods. ","",""
"2015","Adoption of geodemographic and ethno-cultural taxonomies for analysing Big Data"," This paper is intended to contribute to the discussion of the differential level of adoption of Big Data among research communities. Recognising the impracticality of conducting an audit across all forms and uses of Big Data, we have restricted our enquiry to one very specific form of Big Data, namely general purpose taxonomies, of which Mosaic, Acorn and Origins are examples, that rely on data from a variety of Big Data feeds. The intention of these taxonomies is to enable the records of consumers and citizens held on Big Data datasets to be coded according to type of residential neighbourhood or ethno-cultural heritage without any use of questionnaires. Based on our respective experience in the academic social sciences, in government and in the design and marketing of these taxonomies, we identify the features of these classifications which appear to render them attractive or problematic to different categories of potential user or researcher depending on how the relationship is conceived. We conclude by identifying seven classifications of user or potential user who, on account of their background, current position and future career expectations, tend to respond in different ways to the opportunity to adopt these generic systems as aids for understanding social processes. ","",""
"2015","Small Big Data: Using multiple data-sets to explore unfolding social and economic change"," Bold approaches to data collection and large-scale quantitative advances have long been a preoccupation for social science researchers. In this commentary we further debate over the use of large-scale survey data and official statistics with ‘Big Data’ methodologists, and emphasise the ability of these resources to incorporate the essential social and cultural heredity that is intrinsic to the human sciences. In doing so, we introduce a series of new data-sets that integrate approximately 30 years of survey data on victimisation, fear of crime and disorder and social attitudes with indicators of socio-economic conditions and policy outcomes in Britain. The data-sets that we outline below do not conform to typical conceptions of ‘Big Data’. But, we would contend, they are ‘big’ in terms of the volume, variety and complexity of data which has been collated (and to which additional data can be linked) and ‘big’ also in that they allow us to explore key questions pertaining to how social and economic policy change at the national level alters the attitudes and experiences of citizens. Importantly, they are also ‘small’ in the sense that the task of rendering the data usable, linking it and decoding it, required both manual processing and tacit knowledge of the context of the data and intentions of its creators. ","",""
"2015","Institutionalizing Big Data methods in social and political research"," We expect Big Data methods to contribute to research with results that are not inferior to those attained in other ways but possibly better, or hard or impossible to generate in other ways. Those who apply these methods may also aspire to augment the arsenal of research methods, offer surrogates for existing research designs, and re-orient research. Moreover, we can critically examine the institutional, societal and political effects of the Big Data methods and the conditions for the solid institutionalization of these methods in social and political research. To reach its primary objective, this article elaborates conclusions on how Big Data methods, not only by means of their ‘social life’ but also by their ‘political life’, may influence the institutionalization of social and political research. To reach its secondary objective, the article re-examines a study of budgetary legislation in 13 countries carried out by means of Big Data methods to draw conclusions concerning the augmentation of the arsenal of research methods, the surrogation of existing research designs, and the re-orientation of research. ","",""
"2015","Close encounters of the conceptual kind: Disambiguating social structure from text"," Despite its empirical prominence, there is very little extant organizational research on Big Data. However, there is reason to believe this is changing as organizational theory scholars are beginning to embrace new methods and data sources. In this essay, I present a view that suggests there are several latent opportunities, many of which have been simmering unattended for some time. This research approach is not without its challenges, as the ontological terrain of Big Data is untested and potentially disruptive. However, we are observing a renewal of approaches to text and content analysis. By opening up the toolkit of computational linguistics methods for text analysis, Big Data may bring about fresh synthesis and reshape classic debates around social structure. ","",""
"2015","Ontologies, methodologies, and new uses of Big Data in the social and cultural sciences"," In our Introduction to the Conceiving the Social with Big Data Special Issue of Big Data &amp; Society, we survey the 18 contributions from scholars in the humanities and social sciences, and highlight several questions and themes that emerge within and across them. These emergent issues reflect the challenges, problems, and promises of working with Big Data to access and assess the social. They include puzzles about the locus and nature of human life, the nature of interpretation, the categorical constructions of individual entities and agents, the nature and relevance of contexts and temporalities, and the determinations of causality. As such, the Introduction reflects on the contributions along a series of binaries that capture the dualities and dynamisms of these themes: Life/Data; Mind/Machine; and Induction/Deduction. ","",""
"2015","Data and agency"," This introduction to the special issue on data and agency argues that datafication should not only be understood as the process of collecting and analysing data about Internet users, but also as feeding such data back to users, enabling them to orient themselves in the world. It is important that debates about data power recognise that data is also generated, collected and analysed by alternative actors, enhancing rather than undermining the agency of the public. Developing this argument, we first make clear why and how the question of agency should be central to our engagement with data. Subsequently, we discuss how this question has been operationalized in the five contributions to this special issue, which empirically open up the study of alternative forms of datafication. Building on these contributions, we conclude that as data acquire new power, it is vital to explore the space for citizen agency in relation to data structures and to examine the practices of data work, as well as the people involved in these practices. ","",""
"2015","Ad hoc encounters with big data: Engaging citizens in conversations around tabletops","The increasing abundance of data creates new opportunities for communities of interest and communities of practice. We believe that interactive tabletops will allow users to explore data in familiar places such as living rooms, cafés, and public spaces. We propose informal, mobile possibilities for future generations of flexible and portable tabletops. In this paper, we build upon current advances in sensing and in organic user interfaces to propose how tabletops in the future could encourage collaboration and engage users in socially relevant data-oriented activities. Our work focuses on the socio-technical challenges of future democratic deliberation. As part of our vision, we suggest switching from fixed to mobile tabletops and provide two examples of hypothetical interface types: TableTiles and Moldable Displays. We consider how tabletops could foster future civic communities, expanding modes of participation originating in the Greek Agora and in European notions of cafés as locales of political deliberation.","",""
"2015","Inside the Data Spectacle"," This paper focuses first on the scopophilic aspects of large scale data visualization—the fantasy of command and control through seeing—and places these in relation to key sites and conventions inside the tech industry. John Caldwell’s notion of “industrial reflexivity” provides a framework to explain the charismatic power and performative effects that attend representations of data as a visual spectacle. Drawing on twelve months of personal experience working for a large technology company, and observations from a number of relevant showcases, conferences, and events, I take a “production studies” approach to understand the forms of common sense produced in industry settings. I then offer two examples of data work understood as a new kind of “below the line” labor. ","",""
"2015","FCJMESH-006 From Information Activism to the Politics of Data","Tactical Tech has a decade of experience supporting the use of information and digital technologies to support rights activism. They say that in this time they have witnessed a radically altered information eco-system thanks to an explosion of new technologies, a dramatic rise in technology uptake and a burgeoning government and corporate surveillance system. Here Maya Ganesh and Stephanie Hankey, from Tactical Tech, discuss their analysis of the challenges this new information ecosystem poses for rights activism and they describe the ways in which Tactical Tech are choosing to address these challenges.","",""
"2016","How to Respond to Data Science: Early Data Criticism by Lionel Trilling","Abstract:This article was originally drafted just four weeks after the publishing of Dataclysm, a 2014 book by Christian Rudder that sought to popularize data and data science by, in part, dismissing the social sciences and humanities as obsolete approaches to knowledge production. In looking for a potential way of responding to data scientists like Rudder, this article examines a 1948–50 essay about data that was written by Lionel Trilling (1905–75). Trilling frames data as part of our broader cultural history, which includes literature, drama, epic poetry, and the arts. This article argues that what Trilling models in the essay is a line of writing and thinking about data—a type of data criticism—that today offers tremendous promise for responding to data science and to evangelists like Christian Rudder.","",""
"2016","Bottom of the Data Pyramid: Big Data and the Global South","To date, little attention has been given to the impact of big data in the Global South, about 60% of whose residents are below the poverty line. Big data manifests in novel and unprecedented ways in these neglected contexts. For instance, India has created biometric national identities for her 1.2 billion people, linking them to welfare schemes, and social entrepreneurial initiatives like the Ushahidi project that leveraged crowdsourcing to provide real-time crisis maps for humanitarian relief. While these projects are indeed inspirational, this article argues that in the context of the Global South there is a bias in the framing of big data as an instrument of empowerment. Here, the poor, or the “bottom of the pyramid” populace are the new consumer base, agents of social change instead of passive beneficiaries. This neoliberal outlook of big data facilitating inclusive capitalism for the common good sidelines critical perspectives urgently needed if we are to channel big data as a positive social force in emerging economies. This article proposes to assess these new technological developments through the lens of databased democracies, databased identities, and databased geographies to make evident normative assumptions and perspectives in this under-examined context.","",""
"2016","Automation, Big Data and Politics: A Research Review","We review the great variety of critical scholarship on algorithms, automation, and big data in areas of contemporary life both to document where there has been robust scholarship and to contribute to existing scholarship by identifying gaps in our research agenda. We identify five domains with opportunities for further scholarship: (a) China, (b) international interference in democratic politics, (c) civic engagement in Latin American, (d) public services, and (e) national security and foreign affairs. We argue that the time is right to match dedication to critical theory of algorithmic communication with a dedication to empirical research through audit studies, network ethnography, and investigation of the political economy of algorithmic production.","",""
"2016","Bottom of the data pyramid","To date, little attention has been given to the impact of big data in the Global South, about 60% of whose residents are below the poverty line. Big data manifests in novel and unprecedented ways in these neglected contexts. For instance, India has created  biometric national identities for her 1.2 billion people, linking them to welfare schemes, and social entrepreneurial initiatives like the Ushahidi project that leveraged crowdsourcing to provide  real-time crisis maps for humanitarian relief. While these projects are indeed inspirational, this article argues that in the context of the Global South there is a bias in the framing of big data as an instrument of empowerment. Here, the poor, or the “bottom of the pyramid” populace are the new consumer base, agents of social change instead of passive beneficiaries. This neoliberal outlook of big data facilitating inclusive capitalism for the  common good sidelines critical perspectives urgently needed if we are to channel big data as a positive social force in emerging economies. This article proposes to assess these new  technological developments through the lens of databased democracies, databased identities, and databased geographies to make evident normative assumptions and perspectives in this under-examined context.","",""
"2016","Media Genealogy| The Future of Critique: Mark Andrejevic on Power/Knowledge and the Big Data-Driven Decline of Symbolic Efficiency","Mark Andrejevic, Associate Professor at Pomona College, and J.J. Sylvia, Ph.D. student in the Communication Rhetoric and Digital Media Program at North Carolina State University, discusses the impact of the neo-materialist turn for media studies and the importance of critiquing surveillance through the theoretical framework of power in addition to that of privacy. Although the decline of symbolic efficiency, brought on at least in part by the rise of big data, seems to disrupt the link that Michel Foucault draws between power and knowledge, Andrejevic considers possibilities for reimagining the knowledge structures associated with big data’s infrastructure.","",""
"2016","Orit Halpern, Beautiful Data: A History of Vision and Reason Since 1945","Orit Halpern’s ambitious book Beautiful Data: A History of Vision and Reason since 1945 offers historical insight into why we naturally perceive data as valuable in our contemporary society. Unlike many studies on data, big data in particular (e.g., MayerSchonberger & Cukier, 2013), the main focus of this volume is not data per se. Rather, this book presents a genealogy of contemporary society where we are regularly obsessed with big data and visualization. With a particular focus on cybernetics, the author critically traces the trajectory of vision and reason after World War II and thus discusses the relationship between our historically trained attention and contemporary biopolitical rationality.","",""
"2016","Regulating “big data education” in Europe: lessons learned from the US","European schools are increasingly relying on vendors to collect, process, analyse, and even make decisions based on a considerable amount of student data through big data tools and methods. Consequently, portions of school’s power are gradually shifting from traditional public schools to the hands of for-profit organisations. This article discusses the current and forthcoming European Union (EU) data protection regime with respect to the protection of student rights from the potential risk of outsourcing student data utilisation in Kindergarten-12th grade (K-12) educational systems. The article identifies what lessons can be drawn from recent developments in the United States (US) “student data affair”. These lessons can provide a new perspective for designing a balanced policy for regulating the shift in school’s power.","",""
"2016","Big data: big power shifts?","Facing general conceptions of the power effects of big data, this thematic edition is interested in studies that scrutinise big data and power in concrete fields of application. It brings together scholars from different disciplines who analyse the fields agriculture, education, border control and consumer policy. As will be made explicit in the following, each of the articles tells us something about firstly, what big data is and how it relates to power. They secondly also shed light on how we should shape “the big data society” and what research questions need to be answered to be able to do so.","",""
"2016","Impediment to insight to innovation: understanding data assemblages through the breakdown–repair process","ABSTRACT As the era of ‘big data’ unfolds, researchers are increasingly engaging with large, complex data sets compiled from heterogeneous sources and distributed across networked technologies. The nature of these data sets makes it difficult to grasp and manipulate their materiality. We argue that moments of breakdown – points at which progress is stopped due to a material limitation – provide opportunities for researchers to develop new imaginations and configurations of their data sets' materiality, and serve as underappreciated resources for knowledge production. In our ethnographic study of data-intensive research in an academic setting, we emphasize the layers of repair work required to address breakdown, and highlight incremental innovations that stem from this work. We suggest that a focus on the breakdown–repair process can facilitate nuanced understandings of the relationships and labour involved in constituting data assemblages and constructing knowledge from them.","",""
"2016","The work that visualisation conventions do","ABSTRACT This paper argues that visualisation conventions work to make the data represented within visualisations seem objective, that is, transparent and factual. Interrogating the work that visualisation conventions do helps us to make sense of the apparent contradiction between criticisms of visualisations as doing persuasive work and visualisation designers’ belief that through visualisation, it is possible to ‘do good with data’ [Periscopic. 2014. Home page. Retrieved from http://www.periscopic.com/]. We focus on four conventions which imbue visualisations with a sense of objectivity, transparency and facticity. These include: (a) two-dimensional viewpoints; (b) clean layouts; (c) geometric shapes and lines; (d) the inclusion of data sources. We argue that thinking about visualisations from a social semiotic standpoint, as we do in this paper by bringing together what visualisation designers say about their intentions with a semiotic analysis of the visualisations they produce, advances understanding of the ways that data visualisations come into being, how they are imbued with particular qualities and how power operates in and through them. Thus, this paper contributes nuanced understanding of data visualisations and their production, by uncovering the ways in which power is at work within them. In turn, it advances debate about data in society and the emerging field of data studies.","",""
"2016","Neogeography and the democratization of GIS: a metasynthesis of qualitative research","ABSTRACT Neogeography is the name given to the phenomenon of the vastly expanded Geographic Information Systems (GIS) user base. It consists of a collection of practices, tools and users generally found outside of traditional, authoritative GIS. GIS are computer applications that allow users to contribute geotagged data and to access and utilize geospatial data sets in combination with attribute information for a variety of purposes. This paper investigates questions of whether neogeography furthers the democratization of GIS and if increased access translates to empowerment or, conversely, to further marginalization. The research is interpretative and involves a literature review of the topic and a metasynthesis of recent qualitative research. Metasynthesis involves critical evaluation of data to identify an appropriate research sample and synthesis of findings by a compare-and-contrast exercise followed by reciprocal translation of each study into the other studies to reveal overarching metaphors. This is followed by conclusions and recommendations. The findings show that, depending on circumstances, neogeography can result in the democratization of GIS and geospatial data but may also constitute new methods of exclusion depending on technological and societal barriers. Neogeography can also result in empowerment, but this is difficult to define and is often highly contingent on local context.","",""
"2016","Visualization as experience","Modern-day data visualizations have emerged as a new visual language to represent, explore, and convey data, either quantitative or qualitative. Writings in the field of data visualizations have focused predominantly on the computational nature of these algorithm-based representations (Chen and Czerwinski 2000). As an alternative, I propose an approach based on user experience design to both assessing and designing data visualizations, in the recognition that using a visualization of this kind is a form of experience that can benefit from explicit planning. Following a review of a wide range of examples, I conclude by offering the following eight factors:    Perceptibility: Meet humans' sensory input criteria  Pre-knowledge: Provide information to help understand the visualization's  larger context  Comprehension: Apply visual design principles so the visualization can communicate clearly  Utility: Leverage interactive features and functionality  Interpretation: Provide mechanisms to explore deeper meaning  Engagement: Design to maintain the viewer's attention  Outcome: Connect back to life (or not)  Purpose: Assess the visualization against its intent  Les visualisations contemporaines de donnees sont apparues comme nouveau langage visuel afin de representer, explorer et transmettre des donnees, soit quantitatives ou qualitatives. Les ecrits dans le domaine de la visualisation de donnees portaient principalement sur la nature informatique de ces representations basees sur des algorithmes (Chen et Czerwinski 2000). Comme option de rechange, je propose une methode basee sur la conception de l'experience client en ce qui concerne l'evaluation et la conception des visualisations de donnees, en reconnaissant que l'utilisation d'une visualisation de ce genre est une forme d'experience qui peut tirer parti d'une planification explicite. Suite a un examen d'une vaste gamme d'exemples, je conclus en offrant les huit facteurs suivants :    Perceptibilite: Repondre aux criteres de l'apport sensoriel humain  Connaissance prealable: Fournir des renseignements pour aider a comprendre le contexte plus large de la visualisation  Comprehension: Appliquer les principes de conception visuelle afin que la visualisation puisse communiquer clairement  Utilite: Tirer parti des caracteristiques et fonctionnalites interactives  Interpretation: Fournir des mecanismes pour explorer un sens plus profond  Engagement: Concevoir de facon a retenir l'attention du lecteur  Resultat: Se connecter de nouveau a la vie reelle (ou non)  But: Evaluer la visualisation par rapport a son objectif","",""
"2016","Introduction. Politics of Big Data","This special issue offers a critical dialogue around the myriad political dimensions of Big Data. We begin by recognising that the technological objects of Big Data are unprecedented in the speed, scope and scale of their computation and knowledge production. This critical dialogue is grounded in an equal recognition of continuities around Big Data’s social, cultural, and political economic dimensions.","",""
"2016","From Data Analytics to Data Hermeneutics. Online Political Discussions, Digital Methods and the Continuing Relevance of Interpretive Approaches","Abstract                 To advance the study of digital politics it is urgent to complement data analytics with data hermeneutics to be understood as a methodological approach that focuses on the interpretation of the deep structures of meaning in social media conversations as they develop around various political phenomena, from digital protest movements to online election campaigns. The diffusion of Big Data techniques in recent scholarship on political behavior has led to a quantitative bias in the understanding of online political phenomena and a disregard for issues of content and meaning. To solve this problem it is necessary to adapt the hermeneutic approach to the conditions of social media communication, and shift its object of analysis from texts to datasets. On the one hand, this involves identifying procedures to select samples of social media posts out of datasets, so that they can be analysed in more depth. I describe three sampling strategies - top sampling, random sampling and zoom-in sampling - to attain this goal. On the other hand, “close reading” procedures used in hermeneutic analysis need to be adapted to the different quality of digital objects vis-à-vis traditional texts. This can be achieved by analysing posts not only as data-points in a dataset, but also as interventions in a collective conversation, and as utterances of broader “discourses”. The task of interpretation of social media data also requires an understanding of the political and social contexts in which digital political phenomena unfold, as well as taking into account the subjective viewpoints and motivations of those involved, which can be gained through in-depth interviews, and other qualitative social science methods. Data hermeneutics thus holds promise for a closing of the gap between quantitative and qualitative approaches in the study of digital politics, allowing for a deeper and more holistic understanding of online political phenomena.","",""
"2016","Big Data and the Paradox of Diversity","Abstract                 This paper develops a critique of Big Data and associated analytical techniques by focusing not on errors - skewed or imperfect datasets, false positives, underrepresentation, and so forth - but on data mining that works. After a quick framing of these practices as interested readings of reality, I address the question of how data analytics and, in particular, machine learning reveal and operate on the structured and unequal character of contemporary societies, installing “economic morality” (Allen 2012) as the central guiding principle. Rather than critiquing the methods behind Big Data, I inquire into the way these methods make the many differences in decentred, non-traditional societies knowable and, as a consequence, ready for profitable distinction and decision-making. The objective, in short, is to add to our understanding of the “profound ideological role at the intersection of sociality, research, and commerce” (van Dijck 2014: 201) the collection and analysis of large quantities of multifarious data have come to play. Such an understanding needs to embed Big Data in a larger, more fundamental critique of the societal context it operates in.","",""
"2016","The Alternative Epistemologies of Data Activism","Abstract                 As datafication progressively invades all spheres of contemporary society, citizens grow increasingly aware of the critical role of information as the new fabric of social life. This awareness triggers new forms of civic engagement and political action that we term “data activism”. Data activism indicates the range of sociotechnical practices that interrogate the fundamental paradigm shift brought about by datafication. Combining Science and Technology Studies with Social Movement Studies, this theoretical article offers a foretaste of a research agenda on data activism. It foregrounds democratic agency vis-à-vis datafication, and unites under the same label ways of affirmative engagement with data (“proactive data activism”, e. g. databased advocacy) and tactics of resistance to massive data collection (“reactive data activism”, e. g. encryption practices), understood as a continuum along which activists position and reposition themselves and their tactics. The article argues that data activism supports the emergence of novel epistemic cultures within the realm of civil society, making sense of data as a way of knowing the world and turning it into a point of intervention and generation of data countercultures. It offers the notion of data activism as a heuristic tool for the study of new forms of political participation and civil engagement in the age of datafication, and explores data activism as an evolving theoretical construct susceptible to contestation and revision.","",""
"2016","Pushback: Critical data designers and pollution politics"," In this paper, we describe how critical data designers have created projects that ‘push back’ against the eclipse of environmental problems by dominant orders: the pioneering pollution database Scorecard, released by the US NGO Environmental Defense Fund in 1997; the US Environmental Protection Agency’s EnviroAtlas that brings together numerous data sets and provides tools for valuing ecosystem services; and the Houston Clean Air Network’s maps of real-time ozone levels in Houston. Drawing on ethnographic observations and interviews, we analyse how critical data designers turn scientific data and findings into claims and visualisations that are meaningful in contemporary political terms. The skills of critical data designers cross scales and domains; they must identify problems calling for public consideration, and then locate, access, link, and create visualisations of data relevant to the problem. We conclude by describing hazards ahead in work to leverage Big Data to understand and address environmental problems. Critical data designers need to understand what counts as a societal problem in a particular context, what doesn’t, what is seen as connected and not, what is seen as ethically charged, and what is exonerated and discounted. Such recognition is produced through interpretive, ‘close reading’ of the historical moment in which they operate. ","",""
"2016","Critical Data Studies: A dialog on data and space"," In light of recent technological innovations and discourses around data and algorithmic analytics, scholars of many stripes are attempting to develop critical agendas and responses to these developments (boyd and Crawford 2012). In this mutual interview, three scholars discuss the stakes, ideas, responsibilities, and possibilities of critical data studies. The resulting dialog seeks to explore what kinds of critical approaches to these topics, in theory and practice, could open and make available such approaches to a broader audience. ","",""
"2016","Just good enough data: Figuring data citizenships through air pollution sensing and data stories"," Citizen sensing, or the use of low-cost and accessible digital technologies to monitor environments, has contributed to new types of environmental data and data practices. Through a discussion of participatory research into air pollution sensing with residents of northeastern Pennsylvania concerned about the effects of hydraulic fracturing, we examine how new technologies for generating environmental data also give rise to new problems for analysing and making sense of citizen-gathered data. After first outlining the citizen data practices we collaboratively developed with residents for monitoring air quality, we then describe the data stories that we created along with citizens as a method and technique for composing data. We further mobilise the concept of ‘just good enough data’ to discuss the ways in which citizen data gives rise to alternative ways of creating, valuing and interpreting datasets. We specifically consider how environmental data raises different concerns and possibilities in relation to Big Data, which can be distinct from security or social media studies. We then suggest ways in which citizen datasets could generate different practices and interpretive insights that go beyond the usual uses of environmental data for regulation, compliance and modelling to generate expanded data citizenships. ","",""
"2016","Where are human subjects in Big Data research? The emerging ethics divide"," There are growing discontinuities between the research practices of data science and established tools of research ethics regulation. Some of the core commitments of existing research ethics regulations, such as the distinction between research and practice, cannot be cleanly exported from biomedical research to data science research. Such discontinuities have led some data science practitioners and researchers to move toward rejecting ethics regulations outright. These shifts occur at the same time as a proposal for major revisions to the Common Rule—the primary regulation governing human-subjects research in the USA—is under consideration for the first time in decades. We contextualize these revisions in long-running complaints about regulation of social science research and argue data science should be understood as continuous with social sciences in this regard. The proposed regulations are more flexible and scalable to the methods of non-biomedical research, yet problematically largely exclude data science methods from human-subjects regulation, particularly uses of public datasets. The ethical frameworks for Big Data research are highly contested and in flux, and the potential harms of data science research are unpredictable. We examine several contentious cases of research harms in data science, including the 2014 Facebook emotional contagion study and the 2016 use of geographical data techniques to identify the pseudonymous artist Banksy. To address disputes about application of human-subjects research ethics in data science, critical data studies should offer a historically nuanced theory of “data subjectivity” responsive to the epistemic methods, harms and benefits of data science and commerce. ","",""
"2016","Critical data studies: An introduction"," Critical Data Studies (CDS) explore the unique cultural, ethical, and critical challenges posed by Big Data. Rather than treat Big Data as only scientifically empirical and therefore largely neutral phenomena, CDS advocates the view that Big Data should be seen as always-already constituted within wider data assemblages. Assemblages is a concept that helps capture the multitude of ways that already-composed data structures inflect and interact with society, its organization and functioning, and the resulting impact on individuals’ daily lives. CDS questions the many assumptions about Big Data that permeate contemporary literature on information and society by locating instances where Big Data may be naively taken to denote objective and transparent informational entities. In this introduction to the Big Data &amp; Society CDS special theme, we briefly describe CDS work, its orientations, and principles. ","",""
"2016","Digital subjectivation and financial markets: Criticizing Social Studies of Finance with Lazzarato"," The recently rising field of Critical Data Studies is still facing fundamental questions. Among these is the enigma of digital subjectivation. Who are the subjects of Big Data? A field where this question is particularly pressing is finance. Since the 1990s traders have been steadily integrated into computerized data assemblages, which calls for an ontology that eliminates the distinction between human sovereign subjects and non-human instrumental objects. The latter subjectivize traders in pre-conscious ways, because human consciousness runs too slow to follow the volatility of the market. In response to this conundrum Social Studies of Finance has drawn on Actor-Network Theory to interpret financial markets as technically constructed networks of human and non-human actors. I argue that in order to develop an explicitly critical data study it might be advantageous to refer to Maurizio Lazzarato’s theory of machinic subjugation instead. Although both accounts describe financial digital subjectivation similarly, Lazzarato has the advantage of coupling his description to a clear critique of and resistance to finance. ","",""
"2016","Introduction: Spatial Big Data and everyday life"," Spatial Big Data—be this natively geocoded content, geographical metadata, or data that itself refers to spaces and places—has become a pervasive presence in the spaces and practices of everyday life. Beyond preoccupations with “the geotag” and with mapping geocoded social media content, this special theme explores what it means to encounter and experience spatial Big Data as a quotidian phenomenon that is both spatial, characterized by and enacting of material spatialities, and spatializing, configuring relations between subjects, objects, and spaces in new and unprecedented ways. ","",""
"2016","Practicing, materialising and contesting environmental data"," While there are now an increasing number of studies that critically and rigorously engage with Big Data discourses and practices, these analyses often focus on social media and other forms of online data typically generated about users. This introduction discusses how environmental Big Data is emerging as a parallel area of investigation within studies of Big Data. New practices, technologies, actors and issues are concretising that are distinct and specific to the operations of environmental data. Situating these developments in relation to the seven contributions to this special collection, the introduction outlines significant characteristics of environmental data practices, data materialisations and data contestations. In these contributions, it becomes evident that processes for validating, distributing and acting on environmental data become key sites of materialisation and contestation, where new engagements with environmental politics and citizenship are worked through and realised. ","",""
"2016","Hackathons, data and discourse: Convolutions of the data (logical)"," This paper draws together empirical findings from our study of hackathons in the UK with literature on big data through three interconnected frameworks: data as discourse, data as datalogical and data as materiality. We suggest not only that hackathons resonate the wider socio-technical and political constructions of (big) data that are currently enacted in policy, education and the corporate sector (to name a few), but also that an investigation of hackathons reveals the extent to which ‘data’ operates as a powerful discursive tool; how the discourses (and politics) of data mask and reveal a series of tropes pertaining to data; that the politics of data are routinely and simultaneously obscured and claimed with serious implications for expertise and knowledge; and that ultimately, and for the vast majority of hackathons we have attended, the discursive and material constructions of data serve to underpin rather than challenge existing power relations and politics. ","",""
"2016","How should we do the history of Big Data?"," Taking its lead from Ian Hacking’s article ‘How should we do the history of statistics?’, this article reflects on how we might develop a sociologically informed history of Big Data. It argues that within the history of social statistics we have a relatively well developed history of the material phenomenon of Big Data. Yet this article argues that we now need to take the concept of ‘Big Data’ seriously, there is a pressing need to explore the type of work that is being done by that concept. The article suggests a programme for work that explores the emergence of the concept of Big Data so as to track the institutional, organisational, political and everyday adoption of this term. It argues that the term Big Data has the effect of making-up data and, as such, is powerful in framing our understanding of those data and the possibilities that they afford. ","",""
"2016","Analyzing and interpreting “imperfect” Big Data in the 1600s"," One of the characteristics of Big Data is that it often involves “imperfect” information. This paper examines the work of John Graunt (1620–1674) in the tabulation of diseases in London and the development of a life table using the “imperfect data” contained in London’s Bills of Mortality in the 1600s. London’s Bills of Mortality were Big Data for the 1600s, as they included information collected over time, the depth and accuracy of which improved gradually. The main shortcoming of the data available at the time was its nonuniform upkeep and the lack of depth of variables included at its outset. Due to these characteristics, it provides a perfect model for the examination of imperfect Big Data, as it has been analyzed, criticized, and interpreted repeatedly since the 1600s. ","",""
"2016","Datatrust: Or, the political quest for numerical evidence and the epistemologies of Big Data"," Recently, there has been renewed interest in so-called evidence-based policy making. Enticed by the grand promises of Big Data, public officials seem increasingly inclined to experiment with more data-driven forms of governance. But while the rise of Big Data and related consequences has been a major issue of concern across different disciplines, attempts to develop a better understanding of the phenomenon's historical foundations have been rare. This short commentary addresses this gap by situating the current push for numerical evidence within a broader socio-political context, demonstrating how the epistemological claims of Big Data science intersect with specific forms of trust, truth, and objectivity. We conclude by arguing that regulators' faith in numbers can be attributed to a distinct political culture, a representative democracy undermined by pervasive public distrust and uncertainty. ","",""
"2016","Soft skills and hard numbers: Gender discourse in human resources"," The cultural rise of “big data” in the recent years has pressured a number of occupations to make an epistemological shift toward data-driven science. Though expressed as a professional move, this article argues that the push incorporates gendered assumptions that disadvantage women. Using the human resource occupation as an example, I demonstrate how normative perceptions of feminine “soft skills” are seen as irreconcilable with the masculine “hard numbers” of a data-driven epistemology. The history of human resources reflects how assumptions of a biological fit with an occupation limit what women can convincingly describe as her skillsets. However, challenging this cannot stay within the confines of the occupation itself. To undo sexist thinking, it is necessary to understand the broader networks of patriarchal power that dictate how value is defined in corporate environments, especially within other high status professions in business. ","",""
"2016","Developing a feeling for error: Practices of monitoring and modelling air pollution data"," This paper is based on ethnographic research of data practices in a public health project called Weather Health and Air Pollution. (All names are pseudonyms.) I examine two different kinds of practices that make air pollution data, focusing on how they relate to particular modes of sensing and articulating air pollution. I begin by describing the interstitial spaces involved in making measurements of air pollution at monitoring sites and in the running of a computer simulation. Specifically, I attend to a shared dimension of these practices, the checking of a numerical reading for error. Checking a measurement for error is routine practice and a fundamental component of making data, yet these are also moments of interpretation, where the form and meaning of numbers are ambiguous. Through two case studies of modelling and monitoring data practices, I show that making a ‘good’ (error free) measurement requires developing a feeling for the instrument–air pollution interaction in terms of the intended functionality of the measurements made. These affective dimensions of practice are useful analytically, making explicit the interaction of standardised ways of knowing and embodied skill in stabilising data. I suggest that environmental data practices can be studied through researchers’ materialisation of error, which complicate normative accounts of Big Data and highlight the non-linear and entangled relations that are at work in the making of stable, accurate data. ","",""
"2016","A chronology of tactics: Art tackles Big Data and the environment"," Today data art is a full-fledged and maturing artistic practice. Like painting, artists are creating new visuals and representations with data. Like sculpture, artists are recombining bits to build something new out of the commonplace. Like photography, artists are using data to mirror or reflect contemporary society. In my own practice for the last 15 years I have been using data (both sourced and generated) to make works at the intersection of art, design and activism with a recent focus on environmental topics. It is my belief that through improved representation of, access to and public involvement with data we can increase understanding of important issues (such as environmental degradation) and provoke behavioural and systemic change. In this paper, I will examine the evolution of my work using data as my medium as well as outline tactics for data art to promote change. ","",""
"2016","Can we trust Big Data? Applying philosophy of science to software"," We address some of the epistemological challenges highlighted by the Critical Data Studies literature by reference to some of the key debates in the philosophy of science concerning computational modeling and simulation. We provide a brief overview of these debates focusing particularly on what Paul Humphreys calls epistemic opacity. We argue that debates in Critical Data Studies and philosophy of science have neglected the problem of error management and error detection. This is an especially important feature of the epistemology of Big Data. In “Error” section we explain the main characteristics of error detection and correction along with the relationship between error and path complexity in software. In this section we provide an overview of conventional statistical methods for error detection and review their limitations when faced with the high degree of conditionality inherent to modern software systems. ","",""
"2016","Administrative social science data: The challenge of reproducible research"," Powerful new social science data resources are emerging. One particularly important source is administrative data, which were originally collected for organisational purposes but often contain information that is suitable for social science research. In this paper we outline the concept of reproducible research in relation to micro-level administrative social science data. Our central claim is that a planned and organised workflow is essential for high quality research using micro-level administrative social science data. We argue that it is essential for researchers to share research code, because code sharing enables the elements of reproducible research. First, it enables results to be duplicated and therefore allows the accuracy and validity of analyses to be evaluated. Second, it facilitates further tests of the robustness of the original piece of research. Drawing on insights from computer science and other disciplines that have been engaged in e-Research we discuss and advocate the use of Git repositories to provide a useable and effective solution to research code sharing and rendering social science research using micro-level administrative data reproducible. ","",""
"2016","What makes Big Data, Big Data? Exploring the ontological characteristics of 26 datasets"," Big Data has been variously defined in the literature. In the main, definitions suggest that Big Data possess a suite of key traits: volume, velocity and variety (the 3Vs), but also exhaustivity, resolution, indexicality, relationality, extensionality and scalability. However, these definitions lack ontological clarity, with the term acting as an amorphous, catch-all label for a wide selection of data. In this paper, we consider the question ‘what makes Big Data, Big Data?’, applying Kitchin’s taxonomy of seven Big Data traits to 26 datasets drawn from seven domains, each of which is considered in the literature to constitute Big Data. The results demonstrate that only a handful of datasets possess all seven traits, and some do not possess either volume and/or variety. Instead, there are multiple forms of Big Data. Our analysis reveals that the key definitional boundary markers are the traits of velocity and exhaustivity. We contend that Big Data as an analytical category needs to be unpacked, with the genus of Big Data further delineated and its various species identified. It is only through such ontological work that we will gain conceptual clarity about what constitutes Big Data, formulate how best to make sense of it, and identify how it might be best used to make sense of the world. ","",""
"2016","Big Data, epistemology and causality: Knowledge in and knowledge out in EXPOsOMICS"," Recently, it has been argued that the use of Big Data transforms the sciences, making data-driven research possible and studying causality redundant. In this paper, I focus on the claim on causal knowledge by examining the Big Data project EXPOsOMICS, whose research is funded by the European Commission and considered capable of improving our understanding of the relation between exposure and disease. While EXPOsOMICS may seem the perfect exemplification of the data-driven view, I show how causal knowledge is necessary for the project, both as a source for handling complexity and as an output for meeting the project’s goals. Consequently, I argue that data-driven claims about causality are fundamentally flawed and causal knowledge should be considered a necessary aspect of Big Data science. In addition, I present the consequences of this result on other data-driven claims, concerning the role of theoretical considerations. I argue that the importance of causal knowledge and other kinds of theoretical engagement in EXPOsOMICS undermine theory-free accounts and suggest alternative ways of framing science based on Big Data. ","",""
"2016","Shareveillance: Subjectivity between open and closed data"," This article attempts to question modes of sharing and watching to rethink political subjectivity beyond that which is enabled and enforced by the current data regime. It identifies and examines a ‘shareveillant’ subjectivity: a form configured by the sharing and watching that subjects have to withstand and enact in the contemporary data assemblage. Looking at government open and closed data as case studies, this article demonstrates how ‘shareveillance’ produces an anti-political role for the public. In describing shareveillance as, after Jacques Rancière, a distribution of the (digital) sensible, this article posits a politico-ethical injunction to cut into the share and flow of data in order to arrange a more enabling assemblage of data and its affects. In order to interrupt shareveillance, this article borrows a concept from Édouard Glissant and his concern with raced otherness to imagine what a ‘right to opacity’ might mean in the digital context. To assert this right is not to endorse the individual subject in her sovereignty and solitude, but rather to imagine a collective political subjectivity and relationality according to the important question of what it means to ‘share well’ beyond the veillant expectations of the state. ","",""
"2016","Failing the market, failing deliberative democracy: How scaling up corporate carbon reporting proliferates information asymmetries"," Corporate carbon footprint data has become ubiquitous. This data is also highly promissory. But as this paper argues, such data fails both consumers and citizens. The governance of climate change seemingly requires a strong foundation of data on emission sources. Economists approach climate change as a market failure, where the optimisation of the atmosphere is to be evidence based and data driven. Citizens or consumers, state or private agents of control, all require deep access to information to judge emission realities. Whether we are interested in state-led or in neoliberal ‘solutions’ for either democratic participatory decision-making or for preventing market failure, companies’ emissions need to be known. This paper draws on 20 months of ethnographic fieldwork in a Fortune 50 company’s environmental accounting unit to show how carbon reporting interferes with information symmetry requirements, which further troubles possibilities for contesting data. A material-semiotic analysis of the data practices and infrastructures employed in the context of corporate emissions disclosure details the situated political economies of data labour along the data processing chain. The explicit consideration of how information asymmetries are socially and computationally shaped, how contexts are shifted and how data is systematically straightened out informs a reflexive engagement with Big Data. The paper argues that attempts to automatise environmental accounting’s veracity management by means of computing metadata or to ensure that data quality meets requirements through third-party control are not satisfactory. The crossover of Big Data with corporate environmental governance does not promise to trouble the political economy that hitherto sustained unsustainability. ","",""
"2016","Data journeys: Capturing the socio-material constitution of data objects and flows"," In this paper, we discuss the development and piloting of a new methodology for illuminating the socio-material constitution of data objects and flows as data move between different sites of practice. The data journeys approach contributes to the development of critical, qualitative methodologies that can address the geographic and temporal scale of emerging knowledge infrastructures, and capture the ‘life of data’ from their initial generation through to re-use in different contexts. We discuss the theoretical development of the data journeys methodology and the application of the approach on a project examining meteorological data on their journey from initial production through to being re-used in climate science and financial markets. We then discuss three key conceptual findings from this project about: (1) the socio-material constitution of digital data objects, (2) ‘friction’ in the movement of data through space and time and (3) the mutability of digital data as a material property that contributes to driving the movement of data between different sites of practice. ","",""
"2016","A place for Big Data: Close and distant readings of accessions data from the Arnold Arboretum"," Place is a key concept in environmental studies and criticism. However, it is often overlooked as a dimension of situatedness in social studies of information. Rather, situatedness has been defined primarily as embodiment or social context. This paper explores place attachments in Big Data by adapting close and distant approaches for reading texts to examine the accessions data of the Arnold Arboretum, a living collection of trees, vines and shrubs established by Harvard University in 1872 (The original interactive data visualizations can be found online: http://www.lifeanddeathofdata.org ). Although it is an early and unconventional example of the phenomenon, there are several reasons that the Arboretum is a useful site for investigating the relationship between Big Data and place. First, the category of place is embedded in a range of data fields used in the Arboretum’s records. Second, the Arboretum has long sought to be a place in which scientists and citizens alike can encounter large collections of data firsthand. Third, the place has shaped fluctuations in the daily production of data over the course of the Arboretum’s 144 year history. Furthermore, Arboretum data can help us see place in ways not necessarily tied to geolocation. Each of these place attachments suggests a different way in which data can be environmental: by being about, in, from, or generative of place. Taken together, these attachments offer a model for examining other data in relation to their environments. Moreover, the paper contends that rather than being detached from place, as prevailing discourses suggest, Big Data bring together more and further reaching place attachments than data sets of smaller sizes. ","",""
"2016","Questioning Big Data: Crowdsourcing crisis data towards an inclusive humanitarian response"," The aim of this paper is to critically explore whether crowdsourced Big Data enables an inclusive humanitarian response at times of crisis. We argue that all data, including Big Data, are socially constructed artefacts that reflect the contexts and processes of their creation. To support our argument, we qualitatively analysed the process of ‘Big Data making’ that occurred by way of crowdsourcing through open data platforms, in the context of two specific humanitarian crises, namely the 2010 earthquake in Haiti and the 2015 earthquake in Nepal. We show that the process of creating Big Data from local and global sources of knowledge entails the transformation of information as it moves from one distinct group of contributors to the next. The implication of this transformation is that locally based, affected people and often the original ‘crowd’ are excluded from the information flow, and from the interpretation process of crowdsourced crisis knowledge, as used by formal responding organizations, and are marginalized in their ability to benefit from Big Data in support of their own means. Our paper contributes a critical perspective to the debate on participatory Big Data, by explaining the process of in and exclusion during data making, towards more responsive humanitarian relief. ","",""
"2016","When open data is a Trojan Horse: The weaponization of transparency in science and governance"," Openness and transparency are becoming hallmarks of responsible data practice in science and governance. Concerns about data falsification, erroneous analysis, and misleading presentation of research results have recently strengthened the call for new procedures that ensure public accountability for data-driven decisions. Though we generally count ourselves in favor of increased transparency in data practice, this Commentary highlights a caveat. We suggest that legislative efforts that invoke the language of data transparency can sometimes function as “Trojan Horses” through which other political goals are pursued. Framing these maneuvers in the language of transparency can be strategic, because approaches that emphasize open access to data carry tremendous appeal, particularly in current political and technological contexts. We illustrate our argument through two examples of pro-transparency policy efforts, one historical and one current: industry-backed “sound science” initiatives in the 1990s, and contemporary legislative efforts to open environmental data to public inspection. Rules that exist mainly to impede science-based policy processes weaponize the concept of data transparency. The discussion illustrates that, much as Big Data itself requires critical assessment, the processes and principles that attend it—like transparency—also carry political valence, and, as such, warrant careful analysis. ","",""
"2016","Working beyond the confines of academic discipline to resolve a real-world problem: A community of scientists discussing long-tail data in the cloud","This project interrogates a workshop leader and whole-meeting talk among a group of scientists gathered at a workshop to discuss cyberinfrastructure and the sharing of both ‘light’ and ‘dark’ data in the sciences. This project analyzes discourses working through the workshop talk to interrogate the social relations, interdisciplinary identities, concerns, and commonalities in the sciences and in relation to emerging opportunities for computing and data sharing in the cloud. The findings point to the efficacy of arranging scientists around data collection processes for collaborative work as opposed to groupings around data type, discipline, work sectors, or collection location. This research provides an opportunity to consider the democratization of data, academic boundaries in the sciences, as well as interdisciplinary and collaborative problem-solving processes that happen in groups across academic and applied contexts.","",""
"2016","Engaging with (big) data visualizations: Factors that affect engagement and resulting new definitions of effectiveness","As data become increasingly ubiquitous, so too do data visualisations, which are the main means through which non-experts get access to data. Most visualizations circulate and are shared online, and many of them are produced by Internet researchers. For these reasons, data visualization is an important object of study for Internet research. This paper proposes that Internet research should engage critically with data visualization, and it does so by focusing on how people engage with them. Drawing on qualitative, empirical research with users, in this paper we identify six factors that affect engagement, which we define as socio-cultural: subject matter; source/media location; beliefs and opinions; time; emotions; and confidence and skills. We argue that our findings have implications for how effectiveness is defined in relation to data visualizations: such definitions vary depending on how, by whom, where and for what purpose visualizations are encountered. Our research also suggests that research into visualization engagement can benefit from adopting qualitative approaches developed within media audience research.","",""
"2016","Big data for the humanities using Google Ngrams: Discovering hidden patterns of conceptual trends","“Big data” methodologies bring new potential for humanities research. Google’s Ngram Viewer provides an extraordinary tool for tracking long-term usage of terms. Although this is a very high level trend analysis, it may shed light on hidden relations that can be discovered only at the macro resolution level. This short paper will attempt to analyze the historical hidden patterns of the term “Truth” during the last 500 years. Its relation with the term “Love” will be revealed. The results are also compared with the manual analysis of “Truth Systems,” by Pitirim Sorokin in 1937.","",""
"2016","A scholarly divide: Social media, Big Data, and unattainable scholarship","Recent decades have witnessed an increased growth in data generated by information, communication, and technological systems, giving birth to the ‘Big Data’ paradigm. Despite the profusion of raw data being captured by social media platforms, Big Data require specialized skills to parse and analyze — and even with the requisite skills, social media data are not readily available to download. Thus, the Big Data paradigm has not produced a coincidental explosion of research opportunities for the typical scholar. The promising world of unprecedented precision and predictive accuracy that Big Data conjure remains out of reach for most communication and technology researchers, a problem that traditional platforms, namely mass media, did not present. In this paper, we evaluate the system architecture that supports the storage and retrieval of big social data, distinguishing between overt and covert data types, and how both the cost and control of social media data limit opportunities for research. Ultimately, we illuminate a curious but growing ‘scholarly divide’ between researchers with the technical know-how, funding, or institutional connections to extract big social data and the mass of researchers who merely hear big social data invoked as the latest, exciting trend in unattainable scholarship.","",""
"2016","Big playerbase, big data: On data analytics methodologies and their applicability to studying multiplayer games and culture","Rapport with big data is something of a methodological rarity in empirical work on videogames, particularly within humanities oriented literature; an unusual omission considering the scope of many multiplayer game environments. Addressing this, the present work ventures the question ‘how can research into multiplayer videogames benefit from the use of big data’? I offer a response through a case study of Valve Software’s multiplayer game Dota 2, presenting a number of approaches which draw on player data analytics. In addition to mapping out frameworks for empirical research, I explore the theoretical dimensions of porting analytics based approaches to studies of multiplayer videogames, charting perceived incompatibilities between analytics approaches and popular ontologies of play, and how the prevalence of relational ontologies of play privilege particular modes of empirical inquiry.","",""
"2017","Exploring Neuromarketing and Its Reliance on Remote Sensing: Social and Ethical Concerns","This article evaluates the consequences of neuromarketers’ reliance on direct and indirect forms of remote sensing. These remote sensing strategies, tactics, and resources include various sophisticated techniques for evaluating neuronal and behavioral responses to commercial messages with the aid of functional magnetic resonance imaging (fMRI) technology. The information generated with the aid of fMRI, in combination with inferences drawn from the massive data analyses enabled by machine learning techniques, is expected to contribute to the power and influence of market-oriented segmentation and targeting. After characterizing the current state of and future trends in applied neuromarketing research, we discuss how reliance on descriptive, predictive, and prescriptive communications strategies enabled by remote sensing will affect the life chances and well-being of segments of the global population. We conclude with a discussion of the moral and ethical implications of these developments, primarily in the context of public policy deliberations related to privacy and surveillance that we associate with remote sensing.","",""
"2017","What Communication Can Contribute to Data Studies: Three Lenses on Communication and Data","We are awash in predictions about our data-driven future. Enthusiasts believe big data imposes new ways of knowing, while critics worry it will enable powerful regimes of institutional control. This debate has been of keen interest to communication scholars. To encourage conceptual clarity, this article draws on communication scholarship to suggest three lenses for data epistemologies. I review the common social scientific perspective of  communication as data . A  data as discourse  lens interrogates the meanings that data carries.  Communication around data  describes moments where data are constructed. By employing multiple perspectives, we might understand how data operate as a complex structure of dominance.","",""
"2017","Global Digital Culture| The Lurker and the Politics of Knowledge in Data Culture","This article explores the practice of lurking, developing the figure of the lurker as a conceptual persona. The lurker is a sage of the digital era, constructing a form of “private” knowledge. Not involved but performative, constative but only in a manner of probability, the lurker produces frameworks for private truth production through continuous self-adjustment. A mode of knowing and a method of being, lurking is about the poiesis of the embedded self and the power to establish conditionality in digital networks. A lurker maps out a plane that is occupied today by big data analytics. It is data algorithms that lurk, operating with sagacious data wisdoms rather than technical knowledge and constructing partial and probabilistic propositions. The article concludes by inquiring into the consequences of the current digital technical condition in which the conceptual persona of the lurker is fulfilled by algorithms, and its mode of knowing becomes a new mode of governance.","",""
"2017","Analytics in action: users and predictive data in the neonatal intensive care unit","ABSTRACT As the data phenomenon has grown, researchers have increasingly recognized the need to investigate algorithmic and data-driven technology, practices, and culture. While a number of studies have investigated the process of designing algorithms or examined the contours and consequences of algorithms themselves, more research is needed that details the ways in which users of data-driven technology make sense of algorithmic output and the conditions under which these processes unfold. This paper explores how users derive knowledge from predictive algorithms in medical contexts. Drawing upon interviews and observations of a neonatal intensive care unit, I examine how clinicians use data-driven predictive algorithms designed to forecast the onset of infection. Although the developers intend the technology to function as an early warning system, clinicians do not formulate knowledge from the technology solely as intended. Instead, I find that clinicians engage in a set of interpretive processes that I call ‘conditioned reading,’ and ‘accumulative reading.’ I suggest that these processes are possible due to the particular conditions of the medical context, including the institutional entrenchment of evidence-based medicine. I conclude by arguing that fully theorizing the social implications of data analytics will require researchers to investigate the role of institutional contexts.","",""
"2017","Taking Big Data apart: local readings of composite media collections","ABSTRACT If we are to think critically about Big Data initiatives, we must learn to take them apart. This paper explains how to interrogate Big Data, not as large homogenous resources, but as heterogeneous collections with varied and discordant local ties. My argument focuses on the Big Data of media collections: composite digital repositories of texts, images, and video created in different contexts, but brought together online. The primary example used in this paper is the Digital Public Library of America (DPLA), a collection composed of digitized library, museum and archive records from institutions across the United States. I demonstrate how local readings of DPLA data can uncover schemata, errors, infrastructures, classifications, absences, and rituals that have important origins. Moreover, I explain how identifying these local features can support new forms of scholarship, pedagogy, and advocacy in the face of Big Data. For this last point, I use two additional cases: NewsScape, a real-time archive of broadcast news, and Zillow, a marketplace for real estate listings. The range of examples demonstrates how the stakes change from one Big Data initiative to the next. The paper concludes with a set of speculative guidelines for attending to the local conditions in Big Data: get dirty, take a comparative approach, show context, use data to connect people, and create opportunities for the collection of counter-data. When working with Big Data, I argue that thinking locally is thinking critically.","",""
"2017","Big data as governmentality in international development: Digital traces, algorithms, and altered visibilities","ABSTRACT Statistics have long shaped the field of visibility for the governance of development projects. The introduction of big data has altered the field of visibility. Employing Dean's “analytics of government” framework, we analyze two cases—malaria tracking in Kenya and monitoring of food prices in Indonesia. Our analysis shows that big data introduces a bias toward particular types of visualizations. What problems are being made visible through big data depends to some degree on how the underlying data is visualized and who is captured in the visualizations. It is also influenced by technical factors such as distance between mobile phone towers and the truth claims that gain legitimacy.","",""
"2017","Making Sense of Sensors","Abstract                 The paper explores the different projects resulting from a practical workshop on making and hacking biosensors. The projects and the workshop enable a series of reflections about biosensors and their commercial promises and what they might offer to other constituents in digital arts theory and practice. These reflections include issues about expertise and how to “make with sensors,” how inner states of being can be communicated in social situations, non-human relations and the possibility of radical communication beyond the human, and questions about materiality and performance and the role of the manifesto in relation to devices. These points are developed to argue that despite the radical promise of biosensors to offer new forms of communication, the objects they produce often fail. However, the process of design and making opens up questions about the technological horizon and possibilities for connection in a device-orientated culture.","",""
"2017","Data, democracy and school accountability: Controversy over school evaluation in the case of DeVasco High School"," Debate over the closure of DeVasco High School shows that data-driven accountability was a methodological and administrative processes that produced both transparency and opacity. Data, when applied to a system of accountability, produced new capabilities and powers, and as such were political. It created second-hand representations of important objects of analysis. Using these representations administrators spoke on behalf of the school, the student and the classroom, without having to rely on the first-person accounts of students, teachers or principals. They empowered one group—central city administrators—over another—teachers and principals. After analyzing the form these policies took, this article concludes that it is necessary to rethink the processes that create visibility and invisibility. Public data obscured the voices, experiences and collective traumas of students and faculty within the school. A narrow focus on activities within the schools rendered invisible the structural decisions made by the Department of Education in New York City—to favor small schools over large, comprehensive ones. In order to create understanding, and a sense of common purpose, those who are spoken for in simplified data must also be given the opportunity to debate the representations of their performance and quality. ","",""
"2017","Mundane data: The routines, contingencies and accomplishments of digital living"," This article develops and mobilises the concept of ‘mundane data’ as an analytical entry point for understanding Big Data. We call for in-depth investigation of the human experiences, routines, improvisations and accomplishments which implicate digital data in the flow of the everyday. We demonstrate the value of this approach through a discussion of our ethnographic research with self-tracking cycling commuters. We argue that such investigations are crucial in informing our understandings of how digital data become meaningful in mundane contexts of everyday life for two reasons: first because there is a gap in our understanding of the contingencies and specificities through which big digital data sets are produced, and second because designers and policy makers often seek to make interventions for change in everyday contexts through the presentation of mundane data to consumers but with little understanding of how people produce, experience and engage with these data. ","",""
"2017","What is data justice? The case for connecting digital rights and freedoms globally","The increasing availability of digital data reflecting economic and human development, and in particular the availability of data emitted as a by-product of people’s use of technological devices and services, has both political and practical implications for the way people are seen and treated by the state and by the private sector. Yet the data revolution is so far primarily a technical one: the power of data to sort, categorise and intervene has not yet been explicitly connected to a social justice agenda by the agencies and authorities involved. Meanwhile, although data-driven discrimination is advancing at a similar pace to data processing technologies, awareness and mechanisms for combating it are not. This paper posits that just as an idea of justice is needed in order to establish the rule of law, an idea of data justice – fairness in the way people are made visible, represented and treated as a result of their production of digital data – is necessary to determine ethical paths through a datafying world. Bringing together the emerging scholarly perspectives on this topic, I propose three pillars as the basis of a notion of international data justice: (in)visibility, (dis)engagement with technology and antidiscrimination. These pillars integrate positive with negative rights and freedoms, and by doing so challenge both the basis of current data protection regulations and the growing assumption that being visible through the data we emit is part of the contemporary social contract.","",""
"2017","Virtual, visible, and actionable: Data assemblages and the sightlines of justice","This paper explores the politics of representing events in the world in the form of data points, data sets, or data associations. Data collection involves an act of seeing and recording something that was previously hidden and possibly unnamed. The incidences included in a data set are not random or unrelated but stand for coherent, classifiable phenomena in the world. Moreover, for data to have an impact on law and policy, such information must be seen as actionable, that is, the aggregated data must show people both something they can perceive and something that demands interrogation, explanation, or resolution. Actionable data problematize the taken-for-granted order of society by pointing to questions or imbalances that can be corrected or rectified, or simply better understood, through systematic compilations of occurrences, frequencies, distributions, or correlations. The paper describes and analyzes three different modes of authorized seeing that render data on global environmental phenomena such as climate change both visible and actionable. It argues that the political force of environmental data compilations derives from the divergent epistemological standpoints and expert practices associated with producing views from nowhere, everywhere, and somewhere.","",""
"2017","Challenges in administrative data linkage for research","Linkage of population-based administrative data is a valuable tool for combining detailed individual-level information from different sources for research. While not a substitute for classical studies based on primary data collection, analyses of linked administrative data can answer questions that require large sample sizes or detailed data on hard-to-reach populations, and generate evidence with a high level of external validity and applicability for policy making. There are unique challenges in the appropriate research use of linked administrative data, for example with respect to bias from linkage errors where records cannot be linked or are linked together incorrectly. For confidentiality and other reasons, the separation of data linkage processes and analysis of linked data is generally regarded as best practice. However, the ‘black box’ of data linkage can make it difficult for researchers to judge the reliability of the resulting linked data for their required purposes. This article aims to provide an overview of challenges in linking administrative data for research. We aim to increase understanding of the implications of (i) the data linkage environment and privacy preservation; (ii) the linkage process itself (including data preparation, and deterministic and probabilistic linkage methods) and (iii) linkage quality and potential bias in linked data. We draw on examples from a number of countries to illustrate a range of approaches for data linkage in different contexts.","",""
"2017","Trust and privacy in the context of user-generated health data"," This study identifies and explores evolving concepts of trust and privacy in the context of user-generated health data. We define “user-generated health data” as data captured through devices or software (whether purpose built or commercially available) and used outside of traditional clinical settings for tracking personal health data. The investigators conducted qualitative research through semistructured interviews (n = 32) with researchers, health technology start-up companies, and members of the general public to inquire why and how they interact with and understand the value of user-generated health data. We found significant results concerning new attitudes toward trust, privacy, and sharing of health data outside of clinical settings that conflict with regulations governing health data within clinical settings. Members of the general public expressed little concern about sharing health data with the companies that sold the devices or apps they used, and indicated that they rarely read the “terms and conditions” detailing how their data may be exploited by the company or third-party affiliates before consenting to them. In contrast, interviews with researchers revealed significant resistance among potential research participants to sharing their user-generated health data for purposes of scientific study. The widespread rhetoric of personalization and social sharing in “user-generated culture” appears to facilitate an understanding of user-generated health data that deemphasizes the risk of exploitation in favor of loosely defined benefits to individual and social well-being. We recommend clarification and greater transparency of regulations governing data sharing related to health. ","",""
"2017","Open data: Accountability and transparency","The movements by national governments, funding agencies, universities, and research communities toward “open data” face many difficult challenges. In high-level visions of open data, researchers’ data and metadata practices are expected to be robust and structured. The integration of the internet into scientific institutions amplifies these expectations. When examined critically, however, the data and metadata practices of scholarly researchers often appear incomplete or deficient. The concepts of “accountability” and “transparency” provide insight in understanding these perceived gaps. Researchers’ primary accountabilities are related to meeting the expectations of research competency, not to external standards of data deposition or metadata creation. Likewise, making data open in a transparent way can involve a significant investment of time and resources with no obvious benefits. This paper uses differing notions of accountability and transparency to conceptualize “open data” as the result of ongoing achievements, not one-time acts.","",""
"2017","Framing Big Data: The discursive construction of a radio cell query in Germany","The article examines the construction of “Big Data” in media discourse. Rather than asking what Big Data really is or is not, it deals with the discursive work that goes into making Big Data a socially relevant phenomenon and problem in the first place. It starts from the idea that in modern societies the public understanding of technology is largely driven by a media-based discourse, which is a key arena for circulating collectively shared meanings. This largely ignored dimension invites us to appreciate what matters to journalists and the wider public when discussing the collection and use of data. To this end, our study looks at how Big Data is framed in terms of the governmental use of large datasets as a contentious area of data application. It reconstructs the perspectives surrounding the so-called “Handygate” affair in Germany based on broadcast news and social media conversations. In this incident, state authorities collected and analyzed mobile phone data through a radio cell query during events to commemorate the Dresden bombing in February 2011. We employ a qualitative discourse analysis that allows us to reconstruct the conceptualizations of Big Data as a proper instrument for criminal prosecution or an unjustified infringement of constitutional rights.","",""
"2017","Stitching together the heterogeneous party: A complementary social data science experiment","The era of ‘big data’ studies and computational social science has recently given rise to a number of realignments within and beyond the social sciences, where otherwise distinct data formats – digital, numerical, ethnographic, visual, etc. – rub off and emerge from one another in new ways. This article chronicles the collaboration between a team of anthropologists and sociologists, who worked together for one week in an experimental attempt to combine ‘big’ transactional and ‘small’ ethnographic data formats. Our collaboration is part of a larger cross-disciplinary project carried out at the Danish Technical University (DTU), where high-resolution transactional data from smartphones allows for recordings of social networks amongst a freshman class (N = 800). With a parallel deployment of ethnographic fieldwork among the DTU students, this research set-up raises a number of questions concerning how to assemble disparate ‘data-worlds’ and to what epistemological and political effects? To address these questions, a specific social event – a lively student party – was singled out from the broader DTU dataset. Our experimental collaboration used recordings of Bluetooth signals between students’ phones to visualize the ebb and flow of social intensities at the DTU party, juxtaposing these with ethnographic field-notes on shifting party atmospheres. Tracing and reflecting on the process of combining heterogeneous data, the article offers a concrete case of how a ‘stitching together’ of digital and ethnographic data-worlds might take place.","",""
"2017","Data associations and the protection of reputation online in Australia"," This article focuses upon defamation law in Australia and its struggles to adjust to the digital landscape, to illustrate the broader challenges involved in the governance and regulation of data associations. In many instances, online publication will be treated by the courts in a similar fashion to traditional forms of publication. What is more contentious is the question of who, if anyone, should bear the responsibility for digital forms of defamatory publication which result not from an individual author’s activity online but rather from algorithmic associations. This article seeks, in part, to analyse this question, by reference to the Australian case law and associated scholarship regarding search engine liability. Reflecting on the tensions involved here offers us a fresh perspective on defamation law through the conceptual lens of data associations. Here the focus of the article shifts to explore some wider questions posed for defamation law by big data. Defamation law may come to play a significant role in emerging frameworks for algorithmic accountability, but these developments also call into question many of its traditional concepts and assumptions. It may be time to think differently about defamation and to consider its interrelationship with privacy, speech and data protection more fully. As a result, I conclude that the courts and policymakers need to engage more deeply and explicitly with the rationale(s) for the protection of reputation and that more thought needs to be given to changing conceptions of reputation in the context of data associations. ","",""
"2017","Data ideologies of an interested public: A study of grassroots open government data intermediaries"," Government officials claim open data can improve internal and external communication and collaboration. These promises hinge on “data intermediaries”: extra-institutional actors that obtain, use, and translate data for the public. However, we know little about why these individuals might regard open data as a site of civic participation. In response, we draw on Ilana Gershon to conceptualize culturally situated and socially constructed perspectives on data, or “data ideologies.” This study employs mixed methodologies to examine why members of the public hold particular data ideologies and how they vary. In late 2015 the authors engaged the public through a commission in a diverse city of approximately 500,000. Qualitative data was collected from three public focus groups with residents. Simultaneously, we obtained quantitative data from surveys. Participants’ data ideologies varied based on how they perceived data to be useful for collaboration, tasks, and translations. Bucking the “geek” stereotype, only a minority of those surveyed (20%) were professional software developers or engineers. Although only a nascent movement, we argue open data intermediaries have important roles to play in a new political landscape. ","",""
"2017","Understanding the care.data conundrum: New information flows for economic growth"," The analysis of data from electronic health records aspires to facilitate healthcare efficiencies and biomedical innovation. There are also ethical, legal and social implications from the handling of sensitive patient information. The paper explores the concerns, expectations and implications of the National Health Service (NHS) England care.data programme: a national data sharing initiative of linked electronic health records for healthcare and other research purposes. Using Nissenbaum’s contextual integrity of privacy framework through a critical Science and Technology Studies (STS) lens, it examines the way technologies and policies are developed to promote sustainability, governance and economic growth as the de facto social values, while reducing privacy to an individualistic preference. The state, acting as a new, central data broker reappropriates public ownership rights and establishes those information flows and transmission principles that facilitate the assetisation of NHS datasets for the knowledge economy. Various actors and processes from other contexts attempt to erode the public healthcare sector and privilege new information recipients. However, such data sharing initiatives in healthcare will be resisted if we continue to focus only on the monetary and scientific values of these datasets and keep ignoring their equally important social and ethical values. ","",""
"2017","The place of conditionality and individual responsibility in a “data-driven economy”","Advances in information and communication technologies enable more decentralized and individualized mechanisms for coordination and for managing societal complexity. This has important consequences for the role of conditionality and the idea of individual responsibility in two seemingly unrelated policy areas. First, the changing information infrastructure enables an extension of conditionality in the area of welfare through greater activation, enhanced self-management, and a personalization of risks. Second, conditionality and personal responsibility also form an important ideational template and a legitimatory basis for facilitating value creation that is based on data as a raw material. This argument is illustrated looking at the trajectories of the digital strategies in the United Kingdom and Germany. In both cases, data protection is depicted as a question of individual responsibility and tied to certain forms of individual conduct.","",""
"2017","Big Data is not only about data: The two cultures of modelling"," The contribution of Big Data to social science is not limited to data availability but includes the introduction of analytical approaches that have been developed in computer science, and in particular in machine learning. This brings about a new ‘culture’ of statistical modelling that bears considerable potential for the social scientist. This argument is illustrated with a brief discussion of model-based recursive partitioning which can bridge the theory and data-driven approach. Such a method is an example of how this new approach can help revise models that work for the full dataset: it can be used for evaluating different models, a traditional weakness of the ‘traditional’ statistical approach used in social science. ","",""
"2017","Big Data, urban governance, and the ontological politics of hyperindividualism"," Big Data’s calculative ontology relies on and reproduces a form of hyperindividualism in which the ontological unit of analysis is the discrete data point, the meaning and identity of which inheres in itself, preceding, separate, and independent from its context or relation to any other data point. The practice of Big Data governed by an ontology of hyperindividualism is also constitutive of that ontology, naturalizing and diffusing it through practices of governance and, from there, throughout myriad dimensions of everyday life. In this paper, I explicate Big Data’s ontology of hyperindividualism by contrasting it to a coconstitutive ontology that prioritizes relationality, context, and interdependence. I then situate the ontology of hyperindividualism in its genealogical context, drawing from Patrick Joyce’s history of liberalism and John Dewey’s pragmatist account of individualism, liberalism, and social action. True to its genealogical provenance, Big Data’s ontological politics of hyperindividualism reduces governance to the management of atomistic behavior, undermines the contribution of urban complexity as a resource for governance, erodes the potential for urban democracy, and eviscerates the possibility of collective resistance. ","",""
"2017","Data politics","The commentary raises political questions about the ways in which data has been constituted as an object vested with certain powers, influence, and rationalities. We place the emergence and transformation of professional practices such as ‘data science’, ‘data journalism’, ‘data brokerage’, ‘data mining’, ‘data storage’, and ‘data analysis’ as part of the reconfiguration of a series of fields of power and knowledge in the public and private accumulation of data. Data politics asks questions about the ways in which data has become such an object of power and explores how to critically intervene in its deployment as an object of knowledge. It is concerned with the conditions of possibility of data that involve things (infrastructures of servers, devices, and cables), language (code, programming, and algorithms), and people (scientists, entrepreneurs, engineers, information technologists, designers) that together create new worlds. We define ‘data politics’ as both the articulation of political questions about these worlds and the ways in which they provoke subjects to govern themselves and others by making rights claims. We contend that without understanding these conditions of possibility – of worlds, subjects and rights – it would be difficult to intervene in or shape data politics if by that it is meant the transformation of data subjects into data citizens.","",""
"2017","‘Depends on Who’s Got the Data’: Public Understandings of Personal Digital Dataveillance","Post-Snowden, several highly-publicised events and scandals have drawn attention to the use of people’s personal data by other actors and agencies, both legally and illicitly. In this article, we report the findings of a project in which we used cultural probes to generate discussion about personal digital dataveillance. What emerged from our focus groups is a somewhat diffuse but quite extensive understanding on the part of the participants of the ways in which data may be gathered about them and the uses to which these data may be put. We found that the participants tended to veer between recognising the value of both personal data and the big aggregated data sets that their own data may be part of, particularly for their own convenience, and expressing concern or suspicion about how these data may be used by others. Our findings suggest that experimenting with innovative approaches to elicit practices and understandings of personal digital data offers further possibilities for greater depth and breadth of social research with all types of social groups. ","",""
"2017","Big data and learning analytics: Singular or plural?","Recent critiques of both the uses of and discourse surrounding big data have raised important questions as to the extent to which big data and big data techniques should be embraced. However, while the context-dependence of data has been recognized, there remains a tendency among social theorists and other commentators to treat certain aspects of the big data phenomenon, including not only the data but also the methods and tools used to move from data as database to data that can be interpreted and assigned meaning, in a homogenizing way. In this paper, we seek to challenge this tendency, and to explore the ways in which explicit consideration of the plurality of big data might inform particular instances of its exploitation. We compare one currently popular big data-inspired innovation — learning analytics — with three other big data contexts — the physical sciences, business intelligence and public health. Through these comparisons, we highlight some dangers of learning analytics implemented without substantial theoretical, ethical and design effort. In so doing, we also highlight just how plural data, analytical approaches and intentions are, and suggest that each new big data context needs to be recognized in its own singularity.","",""
"2017","Feeling your data: Touch and making sense of personal digital data"," People’s encounters and entanglements with the personal digital data that they generate is a new and compelling area of research interest in this age of the ascendancy of digital data. Masses of personal information are constantly generated via people’s use of digital technologies and used for a variety of purposes by a range of actors. People are faced with the conundrum of how to interpret, control and make sense of their lively data. In this article, I explore the topic of how personal digital data and their circulations can be made more perceptible and therefore interpretable to people with the use of three-dimensional materialisations. These materialisations invite users to ‘feel your data’. As I show, ‘feeling your data’ has two meanings: the sensations of touching these three-dimensional objects and the visceral responses that are generated from these and other sensory encounters with data. ","",""
"2017","The big data public and its problems: Big data and the structural transformation of the public sphere"," The use of algorithms to mine big data for media preferences presents a transformation in the structure of the public sphere that is amplifying the tyranny of the majority. Whereas previous scholarship has lamented the fragmentation of the public sphere caused by the use of big data to inform audience analysis and media production, I argue here that fragmentation itself is not an implicitly bad thing for public debate, as fragmentation can encourage participation from the otherwise disempowered. Instead, I suggest that the use of big data to inform media production causes problems in the public sphere not because it fragments public debate, but because it somewhat paradoxically recentres public engagement around the complementary interests of the broad majority and profitability. The problem for public engagement is not that there are no overarching or all-encompassing media structures anymore but rather that these systems are informed by algorithms that promote a particularly populist ‘profitable and normal’ media experience. ","",""
"2017","Making Data Flow for the Climate Risk Market"," In 2011, the U.K. government announced that the national meteorological agency would be releasing a significant volume of data as part of its Open Data policy agenda. This article explores the interrelationship between this announcement and efforts to boost the competitiveness of the United Kingdom’s weather derivatives industry. Primary qualitative data are analyzed to produce a genealogical account of these policy developments, and Braman’s concept of “informational power” is used to frame a critical narrative of the broader dynamics of power at play. We argue that although there have been significant tensions around efforts to open the United Kingdom’s weather data, these have largely been absorbed by and, ultimately, contained within the hegemonic structures of the United Kingdom’s neoliberal state. We conclude by arguing that this struggle needs to be broadened and externalized beyond the state so that critical questions about the deepening data-driven financialization of climate change can be addressed. ","",""
"2017","The Pleasure and Pain of Visualizing Data in Times of Data Power"," This article reflects on the growing urge among researchers to visualize large-scale digital data. It argues that the desire to visualize unfolds in the context of a complex entanglement of (1) the pragmatics of data visualization, (2) the problematic ideological work that visualizations do, (3) the politics of data power and neoliberalism, and (4) visualization pleasures. The article begins by outlining the considerations that constitute data visualization design, highlighting the complexity of the process. It then provides an overview of critical debates about the way that visualizations work, which are relevant to reflective visualization practice. Then, it turns to the context (of datafication and the neoliberalization of the university) in which academic researchers contemplate visualization futures and which simultaneously constrains the realization of these futures. Finally, the article acknowledges the cracks in these structures, the pleasure of visualizing data, for example, in using visualization for advocacy and social justice. ","",""
"2017","Data Power in Education: Exploring Critical Awareness with the “Learning Analytics Report Card”"," The burgeoning field of learning analytics (LA) is gaining significant traction in education, bolstered by the increasing amounts of student data generated through educational software. However, critical discussions of LA are in short supply. Drawing on work in the cultural studies of data and critical algorithm studies, this paper begins by examining three central issues: the distancing and “black boxing” of LA disciplinary practices, the mythologizing of objective data, and the concern for future prediction. The second section describes the design and implementation of the “Learning Analytics Report Card” (LARC), a pilot project that sought to develop experimental approaches to LA. As such, rather than seeking to simply produce analytics, the LARC attempted to foster critical awareness of computational data analysis among teachers and learners. ","",""
"2018","Data Publics: Urban Protest, Analytics and the Courts","This article reflects on part of a three-year battle over the redevelopment of an iconic Melbourne music venue, the Palace-Metro Nightclub (the Palace), involving the tactical use of Facebook Page data at trial. We were invited by the Save the Palace group, Melbourne City Council and the National Trust of Australia to provide Facebook Page data analysis as evidence of the social value of the venue at an appeals trial heard at the Victorian Civil Administration Tribunal (VCAT) in 2016. We take a reflexive ethnographic approach here to explore the data production, collection and analysis processes as these represent and constitute a “data public”.Although the developers won the appeal and were able to re-develop the site, the court accepted the validity of social media data as evidence of the building’s social value (Jinshan Investment Group Pty Ltd v Melbourne CC [2016] VCAT 626, 117; see also Victorian Planning Reports). Through the case, we elaborate on the concept of data publics by considering the “affordising” (Pollock) processes at play when extracting, analysing and visualising social media data. Affordising refers to the designed, deliberate and incidental effects of datafication and highlights the need to attend to the capacities for data collection and processing as they produce particular analytical outcomes. These processes foreground the compositional character of data publics, and the unevenness of data literacies (McCosker “Data Literacies”; Gray et al.) as a factor of the interpersonal and institutional capacity to read and mobilise data for social outcomes.We begin by reconsidering the often-assumed connection between social media data and their publics. Taking onboard theoretical accounts of publics as problem-oriented (Dewey) and dynamically constituted (Kelty), we conceptualise data publics through the key elements of a) consequentiality, b) sufficient connection over time, c) affective or emotional qualities of connection and interaction with the events. We note that while social data analytics may be a powerful tool for public protest, it equally affords use against public interests and introduces risks in relation to a lack of transparency, access or adequate data literacy.Urban Protest and Data Publics There are many examples globally of the use of social media to engage publics in battles over urban development or similar issues (e.g. Fredericks and Foth). Some have asked how social media might be better used by neighborhood organisations to mobilise protest and save historic buildings, cultural landmarks or urban sites (Johnson and Halegoua). And we can only note here the wealth of research literature on social movements, protest and social media. To emphasise Gerbaudo’s point, drawing on Mattoni, we “need to account for how exactly the use of these media reshapes the ‘repertoire of communication’ of contemporary movements and affects the experience of participants” (2). For us, this also means better understanding the role that social data plays in both aiding and reshaping urban protest or arming third sector groups with evidence useful in social institutions such as the courts.New modes of digital engagement enable forms of distributed digital citizenship, which Meikle sees as the creative political relationships that form through exercising rights and responsibilities. Associated with these practices is the transition from sanctioned, simple discursive forms of social protest in petitions, to new indicators of social engagement in more nuanced social media data and the more interactive forms of online petition platforms like change.org or GetUp (Halpin et al.). These technical forms code publics in specific ways that have implications for contemporary protest action. That is, they provide the operational systems and instructions that shape social actions and relationships for protest purposes (McCosker and Milne).All protest and social movements are underwritten by explicit or implicit concepts of participatory publics as these are shaped, enhanced, or threatened by communication technologies. But participatory protest publics are uneven, and as Kelty asks: “What about all the people who are neither protesters nor Twitter users? In the broadest possible sense this ‘General Public’ cannot be said to exist as an actual entity, but only as a kind of virtual entity” (27). Kelty is pointing to the porous boundary between a general public and an organised public, or formal enterprise, as a reminder that we cannot take for granted representations of a public, or the public as a given, in relation to Like or follower data for instance.If carefully gauged, the concept of data publics can be useful. To start with, the notions of publics and publicness are notoriously slippery. Baym and boyd explore the differences between these two terms, and the way social media reconfigures what “public” is. Does a Comment or a Like on a Facebook Page connect an individual sufficiently to an issues-public? As far back as the 1930s, John Dewey was seeking a pragmatic approach to similar questions regarding human association and the pluralistic space of “the public”. For Dewey, “the machine age has so enormously expanded, multiplied, intensified and complicated the scope of the indirect consequences [of human association] that the resultant public cannot identify itself” (157). To what extent, then, can we use data to constitute a public in relation to social protest in the age of data analytics?There are numerous well formulated approaches to studying publics in relation to social media and social networks. Social network analysis (SNA) determines publics, or communities, through links, ties and clustering, by measuring and mapping those connections and to an extent assuming that they constitute some form of sociality. Networked publics (Ito, 6) are understood as an outcome of social media platforms and practices in the use of new digital media authoring and distribution tools or platforms and the particular actions, relationships or modes of communication they afford, to use James Gibson’s sense of that term. “Publics can be reactors, (re)makers and (re)distributors, engaging in shared culture and knowledge through discourse and social exchange as well as through acts of media reception” (Ito 6). Hashtags, for example, facilitate connectivity and visibility and aid in the formation and “coordination of ad hoc issue publics” (Bruns and Burgess 3). Gray et al., following Ruppert, argue that “data publics are constituted by dynamic, heterogeneous arrangements of actors mobilised around data infrastructures, sometimes figuring as part of them, sometimes emerging as their effect”. The individuals of data publics are neither subjugated by the logics and metrics of digital platforms and data structures, nor simply sovereign agents empowered by the expressive potential of aggregated data (Gray et al.).Data publics are more than just aggregates of individual data points or connections. They are inherently unstable, dynamic (despite static analysis and visualisations), or vibrant, and ephemeral. We emphasise three key elements of active data publics. First, to be more than an aggregate of individual items, a data public needs to be consequential (in Dewey’s sense of issues or problem-oriented). Second, sufficient connection is visible over time. Third, affective or emotional activity is apparent in relation to events that lend coherence to the public and its prevailing sentiment. To these, we add critical attention to the affordising processes – or the deliberate and incidental effects of datafication and analysis, in the capacities for data collection and processing in order to produce particular analytical outcomes, and the data literacies these require. We return to the latter after elaborating on the Save the Palace case.Visualising Publics: Highlighting Engagement and IntensityThe Palace theatre was built in 1912 and served as a venue for theatre, cinema, live performance, musical acts and as a nightclub. In 2014 the Heritage Council decided not to include the Palace on Victoria’s heritage register and hence opened the door for developers, but Melbourne City Council and the National Trust of Australia opposed the redevelopment on the grounds of the building’s social significance as a music venue. Similarly, the Save the Palace group saw the proposed redevelopment as affecting the capacity of Melbourne CBD to host medium size live performances, and therefore impacting deeply on the social fabric of the local music scene. The Save the Palace group, chaired by Rebecca Leslie and Michael Raymond, maintained a 36,000+ strong Facebook Page and mobilised local members through regular public street protests, and participated in court proceedings in 2015 and February 2016 with Melbourne City Council and National Trust Australia. Joining the protesters in the lead up to the 2016 appeals trial, we aimed to use social media engagement data to measure, analyse and present evidence of the extent and intensity of a sustained protest public. The evidence we submitted had to satisfy VCAT’s need to establish the social value of the building and the significance of its redevelopment, and to explain: a) how social media works; b) the meaning of the number of Facebook Likes on the Save The Palace Page and the timing of those Likes, highlighting how the reach and Likes pick up at significant events; and c) whether or not a representative sample of Comments are supportive of the group and the Palace Theatre (McCosker “Statement”). As noted in the case (Jinshan, 117), where courts have traditionally relied on one simple measure for contemporary social value – the petition – our aim was to make use of the richer measures available through social media data, to better represent sustained engagement with the issues over time.Visualising a protest public in this way raises two significant problems for a workable concept of data publics. The first involves the “affordising” (Pollock) work of both the platform and our data analysis. This concerns the role played by data access and platform affordances for data capture, along with methodological choices made to best realise or draw out the affordances of the data for our purposes. The second concerns the issue of digital and data literacies in both the social acts that help to constitute a data public in the first place, and the capacity to read and write public data to represent those activities meaningfully. That is, Facebook and our analysis constitutes a data public in certain ways that includes potentially opaque decisions or processes. And citizens (protesters or casual Facebook commenters alike) along with social institutions (like the courts) have certain uneven capacity to effectively produce or read public protest-oriented data. The risk here, which we return to in the final section, lies in the potential for misrepresentation of publics through data, exclusions of access and ownership of data, and the uneven digital literacies at each stage of data production, analysis and sensemaking.Facebook captures data about individuals in intricate detail. Its data capture strategies are geared toward targeting for the purposes of marketing, although only a small subset of the data is publicly available through the Facebook Application Programming Interface (API), which is a kind of data “gateway”. The visible page data tells only part of the story. The total Page Likes in February 2016 was 36,828, representing a sizeable number of followers, mainly located in Melbourne but including 45 countries in total and 38 different languages. We extracted a data set of 268,211 engagements with the Page between February 2013 and August 2015. This included 45,393 post Likes and 9,139 Comments. Our strategy was to demarcate a structurally defined “community” (in the SNA sense of that term as delineating clusters of people, activities and links within a broader network), by visualising the interactions of Facebook users with Posts over time, and then examine elements of intensity of engagement. In other words, we “affordised” the network data using SNA techniques to most clearly convey the social value of the networked public.We used a combination of API access and Facebook’s native Insights data and analytics to extract use-data from that Page between June 2013 and December 2015. Analysis of a two-mode or bipartite network consisting of users and Posts was compiled using vosonSML, a package in the R programming language created at Australian National University (Graham and Ackland) and visualised with Gephi software. In this network, the nodes (or vertices) represent Facebook users and Facebook Posts submitted on the Page, and ties (or edges) between nodes represent whether a user has commented on and/or liked a post. For example, a user U might have liked Post A and commented on Post B. Additionally, a weight value is assigned for the Comments ties, indicating how many times a user commented on a particular post (note that users can only like Posts once). We took these actions as demonstrating sufficient connection over time in relation to an issue of common concern.Figure 1: Network visualisation of activity on the Save the Palace Facebook Page, June 2013 to December 2015. The colour of the nodes denotes which ‘community’ cluster they belong to (computed via the Infomap algorithm) and nodes are sized by out-degree (number of Likes/Comments made by users to Posts). The graph layout is computed via the Force Atlas 2 algorithm.Community detection was performed on the network using the Infomap algorithm (Rosvall and Bergstrom), which is suited to large-scale weighted and directed networks (Henman et al.). This analysis reveals two large and two smaller clusters or groups represented by colour differences (Fig. 1). Broadly, this suggests the presence of several clusters amongst a sustained network engaging with the page over the three years. Beyond this, a range of other colours denoting smaller clusters indicates a diversity of activity and actors co-participating in the network as part of a broader community.The positioning of nodes within the network is not random – the visualisation is generated by the Force Atlas 2 algorithm (Jacomy et al.) that spatially sorts the nodes through processes of attraction and repulsion according to the observed patterns of connectivity. As we would expect, the two-dimensional spatial arrangement of nodes conforms to the community clustering, helping us to visualise the network in the form of a networked public, and build a narrative interpretation of “what is going on” in this online social space.Social value for VCAT was loosely defined as a sense of connection, sentiment and attachment to the venue. While we could illustrate the extent of the active connections of those engaging with the Page, the network map does not in itself reveal much about the sentiment, or the emotional attachment to the Save the Palace cause. This kind of affect can be understood as “the energy that drives, neutralizes, or entraps networked publics” (Papacharissi 7), and its measure presents a particular challenge, but also interest, for understanding a data public. It is often measured through sentiment analysis of content, but we targeted reach and engagement events – particular moments that indicated intense interaction with the Page and associated events.Figure 2: Save the Palace Facebook Page: Organic post reach November—December 2014The affective connection and orientation could be demonstrated through two dimensions of post “reach”: average reach across the lifespan of the Page, and specific “reach-events”. Average reach illustrates the sustained engagement with the Page over time. Average un-paid reach for Posts with links (primarily news and legal updates), was 12,015 or 33% of the total follower base – a figure well above the standard for Community Page reach at that time. Reach-events indicated particular points of intensity and illustrates the Page’s ability to resonate publicly. Figure 2 points to one such event in November 2015, when news circulated that the developers were defying stop-work orders and demolishing parts of The Palace. The 100k reach indicated intense and widespread activity – Likes, Shares, Comments – in a short timeframe. We examined Comment activity in relation to specific reach events to qualify this reach event and illustrate the sense of outrage directed toward the developers, and expressions of solidarity toward those attempting to stop the redevelopment.      Affordising Data Publics and the Transformative Work of AnalyticsEach stage of deriving evidence of social value through Page data, from building public visibility and online activity to analysis and presentation at VCAT, was affected by the affordising work of the protesters involved (particularly the Page Admins), civil society groups, platform features and data structures and our choices in analysis and presentation. The notion of affordising is useful here because, as Pollock defines the term, it draws attention to the transformative work of metrics, analytics, platform features and other devices that re-package social activity through modes of datafication and analysis. The Save the Palace group mobilised in a particular way so as to channel their activities, make them visible and archival, to capture the resonant effects of their public protest through a platform that would best make that public visible to itself. The growth of the interest in the Facebook Page feeds back on itself reflexively as more people encounter it and participate. Contrary to critiques of “clicktivism”, these acts combine digital-material events and activities that were to become consequential for the public protest – such as the engagement activities around the November 2015 event described in Figure 2.In addition, presenting the research in court introduced particular hurdles, in finding “the meaningful data” appropriate to the needs of the case, “visualizing social data for social purposes”, and the need to be “evocative as well as accurate” (Donath, 16). The visualisation and presentation of the data needed to afford a valid and meaningful expression of the social significance the Palace. Which layout algorithm to use? What scale do we want to use? Which community detection algorithm and colour scheme for nodes? These choices involve challenges regarding legibility of visualisations of public data (McCosker and Wilken; Kennedy et al.).The transformative actions at play in these tactics of public data analysis can inform other instances of data-driven protest or social participation, but also leave room for misuse. The interests of developers, for example, could equally be served by monitoring protesters’ actions through the same data, or by targeting disagreement or ambiguity in the data. Similarly, moves by Facebook to restrict access to Page data will disproportionately affect those without the means to pay for access. These tactics call for further work in ethical principles of open data, standardisation and data literacies for the courts and those who would benefit from use of their own public data in this way.ConclusionsWe have argued through the case of the Save the Palace protest that in order to make use of public social media data to define a data public, multiple levels of data literacy, access and affordising are required. Rather than assuming that public data simply constitutes a data public, we have emphasised: a) the consequentiality of the movement; b) sufficient connection over time; and c) affective or emotional qualities of connection and interaction with public events. This includes the activities of the core members of the Save the Palace protest group, and the tens of thousands who engaged in some way with the Page. It also involves Facebook’s data affordances as these allow for the extraction of public data, alongside our choices in analysis and visualisation, and the court’s capacity and openness to accept all of this as indicative of the social value (connections, sentiment, attachment) it sought for the case. The Senior Member and Member presiding over the case had little knowledge of Facebook or other social media platforms, did not use them, and hence themselves had limited capacity to recognise the social and cultural nuances of activities that took place through the Facebook Page. This does not exclude the use of the data but made it more difficult to present a picture of the relevance and consequence of the data for understanding the social value evident in the contested building. While the court’s acceptance of the analysis as evidence is a significant starting point, further work is required to ensure openness, standardisation and ethical treatment of public data within public institutions like the courts. ReferencesBruns, A., and J. Burgess. “The Use of Twitter Hashtags in the Formation of Ad Hoc Publics.” 6th European Consortium for Political Research General Conference, University of Iceland, Reykjavík, 25-27 August 2011. 1 Aug. 2018 &lt;http://eprints.qut.edu.au/46515/&gt;.Baym, N.K., and d. boyd. “Socially Mediated Publicness: An Introduction.” Journal of Broadcasting &amp; Electronic Media 56.3 (2012): 320-329.Dewey, J. The Public and Its Problems: An Essay in Political Inquiry. Athens, Ohio: Swallow P, 2016 [1927].Donath, J. The Social Machine: Designs for Living Online. Cambridge: MIT P, 2014.Fredericks, J., and M. Foth. “Augmenting Public Participation: Enhancing Planning Outcomes through the Use of Social Media and Web 2.0.” Australian Planner 50.3 (2013): 244-256.Gerbaudo, P. Tweets and the Streets: Social Media and Contemporary Activism. New York: Pluto P, 2012.Gibson, J.J. The Ecological Approach to Visual Perception. Boston: Houghton Mifflin Harcourt, 1979.Graham, T., and R. Ackland. “SocialMediaLab: Tools for Collecting Social Media Data and Generating Networks for Analysis.” CRAN (The Comprehensive R Archive Network). 2018. 1 Aug. 2018 &lt;https://cran.r- project.org/web/packages/SocialMediaLab/SocialMediaLab.pdf&gt;.Gray J., C. Gerlitz, and L. Bounegru. “Data Infrastructure Literacy.” Big Data &amp; Society 5.2 (2018). 1 Aug. 2018 &lt;https://doi.org/10.1177/2053951718786316&gt;.Halpin, T., A. Vromen, M. Vaughan, and M. Raissi. “Online Petitioning and Politics: The Development of Change.org in Australia.” Australian Journal of Political Science (2018). 1 Aug. 2018 &lt;https://doi.org/10.1080/10361146.2018.1499010&gt;.Henman, P., R. Ackland, and T. Graham. “Community Structure in e-Government Hyperlink Networks.” Proceedings of the 14th European Conference on e-Government (ECEG ’14), 12-13 June 2014, Brasov, Romania.Ito, M. “Introduction.” Networked Publics. Ed. K. Varnelis. Cambridge, MA.: MIT P, 2008. 1-14.Jacomy M., T. Venturini, S. Heymann, and M. Bastian. “ForceAtlas2, a Continuous Graph Layout Algorithm for Handy Network Visualization Designed for the Gephi Software.” PLoS ONE 9.6 (2014): e98679. 1 Aug. 2018 &lt;https://doi.org/10.1371/journal.pone.0098679&gt;.Jinshan Investment Group Pty Ltd v Melbourne CC [2016] VCAT 626, 117. 2016. 1 Aug. 2018 &lt;https://bit.ly/2JGRnde&gt;.Johnson, B., and G. Halegoua. “Can Social Media Save a Neighbourhood Organization?” Planning, Practice &amp; Research 30.3 (2015): 248-269.Kennedy, H., R.L. Hill, G. Aiello, and W. Allen. “The Work That Visualisation Conventions Do.” Information, Communication &amp; Society, 19.6 (2016): 715-735.Mattoni, A. Media Practices and Protest Politics: How Precarious Workers Mobilise. Burlington, VT: Ashgate, 2012.McCosker, A. “Data Literacies for the Postdemographic Social Media Self.” First Monday 22.10 (2017). 1 Aug. 2018 &lt;http://firstmonday.org/ojs/index.php/fm/article/view/7307/6550&gt;.McCosker, A. “Statement of Evidence: Palace Theatre Facebook Page Analysis.” Submitted to the Victorian Civil Administration Tribunal, 7 Dec. 2015. 1 Aug. 2018 &lt;https://www.academia.edu/37130238/Evidence_Statement_Save_the_Palace_Facebook_Page_Analysis_VCAT_2015_&gt;.McCosker, A., and M. Esther. """"Coding Labour."""" Cultural Studies Review 20.1 (2014): 4-29.McCosker, A., and R. Wilken. “Rethinking ‘Big Data’ as Visual Knowledge: The Sublime and the Diagrammatic in Data Visualisation.” Visual Studies 29.2 (2014): 155-164.Meikle, G. Social Media: Communication, Sharing and Visibility. New York: Routledge, 2016.Papacharissi, Z. Affective Publics: Sentiment, Technology, and Politics. Oxford: Oxford UP, 2015.Pollock, N. “Ranking Devices: The Socio-Materiality of Ratings.” Materiality and Organizing: Social Interaction in a Technological World. Eds. P.M. Leonardi, Bonnie A. Nardi, and J. Kallinikos. Oxford: Oxford UP, 2012. 91-114.Rosvall, M., and C.T. Bergstrom. “Maps of Random Walks on Complex Networks Reveal Community Structure.” Proceedings of the National Academy of Sciences of the United States of America 105.4 (2008): 1118-1123.Ruppert E. “Doing the Transparent State: Open Government Data as Performance Indicators.” A World of Indicators: The Making of Governmental Knowledge through Quantification. Eds. R. Rottenburg S.E. Merry, S.J. Park, et al. Cambridge: Cambridge UP, 2015. 1–18.Smith, N., and T. Graham. “Mapping the Anti-Vaccination Movement on Facebook.” Information, Communication &amp; Society (2017). 1 Aug. 2018 &lt;https://doi.org/10.1080/1369118X.2017.1418406&gt;.Victorian Planning Reports. “Editorial Comment.” VCAT 3.16 (2016). 1 Aug. 2018 &lt;https://www.vprs.com.au/394-past-editorials/vcat/1595-vcat-volume-3-no-16&gt;.","",""
"2018","Data Desire in the Anthropocene","Data desire flows through protest in the Anthropocene. Citizen science, participation in online discussion forums, documentary film production, protest selfies, glacier recession GPS photography, poster making, etc., are just some of the everyday data proliferation efforts comprising resistance to environmental degradation and destruction. These practices – visualisation, datafication, writing, sign making, archiving geological memory, etc., are, I want to argue, produced pleasurably, especially as modes of emerging as ‘subjects’ in relation to the chaos, chaotic affects, and unprecedented pace of destructive ecological events that these practices try to grasp or ‘make sense of.’ Pleasures of data production are hence closely correlated to emerging as a subject within the Anthropocene. Such pleasures function beyond individual emotion, and in relation to subjectification within chaotic events such as climate change. In this article I propose the concept data desire to map out how ‘data’ and ‘subjectivity’ co-emerge in relation to material forces and how people take pleasure in their subjectification through ‘knowing,’ datafying, and creating ‘meaning’ out of material events which are chaotic or have chaotic affects (Guattari).  I take up contrasting terms of ‘pleasure’ and ‘desire’, drawing on the thought of Gilles Deleuze (""""Desire""""; Essays), for whom pleasure is associated with a craving of individuation in light of chaos while desire speaks to the unlimited postponement of events from being summarised. One such event, and the event I focus on in this article, is oil. Here, I think of the event, not as ‘a moment’ or a ‘happening,’ but as that which has many iterations, instances, and bifurcations, and is often distributed in space and time (Deleuze, The Fold). I draw on my fieldwork in media practices of people taking part in the oil pipeline protests in British Columbia, Canada. I give examples of three data practices, and articulate the relation between media production, generation of ‘data’ and the production of subjectivity within the Anthropocene. These practices include data generation through participation in online news’ comment forums, data created as part of citizen science, and resistance ‘selfies’ or producing oneself as data to be circulated on social media. My analysis diverts from any interest in the representational function of media, towards how pleasures of data practices and the circulation of desire that these are a part of emerge, for many people, as the only ways of becoming subjectified in catastrophic environmental events.Pleasure and desire may not be the most obvious terms to think of when one thinks of resistance, particularly against environmental degradation. While pleasure has been an important aspect of activism, social movements, and feminist politics (e.g. Goodwin, Jasper, and Polletta; Sharpe), it has only recently been engaged with in relation to environmental activism, particularly by Craig, and Alaimo. Alaimo defines pleasure as an important aspects of material engagements and more-than-human ontologies marked by connection and kinship characterised by delight. Craig also calls for the recognition that pleasure is central to the everyday lived resistance found in environmental movements such as the slow food movement and urban farming that are anti-consumerist in orientation. These examples mark pleasure as part of the politics of resistance where the emotion emerges from the belief in a harmonious and symbiotic relationship to ‘nature’ and non-human matter through human emotion. Pleasure however, as I intend to show, can also be thought of beyond the individuating ‘emotion’ and as part of larger flows of desire, where ‘desire’ is conceptualised as vitality and ‘ongoing production’ (Deleuze &amp; Guattari, Anti-Oedipus). Particularly, my focus on pleasure intends to problematise how pleasure through data production emerges perhaps as a mode of ongoing ‘coping’ of ‘navigating’ or of simply ‘trying to be a part of’ or attain some sensation of ‘agency’ amongst ecological catastrophes when being political are deemed to be ineffective or even futile.Data and Desiring-ProductionI propose ‘data desire’ as a concept for thinking about the ongoing social production of subjectivity through data production in the context of the failure of representation in the Anthropocene. Gilles Deleuze (""""Desire"""") argued that pleasure is an individualised emotion related to failures of representation: “pleasure seems to me to be the only means for a person or a subject to ‘find themselves again’ in a process which overwhelms them” (""""Desire"""", n.p.). Such an emotion is one of the outputs of a flow of desire that is non-individual, and not only human.Desiring production “causes the current to flow” (Deleuze and Guattari, A Thousand Plateaus, 5) between the event of oil and the production of subjectivity, both which propagate and bifurcate, and are continuously produced anew. Desire is characterised by vitality, or the unceasing capacity of processes to continuously become difference, to continuously change, rather than ‘arrive’, ‘conclude’, or ‘be.’ In other words, to think with ‘desire’ is to note how production flows, like a current, through ‘overwhelming’ events that including oil, and through subjectification, both of which continuously emerge in new contortions and produce new affects. The pleasure that emerges through a subject being produced, or a subject ‘coming into being’ by way of producing data – summarising, visualising, representing, and trying to give ‘meaning’ to ‘the event’ – is affected by the ongoing ability of ‘the event’ to multiply and be postponed from being summarised, as it proliferates and reproduces itself in ever new human and non-human bifurcations – oil spills and leaks, protests, policies, bitumen, new movements, new rhetoric, new sanctions, new pipelines, etc.Malins for instance notes how desireis not that which a pre-existing subject has for something, nor is it motivated by individual lack or the pursuit of pleasure. It is instead best understood as a pre-subjective, pre-conscious life force or energy that flows between bodies, connecting, animating and transforming them. (2)Data desire is therefore most importantly not a feeling that emerges out of a lack of data, or a desire for data. Rather data desires suggests that data practices become modalities through which people involved in environmental resistance can continuously ‘sense’ themselves as part of the event, or gain the sensation that they ‘are’ political, even if only as a sensation and only if momentarily, and within catastrophic events that are also always changing and defy representation. Events such as oil hence require analysis of the entanglement or multiple ways in which processes of subjectification, ecology, and media practices are in themselves multiple and folded together in multiple ways, something Guattari called the three ecologies, and more recently, Murphie referred to as a catastrophic multiplicity. This orientation towards desire as production positions the analysis of the pleasure of data practices beyond that of an individual into the realm of social production.Data Desire Fieldwork in the Oil-EventMy fieldwork focussed on the data practices of residents living in oil pipeline conflicts in British Columbia. This research included examining the media practices and everyday data engagements of residents engaging with and concerned about two oil pipeline projects: Enbridge’s Northern Gateway Pipeline, which would move crude oil from Edmonton and terminate in Kitimat in Northern British Columbia, and Kinder Morgan’s Trans Mountain oil pipeline that also would move crude oil from the Alberta tar sands to Burnaby, British Columbia. This later pipeline already exists, although the proposed project aimed at twinning of the oil pipeline would substantially increase oil tanker traffic along the West Coast and generate new risk of oil spills, given its increased capacity. As part of my research I spoke with a total of twenty-four (24) residents, and six (6) environmental non-governmental organisations (ENGOs) in Northern British Columbia and the Vancouver Metro Area to examine their media practices, digital strategies and other, everyday data practices in the oil pipeline conflict.Against the backdrop of an uptake in big data’s relation to ecological transformation (e.g.: Ruiz; Hogan; Maddalena &amp; Russill), I found the displays of pleasure accompanying individuals’ ostensibly everyday ‘small data’ productions as enunciations of subjectivity and resistance in the oil pipeline movement, under-examined and intriguing. Oil pipeline resistance can be charted along affective lines of pleasure associated with data practices, as people living in oil pipeline conflicts find themselves amidst an ever-expanding flurry of directions and affects that oil takes on: #NoDAPL, the Kalamazoo oil spill, the Conservative party leadership, Indigenous law suit claims, hypocrisy rhetoric, oil pipeline decisions approved, challenged, and deferred at municipal and federal levels. Oil is hence not only a substance but an event that continues to swirl off in new directions, and encompasses and also connects with a multitude of other events, such as urbanisation, 300,000 airplanes taking off and landing on a daily basis, peak oil, and animal extinction. I therefore consider ‘events’ not as ‘happenings’ or singular image events (DeLuca; DeLuca &amp; Peeples; McHendry; Yang) in the way they are often conceptualised within environmental communication literature, but as something that is ongoing, and often extensive beyond a single time and space. Image events may be one of the expressions of a broader and larger (conceptualised as having multiple expressions) event taking place. This section provides three examples of pleasures of emerging as subjects through data practices as political resistance to oil. These include contributing to discussions in online forums, engaging in citizen science, and proliferation of photos of authentic ‘non/environmentalists’ faces on social media.The first example of subjects emerging through practices of data desire is the production of online data, especially in online political forums or online news comments sections. Here, we might envision the pleasure of data production, in the form of writing online comments, as correlating to the individual wish to ‘count’, particularly as ‘individuals’ are seen to be peripheral to geological forces and capitalist machines of oil production, as well as to the processes of decision making, lawsuits, and municipal and regional politics. One example from this study demonstrates how residents living in oil pipeline conflict areas take pleasure in consuming and producing data. The excerpt below comes from a conversation I had with a resident living in and resisting the Trans Mountain oil pipeline expansion in the Vancouver Metro Area. This resident, an avid canoer and computer programmer in his thirties, showed immense pleasure in generating data in the form of contributing to news comments sections. Below I treat the participant’s talk not as an ‘account’ in the positivist sense in which ‘interview data’ might be taken to represent ‘participants’ voices.’ Rather, I treat such expression as a flow of desire that flows through individuals, often constituting them as subjects.I love discussing these issues. I love identifying what is not necessarily of paramount concern as opposed to what is. I have a lot of conversations. I have friends involved in policy. And I read. I’ve got news alerts coming my way from—you know, I must have about twelve Google alerts coming up just regarding pipeline issues and environmental issues. It’s become such a passion for me that I almost was sad once I felt it was finally defeated. I would get up in the morning and hop on the computer to read the latest articles and, you know, respond to comments and stuff. Often what I’m more interested in than the news article is the comments because it tells me where the Overton window is at any given time. I mentioned that some people attend rallies and stuff, well I post to the comments sections and I have conversations all the time online.As seen in this excerpt, pleasure/the subject emerge simultaneously through projects of comprehension and expression. The excerpt shows how contributions to conversations are ‘productive’ not in terms of any kind of political outcome, but in terms of a sensation of emerging/becoming subjectified in the event. Pleasure manifests within projects related to constituting subjectivity by not only consuming data, but also contributing to its ongoing production. In other words, this resident living in an oil conflict area found pleasure in calculating the Overton Window of online news comments about the oil pipeline, as well as in being constituted within the event as a political ‘subject’ by producing ‘data’. His becoming ‘subject’ was concurrent to a sensation of being able to ‘summarise’ the event and its articulations under ‘a unity’ and giving some ‘meaning’ to the constantly shifting event of ‘oil’. While both ‘the subject’ and ‘oil’ keep being produced anew, the momentary emotion of ‘pleasure’ functions to give a sensation of albeit temporary coherence. Here, as Deleuze and Guattari (A Thousand Plateaus) argue pleasure is “an affection of a person or a subject, a way for people to ‘find themselves’ in the process of desire that exceeds them” (156). This ‘excess’ characterises the evasiveness of ecological events and objects from being ever truly graspable, comprehensible, represented, or even ‘known’ to humans. de Freitas for instance notes how matter is already mathematically monstrous, quite literally multiplying, and evasive in its capacity to be ‘calculated’ (3). Input through online comments are therefore attempts at contribution to calculations, ‘making sense’, and also to feeling ‘counted’, attempts which in themselves amount to a great pleasure.The second example of subjects emerging through practices of data desire involves citizen science as a mode of data generation. Practices such as citizen science became pleasurable activities of subjective enunciations – practices of a ‘subject’ coming into being against, or within, this chaos, through data generation. Citizen science is a prime example of residents living in oil pipeline conflicts becoming enunciated – pleasurably – as subjects in the oil pipeline conflict in BC. Citizen science, for example, can take many forms. Streamkeeping, the act of taking care of local streams, is a key form of citizen science in areas facing oil pipeline conflicts, particularly as it puts data practices front and centre as part of resistance. While streamkeeping has many aspects to it, including stream clean-ups, a key component is the production of data about ecosystems health, which including wading into water to count fish, measure construction runoff such as silt, gravel, and sediment, and create comparative archives. Measuring, noting salmon counts, documenting debris emerged as pleasurable ways of engaging in pipeline politics–emerging as a subject, by way of somehow trying to datafy the oil-event, by making it ‘meaningful.’Data production functions to mathematically calculate a course of action within a concoction of persuasive efforts of oil pipeline corporations, environmental non-governmental organisations, governments, activist, and neighbours to define what ‘political subjectification’ might look like. Science is in perpetual struggle against chaos (Deleuze and Guattari, What Is Philosophy?) and data generation through grass-roots citizen science becomes a tool, or an instillation of data about a changing biome through which to encounter oil, and through which to emerge as a subject in relation to oil. Production of data as part of ‘citizen science’ also functions as a way through which to assert ‘independence’ and stage some resistance within a multiplicity of other ways in which oil becomes a reason of various attempts to define ‘political subjectivity’, such as ENGO campaigns, government statements about the ‘right’ and ‘wrong’ process to show resistance to the oil pipelines, and the branding of environmentalists as ecoterrorists. Perhaps data production becomes a way to effectively fold oneself into the oil event, without needing to confront a lack of other ways one could, or might resist oil pipeline development.The third example of the circulation of data desire are the increasingly common expressions of individuated pleasures associated with showing ‘faces’ of people engaged in environmentalist issues like oil pipelines, on various social media feeds that try to portray ‘real’ political subjects, in contrast to stereotypical representations of ‘activists’ or ‘environmentalists.’ Here I am specifically talking about selfies taken at environmental protests. Such productions of images of ‘authentic’ political subjects within oil movements has been a popular way to demonstrate authenticity of resistance efforts within environmental movements, particularly in relation to a struggle against accusations of hypocrisy fed by oil pipeline corporations and pundits (Piotrowski). Given the numerous social media feeds of environmental anti-oil pipeline groups that attempt to show ‘faces’ of ‘real’ political subjects, these depictions attempt to produce subjectivities, particularly with the intensifying circulation of what might be thought of as “faciality enactments” (Piotrowski, 849). Here, ‘faces’ are generated as ‘data’. The continuous production of faces/data becomes what counts, or matters, within resistance, as a way of continuously reproducing environmentalist subjectivity, particularly at a point of ‘crisis’ of environmentalist group identity. Such micro-productions and pleasures of individual faces on social media feeds or Instagram posts, are part of flows of data desire: the desire of individuals to emerge as subjects within a multitude of stereotypes about environmentalism; the desire for environmentalism to assert itself as meaningful within ecological events such as ‘oil’, and the desire of corporations to assert different rhetorics about both oil and environmentalism itself.To close, I have articulated that a subject – a subject that takes part in ‘their’ resistance to ecological degradation – is a residual one, the product of a circulating flow of pre-personal data desire. This data desire exceeds individual pleasures and undulates between the chaotic event of oil, its continuously shifting political, economic, and social affects, and ‘a subject’ also continuously trying to be enunciated and ‘individuated’ in the event. Satisfaction, or pleasure, becomes the individual expression of a larger circuit of circulating desires which shows the flows of data between the expressions of material and ecological events which generate all sorts of breakdowns in meaning about ‘the human’ and the Anthropocene, and between breakdowns of activist’ subjectivity. Desire functions as a mode of inquiry that moves thinking about pleasure beyond individuals’ emotions of ‘their’ craving for individuation and meaning within the chaos of the Anthropocene and in the anti-oil pipeline resistance. Rather than see data production as a response to a lack of information, I have shown how data desire, as a concept, can help to think about ontological production, or the production of subjects. This ontological production refers both to the event’s capacity to become continuously different and unforeseen, and the subject’s ongoing self-production through data practices. Three examples discussed here – participation in online news comments sections, citizen science, and production of activism selfies are just but some of the media practices that are part of the circulation of data desire, though there are undoubtedly more.ReferencesAlaimo, Stacy. Exposed: Environmental Politics and Pleasures in Posthuman Times. Minneapolis: U of Minnesota P, 2016.Craig, Geoffrey. “Political Participation and Pleasure in Green Lifestyle Journalism.” Environmental Communication 10.1 (2016): 122–141.Deleuze, Gilles. The Fold: Leibniz and the Baroque. New York, NY: Continuum, 1993.———. Essays Critical and Clinical. Minneapolis, MN. 1997.———. “Desire &amp; Pleasure.” Trans. M. McMahon. Unpaginated. 1997. 1 Aug. 2018 &lt;http://www. artdes.monash.edu.au/globe/delfou.html&gt;. Originally published as """"Désir et Plaisir"""" in Magazine Littéraire 325 (Oct. 1994): 59–65.———, and Felix Guattari. Anti-Oedipus: Capitalism and Schizophrenia. Trans. R. Hurley, M. Seem, and H.R. Lane. Minneapolis: U of Minnesota P, 1983 [1972].———, and Felix Guattari. A Thousand Plateaus: Capitalism and Schizophrenia. Trans. B. Massumi. Minneapolis: U of Minnesota P, 1987 [1980].———, and Felix Guattari. What Is Philosophy? Trans. H. Tomlinson and G. Burchell. New York, NY: Columbia UP, 1994.DeLuca, Kevin. Image Politics: The New Rhetoric of Environmental Activism. New York, NY: The Guilford P, 1999.———, and Jennifer Peeples. “From Public Sphere to Public Screen: Democracy, Activism, and the ‘Violence’ of Seattle.” Critical Studies in Media Communication 19.2 (2002): 125–151.Goodwin, Jeff, James M. Jasper, and Francesca Polletta, eds. Passionate Politics: Emotions and Social Movements. Chicago: U of Chicago P, 2009.Guattari, Felix. Chaosmosis: An Ethico-Aesthetic Paradigm. Bloomington, Ind.: Indiana UP, 1995.———. The Three Ecologies. London: Athlone P, 2000.Malins, Peta. “Desiring Assemblages: A Case for Desire over Pleasure in Critical Drug Studies.” International Journal of Drug Policy 49 (Nov. 2017): 126–132.McHendry, George. F. “Whale Wars and the Axiomatization of Image Events on the Public Screen.” Environmental Communication: A Journal of Nature and Culture 6.2 (2012): 139–155.Murphie, Andrew. “On Being Affected: Feeling in the Folding of Multiple Catastrophes.” Cultural Studies 32.1 (2018): 18–42.Piotrowski, Marcelina. “‘Authentic’ Folds: Environmental Audiences, Activists and Subjectification in Hypocrisy Micropolitics.” Continuum 31.6 (2017): 844–856.Sharpe, Erin K. “Festivals and Social Change: Intersections of Pleasure and Politics at a Community Music Festival.” Leisure Sciences 30.3 (2008): 217-234.Yang, Fan. “Under the Dome: ‘Chinese’ Smog as a Viral Media Event.” Critical Studies in Media Communication 33.3 (2016): 232–244.","",""
"2018","Political agency, digital traces, and bottom-up data practices","This theoretical article explores the bottom-up data practices enacted by individuals and groups in the context of organized collective action. Conversing with critical media theory, the sociology of social movements, and platform studies, it asks how activists largely reliant on social media for their activities can leverage datafication and mobilize social media data in their tactics and narratives. Using the notion of digital traces as a heuristic tool to understand the dynamics between platforms and their users, the article reflects on the concurrent materiality and discursiveness of digital traces and analyzes the evolution of political agency vis-a-vis the datafied self. It contributes to our understanding of “digital traces in context” by foregrounding human agency and the meaning-making activities of individuals and groups. Focusing on the possibilities opened up by digital traces, it considers how activists make sense of the ways in which social media structure their interactions. It shows how digital traces trigger a quest for visibility that is unprecedented in the social movement realm, and how they can function as particular “agency machines.”","",""
"2018","Digital Traces in Context| Tracing Capitalism’s Turn to Data: Or, Contextualizing Daily Life’s New Data “Context” — Commentary","This short response to the articles in this Special Section foregrounds the wider context of data traces in the development of capitalism. After analyzing the issue’s articles into three categories (dealing with epistemology, agency, and social consequences), the response argues that the biggest context of all to datafication is the current transformation of capitalism under which the production of value is focused on the extraction of value from data. What drives this? What implications does this have for the social domain and the micro-contexts of our practices with data? These are the larger issues toward which the articles in this Special Section all point.","",""
"2018","Algorithmic governance and the need for consumer empowerment in data-driven markets","The present article argues that the fact that personal data holds great value, in combination with a lack of transparency in its commercial use, leads to a need for consumer policy that strengthens consumer protection. The widespread practice of user agreements and consent-based regulation of personal data collection is not satisfactory for balancing these information-asymmetric markets. The lack of transparency deriving from the complex and massive datafication of consumers – where consumers are profiled, data is brokered and the algorithmically automated decision-making is opaque – speaks to the need for improved supervision at a more structural level above and beyond the individual consumer’s choices, preferably by more active consumer protection authorities.","",""
"2018","Big crisis data: generality-singularity tensions","The current massive surge of digital data, measurements and new forms of (algorithmic) valuation affects emergency situations (both natural and human-made crises) and emergency management systems. By introducing ‘big crisis data’, the very concepts of emergency and crisis rely heavily on the calculations of events and crowd behaviour, constituting, controlling and shifting the interplay between different actors. From a critical data perspective, this paper focuses on the entanglements of crisis digital data assemblages with human and institutional actions, stressing the risks and challenges of the underlying data practices of two key processes what could be called valorisation and singularisation.","",""
"2018","Not just a number? NEETs, data and datalogical systems","ABSTRACT This paper draws on empirical research with NEET populations (16–24-year-olds not in education, employment or training) in the U.K. in order to engage with issues around identification, data and metrics produced through datalogical systems. Our aim is to bridge contemporary discourses around data, digital bureaucracy and datalogical systems with empirical material drawn from a long-term ethnographic project with NEET groups in Leeds, U.K. in order to highlight the way datalogical systems ideologically and politically shape people’s lives. We argue that NEET is a long-standing data category that does work and has resonance within wider datalogical systems. Secondly, that these systems are decision-making and far from benign. They have real impact on people’s lives – not just in a straightforwardly, but in obscure, complex and uneven ways which makes the potential for disruption or intervention increasingly problematic. Finally, these datalogical systems also implicate and are generated by us, even as we seek to critique them.","",""
"2018","Envisioning the power of data analytics","ABSTRACT It could be argued that the power of data is located in what they are used to reveal. Yet we have little understanding of the role played by the emerging industry of data analytics in the interpretation and use of big data. These data analytics companies act as intermediaries in the digital data revolution. Understanding the social influence of big data requires us to understand the role played by data analytics within organisations of different types. This particular article focuses very specifically upon the way in which data and data analytics are envisioned within the marketing rhetoric of the data analytics industry. It is argued that to understand the spread of data analytics and the adoption of certain analytic strategies, we first need to look at the projection of promises upon that data. The way that data and analytics are imagined shapes their incorporation and appropriation into practices and organisational structures – what I call here the data frontiers. This article draws upon a sample of 34 data analytics companies in order to explore the way in which data analytics are envisioned within that increasingly powerful industry.","",""
"2018","The dynamics and potentials of big data for audience research"," This article considers the future of audience research in an era of big data. It does so by interrogating the dynamics and potentials of the big data paradigm in an era of user-generated content and commercial exploitation. In this context, it is proposed that the major dynamics of big data are a conjoint application of numerology and alchemy in the information age. On this basis, the potentials of new data techniques are addressed in light of the critical gap between audience data and the audiences themselves. ","",""
"2018","Can We Think Without Categories?","Abstract                 In this article methods developed for the purpose of what I call “Media Analytics” are contextualized, put into a historical framework and discussed in regard to their relevance for “Cultural Analytics”. Largescale analysis of media and interactions enable NGOs, small and big businesses, scientific research and civic media to create insight and information on various cultural phenomena. They provide quantitative analytical data about aspects of digital culture and are instrumental in designing procedural components for digital applications such as search, recommendations, and contextual advertising. A survey on key texts and propositions from 1830 on until the present sketches the development of “Data Society’s Mind”. I propose that even though Cultural Analytics research uses dozens of algorithms, behind them there is a small number of fundamental paradigms. We can think them as types of data society’s and AI society’s cognition. The three most general paradigmatic approaches are data visualization, unsupervised machine learning, and supervised machine learning. I will discuss important challenges for Cultural Analytics research. Now that we have very large cultural data available, and our computers can do complex analysis quite quickly, how shall we look at culture? Do we only use computational methods to provide better answers to questions already established in the 19th and 20th century humanities paradigms, or do these methods allow fundamentally different new concepts?","",""
"2018","Data anxieties: Finding trust in everyday digital mess"," Digital data is an increasing and continual presence across the sites, activities and relationships of everyday life. In this article we explore what data presence means for the ways that the everyday is organised, sensed, and anticipated. While digital data studies have demonstrated how data is deeply entangled with the way in which everyday life is lived out and valued, at the same time our relationships with data are riddled with anxieties or small niggles or tricky trade-offs and their use is often chaotic and muddled, part of the inevitable uncertainty about what will happen next. If the presence of data is part of the environments we inhabit, this raises the question of how and why data is valuable to us and what forms of hope and trust enable this value to further develop. ","",""
"2018","Conceptualizations of Big Data and their epistemological claims in healthcare: A discourse analysis"," In recent years, the healthcare field welcomed an emerging field of practices captured under the umbrella term ‘Big Data’. This term is surrounded with positive rhetoric and promises about the ability to analyse real-world data quickly and comprehensively. Such rhetoric is highly consequential in shaping debates on Big Data. While the fields of Science and Technology Studies and Critical Data Studies have been instrumental in elaborating the neglected and problematic dimensions of Big Data, it remains an open question how and to what extent such insights become embedded in other fields. In this paper, we analyse the epistemological claims that accompany Big Data in the healthcare domain. We systematically searched scientific literature and selected 206 editorials as these reflect on developments in the domain. Through an interpretive analysis, we construct five ideal-typical discourses that all frame Big Data in specific ways. Three of the discourses (the modernist, instrumentalist and pragmatist) frame Big Data in positive terms and disseminate a compelling rhetoric. Metaphors of ‘capturing’, ‘illuminating’ and ‘harnessing’ data presume that Big Data are benign and leading to valid knowledge. The scientist and critical-interpretive discourses question the objectivity and effectivity claims of Big Data. Metaphors of ‘selecting’ and ‘constructing’ data illustrate another political message, framing Big Data as limited. We conclude that work in the critical-interpretive discourse has not broadly infiltrated the medical domain. Ways to better integrate aspects of the discourse in the healthcare domain are urgently needed. ","",""
"2018","Democratic governance in an age of datafication: Lessons from mapping government discourses and practices"," There is an abundance of enthusiasm and optimism about how governments at all levels can make use of big data, algorithms and artificial intelligence. There is also growing concern about the risks that come with these new systems. This article makes the case for greater government transparency and accountability about uses of big data through a Government of Canada qualitative research case study. Adapting a method from critical cartographers, I employ counter-mapping to map government big data practices and internal discussions of risk and challenge. I do so by drawing on interviews and freedom of information requests. The analysis reveals that there are more concerns and risks than often publicly discussed and that there are significant areas of silence that need greater attention. The article underlines the need for our democratic systems to respond to our new datafied contexts by ensuring that our institutions make changes to better protect citizen rights, uphold democratic principles and ensure means for citizen intervention. ","",""
"2018","The limits of computation: A philosophical critique of contemporary Big Data research"," This paper reviews the contemporary discussion on the epistemological and ontological effects of Big Data within social science, observing an increased focus on relationality and complexity, and a tendency to naturalize social phenomena. The epistemic limits of this emerging computational paradigm are outlined through a comparison with the discussions in the early days of digitalization, when digital technology was primarily seen through the lens of dematerialization, and as part of the larger processes of “postmodernity”. Since then, the online landscape has become increasingly centralized, and the “liquidity” of dematerialized technology has come to empower online platforms in shaping the conditions for human behavior. This contrast between the contemporary epistemological currents and the previous philosophical discussions brings to the fore contradictions within the study of digital social life: While qualitative change has become increasingly dominant, the focus has gone towards quantitative methods; while the platforms have become empowered to shape social behavior, the focus has gone from social context to naturalizing social patterns; while meaning is increasingly contested and fragmented, the role of hermeneutics has diminished; while platforms have become power hubs pursuing their interests through sophisticated data manipulation, the data they provide is increasingly trusted to hold the keys to understanding social life. These contradictions, we argue, are partially the result of a lack of philosophical discussion on the nature of social reality in the digital era; only from a firm metatheoretical perspective can we avoid forgetting the reality of the system under study as we are affected by the powerful social life of Big Data. ","",""
"2018","When digital health meets digital capitalism, how many common goods are at stake?"," In recent years, all major consumer technology corporations have moved into the domain of health research. This ‘Googlization of health research’ (‘GHR’) begs the question of how the common good will be served in this research. As critical data scholars contend, such phenomena must be situated within the political economy of digital capitalism in order to foreground the question of public interest and the common good. Here, trends like GHR are framed within a double, incommensurable logic, where private gain and economic value are pitted against public good and societal value. While helpful for highlighting the exploitative potential of digital capitalism, this framing is limiting, insofar as it acknowledges only one conception of the common good. This article uses the analytical framework of modes of justification developed by Boltanksi and Thévenot to identify a plurality of orders of worth and conceptualizations of the common good at work in GHR. Not just the ‘civic’ (doing good for society) and ‘market’ (enhancing wealth creation) orders, but also an ‘industrial’ (increasing efficiency), a ‘project’ (innovation and experimentation), and what I call a ‘vitalist’ (proliferating life) order. Using promotional material of GHR initiatives and preliminary interviews with participants in GHR projects, I ask what moral orientations guide different actors in GHR. Engaging seriously with these different conceptions of the common good is paramount. First, in order to critically evaluate them and explicate what is at stake in the move towards GHR, and ultimately, in order to develop viable governance solutions that ensure strong ‘civic’ components. ","",""
"2018","The locus of legitimate interpretation in Big Data sciences: Lessons for computational social science from -omic biology and high-energy physics"," This paper argues that analyses of the ways in which Big Data has been enacted in other academic disciplines can provide us with concepts that will help understand the application of Big Data to social questions. We use examples drawn from our Science and Technology Studies (STS) analyses of -omic biology and high energy physics to demonstrate the utility of three theoretical concepts: (i) primary and secondary inscriptions, (ii) crafted and found data, and (iii) the locus of legitimate interpretation. These help us to show how the histories, organisational forms, and power dynamics of a field lead to different enactments of big data. The paper suggests that these concepts can be used to help us to understand the ways in which Big Data is being enacted in the domain of the social sciences, and to outline in general terms the ways in which this enactment might be different to that which we have observed in the ‘hard’ sciences. We contend that the locus of legitimate interpretation of Big Data biology and physics is tightly delineated, found within the disciplinary institutions and cultures of these disciplines. We suggest that when using Big Data to make knowledge claims about ‘the social’ the locus of legitimate interpretation is more diffuse, with knowledge claims that are treated as being credible made from other disciplines, or even by those outside academia entirely. ","",""
"2018","Dangers of the digital fit: Rethinking seamlessness and social sustainability in data-intensive healthcare"," For years, attempts at ensuring the social sustainability of digital solutions have focused on ensuring that they are perceived as helpful and easy to use. A smooth and seamless work experience has been the goal to strive for. Based on document analysis and interviews with 15 stakeholders, we trace the setting up of a data infrastructure in Danish General Practice that had achieved just this goal – only to end in a scandal and subsequent loss of public support. The ease of data access made it possible for data to be extracted, exchanged and used by new actors and for new purposes – without those producing the data fully realizing the expansion of the infrastructure. We suggest that the case has wider relevance for a still more data-intensive healthcare sector and a growing data economy: when those who produce the data are not made aware of new uses of data, it makes it more difficult to resolve potential conflicts along the way. In the Danish case, conflicting views on legitimate data use led to the collapse of the infrastructure. Therefore, while seamlessness may be a solution to the old problem of a poor fit between user and technology, this celebrated virtue may also involve new problems relating to social instability. As digital solutions tend to be integrated still more seamlessly in still more of our activities, we need to develop political mechanisms to define and protect the rights and obligations of both data suppliers and users in order to ensure the long-term sustainability of digital infrastructures. ","",""
"2018","Navigating Big Data dilemmas: Feminist holistic reflexivity in social media research"," Social media offers an attractive site for Big Data research. Access to big social media data, however, is controlled by companies that privilege corporate, governmental, and private research firms. Additionally, Institutional Review Boards’ regulative practices and slow adaptation to emerging ethical dilemmas in online contexts creates challenges for Big Data researchers. We examine these challenges in the context of a feminist qualitative Big Data analysis of the hashtag event #WhyIStayed. We argue power, context, and subjugated knowledges must each be central considerations in conducting Big Data social media research. In doing so, this paper offers a feminist practice of holistic reflexivity in order to help social media researchers navigate and negotiate this terrain. ","",""
"2018","Big–Thick Blending: A method for mixing analytical insights from big and thick data sources"," Recent works have suggested an analytical complementarity in mixing big and thick data sources. These works have, however, remained as programmatic suggestions, leaving us with limited methodological inputs on how to archive such complementary integration. This article responds to this limitation by proposing a method for ‘blending’ big and thick analytical insights. The paper first develops a methodological framework based on the cognitivist linguistics terminology of ‘blending’. Two cases are then explored in which blended spaces are crafted from engaging big and thick analytical insights with each other. Through these examples, we learn how blending processes should be conducted as a rapid, iterative and collaborative effort with respect for individual expertise. Further, we demonstrate how the unique, but often overlooked, granularity of big data plays a key role in affording the blending with thick data. We conclude by suggesting four commonly appearing blending strategies that can be applied when relying upon big and thick data sources. ","",""
"2018","The role and nature of consent in government administrative data"," This article draws on research undertaken by the authors as part of the Administrative Data Research Centre in England (ADRC-E). Between 2014 and 2017, we conducted four case studies on government administrative data for education, transport, energy and health. The purpose of the research was to examine stakeholder perspectives about the sharing, linking and re-use (secondary use) of government administrative data. In relation to the role and nature of consent given by data subjects for re-use, our study revealed significant variations in data provider and researcher attitudes. Although our study setting was England, we believe that the findings have wider resonance. Our analysis identified six factors which might account for the variations around consent: the specificities of the legislative framework governing the collection and processing of particular data; the type of data being collected and the relational context in which it is created; the broader information governance framework in which the data resides; the creating organization's approach to data release; the relative levels of risk aversity within the creating organization; and public perceptions and social attitudes. In conclusion, we consider whether consent is still the best mechanism available for data re-use, or whether a social contract model of data sharing should be developed. ","",""
"2018","Datastructuring—Organizing and curating digital traces into action"," Digital transformations and processes of “datafication” fundamentally reshape how information is produced, circulated and given meaning. In this article, we provide a concept of “datastructuring” which seeks to capture this reshaping as both a product of and productive of social activity. To do this we focus on (1) how new forms of social action map onto and are enabled by technological changes related to datafication, and (2) how new forms of datafied social action constitute a form of knowledge production which becomes embedded in technologies themselves. We illustrate the potential of the datastructuring concept with empirical examples which also serve to highlight some new avenues for research and some empirical questions to explore further. We suggest a focus on datastructuring can ignite scholarly debates across disciplines that may share an interest in the technological configurations, sorting activities, and other socio-material forces that shape digital spaces, but which are rarely brought together. Such cross-disciplinary conceptualizations may give more attention to how information is structured and organized, becomes “algorithmically recognizable”, and emerges as (in)visible in digital, datafied spaces. Such a concept, we suggest, may help us better understand the novel ways in which “backstage datawork” and “data sorting processes” gain traction in political interventions, commercial processes, and social ordering. ","",""
"2018","Constructing global data: Automated techniques in ecological monitoring, precaution and reification of risk"," Automatic aggregation of large-scale data is increasingly conceived as central in the production of ecological knowledge. This article examines the implications of the employment of automation techniques and ‘data-driven analysis’ in long-term biodiversity monitoring. What are the pathways and paradoxes in the possible public acceptance of automated data-sets as a trustworthy source for use in global protection and regulation of biodiversity? This article suggests that the precautionary discourse aid topdown measures for the public acceptability of the use of such techniques. Automated biodiversity monitoring offers distinctive advantages to further precautionary goals in terms of a faster, cost-effective and less messy way of collecting data, at a large scale over long periods of time. However, it contradicts other values implied through precaution – for instance the opacity and reification of the construction of risk. How do the specific forms of data-making relate with specific forms of risk governance, and what implications does this have for helping us to understand appropriate ways of political representation in governance? Can paradoxes attendant to introducing a form of construction of data help understand the nature of the exercise of governmental power?  [Box: see text] ","",""
"2018","Who benefits and how? Public expectations of public benefits from data-intensive health research"," The digitization of society and academic research endeavours have led to an explosion of interest in the potential uses of population data in research. Alongside this, increasing attention is focussing on the conditions necessary for maintaining a social license for research practices. Previous research has pointed to the importance of demonstrating “public benefits” from research for maintaining public support, yet there has been very little consideration of what the term “public benefits” means or what public expectations of “public benefits” are. In order to address this pressing issue a series of deliberative workshops with members of the public were held across Scotland in May and June 2017. The workshops aimed to engage a cross-section of the Scottish population in in-depth discussions of the ways that the public – or publics – might benefit from data-intensive health research. The findings reported here discuss workshop participants’ understandings and expectations of health research; who they considered to be “the public” that should benefit from health research and; in what ways they felt “the public” should benefit. Workshop participants’ preference was clearly for the widest possible public benefit to be felt by all, but they also acknowledged the value in research aiming to primarily benefit vulnerable groups within society. A key focus of discussions was the extent to which workshop participants were confident that potential public benefits would be realised. A crucial consideration then is the extent to which mechanisms and political support are in place to realise and maximise the public benefits of data-intensive health research. ","",""
"2018","Data associations in global law and policy","Social phenomena—or the condition of society—may be ‘‘seized indirectly when there is a slight change in one older association mutating into a slightly newer or different one’’ (Latour, 2005: 36). The aim of this special issue is to trace mutations underway in those associations rendered or experienced in data and to probe some patterns that these changing ties draw. In particular, contributors to this issue reflect upon associations traceable in data that are of a juridical nature (or could be so understood), or that have salience for legal institutions and norms. This is something other than inviting consideration of ‘‘problems’’ that technology makes for law. It is something other, too, than thinking about whether law does or does not determine or reflect socio-technical practice, or vice versa, and how such law-technology correspondence might ‘‘properly’’ be maintained. Instead, contributors engage here in a collective experiment of envisioning data as vectors of lawful relations on the global plane, and at other scales. This is unfinished business for Big Data & Society. In this journal’s opening issue, Rob Kitchin argued that ‘‘the development of digital humanities and computational social sciences. . . propose radically different ways to make sense of culture, history, economy and society’’ (Kitchin, 2014: 1). But what ‘‘sense’’ could ‘‘Big Data empiricism,’’ as Kitchin described it, make in, of and for global law and policy? This is among the questions that the contributors to this special issue take up. Neither digital technology nor law is pivotal to this inquiry, so much as their irrepressible leaking and morphing into would-be or could-be versions of the other. As paradigmatic a shift as the turn to epistemologies of Big Data might seem, making connections between these emergent epistemologies and ‘‘older association[s],’’ in Latour’s words, is also an important task of this collection. Sheila Jasanoff traces, for instance, the history of the production of ‘‘a panoptic viewpoint from which the entire diversity of human experience can be seen, catalogued, aggregated, and mined’’ from the mid-20th-century, especially in the emergence of the ‘‘global environment’’ as an ‘‘actionable object for law and policy.’’ Naveen Thayyil likewise draws an analogy between change in weather and climatological studies from the 1960s onwards (from instrument reading techniques to computer modeling) and parallel shifts in approaches to risk regulation (from conventional risk assessment to precautionary approaches, the latter increasingly advanced through ‘‘Big Data’’ automation). Ben Hurlbut similarly connects ‘‘scientifically authorized imaginations of future risk’’ on the global plane to earlier incarnations of the ‘‘republic of science’’ assembled around pandemic risk since the 19th-century. Other contributions to this volume re-frame contemporary phenomena by reference to associations of more recent provenance: Sarah Logan analyses ‘‘post 9-11 mass surveillance’’ and the ‘‘anxious information state’’ it enshrines. Likewise, Gavin Smith, Kath Albury, Jean Burgess, Ben Light, Kane Race, Rowan Wilken, and Daniel Joyce focus on ‘‘data cultures’’ ascendant during the past decade and the legal, social, and political conflicts and connections that surface amid them. The protagonists and environs of the stories told in these pages vary greatly. Not all are of a kind that one","",""
"2018","How do data come to matter? Living and becoming with personal data"," Humans have become increasingly datafied with the use of digital technologies that generate information with and about their bodies and everyday lives. The onto-epistemological dimensions of human–data assemblages and their relationship to bodies and selves have yet to be thoroughly theorised. In this essay, I draw on key perspectives espoused in feminist materialism, vital materialism and the anthropology of material culture to examine the ways in which these assemblages operate as part of knowing, perceiving and sensing human bodies. I draw particularly on scholarship that employs organic metaphors and concepts of vitality, growth, making, articulation, composition and decomposition. I show how these metaphors and concepts relate to and build on each other, and how they can be applied to think through humans’ encounters with their digital data. I argue that these theoretical perspectives work to highlight the material and embodied dimensions of human–data assemblages as they grow and are enacted, articulated and incorporated into everyday lives. ","",""
"2018","Electricity as (Big) Data: Metering, spatiotemporal granularity and value"," Electricity is hidden within wires and networks only revealing its quantity and flow when metered. The making of its properties into data is therefore particularly important to the relations that are formed around electricity as a produced and managed phenomenon. We propose approaching all metering as a situated activity, a form of quantification work in which data is made and becomes mobile in particular spatial and temporal terms, enabling its entry into data infrastructures and schemes of evaluation and value production. We interrogate the transition from the pre-digital into the making of bigger, more spatiotemporally granular electricity data, through focusing on those actors selling and materialising new metering technologies, data infrastructures and services for larger businesses and public sector organisations in the UK. We examine the claims of truth and visibility that accompany these shifts and their enrolment into management techniques that serve to more precisely apportion responsibility for, and evaluate the status of, particular patterns and instances of electricity use. We argue that whilst through becoming Big Data electricity flow is now able to be known and given identity in significantly new terms, enabling new relations to be formed with the many heterogeneous entities implicated in making and managing energy demand, it is necessary to sustain some ambivalence as to the performative consequences that follow for energy governance. We consider the wider application of our conceptualisation of metering, reflecting on comparisons with the introduction of new metering systems in domestic settings and as part of other infrastructural networks. ","",""
"2018","Broken data: Conceptualising data in an emerging world"," In this article, we introduce and demonstrate the concept-metaphor of broken data. In doing so, we advance critical discussions of digital data by accounting for how data might be in processes of decay, making, repair, re-making and growth, which are inextricable from the ongoing forms of creativity that stem from everyday contingencies and improvisatory human activity. We build and demonstrate our argument through three examples drawn from mundane everyday activity: the incompleteness, inaccuracy and dispersed nature of personal self-tracking data; the data cleaning and repair processes of Big Data analysis and how data can turn into noise and vice versa when they are transduced into sound within practices of music production and sound art. This, we argue is a necessary step for considering the meaning and implications of data as it is increasingly mobilised in ways that impact society and our everyday worlds. ","",""
"2018","Datafication and data fiction: Narrating data and narrating with           data"," Data do not speak for themselves. Data must be narrated—put to work in particular contexts, sunk into narratives that give them shape and meaning, and mobilized as part of broader processes of interpretation and meaning-making. We examine these processes through the lens of ethnographic practice and, in particular, ethnography’s attention to narrative processes. We draw on a particular case in which digital data must be animated and narrated by different groups in order to examine broader questions of how we might come to understand data ethnographically. ","",""
"2018","Grassroots resource mobilization through counter-data action"," In this paper, we document the counter-data action and data activism of a grassroots affordable housing advocacy group in Atlanta. Our observation and insight into these data activities and strategies are achieved through ethnographic and engaged research and participatory design. We find that counter-data action through community-collected data is rooted in a legacy of Atlanta’s black activism and black scholarship; that this data activism enabled resource mobilization and critical conscious making; and that design and media production are essential post counter-data action activities in data activism. Based on these findings, we urge the field of open government data to broaden their concept of social impact of data to include the use data to mobilize resources within oppressed communities not to influence policy and government but to build capacities within community in order to transform, not join, political structures. We also advocate that scholars within the fields of open government data, critical data studies, and data activism recognize the legacy and historic practice of data activism by black communities working towards social change. ","",""
"2018","Data doxa: The affective consequences of data practices"," This paper explores the embedding of data producing technologies in people's everyday lives and practices. It traces how repeated encounters with digital data operate to naturalise these entities, while often blindsiding their agentive properties and the ways they get implicated in processes of exploitation and governance. I propose and develop the notion of ‘data doxa’ to conceptualise the way in which digital data – and the devices and platforms that stage data – have come to be perceived in Western societies as normal, necessary and enabling. The ‘data doxa’ concept also accentuates the enculturation of many individuals into a data sharing habitus which frames digital technologies in simplistic terms as (a) panaceas for the problems associated with contemporary life, (b) figures of progress and convenience, and (c) mediums of knowledge, pleasure and identity. I suggest that three types of data-based relations contribute to the formation of this doxic sensibility: fetishisation, habit and enchantment. Each of these relations come to mediate public understandings of digital devices and the data they generate, obscuring the multifaceted nature and hidden depths of data and their propensity to double up as technologies of exposure and discipline. As a result of this situation, imaginative educational programs and revamped regulatory frameworks are urgently needed to inform individuals about the contribution of data to the leveraging of value and power in today's digital economies, but also to protect them from experiencing data-based harms. ","",""
"2018","Reimagining the Big Data assemblage"," Recent work on Big Data and analytics reveals a tension between analyzing the role of emerging objects and processes in existing systems and using those same objects and processes to create new and purposeful forms of action. While the field of science and technology studies has had considerable success in pursuing the former goal, as Halford and Savage argue, there is an ongoing need to discover or invent ways to “do Big Data analytics differently.” In this commentary, I suggest that attempts to produce new ways of working with Big Data and analytics might be hindered by how science and technology studies-influenced scholars have conceptualized assemblages. While these scholars have foregrounded objects’ relations within existing assemblages, new materialist philosophers draw attention to properties of objects that transcend those relations and might indicate opportunities for more creative or generative uses of Big Data and analytics. ","",""
"2018","Data is airborne; Data is inborn: The labor of the body in technoecologies","This article presents a feminist argument about the evolution of data storage in relation to the body — from our current state of wirelessness that relies on data centers for processing and containment, to future imaginaries about embedded and embodied storage in our DNA — as technologies of ‘soft surveillance’ that function largely due to a denial of the body tracked and perforated. It begins with an examination of the proliferation of largely invisible wireless communication technology and intersects with a new materialist feminist framework that complicates which bodies come to matter and explores how the body is repositioned in differently labored environments. This article is also an invitation to critically engage with the forces that propel and, in turn, reinforce what counts, persists, and is made visible in pervasive technoecologies, often at the expense of what remains unaccounted for or hidden. It finishes with a provocation about storing data in DNA — the genetic component of all living things — the future inborn counterpart to our current airborne data.","",""
"2018","Deconstructing datafication’s brave new world"," As World Economic Forum’s definition of personal data as ‘the new “oil” – a valuable resource of the 21st century’ shows, large-scale data processing is increasingly considered the defining feature of contemporary economy and society. Commercial and governmental discourse on data frequently argues its benefits, and so legitimates its continuous and large-scale extraction and processing as the starting point for developments in specific industries, and potentially as the basis for societies as a whole. Against the background of the General Data Protection Regulation, this article unravels how general discourse on data covers over the social practices enabling collection of data, through the analysis of high-profile business reports and case studies of health and education sectors. We show how conceptualisation of data as having a natural basis in the everyday world protects data collection from ethical questioning while endorsing the use and free flow of data within corporate control, at the expense of its potentially negative impacts on personal autonomy and human freedom. ","",""
"2018","Re-calibrating DIY: Testing digital participation across dust sensors, fry pans and environmental pollution"," An increasing number of low-cost and do-it-yourself (DIY) digital sensors for monitoring air quality are now in circulation. DIY technologies attempt to democratize environmental practices such as air quality sensing that might ordinarily be the domain of expert scientists. But in the process of setting up and using DIY sensors, citizens encounter just as many challenges for ensuring the accuracy of their devices and the validity of their data. In this article, we look specifically at the infrastructures and practices of DIY digital sensing. Through an analysis of urban sensing in London as an environmental media practice, we consider the specific techniques and challenges of calibrating DIY digital sensors for measuring air pollution to ensure the relative accuracy and validity of data. We ask, “How are DIY calibration practices expressive of particular political subjects and environmental relations—and not others?” “How might we re-calibrate DIY as a digital practice and political commitment through engagements with multiple genealogies and counter-genealogies of citizen-led inquiry?” ","",""
"2018","Afterword: Ethics as Impact—Moving From Error-Avoidance and Concept-Driven           Models to a Future-Oriented Approach"," Beginning with the premise that most regulatory guidelines for research ethics are deeply flawed, this article walks the reader through three models that can help social researchers, technologists, and designers identify and reflect on how they’re approaching ethics, or “doing the right thing” in their own work. The first, an error-avoidance model, has traditionally focused on creating frameworks to help researchers avoid repeating historical ethical violations. The second concept-driven model focuses on refining the concepts that undergird core ethical frameworks. Both are dominant in human-focused research and tend to be highly proceduralized, implemented a priori or from the top down as part of largescale regulatory structures. In both of these models, the agency of the researcher is removed or dismissed as less relevant than the agency of the system. The article draws on recent controversies around data collection and corporate experimentation on social media users as well as two academic research cases to illustrate how these two models fail repeatedly because they do not retain enough flexibility to allow for recontextualizing ethics as needed on a case-by-case basis. The third, an impact-model of ethics, offers an alternative whereby researchers, technologists, and designers can take a more active role in decisions about the contexts they study, by exploring the possible positive and negative impact of their work. This article invites us to work toward building a different balance in agential distribution in our models around responsible conduct of research, so that the conceptual and regulatory systems that guide and impede our actions are more balanced with our own agency as decision makers, with accountability and responsibility for doing the ‘right thing’. ","",""
"2018","Ethics Are Admin: Australian Human Research Ethics Review Forms as (Un)Ethical Actors"," In Australian universities, social research projects secure institutional approval as ethical through research ethics committees, and are defined and communicated to these committees through standardized local application forms. In organizational terms, ethics are instituted first as an administrative ritual anterior to research, and routinely elided as such. The documentation constituting this ritual thus bears scrutiny, in terms of what it says and what it does, and in turn, what it requires applicants to say and do. Such scrutiny is a means of fleshing out the standard critique of prospective ethics review from social media researchers: that the opportunity for a proper conversation about research ethics in the community of researchers is supplanted by an administrative exercise in “box ticking.” This paper discusses these ethics application forms, attending specifically to the ethical consequences of the stance they require the applicant to take with respect to prospective research participants, and the implications of their formulation of research as a process of data extraction. ","",""
"2018","(Re)framing Big Data: Activating Situated Knowledges and a Feminist Ethics of Care in Social Media Research"," In this article, we seek to problematize assumptions and trends in “big data” digital methods and research through an intersectional feminist lens. This is articulated through a commitment to understand how a feminist ethics of care and Donna Haraway’s ideas about “situated knowledge” could work methodologically for social media research. Taking up current debates within feminist materialism and digital data, including big, small, thick, and “lively” data, the argument addresses how a set of coherent feminist methods and a corollary epistemology is being rethought in the field today. We consider how the “queering” of Hannah Arendt’s concept of “action” could contribute to a critically optimistic and inclusive reflection on the role of ethical political commitments to the subjects/objects of study imbricated in big data. Finally, we use our recent research to pose a number of practical questions about practices of care in social media research, pointing toward future research directions. ","",""
"2018","Future Anthropology Ethics and Datafication: Temporality and Responsibility in Research"," In this article, we argue for an ethics of big data that is embedded in the emergent processes through which data are made, interpreted, and mobilized in mundane everyday contexts and examine how this could potentially be played out in research practice. We situate this as a response to a current crisis in accountability that has arisen in the context of the use of digital data to inform societal interventions, which we propose calls for a future-oriented anthropological ethics situated in the ongoingness of life. Such a standpoint offers a revised approach to temporality and attends to the ethics of intervening and engaging with the uncertainty of what is as yet unknown rather than simply with an ethics of the past. It offers us an opportunity to think differently about big data and ethics and to create an alternative ethics for big data and their analysis. ","",""
"2018","Big Data, Method and the Ethics of Location: A Case Study of a Hookup App for Men Who Have Sex with Men"," With the rise of geo-social media, location is emerging as a particularly sensitive data point for big data and digital media research. To explore this area, we reflect on our ethics for a study in which we analyze data generated via an app that facilitates public sex among men who have sex with men. The ethical sensitivities around location are further heightened in the context of research into such digital sexual cultures. Public sexual cultures involving men who have sex with men operate both in spaces “meant” for public sex (e.g., gay saunas and dark rooms) and spaces “not meant” for public sex (e.g., shopping centers and public toilets). The app in question facilitates this activity. We developed a web scraper that carefully collected selected data from the app and that data were then analyzed to help identify ethical issues. We used a mixture of content analysis using Python scripts, geovisualisation software and manual qualitative coding techniques. Our findings, which are methodological rather than theoretical in nature, center on the ethics associated with generating, processing, presenting, archiving and deleting big data in a context where harassment, imprisonment, physical harm and even death occur. We find a tension in normal standards of ethical conduct where humans are involved in research. We found that location came to the fore as a key—though not the only—actor requiring attention when considering ethics in a big data context. ","",""
"2018","Ethics as Methods: Doing Ethics in the Era of Big Data Research—Introduction"," This is an introduction to the special issue of “Ethics as Methods: Doing Ethics in the Era of Big Data Research.” Building on a variety of theoretical paradigms (i.e., critical theory, [new] materialism, feminist ethics, theory of cultural techniques) and frameworks (i.e., contextual integrity, deflationary perspective, ethics of care), the Special Issue contributes specific cases and fine-grained conceptual distinctions to ongoing discussions about the ethics in data-driven research. In the second decade of the 21st century, a grand narrative is emerging that posits knowledge derived from data analytics as true, because of the objective qualities of data, their means of collection and analysis, and the sheer size of the data set. The by-product of this grand narrative is that the qualitative aspects of behavior and experience that form the data are diminished, and the human is removed from the process of analysis. This situates data science as a process of analysis performed by the tool, which obscures human decisions in the process. The scholars involved in this Special Issue problematize the assumptions and trends in big data research and point out the crisis in accountability that emerges from using such data to make societal interventions. Our collaborators offer a range of answers to the question of how to configure ethics through a methodological framework in the context of the prevalence of big data, neural networks, and automated, algorithmic governance of much of human socia(bi)lity ","",""
"2018","Addressing Conceptual Gaps in Big Data Research Ethics: An Application of Contextual Integrity"," The rise of big data has provided new avenues for researchers to explore, observe, and measure human opinions, activities, and interactions. While scholars, professional societies, and ethical review boards have long-established research ethics frameworks to ensure the rights and welfare of the research subjects are protected, the rapid rise of big data-based research generates new challenges to long-held ethical assumptions and guidelines. This article discloses emerging conceptual gaps in relation to how researchers and ethical review boards think about privacy, anonymity, consent, and harm in the context of big data research. It closes by invoking Nissenbaum’s theory of “privacy as contextual integrity” as a useful heuristic to guide ethical decision-making in big data research projects. ","",""
"2019","Computational Methods for Communication Science| Data Is the New Oil—But How Do We Drill It? Pathways to Access and Acquire Large Data Sets in Communication Science","In the Internet era, many forms of human communication leave massive digital traces that could serve as a revolutionary source of empirical information. However, researchers are often faced with extensive challenges when they try to access these “big communication data.” These restrictions prevent scientific exploration and the application of new computational methods and, thus, ultimately constrain the development of the field of computational communication science (CCS). As a first step to improve scientific access to large communication data, this article systematizes the data acquisition options and outlines their specific advantages and barriers based on a qualitative interview study with 22 researchers in the field of CCS. Three overarching themes are identified that seem to determine the resulting data quality of all data collection methods. On the basis of these findings, we develop an agenda on how communication science could overcome the challenges of accessing large data sets in the future.","",""
"2019","Making data colonialism liveable: how might data’s social order be regulated?","Humanity is currently underoing a large-scale social, economic, and legal transformation based on the massive appropriation of social life through data extract. This quantification of the social represents a new colonial move. While the modes, intensities, scales and contexts of dispossession have changed, the underlying drive of today’s data colonialism remains the same: the acquire “territory” and resources from which economic value can be extracted by capital. The injustices embedded in this system need to be made “liveable” through a new legal and regulatory order.","",""
"2019","Making sense of data ethics. The powers behind the data ethics debate in European policymaking",": This article offers an analytical investigation of the different actors and forces that mould definitions of “data ethics” in European policy-making. It details how data ethics public policy initiatives took shape in the context of the European General Data Protection reform, and addresses the general uncertainty that exists regarding their role and function. The paper also presents an analytical framework for an action-oriented “data ethics of power” that aims to elucidate the power relations of the ‘Big Data Society’, arguing that we recognise data ethics policy initiatives as open-ended spaces of negotiation among different interest groups that seek to guide the cultural definition of “data ethics”, with complex power relations exercised via cultural positioning.","",""
"2019","The ‘golden view’: data-driven governance in the scoring society","Drawing on the first comprehensive investigation into the uses of data analytics in UK public services, this article outlines developments and practices surrounding the upsurge in data-driven forms of what we term ‘citizen scoring’. This refers to the use of data analytics in government for the purposes of categorisation, assessment and prediction at both individual and population level. Combining Freedom of Information requests and semi-structured interviews with public sector workers and civil society organisations, we detail the practices surrounding these developments and the nature of concerns expressed by different stakeholder groups as a way to elicit the heterogeneity, tensions and negotiations that shape the contemporary landscape of data-driven governance. Described by practitioners as a way to achieve a ‘golden view’ of populations, we argue that data systems need to be situated in this context in order to understand the wider politics of such a ‘view’ and the implications this has for state-citizen relations in the scoring society.","",""
"2019","Datafication, development and marginalised urban communities: an applied data justice framework","ABSTRACT The role of data within international development is rapidly expanding. However, the recency of this phenomenon means analysis has been lagging; particularly, analysis of broader impacts of real-world initiatives. Addressing this gap through a focus on data’s increasing presence in urban development, this paper makes two contributions. First – drawing from the emerging literature on ‘data justice’ – it presents an explicit, systematic and comprehensive new framework that can be used for analysis of datafication. Second, it applies the framework to four mapping initiatives in cities of the global South. These initiatives capture and visualise new data about marginalised communities: residents living in slums and other informal settlements about whom data has traditionally been lacking. Analysing across procedural, rights, instrumental and structural dimensions, it finds these initiatives deliver real incremental gains for their target communities. But it is external actors and wealthier communities that gain more; thus, increasing relative inequality.","",""
"2019","Overcoming terms of service: a proposal for ethical distributed research","ABSTRACT The last two years has marked a turning point in access to large-scale social media data for many researchers, as platforms hobbled their APIs and made recording, archiving, and analyzing social life online far more difficult. Particularly in the context of the United States, where violating the rules put in place by social platforms has the potential to lead to criminal charges, the balance of power between the extremely financially successful social media industry on one side, and the users and researchers of these platforms on the other, has become dangerously skewed. This article argues for a pragmatic partnering with the users to do research, rather than with the platform owners, and suggests some ways in which this might be accomplished.","",""
"2019","Extra-activism: counter-mapping and data justice","ABSTRACT Neither big data, nor data justice are particularly new. Data collection, in the form of land surveys and mapping, was key to successive projects of European imperialist and then capitalist extraction of natural resources. Geo-spatial instruments have been used since the fifteenth century to highlight potential sites of mineral, oil, and gas extraction, and inscribe European economic, cultural and political control across indigenous territories. Although indigenous groups consistently challenged maintained their territorial sovereignty, and resisted corporate and state surveillance practices, they were largely unable to withstand the combined onslaught of surveyors, armed personnel, missionaries and government bureaucrats. This article examines the use of counter-mapping by indigenous nations in Canada, one of the globe’s hubs of extractivism, as part of the exercise of indigenous territorial sovereignty. After a brief review of the colonial period, I then compare the use of counter-mapping during two cycles of indigenous mobilization. During the 1970s, counter-mapping projects were part of a larger repertoire of negotiations with the state over land claims, and served to re-inscribe first nation’s long-standing history of economic, social and cultural relations in their territories, and contribute to new collective imaginaries and identities. In the current cycle of contests over extractivism and indigenous sovereignty, the use, scope and geographic scale of counter-mapping has shifted; maps are used as part of larger trans-media campaigns of Indigenous sovereignty. During both cycles, counter-mapping as data justice required fusion within larger projects of redistributive, transformative and restorative justice.","",""
"2019","The politics of big data. Big data, big brother?","Having grown out of a conference panel titled ‘Big Data, Big Brother?’ this edited volume engages with the politics of big data from different angles. The book comprises contributions from sociolog...","",""
"2019","When data justice and environmental justice meet: formulating a response to extractive logic through environmental data justice","ABSTRACT Environmental data justice (EDJ) emerges from conversations between data justice and environmental justice while identifying the limits and tensions of these lenses. Through a reflexive process of querying our entanglement in non-innocent relations, this paper develops and engages EDJ by examining how it informs the work of the Environmental Data & Governance Initiative (EDGI), a distributed, consensus-based organization that formed in response to the 2016 US presidential election. Through grassroots archiving of data sets, monitoring federal environmental and energy agency websites, and writing rapid-response reports about how federal agencies are being undermined, EDGI mobilizes EDJ to challenge the ‘extractive logic’ of current federal environmental policy and data infrastructures. ‘Extractive logic’ disconnects data from provenance, privileges the matrix of domination, and whitewashes data to generate uncertainty. We use the dynamic EDJ framework to reflect on EDGI’s public comment advising against the US Environmental Protection Agency’s proposed rule for Transparent Science. Through EDJ, EDGI aspires to create new environmental data infrastructures and practices that are participatory and embody equitable, transparent data care.","",""
"2019","Datafying anti-poverty programmes: implications for data justice","ABSTRACT This paper seeks to illuminate the significance of datafication for anti-poverty programmes, meaning social protection schemes designed specifically for poor people. The conversion of beneficiary populations into machine-readable data enables two core functions of social protection, those of recognising entitled beneficiaries and assigning entitlements connected to each anti-poverty scheme. Drawing on the incorporation of Aadhaar, India’s biometric population database, in the national agenda for social protection, we unpack a techno-rational perspective that crafts datafication as a means to enhance the effectiveness of anti-poverty schemes. Nevertheless, narratives collected in the field show multiple forms of data injustice on recipients, underpinned by Aadhaar’s functionality for a shift of the social protection agenda from in-kind subsidies to cash transfers. Based on such narratives the paper introduces a politically embedded view of data, framing datafication as a transformative force that contributes to reforming existing anti-poverty schemes.","",""
"2019","Data witnessing: attending to injustice with data in Amnesty International’s Decoders project","ABSTRACT The concept of witnessing has been used to explore the construction of evidence and experience in settings of law, religion, atrocity, media, history and science. Recent research has examined how digital technologies may multiply the involvement of remote, non-present and unanticipated actors in the witnessing of events. This paper examines what digital data practices at Amnesty International’s Decoders initiative can add to the understanding of witnessing. It introduces the notion of ‘data witnessing’ with reference to four projects on (i) witnessing historical abuses with structured data from digitised documents; (ii) witnessing the destruction of villages with satellite imagery and machine learning; (iii) witnessing environmental injustice with company reports and photographs; and (iv) witnessing online abuse through the classification of Twitter data. These projects illustrate the configuration of experimental apparatuses for witnessing injustices with data. In contrast to accounts which emphasise the presence of an individual human witness at the scene, Amnesty’s data practices are conspicuously collective and distributed, rendering the systemic scale of injustices at a distance, across space and time. Such practices may contribute to research on both (new) media witnessing and data politics, suggesting ways in which care, concern and solidarity may be constructed, structured, extended and delimited by means of digital data.","",""
"2019","The social impact of open government data in Hong Kong: Umbrella Movement protests and adversarial politics","Abstract While there has been much anticipation that open government data (OGD) would increase the inclusion of marginalized groups in government decision-making processes, researchers have found little evidence of it. Such findings or lack of findings of social impact have led researchers to call for critical review of present notions of OGD’s impact and also for better theoretical frameworks. In response to these calls, we develop a theoretical framework based on an ethnographic study of civic use of OGD in Hong Kong. We argue that constrained by the deliberative democracy models that focus on existing mechanisms of political participation, researchers have tended to overlook the use of OGD for protests, contestation, and other expressions of adversarial politics, which also produce a use of OGD for social impacts.","",""
"2019","Big data governance of personal health information and challenges to contextual integrity","Abstract Pervasive digitization and aggregation of personal health information (PHI), along with artificial intelligence (AI) and other advanced analytical techniques, hold promise of improved health and healthcare services. These advances also pose significant data governance challenges for ensuring value for individual, organizational, and societal stakeholders as well as individual privacy and autonomy. Through a case study of a controversial public-private partnership between Royal Free Trust, a National Health Service hospital system in the United Kingdom, and Alphabet’s AI venture DeepMind Health, we investigate how forms of data governance were adapted, as PHI data flowed into new use contexts, to address concerns of contextual integrity, which is violated when personal information collected in one use context moves to another use context with different norms of appropriateness.","",""
"2019","Impersonal subjectivation from platforms to infrastructures"," The rapid expansion of social media has led to the concentration of digitized, networked, and mediated processes into the hands of a few giant corporations (e.g. Google, Facebook, and Amazon), their partners and affiliates. From smart watches to targeted advertising and reputation scores, this new political economy of subjectivation – or subject making – sees an intensification of datafication to sell commodities, manipulate moods, inject ideologies, and influence behaviors. This article argues that in order to understand this new political economy of subjectivation, we need to complicate and build upon framework that focus on the collection of personal data and its risks on individual users. We argue that as social media and digital media giant corporations move away from an enclosed platform model toward a distributed, impersonal infrastructure, the mining of individual data and the shaping of individual attitudes is increasingly geared toward establishing relationships between user data and a plethora of non-human, environmental data. Such an infrastructure invokes impersonal subjects, and thus requires a new politics of relationality. ","",""
"2019","Accounting for Visual Bias in Tangible Data Design","Abstract                 Data engagement has become an important facet of engaged citizenship. While this is celebrated by those who advocate for expanding participatory channels in civic experience, others have rightfully expressed concern about the complicated dimensions of balancing access with data literacy. If engaged citizenship increasingly requires the ability to interpret civic data through city dashboards and open data portals, then there is a concomitant requirement for diverse populations to develop critical perspectives on data representation (what is commonly referred to as data visualisation, information graphics, etc.). Effective data representations are used to ground conversations, communicate policy ideas and substantiate arguments about important civic issues, but they are also frequently used to deceive and mislead. Expanding statistical, graphical, digital and media literacy is a necessary component of fostering a critical data culture, but who are the beneficiaries of expanded models of literacy and modes of civic engagement? Which communities are invalidated in the design of civic data interfaces? In this article, I summarise the results of a design study undertaken to inform the development of accessible data representation techniques. In this study, I conducted fourteen 2-h participatory design-inspired interview sessions with blind and visually impaired citizens. These sessions, in which I iteratively developed new physical data objects and assessed their interpretability, leveraged a public transit dataset made available by the City of Toronto through its open data portal. While ostensibly “open,” this dataset was initially published in a format that was exclusively visual, excluding blind and visually impaired citizens from engaging with it. What I discovered through the study was that the process of translating 2D, screen-based civic dashboards and data visualisations into tangible objects has the capacity to reintroduce visual biases in ways that data designers may not generally be aware of.","",""
"2019","PRESSURE CONTROLS: DATA FORCES CREEPING THROUGH FINGERTIP COMMANDS","AI methods and ubiquitous data sensors have enabled a new algorithmic quantification of affect with the possibility to detect or verify users’ identities, characteristics, emotional states, and physical traits. By scrutinizing how transient datasets are produced by user applied pressure on touch-screens (via fingertip commands) this paper showcases how sensory technology creeps into users’ everyday life with potential implementations connected to a series of emerging data issues engineered by a black-box design: one which obfuscates data production and precludes user consent under the disguise of “non-intrusive” features. Thereby, this paper explores the limits of user-based interrogation of black-boxes by researching tactile modes of operation, as a subset of behavioural biometrics, and sensors that register force in touch analysis and haptic technologies.&#x0D; Presenting a citation analysis of biometric techniques around the proposed usage of pressure; the authors offer a case-study examination of zinc-based force-sensing materials that are cost-effective and scalable to ubiquitous-computing and a prototype developed using ‘each pixel as a sensor’. By combining these approaches, this paper argues that such developments constitute a phenomenological shift away from users’ perception to data infrastructures working as assemblages of hidden technical sensations, and there is a need to expose these complex networks to afford some grasp, if not direct agency, over their micro temporal operation. This work aims not simply to theorise, but to help reveal ways users may revise, embrace, resist, subvert or even live data practices that operate unlike conventional data harvesting techniques.&#x0D;  ","",""
"2019","PRINCIPLES OF GOOD DATA","In recent years, there has been an exponential increase in the collection, aggregation and automated analysis of information by government and private actors that disproportionately disadvantages the underrepresented, marginalized and unheard. In response to this there has been significant critique regarding what could be termed ‘bad’ data practices in the globalised digital economy. Considerations of ‘bad data’ practices often only provide critiques rather than engaging constructively with a new vision of how digital technologies and data can be used productively and justly to promote social, economic, cultural and politically progressive goals. In this paper we consider the fundamentals of Good Data to increase trust. We begin by conceptual considerations of the nature of ‘data’ and ‘goodness’. We align our principles with the Data Information Knowledge Wisdom (DIKW) model and use the term ‘data’ as a proxy for the whole DIKW model. Given the limits of our knowledge of moral facts (should they exist) and in light of colonial and post-colonial data practices we assume a hybrid moral theory—where we allow that some moral facts may be objective (e.g. ‘tolerance’ or ‘openness’) and others relative. We advocate an ethic of active seeking, openness and tolerance to diverse views on ‘the good’ particularly consultation with the underrepresented, marginalised and unheard. We go on to defend fifteen principles of good data under four banners: Community, Rights, Usability &amp; Politics in order to ultimately progress a more just digital economy and society.","",""
"2019","Assessing the consequences of decentralizing biomedical research"," Advancements in technology are shifting the ways that biomedical data are collected, managed, and used. The pervasiveness of connected devices is expanding the types of information that are defined as ‘health data.’ Additionally, cloud-based mechanisms for data collection and distribution are shifting biomedical research away from traditional infrastructure towards a more distributed and interconnected ecosystem. This shift provides an opportunity for us to reimagine the roles of scientists and participants in health research, with the potential to more meaningfully engage in partnership across the research process. At the same time, these emerging practices present a potential to expose research participants to unanticipated and unintended consequences. Social norms and policy can help to mitigate these risks, but their development is often slow relative to the pace of technological advances and, as such, they can become reactive rather than prospective. As an alternative, the integrated development of data governance structures within technological advancements, supports their effective implementation, evaluation and evolution in a manner that can balance the benefits and risks of biomedical researcher in a decentralized ecosystem. ","",""
"2019","Logged out: Ownership, exclusion and public value in the digital data and information commons"," In recent years, critical scholarship has drawn attention to increasing power differentials between corporations that use data and people whose data is used. A growing number of scholars see digital data and information commons as a way to counteract this asymmetry. In this paper I raise two concerns with this argument: First, because digital data and information can be in more than one place at once, governance models for physical common-pool resources cannot be easily transposed to digital commons. Second, not all data and information commons are suitable to address power differentials. In order to create digital commons that effectively address power asymmetries we must pay more systematic attention to the issue of exclusion from digital data and information commons. Why and how digital data and information commons exclude, and what the consequences of such exclusion are, decide whether commons can change power asymmetries or whether they are more likely to perpetuate them. ","",""
"2019","Opening the black box of data-based school monitoring: Data infrastructures, flows and practices in state education agencies"," Contributing to a rising number of Critical Data Studies which seek to understand and critically reflect on the increasing datafication and digitalisation of governance, this paper focuses on the field of school monitoring, in particular on digital data infrastructures, flows and practices in state education agencies. Our goal is to examine selected features of the enactment of datafication and, hence, to open up what has widely remained a black box for most education researchers. Our findings are based on interviews conducted in three state education agencies in two different national contexts (the US and Germany), thus addressing the question of how the datafication and digitalisation of school governance has not only manifested within but also across educational contexts and systems. As our findings illustrate, the implementation of data-based school monitoring and leadership in state education agencies appears as a complex entanglement of very different logics, practices and problems, producing both new capabilities and powers. Nonetheless, by identifying different types of ‘doing data discrepancies’ reported by our interviewees, we suggest an analytical heuristic to better understand at least some features of the multifaceted enactment of data-based, increasingly digitalised governance, within and beyond the field of education. ","",""
"2019","What is responsible and sustainable data science?"," In the expansion of health ecosystems, issues of responsibility and sustainability of the data science involved are central. The idea that these values should be central to the practice of data science is increasingly gaining traction, yet there is no agreement on what exactly makes data science responsible or sustainable because these concepts prove slippery when applied to a global field involving commercial, academic and governmental actors. This lack of clarity is causing problems in setting goals and boundaries for data scientific practice, and risks fundamental disagreement on governance principles for this emerging field. We will argue in this commentary for a commons analytical framework as one approach to this problem, since it offers useful signposts for how to establish governance principles for shared resources. ","",""
"2019","Institutions, infrastructures, and data friction – Reforming secondary use of health data in Finland","New data-driven ideas of healthcare have increased pressures to reform existing data infrastructures. This article explores the role of data governing institutions during a reform of both secondary health data infrastructure and related legislation in Finland. The analysis elaborates on recent conceptual work on data journeys and data frictions, connecting them to institutional and regulatory issues. The study employs an interpretative approach, using interview and document data. The results show the stark contrast between the goals of open and Big Data inspired reforms and the existing institutional realities. The multiple tensions that emerged during the process indicate how data frictions emanate to the institutional level, and how mundane data practices and institutional dynamics are intertwined. The article argues that in the Finnish case, public institutions acted as sage-guards of public interest, preventing more controversial parts from passing. Finally, it argues that initiating regulatory and infrastructural reforms simultaneously was beneficial for solving the tensions of the initiative and analysing either side separately would have produced misleading accounts of the overall initiative. The results highlight the benefits of analysing institutional dynamics and data practices as connected issues.","",""
"2019","Negotiating the reuse of health-data: Research, Big Data, and the European General Data Protection Regulation","Before the EU General Data Protection Regulation entered into force in May 2018, we witnessed an intense struggle of actors associated with data-dependent fields of science, in particular health-related academia and biobanks striving for legal derogations for data reuse in research. These actors engaged in a similar line of argument and formed issue alliances to pool their collective power. Using descriptive coding followed by an interpretive analysis, this article investigates the argumentative repertoire of these actors and embeds the analysis in ethical debates on data sharing and biobank-related data governance. We observe efforts to perform a paradigmatic shift of the discourse around the General Data Protection Regulation-implementation away from ‘protecting data’ as key concern to ‘protecting health’ of individuals and societies at large. Instead of data protection, the key risks stressed by health researchers became potential obstacles to research. In line, exchange of information with data subjects is not a key concern in the arguments of biobank-related actors and it is assumed that patients want ‘their’ data to be used. We interpret these narratives as a ‘reaction’ to potential restrictions for data reuse and in line with a broader trend towards Big Data science, as the very idea of biobanking is conceptualized around long-term use of readily prepared data. We conclude that a sustainable implementation of biobanks needs not only to comply with the General Data Protection Regulation, but must proactively re-imagine its relation to citizens and data subjects in order to account for the various ways that science gets entangled with society.","",""
"2019","The social imaginaries of data activism"," Data activism, promoting new forms of civic and political engagement, has emerged as a response to problematic aspects of datafication that include tensions between data openness and data ownership, and asymmetries in terms of data usage and distribution. In this article, we discuss MyData, a data activism initiative originating in Finland, which aims to shape a more sustainable citizen-centric data economy by means of increasing individuals' control of their personal data. Using data gathered during long-term participant-observation in collaborative projects with data activists, we explore the internal tensions of data activism by first outlining two different social imaginaries – technological and socio-critical – within MyData, and then merging them to open practical and analytical space for engaging with the socio-technical futures currently in the making. While the technological imaginary favours data infrastructures as corrective measures, the socio-critical imaginary questions the effectiveness of technological correction. Unpacking them clarifies the kinds of political and social alternatives that different social imaginaries ascribe to the notions underlying data activism, and highlights the need to consider the social structures in play. The more far-reaching goal of our exercise is to provide practical and analytical resources for critical engagement in the context of data activism. By merging technological and socio-critical imaginaries in the work of reimagining governing structures and knowledge practices alongside infrastructural arrangements, scholars can depart from the most obvious forms of critique, influence data activism practice, and formulate data ethics and data futures. ","",""
"2019","Clouded data: Privacy and the promise of encryption"," Personal data is highly vulnerable to security exploits, spurring moves to lock it down through encryption, to cryptographically ‘cloud’ it. But personal data is also highly valuable to corporations and states, triggering moves to unlock its insights by relocating it in the cloud. We characterise this twinned condition as ‘clouded data’. Clouded data constructs a political and technological notion of privacy that operates through the intersection of corporate power, computational resources and the ability to obfuscate, gain insights from and valorise a dependency between public and private. First, we survey prominent clouded data approaches (blockchain, multiparty computation, differential privacy, and homomorphic encryption), suggesting their particular affordances produce distinctive versions of privacy. Next, we perform two notional code-based experiments using synthetic datasets. In the field of health, we submit a patient’s blood pressure to a notional cloud-based diagnostics service; in education, we construct a student survey that enables aggregate reporting without individual identification. We argue that these technical affordances legitimate new political claims to capture and commodify personal data. The final section broadens the discussion to consider the political force of clouded data and its reconstitution of traditional notions such as the public and the private. ","",""
"2019","Datafied knowledge production: Introduction to the special theme","Framing datafication as new form of knowledge production has become a trope in both academic and commercial contexts. This special theme examines and ultimately rejects the familiar grand claims of datafication, to instead pay attention to emergent conversations that seek to take a more nuanced stock of the status and nature of datafied knowledge production. The articles in this special theme thus engage with datafied knowledge production through elaborate explorations of how datafied knowledge depends on the contexts of its production and the forms of knowledge production that precede it in those contexts. Our basic argument is that while the resources, material features and analytical operations involved in datafied knowledge production may be different, many fundamental concerns about epistemology, ontology and methods remain relevant to understand what shapes it. We still need to understand and explicate the assumptions, operations and consequences of emergent forms of knowledge production. If datafied knowledge production is neither a clean revolutionary break with past forms of knowledge production nor a balloon of pure hype, the articles in this special theme ask: what does the phenomenon of datafied knowledge production look like? Which digital and datafied infrastructures support its future development? And what potentialities and limits do such forms of analysis and knowledge production contain?","",""
"2019","Conceptual frameworks for social and cultural Big Data analytics: Answering the epistemological challenge"," This paper aims to contribute to the development of tools to support an analysis of Big Data as manifestations of social processes and human behaviour. Such a task demands both an understanding of the epistemological challenge posed by the Big Data phenomenon and a critical assessment of the offers and promises coming from the area of Big Data analytics. This paper draws upon the critical social and data scientists’ view on Big Data as an epistemological challenge that stems not only from the sheer volume of digital data but, predominantly, from the proliferation of the narrow-technological and the positivist views on data. Adoption of the social-scientific epistemological stance presupposes that digital data was conceptualised as manifestations of the social. In order to answer the epistemological challenge, social scientists need to extend the repertoire of social scientific theories and conceptual frameworks that may inform the analysis of the social in the age of Big Data. However, an ‘epistemological revolution’ discourse on Big Data may hinder the integration of the social scientific knowledge into the Big Data analytics. ","",""
"2019","When data is capital: Datafication, accumulation, and           extraction"," The collection and circulation of data is now a central element of increasingly more sectors of contemporary capitalism. This article analyses data as a form of capital that is distinct from, but has its roots in, economic capital. Data collection is driven by the perpetual cycle of capital accumulation, which in turn drives capital to construct and rely upon a universe in which everything is made of data. The imperative to capture all data, from all sources, by any means possible influences many key decisions about business models, political governance, and technological development. This article argues that many common practices of data accumulation should actually be understood in terms of data extraction, wherein data is taken with little regard for consent and compensation. By understanding data as a form capital, we can better analyse the meaning, practices, and implications of datafication as a political economic regime. ","",""
"2019","“You Social Scientists Love Mind Games”: Experimenting in the “divide” between data science and critical algorithm studies"," In recent years, many qualitative sociologists, anthropologists, and social theorists have critiqued the use of algorithms and other automated processes involved in data science on both epistemological and political grounds. Yet, it has proven difficult to bring these important insights into the practice of data science itself. We suggest that part of this problem has to do with under-examined or unacknowledged assumptions about the relationship between the two fields—ideas about how data science and its critics can and should relate. Inspired by recent work in Science and Technology Studies on interventions, we attempted to stage an encounter in which practicing data scientists were asked to analyze a corpus of critical social science literature about their work, using tools of textual analysis such as co-word and topic modelling. The idea was to provoke discussion both about the content of these texts and the possible limits of such analyses. In this commentary, we reflect on the planning stages of the experiment and how responses to the exercise, from both data scientists and qualitative social scientists, revealed some of the tensions and interactions between the normative positions of the different fields. We argue for further studies which can help us understand what these interdisciplinary tensions turn on—which do not paper over them but also do not take them as given. ","",""
"2019","Introduction to the Special Theme: The expansion of the health data ecosystem – Rethinking data ethics and governance","As in other domains, digital data are taking on an ever more central role in health and medicine today. And as it has in other domains, ‘datafication’ is contributing to a re-configuration of health and medicine, prompting its expansion to include new spaces, new practices, new techniques and new actors. Indeed, possibilities to quantify and ‘datafy’ areas of life that have not traditionally been considered the remit of biomedicine – such as sleep, ageing and emotions – and activities that have not traditionally been considered markers of health and disease – such as a person’s consumption patterns, her social media activity or her dietary habits – coupled with the promise of linking these heterogeneous datasets to glean medical insights, have contributed to a redefinition of almost any data as health-related data (Lucivero and Prainsack, 2015; Weber et al., 2014). Increasingly, these new types of data are being generated outside the traditional spaces of medicine, as people go about their daily lives interacting with consumer mobile devices. Similarly, the technological tools needed to capture, store, analyze and manage the flow of these data, from wearables and smart phones to cloud platforms and machine learning, increasingly rely on infrastructure and know-how that lie beyond the scope of traditional medical systems and scientists, amongst data scientists and information and communication technologies specialists. Moreover, new stakeholders are cropping up in these quasi-medical yet still undomesticated territories. On one end of the spectrum, individuals who generate health data as they track and monitor medical conditions, well-being, physical activity, or air quality, are both solicited as research participants and are making demands on researchers to utilize their personal health data (Health Data Exploration Project, 2014). On the other end of the spectrum, consumer technology corporations such as Apple and Google are reinventing themselves as obligatory passage points for dataintensive precision medicine (Sharon, 2016). And somewhere in between, not-for-profit organizations, such as Sage Bionetworks and OpenHumans.org, are positioning themselves as mediators in this ecosystem in formation, between the medical research community, individual and collective generators of data and technology developers. As proponents uphold, this expansion and decentralization of the health data ecosystem is promising, both in terms of the potential to advance data-driven research and healthcare, and in terms of rendering research more inclusive and more meaningful for participants (Shen, 2015; Topol, 2015). But, as critical scholars of science and technology have consistently shown, a fuller grasp of our technological present must always include the far-reaching, unexpected and sometimes deleterious social, political and cultural effects of discourses of scientific progress and technologically enabled democratization and participation. In recent years, such critical scholarship has been particularly wary of the new power asymmetries that datafication contributes to. Rather than levelling power relations, critics observe, these are being redrawn along new digital divides based on data ownership or access, control over digital infrastructures and new types of computational expertise, where those who generate data, especially citizens, patients and consumers, are positioned on the losing side of the on-going extraction and scramble for the world’s data driven by state","",""
"2019","Producing and projecting data: Aesthetic practices of government data portals"," We develop the concept of ‘aesthetic practices’ to capture the work needed for population data to be disseminated via government data portals. Specifically, we look at the Census Hub of the European Statistical System and the Danish Ministry of Education’s Data Warehouse. These portals form part of open government data initiatives, which we understand as governing technologies. We argue that to function as such, aesthetic practices are required so that data produced at dispersed sites can be brought into relation and projected as populations in forms such as bar charts, heat maps and tables. Two examples of aesthetic practices are analysed based on ethnographic studies we have conducted on the production of data for the Hub and Warehouse: metadata and data cleaning. Metadata enables data to come into relation by containing and accounting for (some of) the differences between data. Data cleaning deals with the indeterminacies and absences of data and involves algorithms to determine what values data can obtain so they can be brought into relation. We attend to how both aesthetic practices involve normative decisions that make absent what exceeds them: embodied knowledge that cannot or has not been documented as well as data that cannot meet the forms required of data portals. While these aesthetic practices are necessary to sustain data portals as ‘sites of projection,’ we also bring critical attention to their performative effects for knowing, enacting and governing populations. ","",""
"2019","Data out of place: Toxic traces and the politics of recycling"," It has become increasingly common to talk about “digital traces”. The idea that we leak, drop and leave traces wherever we go has given rise to a culture of traceability, and this culture of traceability, I argue, is intimately entangled with a socio-economics of data disposability and recycling. While the culture of traceability has often been theorised in terms of, and in relation to, privacy, I offer another approach, framing digital traces instead as a question of waste. This perspective, I argue, allows us to connect to, extend and nuance existing discussions of digital traces. It shows us that data traces raise questions about not only how data capitalism tracks individual and multiple data behaviours, but also how it links to social and environmental toxicities in the form of abuse and environmental pollution, which follow gendered and colonial structures of violence. ","",""
"2019","The optical unconscious of Big Data: Datafication of vision and care for unknown futures"," Ever since Big Data became a mot du jour across social fields, optical metaphors such as the microscope began to surface in popular discourse to describe and qualify its epistemological impact. While the persistence of optics seems to be at odds with the datafication of vision, this article suggests that the optical metaphor offers an opportunity to reflect about the material consequences of the modes of seeing and knowing that currently shape datafied worlds. Drawing on feminist new materialism, the article investigates the optical metaphor as a material-discursive practice that actively constitutes the world, as metaphors imply modes of thinking, knowing and doing that have material enactions. Expanding visual culture theories, the notion of ‘optical unconscious’ is taken up to discuss the tensions between displacement and persistence of optics within datafied worlds, that is, how optical vision is displaced but also mobilised and repurposed by data-driven knowledge. In dialogue with feminist science and technology studies and speculative ethics, I suggest that the datafication of vision offers a chance to reconceptualize the sense of sight towards a sensorial engagement with Big Data premised on responsibility, care, and an ethics of unknowability. Within this framework, vision may be conceived differently, perhaps not only as enhancement and control, but as generator of new possibilities. Ultimately, the article proposes that the visual theories after which Big Data is being imagined matter not only for our understanding of Big Data's epistemic potential, but also for the possibility of shaping emerging data worlds. ","",""
"2019","Medical research, Big Data and the need for privacy by design"," Medical research data is sensitive personal data that needs to be protected from unauthorized access and unintentional disclosure. In a research setting, sharing of (big) data within the scientific community is necessary in order to make progress and maximize scientific benefits derived from valuable and costly data. At the same time, convincingly protecting the privacy of people (patients) participating in medical research is a prerequisite for maintaining trust and willingness to share. In this commentary, we will address this issue and the pitfalls involved in the context of the PEP project 1  that provides the infrastructure for the Personalized Parkinson’s Project, 2  a large cohort study on Parkinson’s disease from Radboud University Medical Center (Radboudumc), in cooperation with Verily life Sciences, an Alphabet subsidiary. ","",""
"2019","Big Data, precision medicine and private insurance: A delicate balancing act"," In this paper, we discuss how access to health-related data by private insurers, other than affecting the interests of prospective policy-holders, can also influence their propensity to make personal data available for research purposes. We take the case of national precision medicine initiatives as an illustrative example of this possible tendency. Precision medicine pools together unprecedented amounts of genetic as well as phenotypic data. The possibility that private insurers could claim access to such rapidly accumulating biomedical Big Data or to health-related information derived from it would discourage people from enrolling in precision medicine studies. Should that be the case, the economic value of personal data for the insurance industry would end up affecting the public value of data as a scientific resource. In what follows we articulate three principles – trustworthiness, openness and evidence – to address this problem and tame its potentially harmful effects on the development of precision medicine and, more generally, on the advancement of medical science. ","",""
"2019","Engaging with ethics in Internet of Things: Imaginaries in the social milieu of technology developers"," Discussions about ethics of Big Data often focus on the ethics of data processing: collecting, storing, handling, analysing and sharing data. Data-based systems, however, do not come from nowhere. They are designed and brought into being within social spaces – or social milieu. This paper connects philosophical considerations of individual and collective capacity to enact practical reason to the influence of social spaces. Building a deeper engagement with the social imaginaries of technology development through analysis of two years of fieldwork with start-ups working on Internet of Things, this paper suggests that different action positions can emerge, with consequences for how data is understood and valued. The Disengaged, Pragmatist and Idealist ethical action positions identified in the paper reveal the ways individuals and groups negotiate possibilities for ethical action, through justifications, explanations and structuring of system features. ","",""
"2019","From data politics to the contentious politics of data","This article approaches the paradigm shift of datafication from the perspective of civil society. Looking at how individuals and groups engage with datafication, it complements the notion of “data politics” by exploring what we call the “contentious politics of data”. By contentious politics of data we indicate the bottom-up, transformative initiatives interfering with and/or hijacking dominant processes of datafication, contesting existing power relations or re-appropriating data practices and infrastructure for purposes distinct from the intended. Said contentious politics of data is articulated in an array of practices of data activism taking a critical stance towards datafication. In data activism, data as mediators take a central role, both as part of an action repertoire or as objects of struggle in their own right. Leveraging social movement studies and science and technology studies, this theoretical essay argues that data activism can be mapped along two analytical dimensions: “data as stakes” (as issues and/or objects of political struggle in their own right) vs. “data as repertoires” (or modular tools for political struggle), and “individual practice vs. collective action”. Mapping action repertoires and tactics along these axes allows us to chart the potential emergence of a political ( contentious) data subject at the intersection of these two dimensions. This furthers our understanding of people’s engagement with data in relation to other forms of activism and existing work in social movement studies. It also helps us interpreting potential trajectories of contemporary social movements, as they increasingly interface with data, devices and platforms.","",""
"2019","Cat-and-Mouse Games: Dataveillance and Performativity in Urban Schools","This paper focuses on the responses of teachers and students in a South Los Angeles public high school to dataveillance regimes that were meant to control specific behaviors. Over a period of two years, a newly deployed one-to-one tablet computer program supported the integration of dataveillance regimes with previously established modes of pursuing teacher and student accountability. As tablet computers achieved ubiquity, students, teachers, and administrators challenged the ambiguous relationship between digital data and the behavior of subjects putatively described by these data. Conflicts over digital data—what data could mean, what they could stand in for, and what could be deemed normal or aberrant—emerged between school authorities and targets of dataveilleance. Where school authorities often depicted their own surveillance capabilities as immediate, inescapable, and predictive, contests over the interpretation of data attenuated this power, showing it to be partial, negotiated, and retroactive, a dynamic this study refers to as interpretive resistance. This study uses a theoretical framework based on performativity of digital data to think through the implications of observed contestations around representation. Performativity conceptualizes digital data not as a set of objective, value-neutral observations but as the ability to produce statuses of norm and deviance.","",""
"2019","Uncertain Archives: Approaching the Unknowns, Errors, and Vulnerabilities of Big Data through Cultural Theories of the Archive","From global search engines to local smart cities, from public health monitoring to personal self-tracking technologies, digital technologies continuously capture, process, and archive social, material, and affective information in the form of big data. Although the use of big data emerged from the human desire to acquire more knowledge and master more information and to eliminate human error in large-scale information management, it has become clear in recent years that big data technologies, and the archives of data they accrue, bring with them new and important uncertainties in the form of new biases, systemic errors, and, as a result, new ethical challenges that require urgent attention and analysis. This collaboratively written article outlines the conceptual framework of the Uncertain Archives research collective to show how cultural theories of the archive can be meaningfully applied to the empirical field of big data. More specifically, the article argues that this approach grounded in cultural theory can help research going forward to attune to and address the uncertainties present in the storage and analysis of large amounts of information. By focusing on the notions of the unknown, error, and vulnerability, we reveal a set of different, albeit intertwined, configurations of archival uncertainty that emerge along with the phenomenon of big data use. We regard these configurations as central to understanding the conditions of the digitally networked data archives that are a crucial component of today’s cultures of surveillance and governmentality.","",""
"2019","Open data, closed government: Unpacking data.gov.sg","In 2011, Singapore created data.gov.sg as an open, online repository for government data. This essay examines this Web portal, the data it contains, and some of the applications that have been built using it and aims to understand the role that data.gov.sg plays within the context of Singapore’s continued political and economic development. Although such portals and the data they contain are often presented as offering transformative modes of governance and democratic participation, analysis of data.gov.sg shows how the data portal can act to reinforce and entrench existing modes of governance.","",""
"2019","Playing with data and its consequences","The fundamental paradigm shift brought about by datafication alters how people participate as citizens on a daily basis. “Big data” has come to constitute a new terrain of engagement, which brings organized collective action, communicative practices and data infrastructure into a fruitful dialogue. While scholarship is progressively acknowledging the emergence of bottom-up data practices, to date no research has explored the influence of these practices on the activists themselves. Leveraging the disciplines of critical data and social movement studies, this paper explores “proactive data activism”, using, producing and/or appropriating data for social change, and examines its biographical, political, tactical and epistemological consequences. Approaching engagement with data as practice, this study focuses on the social contexts in which data are produced, consumed and circulated, and analyzes how tactics, skills and emotions of individuals evolve in interplay with data. Through content and co-occurrence analysis of semi-structured practitioner interviews (N=20), the article shows how the employment of data and data infrastructure in activism fundamentally transforms the way activists go about changing the world.","",""
"2019","The politics of big borders: Data (in)justice and the governance of refugees","This article provides an overview of the collection and uses of data in relation to European border regimes. We analyse the significance of these developments for the governance of refugee populations and make the case that within the current policy context of European border control, data functions to systematically stigmatize, exclude and oppress ‘unwanted’ migrant populations through mechanisms of criminalisation, identification, and social sorting. This, we argue, highlights the need to engage with data politics in a way that considers both the politics in data as well as the politics of data, highlighting the agendas and interests that advance the implementation of these technologies, privileging justice concerns on terms that go beyond techno-legal solutions, and positioning those who are most impacted by developments at the forefront of discussions.","",""
"2019","Data-driven models of governance across borders: Datafication from the local to the global","This special issue looks closely at contemporary data systems in diverse global contexts and through this set of papers, highlights the struggles we face as we negotiate efficiency and innovation with universal human rights and social inclusion. The studies presented in these essays are situated in diverse models of policy-making, governance, and/or activism across borders. Attention to big data governance in western contexts has tended to highlight how data increases state and corporate surveillance of citizens, affecting rights to privacy. By moving beyond Euro-American borders — to places such as Africa, India, China, and Singapore — we show here how data regimes are motivated and understood on very different terms.","",""
"2019","Lay perspectives on big data: Insights from citizen conferences in Germany","As big data shapes more and more aspects of our lives, a wide-spread concern is that the affected people’s interests are not sufficiently taken into account. The field of participatory technology assessment (pTA) has attempted to make such processes more democratic by involving laypeople as an additional voice to the often rather expert-driven development. This text presents the lessons learned from such an endeavor, namely three citizen conferences on big data held in Germany. The empirical results are presented and critically contextualized in the larger discourse on pTA and big data. Therefore, the article sheds light on lay perspectives on big data while also providing insights into the strengths and weaknesses of participatory methods such as citizen conferences.","",""
"2019","Ethics of identity in the time of big data","Compartmentalizing our distinct personal identities is increasingly difficult in big data reality. Pictures of the person we were on past vacations resurface in employers’ Google searches; LinkedIn which exhibits our income level is increasingly used as a dating web site. Whether on vacation, at work, or seeking romance, our digital selves stream together. One result is that a perennial ethical question about personal identity has spilled out of philosophy departments and into the real world. Ought we possess one, unified identity that coherently integrates the various aspects of our lives, or, incarnate deeply distinct selves suited to different occasions and contexts? At bottom, are we one, or many? The question is not only palpable today, but also urgent because if a decision is not made by us, the forces of big data and surveillance capitalism will make it for us by compelling unity. Speaking in favor of the big data tendency, Facebook’s Mark Zuckerberg promotes the ethics of an integrated identity, a single version of selfhood maintained across diverse contexts and human relationships. This essay goes in the other direction by sketching two ethical frameworks arranged to defend our compartmentalized identities, which amounts to promoting the dis-integration of our selves. One framework connects with natural law, the other with language, and both aim to create a sense of selfhood that breaks away from its own past, and from the unifying powers of big data technology.","",""
"2019","Aggregations of the opaque: Rethinking datafication and e-waste","This paper points to phenomena that are undeniably intrinsic to the datafied society, yet that themselves belie the dream/nightmare of total control through datafication: electronic waste (e-waste) and its recycling. In recycling industries and reverse logistics, invisibility, opacity, and uncertainty persist despite worldwide networks of surveillance, datafication, and algorithmic calculation. Mobilizing different technologies from RFID to big data, data assemblages enact particular regimes of visibility that cohere three “gazes”: security’s gaze, efficiency’s gaze, and speculation’s gaze. Yet along with these gazes come various forms of sightlessness, which I frame respectively as “blind eye,” “blind spot,” and “blindsight.” Looking at datafication through e-waste teaches us that critique should not start from the presumption of increasingly all-encompassing datafication, but instead analyze the (constitutive) limitations and (productive) excesses at stake in data assemblages.","",""
"2019","Analyzing the legal roots and moral core of digital consent"," We will argue that clarifying the “moral core” of consent offers a common metric by which we can evaluate how well different legal frameworks are able to protect the central moral rights and interests at stake. We begin by revisiting how legal frameworks for digital consent developed in order to see where there may be common moral ground and where these different cultures diverge on the issue of protection of personal information. We then turn to ethics to clarify the central interests and rights at stake in morally transformative consent, in order to provide a common basis for evaluating the different legal frameworks. Ultimately, we seek the moral core of digital consent in order to reimagine its role in international conflicts. ","",""
"2019","Imagining big data: Illustrations of “big data” in US news articles, 2010–2016"," Imagining “big data” brings up a palette of concerns about their technological intricacies, political significance, commercial value, and cultural impact. We look at this emerging arena of public sense-making and consider the spectrum of press illustrations that are employed to show what big data are and what their consequences could be. We collected all images from big data-related articles published in the online editions of The New York Times and The Washington Post. As the first examination of the visual dimension of big data news reports to date, our study suggests that big data are predominantly illustrated with reference to their areas of application and the people and materials involved in data analytics. As such, they provide concrete physical form to abstract data. Rather than conceiving of potential ramifications that are more or less likely to materialize, the dominant mode of illustration draws on existing, though often trite, visual evidence. ","",""
"2019","Technocolonialism: Digital Innovation and Data Practices in the Humanitarian Response to Refugee Crises"," Digital innovation and data practices are increasingly central to the humanitarian response to recent refugee and migration crises. In this article, I introduce the concept of technocolonialism to capture how the convergence of digital developments with humanitarian structures and market forces reinvigorates and reshapes colonial relationships of dependency. Technocolonialism shifts the attention to the constitutive role that data and digital innovation play in entrenching power asymmetries between refugees and aid agencies and ultimately inequalities in the global context. This occurs through a number of interconnected processes: by extracting value from refugee data and innovation practices for the benefit of various stakeholders; by materializing discrimination associated with colonial legacies; by contributing to the production of social orders that entrench the “coloniality of power”; and by justifying some of these practices under the context of “emergencies.” By reproducing the power asymmetries of humanitarianism, data and innovation practices become constitutive of humanitarian crises themselves. ","",""
"2019","Hacking Social Science for the Age of Datafication","  The ongoing and intensifying datafication of our societies poses huge challenges as well as opportunities for social science to rethink core elements of its research enterprise. Prominently, there is a pressing need to move beyond the long-standing qualitative/quantitative divide. This paper is an argument towards developing a critical science of data, by bringing together the interpretive theoretical and ethical sensibilities of social science with the predictive and prognostic powers of data science and computational methods. I argue that the renegotiation of theories and research methods that must be made in order for them to be more relevant and useful, can be fruitfully understood through the metaphor of hacking social science: developing creative ways of exploiting existing tools in alternative and unexpected ways to solve problems  ","",""
"2019","In Search of Meaning: Why We Still Don't Know What Digital Data Represent","  In the early years, researchers greeted the internet and digital data with almost wide-eyed wonder and excitement. The opportunities provided by digital media such as websites, bulletin boards, and blogs—and later by social media platforms and mobile apps—seemed nearly endless, and researchers were suddenly awash in data. The bounty was so great that it required new methods for processing, organizing, and analysis. Yet in all the excitement, it seems that the digital research community largely lost sight of something fundamental: a sense of what all these data actually represent. In this essay, I argue that moving forward, researchers need to take a critical look into, be more open about, and develop better approaches for drawing inferences and larger meaning from digital data. I suggest that we need to more closely interrogate what these data represent in at least two senses: statistical and contextual. In the former instance I call for much greater modesty in digital social research. In the latter, I call for heuristic models that permit bolder, more robust comparisons throughout our work.  ","",""
"2019","(Big) Data and the North-<i>in</i>-South: Australia’s Informational Imperialism and Digital Colonialism"," Australia is a country firmly part of the Global North, yet geographically located in the Global South. This North-in-South divide plays out internally within Australia given its status as a British settler-colonial society which continues to perpetrate imperial and colonial practices vis-à-vis the Indigenous peoples and vis-à-vis Australia’s neighboring countries in the Asia-Pacific region. This article draws on and discusses five seminal examples forming a case study on Australia to examine big data practices through the lens of Southern Theory from a criminological perspective. We argue that Australia’s use of big data cements its status as a North-in-South environment where colonial domination is continued via modern technologies to effect enduring informational imperialism and digital colonialism. We conclude by outlining some promising ways in which data practices can be decolonized through Indigenous Data Sovereignty but acknowledge these are not currently the norm; so Australia’s digital colonialism/coloniality endures for the time being. ","",""
"2019","Data Colonialism: Rethinking Big Data’s Relation to the Contemporary Subject"," We are often told that data are the new oil. But unlike oil, data are not a substance found in nature. It must be appropriated. The capture and processing of social data unfolds through a process we call data relations, which ensures the “natural” conversion of daily life into a data stream. The result is nothing less than a new social order, based on continuous tracking, and offering unprecedented new opportunities for social discrimination and behavioral influence. We propose that this process is best understood through the history of colonialism. Thus, data relations enact a new form of data colonialism, normalizing the exploitation of human beings through data, just as historic colonialism appropriated territory and resources and ruled subjects for profit. Data colonialism paves the way for a new stage of capitalism whose outlines we only glimpse: the capitalization of life without limit. ","",""
"2019","Between Data Capitalism and Data Citizenship"," We discuss two points raised by the articles in this special issue, which are related to our previous work on media movements in Latin America. First, we analyze the dimensions of data activism in the region. Recent experiences in Latin America suggest two types of data activism differentiated by goals and spheres of action: social data activism and data rights activism. They also have diverse tactics and achievements. Second, we discuss the Global South as the site of counter-epistemic and alternative practices, and we wonder whether the concept of “data colonialism” adequately captures the dynamics of the digital society in areas of well-entrenched digital divides. We argue that datafication and the opposition to datafication in the South does not develop exactly as in the North given huge political, economic, social, and technological differences in the context of the expansion of digital capitalism. ","",""
"2019","#NiUnaMenos: Data Activism From the Global South"," This article explores the creation of a national index of sexist violence in Argentina in 2016 as an example of data activism in the Global South. Drawing upon a qualitative content analysis of press coverage and activist posts on social media, as well as interviews with activists, it describes the context of the #NiUnaMenos feminist mobilization and the collection “from below” of data on gender violence. This study illustrates how activists in the Global South can appropriate technology and promote new uses that not only respond to their local and immediate needs but also contribute to the production of alternative imaginaries on big data in the longer term. Moreover, the article positions women’s movements as an essential component of current social movements in Latin America. ","",""
"2019","Big Data from the South(s): Beyond Data Universalism"," This article introduces the tenets of a theory of datafication of and in the Souths. It calls for a de-Westernization of critical data studies, in view of promoting a reparation to the cognitive injustice that fails to recognize non-mainstream ways of knowing the world through data. It situates the “Big Data from the South” research agenda as an epistemological, ontological, and ethical program and outlines five conceptual operations to shape this agenda. First, it suggests moving past the “universalism” associated with our interpretations of datafication. Second, it advocates understanding the South as a composite and plural entity, beyond the geographical connotation (i.e., “global South”). Third, it postulates a critical engagement with the decolonial approach. Fourth, it argues for the need to bring agency to the core of our analyses. Finally, it suggests embracing the imaginaries of datafication emerging from the Souths, foregrounding empowering ways of thinking data from the margins. ","",""
"2019","Audiences in an Age of Datafication: Critical Questions for Media Research"," This article critically examines how fears of audience gullibility, ignorance, and exploitation impede media studies’ response to the pressing challenges posed by the growing power of social media platforms and their innovative datafication practices. I revisit the history of audience research to show how empirical findings contested the pejorative conception of the audience problematically yet persistently imagined by theorists of media power during the twentieth century. As media studies joins other disciplines in responding to the growing datafication of society, I propose that the circuit of culture model can help theorize media (including platform and algorithmic) power by opening up the hermeneutic and action space between production and consumption. In this way, critical scholarship might more effectively analyze such metaprocesses as mediatization and datafication precisely by recognizing rather than erasing audiences’ relation to both the everyday lifeworld and the public world of citizen action, regulatory intervention, and the wider society. ","",""
"2019","Data Epistemologies, The Coloniality of Power, and Resistance"," Data assemblages amplify historical forms of colonization through a complex arrangement of practices, materialities, territories, bodies, and subjectivities. Data-centric epistemologies should be understood as an expression of the coloniality of power manifested as the violent imposition of ways of being, thinking, and feeling that leads to the expulsion of human beings from the social order, denies the existence of alternative worlds and epistemologies, and threatens life on Earth. This article develops a theoretical model to analyze the coloniality of power through data and explores the multiple dimensions of coloniality as a framework for identifying ways of resisting data colonization. Finally, this article suggests possible alternative data epistemologies that are respectful of populations, cultural diversity, and environments. ","",""
"2020","What Data Can Do: A Typology of Mechanisms","This article offers an analytical framework for understanding the effects of data on the social world. Specifically, I ask: What happens when new data —digital or not—is introduced in a given context? Drawing on a mix of historical and contemporary examples, I provide a typology of 5 mechanisms: tracking, homogenizing, triaging, nudging, and valuating. I then demonstrate how this framework can change how we understand two empirical cases involving data-driven software programs, one in Web journalism and the other in criminal justice. Based on this analysis, the article makes three main points. First, at a time of rapid technological development, we should pay particular attention to what is not changing with digitization. Second, we need further theoretical integration in the rapidly growing field of critical data studies. Third, I suggest that the umbrella concept of “data” should be broken down into smaller and more manageable components depending on the mechanisms scholars are interested in studying.","",""
"2020","Thinking With Care About Personal Data Profiling: A More-Than-Human Approach","People’s understandings and practices related to their digitized personal information are urgent topics of social inquiry in an increasingly datafied world. This article draws on findings from an Australian qualitative study in which the stimulus of the “data persona” and an online platform were used to engage participants’ social imaginaries concerning how data profiling can benefit or harm them and to what extent they care about their personal data. The findings were theorized by thinking with more-than-human scholarship and theories of care. The study found that although these participants were well aware of data profiling and algorithmic processes such as those used for targeted advertising, most did not feel personally vulnerable to harms or risks. The participants suggested that datafication and dataveillance could never access their “real selves.” Data profiling was predominantly viewed as helpful in providing better customization. In some situations, however, data profiling and related data processing could be selective, fragmentary, and dehumanizing. The article ends with discussion of the broader implications of the study’s findings for theorizing and understanding human–data relations.","",""
"2020","The Power of Data From the Global South: Environmental Civic Tech and Data Activism in China","This article explores how an established environmental nongovernmental organization, the Institute of Public and Environmental Affairs (IPE), engaged in data activism around a civic tech platform in China, expanding the space for public participation. By conducting participatory observation and interviews, along with document analysis, we describe three modes of data activism that represent different mechanisms of civic oversight in the environmental sphere. Unlike contentious data activism in the Western context, we argue that IPE activists’ data practices are localized in the specific sociopolitical culture shaped by China’s authoritarian system. These practices do not involve contentious political criticism against the government, although they have monitoring functions. By finding the middle ground between confrontation and state control, IPE activists participated in the political process as policy entrepreneurs who pursue their political goals in cooperation with the government. Rather than mobilizing radical contestation, environmental data activism in China works as a constructive alternative to the denial of the existing government system, transmitting public input into the policy-making process.","",""
"2020","Cryptoparties: empowerment in internet security",": Cryptoparties (CPs) are a global movement of forums where citizens can come to learn how to improve their digital privacy and security. The present paper is one of the few empirical studies on CPs and is based on participant observation of three CPs. I demonstrate that the organisers of CPs strive for an egalitarian space for teaching and learning. Even though this goal is not always achieved, CPs might still serve as an example of citizen education in a technological society where every citizen needs to deal with complex technological issues. In addition, this paper contributes to the emerging debate on ‘doing internet governance’, broadening our focus to include user-based and decentred practices. I argue for the political relevance of CPs showing how they enact decentred threat-scenarios to a non-expert public.","",""
"2020","Algorithmic systems: the consent is in the detail?","Applications of algorithmically informed decisions are becoming entrenched in society, with data processing being their main process and ingredient. While these applications are progressively gaining momentum, established data protection and privacy rules have struggled to incorporate the particularities of data-intensive information societies. It is a truism to point out the resulting misalignment between algorithmic processing of personal data and the data protection regulatory frameworks that strive for meaningful control over personal data. However, the challenges to the (traditional) role and concept of consent are particularly manifest. This article examines the transformation of consent models in order to assess how the concept and the applied models of consent can be reconciled so as to correspond not only to the current regulatory landscapes but also to the exponential growth of algorithmic processing technologies. This particularly pressing area of safeguarding a basic aspect of individual control over personal data in the algorithmic era is interlinked with practical implementations of consent in the technology used and with adopted interpretations of the concept of consent, the scope of application of personal data, as well as the obligations enshrined in them. What makes consent effective as a data protection tool and how can we maintain its previous glory within the current technological challenges?","",""
"2020","Vocations, visions and vitalities of data analysis. An introduction","ABSTRACT Vocations and visions are vital to data analyses: without them, there is neither data, nor analysis. Visions are the solutions that technology designers and data analysts strive towards, and vocations are those callings that data follows spontaneously in the course of the analytic process. In data analyses, vocations and visions can take mathematical, semiotic or other social forms. Due to the integration of data analyses with digital technologies, however, vocations and visions are increasingly hard to grasp. Contributions to this issue identify the vocations and visions of data analyses as we find them in thermal cameras, in wearables for aid and medical treatment, in financial platforms, search engines, software and algorithms. They also trace how vocations and visions become productive of social and biological life and are therefore not only vitally important to data analysis, but also vital because they co-produce and re-ontologize life. They shape commercial, intellectual and social spheres, as well as the body, biology and bare life. Data analyses interact with human lives as data and analytic tools become lively, too. When applied to human beings and other organic life forms, to analytic tools, to digital data and to their relationship of becoming with each other, a methodology of life cycles captures these dynamics. If we acknowledge the vocations, visions and vitalities involved, analyses of data analysis must be conducted to help us understand, relate to and navigate these strange and familiar agencies.","",""
"2020","Complex ecologies of trust in data practices and data-driven systems","ABSTRACT Trust in data practices and data-driven systems is widely seen as both important and elusive. A data trust deficit has been identified, to which proposed solutions are often localised or individualised, focusing either on what institutions can do to increase user trust in their data practices or on data management models that empower the individual user. Scholarship on trust often focuses on typologies of trust. This paper shifts the emphasis to those doing the trusting, by presenting findings from empirical research which explored user perspectives on the data practices of the BBC. These findings challenge the assumption that localised or individualised solutions can be effective. They also suggest that conceptualisations of trust in data practices need to account for the complex range of factors which come into play in relation to trust in data and so move beyond the production of typologies. In this paper, we propose the concept of ‘complex ecologies of trust’ as a way of addressing all of these issues.","",""
"2020","Ethical and legal governance of health-related research that use digital data from user-generated online health content","ABSTRACT Advances in information and communication technologies have enabled health care users and providers to share health information online thus generating contents, which may be used for health-related research. In addition, the data may be used for health care decision-making thus blurring the boundaries between health care and research particularly with the repurposing of data for other uses. This paper discusses the ethical and legal concerns that emerge from using digital data from user-generated online health content for health-related research. It analyses the nature of digital health data from user-generated online content and considers the extent to which its use can be governed through the current regulatory and ethical frameworks. It then highlights the strengths and weaknesses of these frameworks and proposes strategies that can be used to protect data subjects’ privacy while facilitating research in an ethical manner.","",""
"2020","Ethnography’s future in the big data era","ABSTRACT This essay explores knowledge claims about Big Data/BD from an ethnographic viewpoint. This epistemological exploration was triggered by social scientist/BD analyst Seth Stephens-Davidowitz’ best-selling book Everybody Lies (2017). In my reading, it portrays BD in a way that evokes affinity with ethnography: as a naturalistic research practice that makes visible small subpopulations and discloses people’s hidden motives. This threefold assertion rests on misguided conceptions however. To the ethnographic researcher, ‘naturalism’ refers to a reflexive practice, but the BD researcher associates it with researcher invisibility. The term ‘population’, which has a statistical meaning in BD, has a theoretical connotation in ethnography. Finally, ‘motives’ in BD are about direct interpretation of revealed preferences as social facts, whereas the ethnographer considers them to be expressions of social behaviour that require a Verstehende interpretation. A BD revolution may be unfolding, but that does not make ethnography obsolete; ideally, both can be combined in a symphonic social science.","",""
"2020","Deconstructing the data life-cycle in digital humanitarianism","ABSTRACT The role that technologies have historically played in producing and reproducing global inequalities is well documented. Although technological innovation is associated with progress that does not mean that it necessarily narrows the gap between rich and poor, instead technological inequalities tend to exacerbate other inequalities. This applies also to information and communication technologies (ICT) and Big Data, which play an increasingly important role in humanitarianism. In this article, we address the socio-technical work that is necessary to acquire, process, store and use data and study the power relations that are embedded in these processes. We focus in particular on the use of Big Data in digital humanitarianism and argue that at each stage of the digital data life-cycle (data acquisition, data processing, data storage, and data usage and decision making) different resources are required. These include not only access to hardware, software and connectivity but also the ability to make use of the affordances of digital technologies. We posit that in the context of humanitarianism, ICT and Big Data are a particularly intriguing to study due to their ambivalent position of seeking to address inequalities while at the same time perpetuating them.","",""
"2020","Materializing Data: New Research Methods for Feminist Digital Humanities","This paper argues that materializing data may be a useful methodology in intersectional feminst digital humanities, because it requires close attention not only to the content of data and the contexts in which it is produced, but also to the individual, situated, differing knowledges that researchers leverage in the processes of generating, analyzing, and disseminating research data. We introduce two approaches to data materialization currently used at the qCollaborative, an intersectional feminist design research lab with nodes at the University of Waterloo, Mount Royal University, and the University of Illinois, Urbana-Champaign. The outcomes of these methods, which we call “forcing connections between the digital and the material” and “dwelling with embodied data in research scenes”, have included productive opportunities to: relax behavioural expectations and inhibitions; leverage tacit as well as explicit knowledges; engage in processes of vulnerable co-creation; engage in equitable co-creation of knowledge across differences in lived experience; cycle through stages of public representation, gathering, and presentation; account for the complex events, actions, and contestations that influence our processes of data-production, analysis, and remediation; generate research products that can become future research scenes for equitable data-dwelling processes; and leverage old-media tactics to intervene into harmful, normative digital cultures; and generate new conceptual paradigms; and: make explicit interventions into institutional cultures. These outcomes suggest the need for further work to develop a validated, transferable data materialization methodology for use by qCollaborative and and other digital humanities researchers. Resume Cet article argumente que concretiser des donnees peut etre une methodologie utile dans les humanites numeriques feministes intersectionnelles, parce que cela necessite une attention particuliere non seulement accordee au contenu des donnees et aux contextes dans lesquels elles sont produites, mais aussi accordee aux connaissances differentes situees individuelles que les chercheurs exploitent durant le processus de generer, d’analyser et de disseminer des donnees de recherche. Nous presentons deux approches de concretiser des donnees, lesquelles approches s’utilisent actuellement a qCollaborative, un laboratoire de recherche stylistique feministe intersectionnelle qui a des noeuds a l’Universite de Waterloo, a l’Universite Mount Royal et a l’Universite d’Illinois a Urbana-Champaign. Les resultats de ces methodes, ce que nous appelons « forcer des connections entre la numerique et le materiel » et « analyser des donnees incorporees dans des scenes de recherche », incluent des opportunites productives pour : ecarter des attentes de comportement ; pour exploiter des connaissances explicites et implicites ; pour s’engager dans des processus de co-creation vulnerable ; pour s’engager dans la co-creation equitable de connaissances en fonction de differences dans des experiences vecues ; pour parcourir les cycles des etapes de representation, de rassemblement et de presentation publics ; pour justifier les evenements, les actions et les contestations complexes qui influent sur nos processus de produire, d’analyser et d’assainir des donnees ; pour generer des produits de recherche qui peuvent devenir des scenes de recherche futures pour des processus equitables d’analyse de donnees ; pour exploiter des strategies de vieux medias pour intervenir dans des cultures numeriques normatives nocives ; pour generer de nouveaux paradigmes conceptuels ; et pour effectuer des interventions explicites dans des cultures institutionnelles. Ces resultats suggerent la necessite de travail supplementaire pour le developpement d’une methodologie transferable validee qui concretise des donnees exploitables pour qCollaborative et pour d’autres chercheurs des humanites numeriques. Mots-cles: qCollaborative; humanites numeriques feminists; concretiser des donnees; forcer des comparaisons; analyser des donnees","",""
"2020","AUTOBIOGRAPHY OF AN AUDIT: TRACING THE ROOTS AND REPERCUSSIONS OF THE   HRT-TRANSGENDER DATABASE","Focus on the harms in data collection, distribution, and use in sociotechnical systems tends to reify the idea that research conducted by universities and other public-sector parties is both more ethical and more easily lends itself to auditing. This falsely positions data collection and distribution undertaken by public institutions as more available to review and scrutiny. Documenting our attempts to audit the HRT-Transgender Database - a database collected by a public university in the United States - we engage in a critical examination of not only the gaps in IRB coverage of “big data” research, but also the practical limitations and troubles involved in attempting to audit data practices that, on paper, should be highly documented. Drawing from feminist and trans studies critical approaches to information practice, our work brings into frame vital issues that researchers seeking to design oversight mechanisms should address, and begins a conversation about the visceral and often painful work of providing that oversight. This research extends from a review of the limits of IRB oversight to incorporate an interrogation of how technological interventions increase the likelihood of actual and symbolic violence in the lives of transgender people, including those not present in the actual HRT-Transgender Database.","",""
"2020","ETHICAL REVIEW BOARDS AND PERVASIVE DATA RESEARCH: GAPS AND   OPPORTUNITIES","The growing prevalence of data-rich networked information technologies—such as social media platforms, smartphones, wearable devices, and the internet of things —brings an increase in the flow of rich, deep, and often identifiable personal information available for researchers. More than just “big data,” these datasets reflect people’s lives and activities, bridge multiple dimensions of a person’s life, and are often collected, aggregated, exchanged, and mined without them knowing. We call this data “pervasive data,” and the increased scale, scope, speed, and depth of pervasive data available to researchers require that we confront the ethical frameworks that guide such research activities. Multiple stakeholders are embroiled in the challenges of research ethics in pervasive data research: researchers struggle with questions of privacy and consent, user communities may not even be aware of the widespread harvesting of their data for scientific study, platforms are increasingly restricting researcher’s access to data over fears of privacy and security, and ethical review boards face increasing difficulties in properly considering the complexities of research protocols relying on user data collected online. The results presented in this paper expand our understanding of how ethical review board members think about pervasive data research. It provides insights into how IRB professionals make decisions about the use of pervasive data in cases not obviously covered by traditional research ethics guidelines, and points to challenges for IRBs when reviewing research protocols relying on pervasive data.","",""
"2020","DATAFICATION IN THE PUBLIC SECTOR: EXPLORING THE BORDERS BETWEEN PUBLIC        SERVICES AND CITIZENS","This panel presents on-going research from a large research project on digital infrastructures and citizen participation in the Nordic countries, with a focus on the datafication of the public sector and the construction of new borders between public services and citizens. In recent years, governments have faced increasing pressures to become datafied or “data-driven”. A more data-driven public is said to be able to develop a whole new range of services that are envisaged to result in better services, more effective government, more transparency in the public sector, more just service delivery, and the empowerment of citizens. The panel critically examines the challenges that arise when the precepts are to be converted into working services – such as: What kinds of foreseen and unforeseen transformations does the development of new services give rise to? • What kinds of resistance are the new services facing? • What new forms of expertise, enrollment of new actors, organizational restructuring and redelegation of roles and relations are needed? • How are citizens/clients envisioned and inscribed into the scenarios for future public administration? • How are citizens/clients consulted in the design and development of the services? • How are the new services experienced by citizens/clients? In sum, the presentations in this panel span a range of urgent themes related to the construction of borders (and alleys) between public sector services and citizens – from anticipations to effects and efforts.","",""
"2020","MORAL ECONOMIES OF OPEN DATA PLATFORMS","Municipal open data platforms are currently caught in a range of tensions. They rely on an unspecified subject to analyze the data, and yet are surrounded by discourses of """"empowerment"""" and """"transparency"""". They are often most beneficient when approached with data science skills, yet often entail unremunerated digital labor. And they are often engaged by organizations tacking """"for Social Good"""" onto their mandate - the Canada-wide organization Data for Good being a key example. To date, STS research has generated important insights into the political economies of data and platforms that highlight the ways they produce, mediate, circulate, and accumulate surplus and exchange value. Less attention has been devoted to understanding the ways moral values and sentiments are deployed to attract the digital volunteered labor subtending municipal open data platform usage. Those who mobilize these moral economies are deeply situated within capitalist platform economies, and benefit from the free labor of those wishing to improve their communities. In this presentation, we argue that hackathons, datathons, and open data platforms are constituted through moral economies that are entangled within technoscientific capitalist accumulation practices and logics. These moral economies are key ways in which digital labor is procured, and represent a core component of what Boltanski and Chiapello call the """"new spirit of capitalism"""". To substantiate our argument, we draw on an ongoing long-term ethnography into Calgary, Alberta's open data ecosystem. We conclude by politicizing the fissures of these moral economies, to identify the new political strategies that they necessitate.","",""
"2020","A DIVISION OF LABOR: THE ROLE OF BIG DATA ANALYSIS IN THE REPERTOIRE OF INTERNET RESEARCH METHODS","In recent years, large-scale analysis of log data from digital devices - often termed """"""""big data analysis"""""""" (Lazer, Kennedy, King, &amp; Vespignani, 2014) - have taken hold in the field of internet research. Through Application Programming Interfaces (APIs) and commercial measurement, scholars have been able to analyze social media users (Freelon 2014) and web audiences (Taneja, 2016) on an uprecedented scale. And by developing digital research tools, scholars have been able to track individuals across websites (Menchen-Trevino, 2013) and mobile applications (Ørmen &amp; Thorhauge 2015) in greater detail than ever before. Big data analysis holds unique potential for studying communication in depth and across many individuals (see e.g. Boase &amp; Ling, 2013; Prior, 2013). At the same time, this approach introduces new methodological challenges in the transparency of data collection (Webster, 2014), sampling of participants and validity of conclusions (Rieder, Abdulla, Poell, Woltering, &amp; Zack, 2015). Firstly, data aggregation is typically designed for commercial rather than academic purposes. The type of data included as well as how it is presented depend in large part on the business interests of measurement and advertisement companies (Webster, 2014). Secondly, when relying on this kind of secondary data it can be difficult to validate the output or techniques used to generate the data (Rieder, Abdulla, Poell, Woltering, &amp; Zack, 2015). Thirdly, often the unit of analysis is media-centric, taking specific websites or social network pages as the empirical basis instead of individual users (Taneja, 2016). This makes it hard to untangle the behavior of real-world users from the aggregate trends. Lastly, variations in what users do might be so large that it is necessary to move from the aggregate to smaller groups of users to make meaningful inferences (Welles, 2014). Internet research is thus faced with a new research approach in big data analysis with potentials and perils that need to be discussed in combination with traditional approaches. This panel explores the role of big data analysis in relation to the wider repertoire of methods in internet research. The panel comprises four presentations that each sheds light on the complementarity of big data analysis with more traditional qualitative and quantitative methods. The first presentation opens the discussion with an overview of strategies for combining digital traces and commercial audience data with qualitative interviews and quantitative survey methods. The next presentation explores the potential of trace data to improve upon the experimental method. Researcher-collected data enables scholars to operate in a real-world setting, in contrast to a research lab, while obtaining informed consent from participants. The third presentation argues that large-scale audience data provide a unique perspective on internet use. By integrating census-level information about users with detailed traces of their behavior across websites, commercial audience data combines the strength of surveys and digital trace data respectively. Lastly, the fourth presentation shows how multi-institutional collaboration makes it possible do document social media activity (on Twitter) for a whole country (Australia) in a comprehensive manner. A feat not possible through other methods on a similar scale. Through these four presentations, the panel aims to situate big data analysis in the broader repertoire of internet research methods. ","",""
"2020","MEASURED EDUCATION: SENSING, CONFIGURING AND INTERVENING WITH ADVANCED         MEDIA","Education has long been a space of in which knowledge was created         through data practices. But the ongoing datafication and digitalisation has made new forms         of datafied knowledge production within educational research possible. This new form of         datafied knowledge creation has shifted the sites of expertise and the authority to create         educational knowledge to a more-than-human network. This panel conceptually and empirically         examines the possibilities and implications that arise from the entanglement of education         with advanced media such as ubiquitous sensory environments, APIs, machine learning, and         codes. The panel shows how the idea of measurable and re-configurable bodies of students is         being performed and stabilized through trade shows and academic conferences; it moves         towards a critical analysis of different applications of facial recognition in education and         the role of doubt in machine learning methods; it shows the complex involvement of advanced         learning analytics through a critical examination of interrelated studies in behavioural         genetics and genoeconomics looking for associations between genes and educational outcomes         through bioinformatic methods; and, it examines learning and living spaces that create a         situation of ubiquitous sensation and explores interventions to disrupt the technical         milieu. What connects these papers is more than the spaces, ideas and practices that         surround education. All contributions look at datafied knowledge about human life – whether         in behavioural, physiological, emotional, or genetic form. The panel aims to show what         critical education research has adopted from other disciplines, but also show how it can         contribute to the wider discourse around science, technology and society.","",""
"2020","An invitation to critical social science of big data: from critical theory and critical research to omniresistance","","",""
"2020","Smart forests and data practices: From the Internet of Trees to planetary governance","Environments are increasingly becoming technologized sites of data production. From smart cities to smart forests, digital networks are analyzing and joining up environmental processes. This commentary focuses on one such understudied smart environment, smart forests, as emerging digital infrastructures that are materializing to manage and mitigate environmental change. How does the digitalization of forests not only change understandings of these environments but also generate different practices and ontologies for addressing environmental change? I first analyze smart forests within the expanding area of smart environments, and then discuss five digital practices that characterize smart forests. Based on this analysis, I suggest that forests are not only becoming highly digital environments but also that forests are transforming into technologies for managing environmental change. Smart forest interventions therefore expand the scope of what could count as a technology, especially in the context of data-oriented planetary governance.","",""
"2020","Sunlight alone is not a disinfectant: Consent and the futility of opening Big Data black boxes (without assistance)"," In our attempts to achieve privacy and reputation deliverables, advocating for service providers and other data managers to open Big Data black boxes and be more transparent about consent processes, algorithmic details, and data practice is easy. Moving from this call to meaningful forms of transparency, where the Big Data details are available, useful, and manageable is more difficult. Most challenging is moving from that difficult task of meaningful transparency to the seemingly impossible scenario of achieving, consistently and ubiquitously, meaningful forms of consent, where individuals are aware of data practices and implications, understand these realities, and agree to them as well. This commentary unpacks these concerns in the online consent context. It emphasizes that self-governance fallacy pervades current approaches to achieving digital forms of privacy, exemplified by the assertion that transparency and information access alone are enough to help individuals achieve privacy and reputation protections. ","",""
"2020","Prospecting (in) the data sciences","Data science is characterized by engaging heterogeneous data to tackle real world questions and problems. But data science has no data of its own and must seek it within real world domains. We call this search for data “prospecting” and argue that the dynamics of prospecting are pervasive in, even characteristic of, data science. Prospecting aims to render the data, knowledge, expertise, and practices of worldly domains available and tractable to data science method and epistemology. Prospecting precedes data synthesis, analysis, or visualization, and is constituted by the upstream work of discovering disordered or inaccessible data resources, thereafter to be ordered and rendered available for computation. Through this work, data science positions itself in the middle of all things—capable of engaging this, that, or any domain—and thus prospecting is a key driver of data science’s ongoing formation as a universal(izing) science.","",""
"2020","Good organizational reasons for better medical records: The data work of clinical documentation integrity specialists"," Healthcare organizations and workers are under pressure to produce increasingly complete and accurate data for multiple data-intensive endeavors. However, little research has examined the emerging occupations arising to carry out the data work necessary to produce “improved” data sets, or the specific work activities of these emerging data occupations. We describe the work of Clinical Documentation Integrity Specialists (CDIS), an emerging occupation that focuses on improving clinical documentation to produce more detailed and accurate administrative datasets crucial for evolving data-intensive forms of healthcare accountability, management, and research. Using ethnographic methods, we describe the core of CDIS’ work as a translation practice in which the language, interests, and concerns of clinicians and clinical documentation are translated via real-time “nudging” and ongoing education of clinicians into the language, interests, and concerns of medical coders, structured administrative datasets, and the various stakeholders of these datasets. Further, we show how the institutional context of CDIS’ work shapes the occupational virtues that guide CDIS’ translation practice, including financial reimbursement, quality measures, clinical accuracy, and protecting clinician’s time. Despite the existence of these multiple virtues, financial reimbursement is the most prominent virtue guiding CDIS’ limited attention. Thus, overall clinical documentation is “improved” in specific, partial ways. This research provides one of the first studies of the emergent data work occupations arising in the wake of digitization and big data opportunities, and shows how local data settings shape large scale data in specific ways and thus may influence outcomes of analyses based on such data. ","",""
"2020","Data-bodies and data activism: Presencing women in digital heritage research"," As heritage-as-the-already-occurred folds into heritage-in-the-making practices, temporal and spatial fluidity is made more complex by digital mediation and particularly by Big Data. Such liveliness evokes ontological, epistemological and methodological challenges. Drawing on more-than-human theorizing, this article reframes the notion of data-bodies to advance data activist-oriented research in heritage. Focused primarily on women, it examines how their distributed agency and voice with respect to data practices and the (re)makings of (digital) heritage could be amplified. I describe three methodological directions, influenced by feminist work in critical data studies, which could be employed by researchers: attuning to and becoming with data, making data physical and changing narratives. From data-bodies to haunted data, performative data curation and mapping data-bodies, and attuning to data streams and re-voicing narratives, this article contributes to discussions of how to engage critically and creatively with the datafication of digital heritage practices, knowings and ontologies. ","",""
"2020","Establishing a social licence for Financial Technology: Reflections on the role of the private sector in pursuing ethical data practices","Current attention directed at ethical dimensions of data and Artificial Intelligence have led to increasing recognition of the need to secure and maintain public support for uses (and reuses) of people’s data. This is essential to establish a “Social Licence” for current and future practices. The notion of a “Social Licence” recognises that there can be meaningful differences between what is legally permissible and what is socially acceptable. Establishing a Social Licence entails public engagement to build relationships of trust and ensure that practices align with public values. While the concept of the Social Licence is well-established in other sectors – notably in relation to extractive industries – it has only very recently begun to be discussed in relation to digital innovation and data-intensive industries. This article therefore draws on existing literature relating to the Social Licence in extractive industries to explore the potential approaches needed to establish a Social Licence for emerging data-intensive industries. Additionally, it draws on well-established literature relating to trust (from psychology and organisational science) to examine the relevance of trust, and trustworthiness, for emerging practices in data-intensive industries. In doing so the article considers the extent to which pursuing a Social Licence might complement regulation and inform codes of practice to place ethical and social considerations at the heart of industry practice. We focus on one key industry: Financial Technology. We demonstrate the importance of combining technical and social approaches to address ethical challenges in data-intensive innovation (particularly relating to Artificial Intelligence) and to establish relationships of trust to underpin a Social Licence for Financial Technology. Such approaches are needed across all areas and industries of data-intensive innovation to complement regulation and inform the development of ethical codes of practice. This is important to underpin culture change and to move beyond rhetorical commitments to develop best practice putting ethics at the heart of innovation.","",""
"2020","For a situational analytics: An interpretative methodology for the study of situations in computational settings"," This article introduces an interpretative approach to the analysis of situations in computational settings called situational analytics. I outline the theoretical and methodological underpinnings of this approach, which is still under development, and show how it can be used to surface situations from large data sets derived from online platforms such as YouTube. Situational analytics extends to computationally-mediated settings a qualitative methodology developed by Adele Clarke, Situational Analysis (2005), which uses data mapping to detect heterogeneous entities in fieldwork data to determine ‘what makes a difference’ in a situation. Situational analytics scales up this methodology to analyse situations latent in computational data sets with semi-automated methods of textual and visual analysis. I discuss how this approach deviates from recent analyses of situations in computational social science, and argue that Clarke’s framework renders tractable a fundamental methodological problem that arises in this area of research: while social researchers turn to computational settings in order to analyse social life, the social processes unfolding in these envirnoments are fundamentally affected by the computational architectures in which they occur. Situational analytics offers a way to address this problematic by making a heterogeneously composed situation – involving social, technical and media elements – the unit of computational analysis. To conclude, I show how situational analytics can be applied in a case study of YouTube videos featuring intelligent vehicles and discuss how situational analysis itself needs to be elaborated if we are to come to terms with computational transformations of the situational fabric of social life. ","",""
"2020","Perils of data-driven equity: Safety-net care and big data’s elusive grasp on health inequality","Large-scale data systems are increasingly envisioned as tools for justice, with big data analytics offering a key opportunity to advance health equity. Health systems face growing public pressure to collect data on patient “social factors,” and advocates and public officials seek to leverage such data sources as a means of system transformation. Despite the promise of this “data-driven” strategy, there is little empirical work that examines big data in action directly within the sites of care expected to transform. In this article, I present a case study on one such initiative, focusing on a large public safety-net health system’s initiation of sexual orientation and gender identity (SOGI) data collection within the clinical setting. Drawing from ethnographic fieldwork and in-depth interviews with providers, staff, and administrators, I highlight three main challenges that elude big data’s grasp on inequality: (1) provider and staff’s limited understanding of the social significance of data collection; (2) patient perception of the cultural insensitivity of data items; and (3) clinic need to balance data requests with competing priorities within a constrained time window. These issues reflect structural challenges within safety-net care that big data alone are unable to address in advancing social justice. I discuss these findings by considering the present data-driven strategy alongside two complementary courses of action: diversifying the health professions workforce and clinical education reform. To truly advance justice, we need more than “just data”: we need to confront the fundamental conditions of social inequality.","",""
"2020","The Nordic data imaginary","The Nordic countries aim to have a unique place within the European and global health data economy. They have extensive nationally maintained and centralized health data records, as well as numerous biobanks where data from individuals can be connected based on personal identification numbers. Much of this phenomenon can be attributed to the emergence and development of the Nordic welfare state, where Nordic countries sought to systematically collect large amounts of population data to guide decision making and improve the health and living conditions of the population. Recently, however, the so-called Nordic gold mine of data is being re-imagined in a wholly other context, where data and its ever-increasing logic of accumulation is seen as a driver for economic growth and private business development. This article explores the development of policies and strategies for health data economy in Denmark and Finland. We ask how nation states try to adjust and benefit from new pressures and opportunities to utilize their data resources in data markets. This raises questions of social sustainability in terms of states being producers, providers, and consumers of data. The data imaginaries related to emerging health data markets also provide insight into how a broad range of different data sources, ranging from hospital records and pharmacy prescriptions to biobank sample data, are brought together to enable “full-scale utilization” of health and welfare data.","",""
"2020","Public perceptions of good data management: Findings from a UK-based survey","Low levels of public trust in data practices have led to growing calls for changes to data-driven systems, and in the EU, the General Data Protection Regulation provides a legal motivation for such changes. Data management is a vital component of data-driven systems, but what constitutes ‘good’ data management is not straightforward. Academic attention is turning to the question of what ‘good data’ might look like more generally, but public views are absent from these debates. This paper addresses this gap, reporting on a survey of the public on their views of data management approaches, undertaken by the authors and administered in the UK, where departure from the EU makes future data legislation uncertain. The survey found that respondents dislike the current approach in which commercial organizations control their personal data and prefer approaches that give them control over their data, that include oversight from regulatory bodies or that enable them to opt out of data gathering. Variations of data trusts – that is, structures that provide independent stewardship of data – were also preferable to the current approach, but not as widely preferred as control, oversight and opt out options. These features therefore constitute ‘good data management’ for survey respondents. These findings align only in part with principles of good data identified by policy experts and researchers. Our findings nuance understandings of good data as a concept and of good data management as a practice and point to where further research and policy action are needed.","",""
"2020","Making data science systems work"," How are data science systems made to work? It may seem that whether a system works is a function of its technical design, but it is also accomplished through ongoing forms of discretionary work by many actors. Based on six months of ethnographic fieldwork with a corporate data science team, we describe how actors involved in a corporate project negotiated what work the system should do, how it should work, and how to assess whether it works. These negotiations laid the foundation for how, why, and to what extent the system ultimately worked. We describe three main findings. First, how already-existing technologies are essential reference points to determine how and whether systems work. Second, how the situated resolution of development challenges continually reshapes the understanding of how and whether systems work. Third, how business goals, and especially their negotiated balance with data science imperatives, affect a system’s working. We conclude with takeaways for critical data studies, orienting researchers to focus on the organizational and cultural aspects of data science, the third-party platforms underlying data science systems, and ways to engage with practitioners’ imagination of how systems can and should work. ","",""
"2020","“We called that a behavior”: The making of institutional data","Predictive uses of data are becoming widespread in institutional settings as actors seek to anticipate people and their activities. Predictive modeling is increasingly the subject of scholarly and public criticism. Less common, however, is scrutiny directed at the data that inform predictive models beyond concerns about homogenous training data or general epistemological critiques of data. In this paper, I draw from a qualitative case study set in higher education in the United States to investigate the making of data. Data analytics projects at universities have become more pervasive and intensive to better understand and anticipate undergraduate student bodies. Drawing from 12 months of ethnographic research at a large public university, I analyze the ways data personnel at the institution—data scientists, administrators, and programmers—sort student data into “attributes” and “behaviors,” where “attributes” are demographic data that students “can’t change.” “Behaviors,” in contrast, are data defined as reflective of what students can choose: attending and paying attention in class, studying on campus, among other data which personnel categorize as what students have control over. This discursive split enables the institution nudge students to make responsible choices according to behavior data that correlate with success in the predictive model. In discussing how personnel type, sort, stabilize, and nudge on behavior data, this paper examines the contingencies of data making processes and implications for the application of student data.","",""
"2020","Intentionality and design in the data sonification of social issues"," Data sonification is a practice for conducting scientific analysis through the use of sound to represent data. It is now transitioning to a practice for communicating and reaching wider publics by expanding the range of languages and senses for understanding complexity in data-intensive societies. Communicating to wider publics, though, requires that authors intentionally shape sonification in ways that consider the goals and contexts in which publics relate. It requires a specific set of knowledge and skills that design as a discipline could provide. In this article, we interpret five recent sonification projects and locate them on a scale of intentionality in how authors communicate socially relevant issues to publics. ","",""
"2020","Disambiguating the benefits and risks from public health data in the digital economy","This article focuses on key roles that the ill-defined concept of ‘public benefit’ plays in accessing the public health data held by the UK’s National Health Service. Using the concept of the ‘trade-off fallacy’, this article argues that current data access and governance structures, based on particular construals of public benefit in the context of public health data, largely negate the possibility of effective control by individuals over future uses of personal health data. This generates a health data version of the trade-off fallacy that enables widespread involvement of commercial actors in personal data, despite public concerns over commercial involvement in, and potential exploitation of, public health data. The article suggests that, despite ostensibly robust regulatory and governance structures, this publicly held data is potentially subject to similar logics of accumulation as seen elsewhere in the digital economy, highlighting the inadequacies of current data regulatory frameworks in the digital era.","",""
"2020","Revisiting the Black Box Society by rethinking the political economy of big data"," The Black Box Society was one of first scholarly accounts to propose a social theory of the use of data in constructing personal reputations, new media audiences, and financial power, by illuminating recurrent patterns of power and exploitation in the digital economy. While many corporations have a direct window into our lives through constant, ubiquitous data collection, our knowledge of their inner workings is often partial and incomplete. Closely guarded by private companies and inaccessible to most researchers or the broader public, too much algorithmic decision-making remains a black box to this day. Much has happened since 2015 that vindicates and challenges the book’s main themes. To answer many of the concerns raised in the volume in light of the most recent developments, we have brought together leading thinkers who have explored the interplay of politics, economics, and culture in domains ordered algorithmically by managers, bureaucrats, and technology workers. While the contributions are diverse, a unifying theme animates them. Each offers a sophisticated critique of the interplay between state and market forces in building or eroding the many layers of our common lives, as well as the privatization of spheres of reputation, search, and finance. Unsatisfied with narrow methodologies of economics or political science, they advance politico-economic analysis. They therefore succeed in unveiling the foundational role that the turn to big data has in organizing economic and social relations. ","",""
"2020","Seven intersectional feminist principles for equitable and actionable COVID-19 data"," This essay offers seven intersectional feminist principles for equitable and actionable COVID-19 data, drawing from the authors' prior work on data feminism. Our book, Data Feminism (D'Ignazio and Klein, 2020), offers seven principles which suggest possible points of entry for challenging and changing power imbalances in data science. In this essay, we offer seven sets of examples, one inspired by each of our principles, for both identifying existing power imbalances with respect to the impact of the novel coronavirus and its response, and for beginning the work of change. ","",""
"2020","The “black box” at work"," An oversized reliance on big data-driven algorithmic decision-making systems, coupled with a lack of critical inquiry regarding such systems, combine to create the paradoxical “black box” at work. The “black box” simultaneously demands a higher level of transparency from the worker in regard to data collection, while shrouding the decision-making in secrecy, making employer decisions even more opaque to the worker. To access employment, the worker is commanded to divulge highly personal information, and when hired, must submit further still to algorithmic processes of evaluations which will make authoritative claims as to the workers’ productivity. Furthermore, in and out of the workplace, the worker is governed by an invisible data-created leash deploying wearable technology to collect intimate worker data. At all stages, the worker is confronted with a lack of transparency, accountability, or explanation as to the inner workings or even the logic of the “black box” at work. This data revolution of the workplace is alarming for several reasons: (1) the “black box at work” not only serves to conceal disparities in hiring, but could also allow for a level of “data-laundering” that beggars any notion of equal opportunity in employment and (2) there exists, the danger of a “mission creep” attitude to data collection that allows for pervasive surveillance, contributing to the erosion of both the personhood and autonomy of workers. Thus, the “black box at work” not only enables worker domination in the workplace, it deprives the worker of Rawlsian justice. ","",""
"2020","Emerging models of data governance in the age of datafication"," The article examines four models of data governance emerging in the current platform society. While major attention is currently given to the dominant model of corporate platforms collecting and economically exploiting massive amounts of personal data, other actors, such as small businesses, public bodies and civic society, take also part in data governance. The article sheds light on four models emerging from the practices of these actors: data sharing pools, data cooperatives, public data trusts and personal data sovereignty. We propose a social science-informed conceptualisation of data governance. Drawing from the notion of data infrastructure we identify the models as a function of the stakeholders’ roles, their interrelationships, articulations of value, and governance principles. Addressing the politics of data, we considered the actors’ competitive struggles for governing data. This conceptualisation brings to the forefront the power relations and multifaceted economic and social interactions within data governance models emerging in an environment mainly dominated by corporate actors. These models highlight that civic society and public bodies are key actors for democratising data governance and redistributing value produced through data. Through the discussion of the models, their underpinning principles and limitations, the article wishes to inform future investigations of socio-technical imaginaries for the governance of data, particularly now that the policy debate around data governance is very active in Europe. ","",""
"2020","Open Ethnographic Archiving as Feminist, Decolonizing Practice","Dubbed Silicon Savannah, Nairobi has become a hot spot of tech development that promises to “save Africa.” Qualitative research—carried out by a tangle of private, academic, and non-profit organizations—is part of the work, promising to reveal how people in Kenya are building and benefiting from a dazzling array of digital products. Amidst the enthusiasm, longstanding problems with ways in which research data in Nairobi is conceived, collected, and shared are easily glossed over. This article advances thinking about the politics of qualitative data, unraveling normative concepts like ethics and transparency by both examining existing data practices and modeling alternatives. I describe the sociotechnical infrastructure underlying the ethnographic project, detailing tactics for deploying an instance of open source software—the Platform for Experimental, Collaborative Ethnography (PECE)—to draw research interlocutors into collaborative effort to understand and build decolonized qualitative data infrastructures. Through such processes I learned that collaborating on data not only refreshes the social contract of qualitative work; it can also enhance its robustness and validity. I advise scholars to better document our own knowing practices in order to attend to the inevitability of margins created through all data practices, including our own","",""
"2020","Review of Cooking Data: Culture and Politics in and African Research World, by Crystal Biruk (Duke University Press, 2018)","Review of Cooking Data: Culture and Politics in and African Research World, by Crystal Biruk (Duke University Press, 2018)","",""
"2020","‘How can you not be romantic about baseball?’ Or how we are platonic about data"," Due to the influence of Michael Lewis’s book and its film adaptation of the same title, ‘Moneyball’ is now a euphemism for using data analytics to generate insights. These texts perform important cultural explications of machine learning. Methodologically informed by critical discourse analysis, film studies, and cultural studies, this essay describes how the 2011 film in particular aestheticizes epistemological notions such as data framing, the semantic gap, and deep learning. Moneyball also proffers a view of analytics as Platonic knowledge, functioning ideologically alongside nerd archetypes and buddy-comedy conventions. The resultant duality between the Platonic and embodied, innervated by relations between visibility and invisibility, typifies the way people relate to Big Data and to the institutions that govern our digital lives in algorithmic culture. Moneyball performs cultural work by encouraging us to embrace data science while remaining alienated from technology and deferential to experts. Calls for technological literacy in the age of Big Data cannot underestimate the importance of cultural literacy. ","",""
"2020","Sensing data: Encountering data sonifications, materializations, and interactives as <i>knowledge objects</i>"," Digital and networked media are characterized by a fundamental disconnection between the modes of operating of these media, the human sensorium and knowledge. In order for humans to consciously participate in this expanded domain of sensibility, additional mediation is required to ‘presentify’ what is not accessible to human perception. This situation has motivated the creation of manifold ‘data objects’ in the form of visualizations, soundscapes and sonifications, 3D materializations, and data-driven interactives in the neighboring domains of art, design, science, and humanities scholarship. These new knowledge objects, as we propose to call them, both produce and mediate knowledge in the process of making data experienceable. They turn that what essentially does not correlate to human sensory capacities into something that the human sensorium is capable of engaging with. As such, they can play a crucial role in providing access, and thereby modalities of critical and creative relating, to what Hansen (2015) describes as the expanded domain of sensibility. Yet, the effects and implications of the sensory specificities of these knowledge objects remain underacknowledged, as are the potentials of these modes of presentifying data. Here, we explore and compare a diversity of such knowledge objects and look at their different media modalities and different experiential qualities, and how these afford ways of knowing. By approaching several knowledge objects as ‘theoretical objects’ (Bal (2013); Damisch in Bois et al. (1998), we investigate which and how experimental sensory techniques are used for data presentification. With this, we want to draw attention to the onto-epistemological implications of the design of these knowledge objects, the main implications being relationality and performativity. Understanding the potential and implications of this performativity would benefit from what we call a creative humanities approach that combines insights from the critical and digital humanities with those from the fields of creative arts and design. ","",""
"2020","Reflecting and acting on datafication – CryptoParties as an example of re-active data activism"," CryptoParties are events in which people meet to pass on their knowledge or to learn about encrypting online communication and digital media technologies or safe Internet browsing. While some people offer help in realizing these practices, others attend with their laptops, tablets and smartphones to learn how to encrypt. CryptoParties are organized by different people in different locations. The article presents results of an exploratory ethnographic study, in which public CryptoParties in Germany were analysed. The study shows that people participating in CryptoParties reflect on and criticize current processes of datafication. Moreover, they aim at shaping datafication by encrypting their online communication and digital media technologies. Therefore, CryptoParties are discussed as examples of re-active data activism in this article. Applying a critical perspective hierarchies and inequalities at these events are revealed. ","",""
"2020","Approaching media as socio-technical assemblages in a datafied age","In times when new means of communication are emerging, it becomes increasingly relevant to revisit and reconsider media studies’ main concerns, and how contemporary media can be understood and studied. This paper draws attention to how the presumption of characteristics belonging to certain entities may elevate problems in a datafied age when streaming services, texts, content, producers, audiences, social media sites, and television are always intensely entangled. Here, the paper argues that it might no longer make sense, or even be possible, to make clear-cut distinctions between such entities. The paper further elaborates on the relevance and possibilities for media studies to draw upon actor-network theory (ANT). The paper argues that ANT, through its ideas of approaching objects as situated and local, can be a useful alternative theoretical approach when studying media phenomena in a datafied age.","",""
"2020","Data Quirks and Impressions","David Beer is a Professor of Sociology at the University of York. He is the author of seven books and dozens of articles that encompass the culture and politics of new media, data, and technology. His most recent works have focused specifically on the implications of data analytics industries and the social power of metrics to govern everyday life. David sits on the editorial boards of several key journals in these fields, including Theory, Culture &amp; Society, Information, Communication &amp; Society, Cultural Sociology, and Big Data &amp; Society. His work has made significant contributions to advancing contemporary understandings of new media cultures, as well as the histories and philosophies of social theory, such as his most recent works on Georg Simmel. This interview examines some of the underlying rationales and approaches to David’s work. We focus on key themes of ‘quirks’ and ‘impressions’. The interview looks at how data analytics industries imagine and actualize specific kinds of relationships between populations and data, and how these relations are subsequently ordered for value production. We discuss how platforms and data analytics industries negotiate the rules of social interaction in a context of cultural eclecticism. Finally, we discuss how art and popular culture can guide the creative process for academic research and writing.   ","",""
"2020","Data agency at stake: MyData activism and alternative frames of equal participation"," Data activism has emerged as a response to asymmetries in how data and the means of knowledge production are distributed. This article examines MyData, a data activism initiative developing principles for a new technical and commercial ecosystem in which individuals control the use of personal data. Analyzing material collected at a formative event shaping MyData activism, we examine how more just data arrangements are framed to enhance equal participation. Our analysis shows agreement on what is ultimately at stake: individual data agency and fair competition in the data economy. However, two alternatives are offered for what participation involves. Collaboration with commercial actors favors framing participation as agency in data markets, thereby potentially limiting the scope of what is at stake. The alternative framing presents a rights-based understanding of economic and civic agency, potentially leading to a broader understanding of participation in a datafied society. ","",""
"2020","The practical and ethical challenges in acquiring and sharing digital trace data: Negotiating public-private partnerships"," The ubiquity of digital devices and the increasing intensity of users’ interactions with them create vast amounts of digital trace data. Companies use these data to optimize their services or products, but these data are also of interest to researchers studying human behavior. As most of these data are owned by private companies and their collection requires adherence to their terms of service, research with digital trace data often entails some form of public-private partnership. Private companies and academic researchers each have their own interests, some of which are shared, while others may conflict. In this article, we explore different types of private-public partnerships for research with digital trace data. Based on general considerations and particular experiences from a research project with linked digital trace data, we propose strategies for identifying and productively negotiating both shared and conflicting interests in these relationships. ","",""
"2020","Recovering critique in an age of datafication"," This article starts out from the need for critical work on processes of datafication and their consequences for the constitution of social knowledge and the social world. Current social science work on datafication has been greatly shaped by the theoretical approach of Bruno Latour, as reflected in the work of Actor Network Theory and Science and Technology Studies (ANT/STS). The article asks whether this approach, given its philosophical underpinnings, provides sufficient resources for the critical work that is required in relation to datafication. Drawing on Latour’s own reflections about the flatness of the social, it concludes that it does not, since key questions, in particular about the nature of social order cannot be asked or answered within ANT. In the article’s final section, three approaches from earlier social theory are considered as possible supplements to ANT/STS for a social science serious about addressing the challenges that datafication poses for society. ","",""
"2020","What is Data and What Can it be Used For? Key Questions in the Age of Burgeoning Data-essentialism","In this article we describe the rise of a data orthodoxy that we suggest to label ‘data-essentialism’. We question this data-essentialism by problematizing its premises, and unveil its ideological indebtedness to deeper (previous) currents in Western thought and history. Data-essentialism is the assumption that data is the essence of basically everything, and thus provides the ideological underpinnings for the imagination of creating an Artificial Intelligence (AI) that would transform the human race and our existence. The imagination of data as an essence is in contrast to, while often conflated with, ideas of data as traces we leave behind existing in highly connected societies. This confusion over what data is, and can be used for, underlines the importance to engage in questions of the nature of data, whether everything in the universe can be described in terms of data and the implications of subscribing to such a data-essentialist worldview. We connect data-essentialism to a revival of positivism, critique a belief in the objectivity of data and that predictions based on data correlations can be fully accurate. We end the article with a discussion of how some aspects of AI rely on data-essentialist accounts and how these have a history and roots in Modernity.","",""
"2020","Mobilizing Media Studies in an Age of Datafication"," We are at a pivotal moment for understanding and deciding what is actually at stake with datafication. In this contribution, I argue for the increasingly important and politicized role of media scholarship to privilege lived experiences and situated practices as a counter to the active neutralization of data-driven systems and their implications. In particular, I argue for the relevance of media studies to emphasize the uses to which technology is put and explore how data practices relate to other social practices and historical contexts as a way to broaden the parameters of response, moving data politics beyond the confines of the technology itself, and contending instead with the premise and terms of the debate. ","",""
"2020","Data Civics: A Response to the “Ethical Turn”"," In addition to the recent proliferation of approaches, programs, and research centers devoted to ethical data and Artifiical Intelligence, it is becoming increasingly clear that we need to directly address the political question. Ethics, while crucial, comprise only an indirect response to recent concerns about the political uses and misuses of data mining, AI, and automated processes. If we are concerned about the impact of digital media on democracy, it will be important to consider what it might mean to foster democratic arrangements for the collection and use of data, and for the institutions that perform these tasks. This essay considers what it might mean to supplement ethical concerns with political ones. It argues for the importance of considering the tensions between civic life and the wholesale commercialization of news, information, and entertainment platforms—and how these are exacerbated by the dominant economic model of data-driven hyper-customization. ","",""
"2020","Data-driven creativity for screen production students: developing and testing learning materials involving audience biometrics","ABSTRACT This article presents the Data-Driven Creativity Project (DDCP) materials designed to enhance screen students’ understandings of how aesthetic choices impact the audience. The project first collected data on audience attention (eye-tracking), arousal (skin conductance level) and emotion (using facial expression). This data was then used in pedagogical materials delivered to two student cohorts in both lecture format and as an e-learning package. Self-reported survey data on the student experience indicates significant increase in Learning Interest toward the concepts of the DDCP, as well as strong ratings of the material’s Useability and Application to Knowledge. We also report on focus group discussions of the strengths and weaknesses of the DDCP. We show that the DDCP offers an innovative and novel intervention into contemporary screen creativity pedagogy, forging a valuable teaching-research nexus between the findings of the research field of cognitive media theory and their application in the field of student production.","",""
"2021","Darkness, Datafication, and Provenance as an Illuminating Methodology"," Data are generated and employed for many ends, including governing societies, managing organisations, leveraging profit, and regulating places. In all these cases, data are key inputs into systems that paradoxically are implemented in the name of making societies more secure, safe, competitive, productive, efficient, transparent and accountable, yet do so through processes that monitor, discipline, repress, coerce, and exploit people. (Kitchin, 165)  Introduction Provenance refers to the place of origin or earliest known history of a thing. It refers to the custodial history of objects. It is a term that is commonly used in the art-world but also has come into the language of other disciplines such as computer science. It has also been applied in reference to the transactional nature of objects in supply chains and circular economies. In an interview with Scotland’s Institute for Public Policy Research, Adam Greenfield suggests that provenance has a role to play in the “establishment of reliability” given that a “transaction or artifact has a specified provenance, then that assertion can be tested and verified to the satisfaction of all parities” (Lawrence). Recent debates on the unrecognised effects of digital media have convincingly argued that data is fully embroiled within capitalism, but it is necessary to remember that data is more than just a transactable commodity. One challenge in bringing processes of datafication into critical light is how we understand what happens to data from its point of acquisition to the point where it becomes instrumental in the production of outcomes that are of ethical concern. All data gather their meaning through relationality; whether acting as a representation of an exterior world or representing relations between other data points. Data objectifies relations, and despite any higher-order complexities, at its core, data is involved in factualising a relation into a binary. Assumptions like these about data shape reasoning, decision-making and evidence-based practice in private, personal and economic contexts. If processes of datafication are to be better understood, then we need to seek out conceptual frameworks that are adequate to the way that data is used and understood by its users. Deborah Lupton suggests that often we give data “other vital capacities because they are about human life itself, have implications for human life opportunities and livelihoods, [and] can have recursive effects on human lives (shaping action and concepts of embodiment ... selfhood [and subjectivity]) and generate economic value”. But when data are afforded such capacities, the analysis of its politics also calls for us to “consider context” and “making the labour [of datafication] visible” (D’Ignazio and Klein). For Jenny L. Davis, getting beyond simply thinking about what data affords involves bringing to light how continually and dynamically to requests, demands, encourages, discourages, and refuses certain operations and interpretations. It is in this re-orientation of the question from what to how where “practical analytical tool[s]” (Davis) can be found. Davis writes:  requests and demands are bids placed by technological objects, on user-subjects. Encourage, discourage and refuse are the ways technologies respond to bids user-subjects place upon them. Allow pertains equally to bids from technological objects and the object’s response to user-subjects. (Davis)  Building on Lupton, Davis, and D’Ignazio and Klein, we see three principles that we consider crucial for work on data, darkness and light:  data is not simply a technological object that exists within sociotechnical systems without having undergone any priming or processing, so as a consequence the data collecting entity imposes standards and way of imagining data before it comes into contact with user-subjects; data is not neutral and does not possess qualities that make it equivalent to the things that it comes to represent; data is partial, situated, and contingent on technical processes, but the outcomes of its use afford it properties beyond those that are purely informational.  This article builds from these principles and traces a framework for investigating the complications arising when data moves from one context to another. We draw from the “data provenance” as it is applied in the computing and informational sciences where it is used to query the location and accuracy of data in databases. In developing “data provenance”, we adapt provenance from an approach that solely focuses on technical infrastructures and material processes that move data from one place to another and turn to sociotechnical, institutional, and discursive forces that bring about data acquisition, sharing, interpretation, and re-use. As data passes through open, opaque, and darkened spaces within sociotechnical systems, we argue that provenance can shed light on gaps and overlaps in technical, legal, ethical, and ideological forms of data governance. Whether data becomes exclusive by moving from light to dark (as has happened with the removal of many pages and links from Facebook around the Australian news revenue-sharing bill), or is publicised by shifting from dark to light (such as the Australian government releasing investigative journalist Andie Fox’s welfare history to the press), or even recontextualised from one dark space to another (as with genetic data shifting from medical to legal contexts, or the theft of personal financial data), there is still a process of transmission here that we can assess and critique through provenance. These different modalities, which guide data acquisition, sharing, interpretation, and re-use, cascade and influence different elements and apparatuses within data-driven sociotechnical systems to different extents depending on context. Attempts to illuminate and make sense of these complex forces, we argue, exposes data-driven practices as inherently political in terms of whose interests they serve. Provenance in Darkness and in Light When processes of data capture, sharing, interpretation, and re-use are obscured, it impacts on the extent to which we might retrospectively examine cases where malpractice in responsible data custodianship and stewardship has occurred, because it makes it difficult to see how things have been rendered real and knowable, changed over time, had causality ascribed to them, and to what degree of confidence a decision has been made based on a given dataset. To borrow from this issue’s concerns, the paradigm of dark spaces covers a range of different kinds of valences on the idea of private, secret, or exclusive contexts. We can parallel it with the idea of ‘light’ spaces, which equally holds a range of different concepts about what is open, public, or accessible. For instance, in the use of social data garnered from online platforms, the practices of academic researchers and analysts working in the private sector often fall within a grey zone when it comes to consent and transparency. Here the binary notion of public and private is complicated by the passage of data from light to dark (and back to light). Writing in a different context, Michael Warner complicates the notion of publicness. He observes that the idea of something being public is in and of itself always sectioned off, divorced from being fully generalisable, and it is “just whatever people in a given context think it is” (11). Michael Hardt and Antonio Negri argue that publicness is already shadowed by an idea of state ownership, leaving us in a situation where public and private already both sit on the same side of the propertied/commons divide as if the “only alternative to the private is the public, that is, what is managed and regulated by states and other governmental authorities” (vii). The same can be said about the way data is conceived as a public good or common asset. These ideas of light and dark are useful categorisations for deliberately moving past the tensions that arise when trying to qualify different subspecies of privacy and openness. The problem with specific linguistic dyads of private vs. public, or open vs. closed, and so on, is that they are embedded within legal, moral, technical, economic, or rhetorical distinctions that already involve normative judgements on whether such categories are appropriate or valid. Data may be located in a dark space for legal reasons that fall under the legal domain of ‘private’ or it may be dark because it has been stolen. It may simply be inaccessible, encrypted away behind a lost password on a forgotten external drive. Equally, there are distinctions around lightness that can be glossed – the openness of Open Data (see: theodi.org) is of an entirely separate category to the AACS encryption key, which was illegally but enthusiastically shared across the internet in 2007 to the point where it is now accessible on Wikipedia. The language of light and dark spaces allows us to cut across these distinctions and discuss in deliberately loose terms the degree to which something is accessed, with any normative judgments reserved for the cases themselves. Data provenance, in this sense, can be used as a methodology to critique the way that data is recontextualised from light to dark, dark to light, and even within these distinctions. Data provenance critiques the way that data is presented as if it were “there for the taking”. This also suggests that when data is used for some or another secondary purpose – generally for value creation – some form of closure or darkening is to be expected. Data in the public domain is more than simply a specific informational thing: there is always context, and this contextual specificity, we argue, extends far beyond anything that can be captured in a metadata schema or a licensing model. Even the transfer of data from one open, public, or light context to another will evoke new degrees of openness and luminosity that should not be assumed to be straightforward. And with this a new set of relations between data-user-subjects and stewards emerges. The movement of data between public and private contexts by virtue of the growing amount of personal information that is generated through the traces left behind as people make use of increasingly digitised services going about their everyday lives means that data-motile processes are constantly occurring behind the scenes – in darkness – where it comes into the view, or possession, of third parties without obvious mechanisms of consent, disclosure, or justification. Given that there are “many hands” (D’Iganzio and Klein) involved in making data portable between light and dark spaces, equally there can be diversity in the approaches taken to generate critical literacies of these relations. There are two complexities that we argue are important for considering the ethics of data motility from light to dark, and this differs from the concerns that we might have when we think about other illuminating tactics such as open data publishing, freedom-of-information requests, or when data is anonymously leaked in the public interest. The first is that the terms of ethics must be communicable to individuals and groups whose data literacy may be low, effectively non-existent, or not oriented around the objective of upholding or generating data-luminosity as an element of a wider, more general form of responsible data stewardship. Historically, a productive approach to data literacy has been finding appropriate metaphors from adjacent fields that can help add depth – by way of analogy – to understanding data motility. Here we return to our earlier assertion that data is more than simply a transactable commodity. Consider the notion of “giving” and “taking” in the context of darkness and light. The analogy of giving and taking is deeply embedded into the notion of data acquisition and sharing by virtue of the etymology of the word data itself: in Latin, “things having been given”, whereby in French données, a natural gift, perhaps one that is given to those that attempt capture for the purposes of empiricism – representation in quantitative form is a quality that is given to phenomena being brought into the light. However, in the contemporary parlance of “analytics” data is “taken” in the form of recording, measuring, and tracking. Data is considered to be something valuable enough to give or take because of its capacity to stand in for real things. The empiricist’s preferred method is to take rather than to accept what is given (Kitchin, 2); the data-capitalist’s is to incentivise the act of giving or to take what is already given (or yet to be taken). Because data-motile processes are not simply passive forms of reading what is contained within a dataset, the materiality and subjectivity of data extraction and interpretation is something that should not be ignored. These processes represent the recontextualisation of data from one space to another and are expressed in the landmark case of Cambridge Analytica, where a private research company extracted data from Facebook and used it to engage in psychometric analysis of unknowing users.     Data Capture Mechanism   Characteristics and Approach to Data Stewardship     Historical    Information created, recorded, or gathered about people of things directly from the source or a delegate but accessed for secondary purposes.      Observational    Represents patterns and realities of everyday life, collected by subjects by their own choice and with some degree of discretion over the methods. Third parties access this data through reciprocal arrangement with the subject (e.g., in exchange for providing a digital service such as online shopping, banking, healthcare, or social networking).      Purposeful    Data gathered with a specific purpose in mind and collected with the objective to manipulate its analysis to achieve certain ends.     Integrative    Places less emphasis on specific data types but rather looks towards social and cultural factors that afford access to and facilitate the integration and linkage of disparate datasets     Table 1: Mechanisms of Data Capture There are ethical challenges associated with data that has been sourced from pre-existing sets or that has been extracted from websites and online platforms through scraping data and then enriching it through cleaning, annotation, de-identification, aggregation, or linking to other data sources (tab. 1). As a way to address this challenge, our suggestion of “data provenance” can be defined as where a data point comes from, how it came into being, and how it became valuable for some or another purpose. In developing this idea, we borrow from both the computational and biological sciences (Buneman et al.) where provenance, as a form of qualitative inquiry into data-motile processes, centres around understanding the origin of a data point as part of a broader almost forensic analysis of quality and error-potential in datasets. Provenance is an evaluation of a priori computational inputs and outputs from the results of database queries and audits. Provenance can also be applied to other contexts where data passes through sociotechnical systems, such as behavioural analytics, targeted advertising, machine learning, and algorithmic decision-making. Conventionally, data provenance is based on understanding where data has come from and why it was collected. Both these questions are concerned with the evaluation of the nature of a data point within the wider context of a database that is itself situated within a larger sociotechnical system where the data is made available for use. In its conventional sense, provenance is a means of ensuring that a data point is maintained as a single source of truth (Buneman, 89), and by way of a reproducible mechanism which allows for its path through a set of technical processes, it affords the assessment of a how reliable a system’s output might be by sheer virtue of the ability for one to retrace the steps from point A to B. “Where” and “why” questions are illuminating because they offer an ends-and-means view of the relation between the origins and ultimate uses of a given data point or set. Provenance is interesting when studying data luminosity because means and ends have much to tell us about the origins and uses of data in ways that gesture towards a more accurate and structured research agenda for data ethics that takes the emphasis away from individual moral patients and reorients it towards practices that occur within information management environments. Provenance offers researchers seeking to study data-driven practices a similar heuristic to a journalist’s line of questioning who, what, when, where, why, and how? This last question of how is something that can be incorporated into conventional models of provenance that make it useful in data ethics. The question of how data comes into being extends questions of power, legality, literacy, permission-seeking, and harm in an entangled way and notes how these factors shape the nature of personal data as it moves between contexts. Forms of provenance accumulate from transaction to transaction, cascading along, as a dataset ‘picks up’ the types of provenance that have led to its creation. This may involve multiple forms of overlapping provenance – methodological and epistemological, legal and illegal – which modulate different elements and apparatuses. Provenance, we argue is an important methodological consideration for workers in the humanities and social sciences. Provenance provides a set of shared questions on which models of transparency, accountability, and trust may be established. It points us towards tactics that might help data-subjects understand privacy in a contextual manner (Nissenbaum) and even establish practices of obfuscation and “informational self-defence” against regimes of datafication (Brunton and Nissenbaum). Here provenance is not just a declaration of what means and ends of data capture, sharing, linkage, and analysis are. We sketch the outlines of a provenance model in table 2 below.      Type   Metaphorical frame   Dark   Light       What?   The epistemological structure of a database determines the accuracy of subsequent decisions. Data must be consistent.   What data is asked of a person beyond what is strictly needed for service delivery.   Data that is collected for a specific stated purpose with informed consent from the data-subject. How does the decision about what to collect disrupt existing polities and communities? What demands for conformity does the database make of its subjects?     Where?   The contents of a database is important for making informed decisions. Data must be represented.   The parameters of inclusion/exclusion that create unjust risks or costs to people because of their inclusion or exclusion in a dataset.   The parameters of inclusion or exclusion that afford individuals representation or acknowledgement by being included or excluded from a dataset. How are populations recruited into a dataset? What divides exist that systematically exclude individuals?     Who?   Who has access to data, and how privacy is framed is important for the security of data-subjects. Data access is political.   Access to the data by parties not disclosed to the data-subject.     Who has collected the data and who has or will access it? How is the data made available to those beyond the data subjects?     How?   Data is created with a purpose and is never neutral. Data is instrumental.   How the data is used, to what ends, discursively, practically, instrumentally. Is it a private record, a source of value creation, the subject of extortion or blackmail?   How the data was intended to be used at the time that it was collected.     Why?   Data is created by people who are shaped by ideological factors. Data has potential.   The political rationality that shapes data governance with regard to technological innovation.   The trade-offs that are made known to individuals when they contribute data into sociotechnical systems over which they have limited control.     Table 2: Forms of Data Provenance  Conclusion As an illuminating methodology, provenance offers a specific line of questioning practices that take information through darkness and light. The emphasis that it places on a narrative for data assets themselves (asking what when, who, how, and why) offers a mechanism for traceability and has potential for application across contexts and cases that allows us to see data malpractice as something that can be productively generalised and understood as a series of ideologically driven technical events with social and political consequences without being marred by perceptions of exceptionality of individual, localised cases of data harm or data violence. References Brunton, Finn, and Helen Nissenbaum. """"Political and Ethical Perspectives on Data Obfuscation."""" Privacy, Due Process and the Computational Turn: The Philosophy of Law Meets the Philosophy of Technology. Eds. Mireille Hildebrandt and Katja de Vries. New York: Routledge, 2013. 171-195.  Buneman, Peter, Sanjeev Khanna, and Wang-Chiew Tan. """"Data Provenance: Some Basic Issues."""" International Conference on Foundations of Software Technology and Theoretical Computer Science. Berlin: Springer, 2000. Davis, Jenny L. How Artifacts Afford: The Power and Politics of Everyday Things. Cambridge: MIT Press, 2020. D'Ignazio, Catherine, and Lauren F. Klein. Data Feminism. Cambridge: MIT Press, 2020. Hardt, Michael, and Antonio Negri. Commonwealth. Cambridge: Harvard UP, 2009. Kitchin, Rob. """"Big Data, New Epistemologies and Paradigm Shifts."""" Big Data &amp; Society 1.1 (2014). Lawrence, Matthew. “Emerging Technology: An Interview with Adam Greenfield. ‘God Forbid That Anyone Stopped to Ask What Harm This Might Do to Us’. Institute for Public Policy Research, 13 Oct. 2017. &lt;https://www.ippr.org/juncture-item/emerging-technology-an-interview-with-adam-greenfield-god-forbid-that-anyone-stopped-to-ask-what-harm-this-might-do-us&gt;. Lupton, Deborah. """"Vital Materialism and the Thing-Power of Lively Digital Data."""" Social Theory, Health and Education. Eds. Deana Leahy, Katie Fitzpatrick, and Jan Wright. London: Routledge, 2018. Nissenbaum, Helen F. Privacy in Context: Technology, Policy, and the Integrity of Social Life. Stanford: Stanford Law Books, 2020. Warner, Michael. """"Publics and Counterpublics."""" Public Culture 14.1 (2002): 49-90.","",""
"2021","Giving by taking away: big tech, data colonialism and the reconfiguration of social good","Big Tech companies have recently led and financed projects that claim to use datafication for the “social good.” This article explores what kind of social good it is that this sort of datafication engenders. Drawing mostly on the analysis of corporate public communications and patent applications, it finds that these initiatives hinge on the reconfiguration of social good as datafied, probabilistic, and profitable. These features, the article argues, are better understood within the framework of data colonialism. Rethinking “doing good” as a facet of data colonialism illuminates the inherent harm to freedom these projects produce and why, to “give,” Big Tech must often take away.","",""
"2021","Data and Afrofuturism: an emancipated subject?",": The concept of an individual, liberal data subject, who was traditionally at the centre of data protection efforts has recently come under scrutiny. At the same time, the particularly destructive effect of digital technology on Black people establishes the need for an analysis that not only considers but brings racial dimensions to the forefront. I argue that because Afrofuturism situates the Black struggle in persistent, yet continuously changing structural disparities and power relations, it offers a powerful departure point for re-imagining data protection. Sketching an Afrofuturist data subject then centres on radical subjectivity, collectivity, and contextuality.","",""
"2021","What we do with data: a performative critique of data 'collection'",": Data collection is everywhere. It happens overtly and behind the scenes. It is a specific moment of legal obligation, the point at which the purpose and conditions of the data are legitimised. But what does the term data collection mean? What does it say or not say? Does it really capture the extraction or imposition taking place? How do terms and practices relate in defining the norms of data in society? This article undertakes a critique of data collection using data feminism and a performative theory of privacy: as a resource, an objective discovery and an assumption. It also discusses alternative terms and the implications of how we describe practices of ‘collecting’ data.","",""
"2021","Feminist data protection: an introduction",": ‘Feminist data protection’ is not an established term or field of study: data protection discourse is dominated by doctrinal legal and economic positions, and feminist perspectives are few and far between. This editorial introduction summarises a number of recent interventions in the broader fields of data sciences and surveillance studies, then turns to data protection itself and considers how it might be understood, critiqued and possibly reimagined in feminist terms. Finally, the authors return to ‘feminist data protection’ and the different directions in which it might be further developed—as a feminist approach to data protection,","",""
"2021","Governing “European values” inside data flows: interdisciplinary perspectives","This editorial introduces ten research articles, which form part of this special issue, exploring the governance of “European values” inside data flows. Protecting fundamental human rights and critical public interests that undergird European societies in a global digital ecosystem poses complex challenges, especially because the United States and China are leading in novel technologies. We envision a research agenda calling upon different disciplines to further identify and understand European values that can adequately perform under conditions of transnational data flows.","",""
"2021","Personal data ordering in context: the interaction of meso-level data governance regimes with macro frameworks",": The technological infrastructures enabling the collection, processing, and trading of data have fuelled a rapid innovation of data governance models. We differentiate between macro, meso, and micro level models, which correspond to major political blocks; societal-, industry-, or community level systems, and individual approaches, respectively. We focus on meso-level models, which coalesce around: (1) organisations prioritising their own interests over interests of other stakeholders; (2) organisations offering technological and legal tools aiming to empower individuals; (3) community-based data intermediaries fostering collective rights and interests. In this article we assess these meso-level models, and discuss their interaction with the macro-level legal frameworks that have evolved in the US, the EU, and China. The legal landscape has largely remained inconsistent and fragmented, with enforcement struggling to keep up with the latest developments. We argue, first, that the success of meso-logics is largely defined by global economic competition, and, second, that these meso-logics may potentially put the EU’s macro-level framework with its mixed internal market and fundamental rights-oriented model under pressure. We conclude that, given the relative absence of a strong macro level-framework and an intensive competition of governance models at meso-level, it may be challenging to avoid compromises to the European macro framework.","",""
"2021","Towards Informatic Personhood: understanding contemporary subjects in a data-driven society","ABSTRACT This paper explores the relationships of subjects in the context of data and data technologies, and advances an original theoretical framework called Informatic Personhood to better conceptual subjects and their relationships. Because of the enormous structural change that data has contributed to, subjects are sometimes distant and backgrounded in studies of data, despite data having significant impacts on their lives. Data-mediated relationships mean an increased scale to a relationship, with individuals able to connect to much broader contexts of data, but also have these structures reach down to their subjective context through data. Informatic Personhood seeks to capture the dynamics of data present in everyday life, addressing this distance and better conceptualising the scale of data-mediated relationships. This framework has two parts. The first – The Informatic Context – explores salient structural developments around data and conceptualises this as being defined by the presence of ‘data interfaces’ (that connect individuals to digital contexts), ‘data circulation’ (trends in the movement and storage of data), and ‘data abstraction’ (data manipulation practices). The second part concerns the Informatic Person, and the embodied, affective, and sensemaking relationships of individuals occurring across and through the Informatic Context. This framework better addresses the scale of data-mediated relationships, and places subjects firmly in the foreground of how data is understood.","",""
"2021","<i>History and Class Consciousness</i> 2.0<i>:</i> Georg Lukács in the age of digital capitalism and big data","ABSTRACT This paper discusses the relevance of Georg Lukács’ 1923 book History and Class Consciousness in the context of digital capitalism. It does so by analysing how Lukács’ concepts of the dialectic of subject and object, ideology, reification, reified consciousness matter today in the context of big data and digital capitalism. The essay shows that History and Class Consciousness’ critique of reification, ideology, and reified consciousness remains highly topical in the age of digital capitalism and big data. Lukács’ analysis allows us to critically analyse how social media, big data, and various other Internet technologies are used as tools of reification. At the same time, Lukács reminds us that only human praxis can establish alternatives.","",""
"2021","Approaching public perceptions of datafication through the lens of inequality: a case study in public service media","ABSTRACT In the emerging field of critical data studies, there is increasing acknowledgement that the negative effects of datafication are not experienced equally by all. Research on data and discrimination in particular has highlighted how already socially unequal populations are discriminated against in data-driven systems. Elsewhere, there is growing interest in public perceptions of datafication, amongst academic researchers interested in producing ‘bottom up’ understandings of the new roles of data in society and non-academic stakeholders keen to establish positive perceptions of data-driven systems. However, research into public perceptions rarely engages with the issue of inequality which is so central in data and discrimination scholarship. Bringing these two issues together, this paper explores public perceptions of datafication through the lens of inequality, focusing on the relationship between understandings and feelings within these perceptions. The paper draws on empirical focus group research into how audiences perceive the data practices that signing in to access BBC digital services enable. The paper shows how inequalities relating to age, dis/ability, poverty and their intersections played a role in shaping perceptions and that these social inequalities informed understandings of and feelings about data practices in complex and diverse ways. It concludes with reflections on the significance of these findings for future research and for data-related policy.","",""
"2021","Data feminism","All data have biographies: they are collected, cleaned, and complied before they could support powerful decisions. Every junction on this trajectory matters. Yet, according to Catherine D’Ignazio a...","",""
"2021","Numbers will not save us: Agonistic data practices","Abstract Contemporary forms of data activism promise community organizers the means to pursue political action, but they simultaneously threaten to responsibilize individuals and communities for documenting collective harms that are already known to the state. In this article, we use Mouffe’s articulation of agonistic pluralism to analyze recent literature on data activism in terms of this double bind, the threat that authentic community voice might be muted when data is used for activist purposes. We argue that community organizers navigate this double bind through agonistic data practices, tactics which draw on the affective and narrative potentialities of data to dispute the terms by which majoritarian political agents rationalize their actions and direct policy. Agonistic data practices do not presume that data will lead to more equitable consensus in representative government or to a more rational debate in the public sphere; instead, agonistic data practices mobilize the antagonisms that motivate people to act, to imagine alternative political arrangements, and to contribute to long-term collective action. We conclude by mapping out a research agenda that focuses on agonistic data practices enacted in minoritized communities in the Los Angeles metropolitan area.","",""
"2021","Data storytelling is not storytelling with data: A framework for storytelling in science communication and data journalism","Abstract Storytelling teaches. All good storytelling is good teaching. Storytelling is a form of teaching and learning because it asks the readers or listeners to replace well-established explanations that are considered facts with new, unexpected ones. We always learn new things when listening to good stories. Good stories do so by violating expectations and surprising the listener or the reader. Surprise breeds suspense, which generates engagement, which is a catalyst for learning – even truer for scientific and data-driven stories. In this paper we show how understanding the nature of good stories by focusing on the novelty they introduce and assumption they violate helps us to do effective scientific work and tell excellent data-based stories. We start by providing definitions of “story,” “storytelling,” and “good stories.” We then outline a methodology for building stories and provide an illustrative example of an effective data-based story from the history of medicine.","",""
"2021","Urban Data Analytics as Research Topic, Method and Ethical Concern","Local and global business interests assemble images of neighbourhoods from localised knowledge, including disparate forms of public data such as reviews, blog posts, and open data from municipalities and other organisations. (In)visible forms of working with and worrying about neighbourhood data can be understood as an engagement with the neighbourhood’s reputation, or rather its symbolic trajectory: a set of tangible and intangible indicators through which an urban space is known and treated accordingly over time. This paper addresses ethical concerns that emerge from contemporary datafied urban ethnogra-phy. We consider a combination of large-scale and bespoke, quantitative, and qualitative analyses of available sources with sustained ethnographic engagement with a Dutch neighbourhood coping with a troubled reputation. While the latter activities can mitigate ethical issues stemming from the former, ethnography in turn raises further concerns of exploitation and risk exposure and should not be treated as a kind of ‘ethical panacea’ for big, open, or public data projects. A multifaceted and interrogative approach to data collection may offer a more rounded account of contemporary urban data practices by drawing upon distinct and possibly conflicting accounts of social life. The challenge is to prioritise under-represented and otherwise mar-ginalised voices in both the design and the dissemination of research on urban data analytics.","",""
"2021","EVERYDAY DATA CULTURES","This panel deploys a range of qualitative methodologies to investigate how processes of datafication meet with the subjective experiences of ordinary people, and the practices of everyday life. We draw on the model of ‘everyday data cultures’ proposed by Burgess (2017) to explore the ways diverse data practices – including the production and circulation of data visualisations, modes of data storage and vernacular engagements with data literacy – can be understood as aspects of culture. Following Burgess, we define everyday data cultures as the practices that form around and in response to the social media and other data (and data trails) that people generate as we go about our daily lives. These practices form from our diverse engagements with, experiences of, and approaches to understanding and negotiating these data Across these four papers, we address the everyday politics of social media platforms; the development of vernacular pedagogies of AI and machine leaning practices; the historical datafication of sex and gender, and mundane workplace practices of storing, concealing and revealing personal data. In doing so, we seek to highlight and amplify everyday human agency, as well as explore its limits and uneven distribution, and consider how it is being transformed through the logics of data and the machines that feed on them.","",""
"2021","TOWARDS CIVIC PARTICIPATION IN THE DATAFIED SOCIETY: CAN CITIZEN        ASSEMBLIES DEMOCRATIZE ALGORITHMIC GOVERNANCE?","Citizens are increasingly assessed, profiled, categorized and scored according to data analytics, their future behavior is predicted, and services are allocated accordingly. State-citizen relations become quasi-automated and dependent on algorithmic decision-making, yet (largely) without people’s knowledge and without avenues to meaningfully engage and intervene. This raises significant challenges for democratic processes and active citizenship. How do we participate as citizens in a society in which we are constantly rated and categorized in ways that we do not understand? How do we affect the development and management of the very data systems that increasingly organize society? How do we develop new democratic practices to ensure participation and accountability? This paper explores emerging opportunities for participatory and deliberative forms of governing the implementation of data analytics, particularly in the public sector. It investigates how models of engagement and deliberation – from citizen juries and citizen assemblies to deliberative polls and public dialogues – can advance civic participation in the roll-out and implementation of data analytics and thus democratize algorithmic governance. It assesses the suitability of these practices by evaluating, e.g., the level of participation, policy impcts, and institutional challenges and obstacles, bringing together insights from the fields of critical data studies and democratic innovation. The paper draws on findings from 15 expert interviews conducted between 2019 and 2021 with members of government and civil society as well as a fact-finding workshop that form part of a two-year project investigating the practices, structures and constraints of citizen engagement with datafied governance.","",""
"2021","CRITICAL PEDAGOGY AS A PRACTICE OF RESISTANCE TO ALGORITHMS","Today using the Internet implies primarily using digital platforms,         that actively participate in the co-construction of social life. In this scenario, users         have often been depicted as powerless, subjected to exploitative commercial practices, and         as having internalized their condition of surveilled and datafied individuals. However,         little attention has been paid to how individuals make sense of algorithms in their everyday         life and how exert their agency while using platforms. Furthermore, little is known         regarding how researchers can actively elicit critical reflections regarding structures of         datafication, thereby helping individuals increase their awareness and data literacy. This         paper contends that auto-ethnographic diaries, elaborated following a critical pedagogical         approach, can be valuable to investigate user practices and how algorithms are enacted in         everyday life by those practices. Furthermore, a critical pedagogy approach can raise         awareness among individuals regarding processes of pervasive datafication and surveillance,         thereby being a way to redistribute social value to the public while doing social research         and a practice of independence and resistance to algorithmic surveillance.","",""
"2021","MAPPING HEALTH: HOW DANES EXPERIENCE THEIR DIGITAL HEALTH DATA","This paper explores how Danish citizens experience digital health         data and how these in turn affect their understanding of digital health data and their         self-understanding as a patient. Previous research on digital health data examines primarily         opportunities and challenges as well as structural effects concluding that having access to         one's medical data is generally beneficial for patients but also comes with literacy         challenges. The aim of this research is to look deeper into personal experiences with         digital health data in order to understand what is at stake when people become digitally         mapped patients and how experiences of empowerment, independence, perplexity, and doubt         intermingle when reading one’s own health data. Taking a user’s view, the paper draws         theoretically on the concept of ‘assemblage’ understanding digital health data as a complex         nexus of user-data relationships. The empirical analysis draws on 16 in-depth purposefully         sampled interviews that have been coded thematically. The primary analysis shows that         digital health data creates unique, deeply emotional experiences that lead towards a variety         of existential questions. Combining the theoretical lens with the empirical analysis this         paper contributes with what we call ‘health assemblages’ that highlight the emerging         relationships and personal emotional attachments users make with their digital health data.         In conclusion, it can be stated that seeing oneself mapped in data creates unique         experiences, often challenging the self-understanding of the patient.","",""
"2021","STITCHING THE CURVE: PANDEMIC CRAFT AND FEMINIST DATA         VISUALIZATION","Feminist scholars are increasingly drawing attention to the ways “big         data” and data representations reinscribe gender and racial inequality, an issue made even         more pressing by the role data has taken in our daily lives since the start of the COVID-19         pandemic. """"Stitching the Curve,"""" a knitted pandemic data visualization project by librarians         at the University of Alberta, offers an intersection between digital activism and         craftivism, enabling a material, feminist response to an erasure and minimization of         collective loss. We examine the media coverage around the project, which includes the online         blogs of the project’s participants. Using critical technocultural discourse analysis (CTDA)         as a guiding methodology, we consider simultaneously the feminist, activist framing and the         influence of material and digital platforms on the cultural influence of the work (Brock         2018). Blogging and knitting are frequently associated with craft and writing as an         expression of the domestic and personal, relegated to a feminine and, consequently,         minimized space of care and labor. Through a critical technocultural discourse analysis of         Stitching the Curve, we understand how the project makes a powerful statement in         representing not only the oft-dismissed human cost of the COVID-19 pandemic, but also uses         mediums of representation that challenge patriarchal “big data” collection and         representational practices. Stitching the Curve makes data visualization a rhetoric of         care.","",""
"2021","DATA INQUIRY: METHODOLOGICAL CONSIDERATIONS ON DATAFICATION IN SOCIAL         RESEARCH","Datafication is widely acknowledged as a process “transforming all         things under the sun into a data format” (van Dijck, 2017, p. 11). As data become both         objects and instruments of social science, many scholars call for attention to the ways         datafication reconfigures scholarly knowledge production, its methodological opportunities,         and challenges (Lomborg et al., 2020). This contribution offers a reflection on the         interdependence between methodological approaches taken to study datafication and concepts         about it, that these approaches provide within the domains of critical data studies and         media studies. Expanding on the concept of methods' performativity (Barad, 2007), I apply         the notion of methods assemblages: “a continuing process of crafting and enacting necessary         boundaries [and relations]"""" between researchers and all relevant matters (Law, 2004: 144).         The key question in the presented study is what kinds of methods assemblages are being         applied in current datafication research and what concepts of datafication they produce. 32         expert interviews were conducted with scholars who published empirical work on dataficaiton         between 2015 and 2020. Three methods assemblages were developed. Central to distinguishing         between methods assemblages are the ways of associating of the involved actors and things.         In my analysis the questions of (1) what we are talking about when talking about         datafication and (2) kinds of knowledges that researchers were interested in producing can         be understood as such ways of associating. The methods assemblages contribute to critical         data studies by producing accounts about datafication processes that are in concert with the         methods assemblages applied to study these.","",""
"2021","What does it mean to embed ethics in data science? An integrative approach based on microethics and virtues","AbstractIn the past few years, scholars have been questioning whether the current approach in data ethics based on the higher level case studies and general principles is effective. In particular, some have been complaining that such an approach to ethics is difficult to be applied and to be taught in the context of data science. In response to these concerns, there have been discussions about how ethics should be “embedded” in the practice of data science, in the sense of showing how ethical issues emerge in small technical choices made by data scientists in their day-to-day activities, and how such an approach can be used to teach data ethics. However, a precise description of how such proposals have to be theoretically conceived and could be operationalized has been lacking. In this article, we propose a full-fledged characterization of ‘embedding’ ethics, and how this can be applied especially to the problem of teaching data science ethics. Using the emerging model of ‘microethics’, we propose a way of teaching daily responsibility in digital activities that is connected to (and draws from) the higher level ethical challenges discussed in digital/data ethics. We ground this microethical approach into a virtue theory framework, by stressing that the goal of a microethics is to foster the cultivation of moral virtues. After delineating this approach of embedding ethics in theoretical detail, this article discusses a concrete example of how such a ‘micro-virtue ethics’ approach could be practically taught to data science students.","",""
"2021","Critical companionship: Some  sensibilities for studying the lived experience of data subjects"," What are the challenges of turning data subjects into research participants—and how can we approach this task responsibly? In this paper, we develop a methodology for studying the lived experiences of people who are subject to automated scoring systems. Unlike most media technologies, automated scoring systems are designed to track and rate specific qualities of people without their active participation. Credit scoring, risk assessments, and predictive policing all operate obliquely in the background long before they come to matter. In doing so, they constitute a problem not only for those subject to these systems but also for researchers who try to study their experience. Specifically, we identify three challenges that are distinct to studying experiences of automated scoring: limited awareness, embeddedness, and ongoing inquiry. Starting from the observation that coming to terms with one's position as a data subject constitutes a form of learning in its own right, we propose a research strategy called critical companionship. Originally articulated in the context of nursing research, critical companionship invites us to accompany a data subject over time, paying critical attention to how the participant's and the researcher's inquiries complicate and constitute each other. We illustrate the strengths and limitations of this methodology with materials from a recent study we conducted about people's credit repair practices and sketch a set of sensibilities for studying contemporary scoring systems from the margins. ","",""
"2021","Digital failure: Unbecoming the “good” data subject through entropic, fugitive, and queer data"," This paper explores the political potential of digital failure as a refusal to work in service of today’s dataveillance society. Moving beyond criticisms of flawed digital systems, this paper traces the moments of digital failure that seek to break, rather than fix, existing systems. Instead, digital failure is characterized by pesky data that sneaks through the cracks of digital capitalism and dissipates into the unproductive; it supports run-away data prone to misidentifications by digital marketers, coders, and content moderators; and it celebrates data predisposed to “back-talk” with playful irreverence toward those that seek to bring order through normative categorization and moderation. I call these data entropic, fugitive, and queer and explore their mischievous practices through three case studies: the unaccountable data in identity resolution, public shaming of the ImageNet training data, and reading practices of sex worker and influencer, @Charlieshe. Together these case studies articulate the political potential of digital failure as a process of unbecoming the good data subject by pushing past the margins of legibility, knowability, and thinkability, to reveal what is made illegible, unknowable, and unthinkable to data’s seeing eye. As predictive analytics, automated decision-systems, and artificial intelligence take on increasingly central roles in public governance, digital failure reveals how data itself is a flawed concept prone to political abuse and social engineering to protect the interests of the powerful, while keeping those marginalized over-surveilled and underrepresented. ","",""
"2021","Low on trust, high on use: Datafied  media, trust and everyday life"," This article explores yet another paradox – aside from the privacy paradox – related to the datafication of media: citizens trust least the media they use most It investigates the role that daily life plays in shaping the trust that citizens place in datafied media. The study reveals five sets of heuristics guiding the trust assessments of citizens: (1) characteristics of media organisations, (2) old media standards, (3) context of use and purpose, (4) experiences of datafication and (5) understandings of datafication. The article discusses the use of these heuristics and the value that everyday life holds in assessing trust in datafied media. It concludes that, guided by a partial ‘structure of perception’ and enticed into trusting datafied media in the context of their daily lives, citizens may be highly concerned by the datafication of media but use them nevertheless. ","",""
"2021","Reading datasets: Strategies for interpreting the politics of data signification"," All datasets emerge from and are enmeshed in power-laden semiotic systems. While emerging data ethics curriculum is supporting data science students in identifying data biases and their consequences, critical attention to the cultural histories and vested interests animating data semantics is needed to elucidate the assumptions and political commitments on which data rest, along with the externalities they produce. In this article, I introduce three modes of reading that can be engaged when studying datasets—a denotative reading (extrapolating the literal meaning of values in a dataset), a connotative reading (tracing the socio-political provenance of data semantics), and a deconstructive reading (seeking what gets Othered through data semantics and structure). I then outline how I have taught students to engage these methods when analyzing three datasets in Data and Society—a course designed to cultivate student competency in politically aware data analysis and interpretation. I show how combined, the reading strategies prompt students to grapple with the double binds of perceiving contemporary problems through systems of representation that are always situated, incomplete, and inflected with diverse politics. While I introduce these methods in the context of teaching, I argue that the methods are integral to any data practice in the conclusion. ","",""
"2021","What do we see when we look at networks: Visual network analysis, relational ambiguity, and force-directed layouts"," It is increasingly common in natural and social sciences to rely on network visualizations to explore relational datasets and illustrate findings. Such practices have been around long enough to prove that scholars find it useful to project networks in a two-dimensional space and to use their visual qualities as proxies for their topological features. Yet these practices remain based on intuition, and the foundations and limits of this type of exploration are still implicit. To fill this lack of formalization, this paper offers explicit documentation for the kind of visual network analysis encouraged by force-directed layouts. Using the example of a network of Jazz performers, band and record labels extracted from Wikipedia, the paper provides guidelines on how to make networks readable and how to interpret their visual features. It discusses how the inherent ambiguity of network visualizations can be exploited for exploratory data analysis. Acknowledging that vagueness is a feature of many relational datasets in the humanities and social sciences, the paper contends that visual ambiguity, if properly interpreted, can be an asset for the analysis. Finally, we propose two attempts to distinguish the ambiguity inherited from the represented phenomenon from the distortions coming from fitting a multidimensional object in a two-dimensional space. We discuss why these attempts are only partially successful, and we propose further steps towards a metric of spatialization quality. ","",""
"2021","Excavating awareness and power in data science: A manifesto for trustworthy pervasive data research"," Frequent public uproar over forms of data science that rely on information about people demonstrates the challenges of defining and demonstrating trustworthy digital data research practices. This paper reviews problems of trustworthiness in what we term pervasive data research: scholarship that relies on the rich information generated about people through digital interaction. We highlight the entwined problems of participant unawareness of such research and the relationship of pervasive data research to corporate datafication and surveillance. We suggest a way forward by drawing from the history of a different methodological approach in which researchers have struggled with trustworthy practice: ethnography. To grapple with the colonial legacy of their methods, ethnographers have developed analytic lenses and researcher practices that foreground relations of awareness and power. These lenses are inspiring but also challenging for pervasive data research, given the flattening of contexts inherent in digital data collection. We propose ways that pervasive data researchers can incorporate reflection on awareness and power within their research to support the development of trustworthy data science. ","",""
"2021","From FAIR data to fair data use: Methodological data fairness in health-related social media research"," The paper problematises the reliability and ethics of using social media data, such as sourced from Twitter or Instagram, to carry out health-related research. As in many other domains, the opportunity to mine social media for information has been hailed as transformative for research on well-being and disease. Considerations around the fairness, responsibilities and accountabilities relating to using such data have often been set aside, on the understanding that as long as data were anonymised, no real ethical or scientific issue would arise. We first counter this perception by emphasising that the use of social media data in health research can yield problematic and unethical results. We then provide a conceptualisation of methodological data fairness that can complement data management principles such as FAIR by enhancing the actionability of social media data for future research. We highlight the forms that methodological data fairness can take at different stages of the research process and identify practical steps through which researchers can ensure that their practices and outcomes are scientifically sound as well as fair to society at large. We conclude that making research data fair as well as FAIR is inextricably linked to concerns around the adequacy of data practices. The failure to act on those concerns raises serious ethical, methodological and epistemic issues with the knowledge and evidence that are being produced. ","",""
"2021","The data archive as factory: Alienation and resistance of data processors"," Archival data processing consists of cleaning and formatting data between the moment a dataset is deposited and its publication on the archive’s website. In this article, I approach data processing by combining scholarship on invisible labor in knowledge infrastructures with a Marxian framework and show the relevance of considering data processing as factory labor. Using this perspective to analyze ethnographic data collected during a six-month participatory observation at a U.S. data archive, I generate a taxonomy of the forms of alienation that data processing generates, but also the types of resistance that processors develop, across four categories: routine, speed, skill, and meaning. This synthetic approach demonstrates, first, that data processing reproduces typical forms of factory worker’s alienation: processors are asked to work along a strict standardized pipeline, at a fast pace, without acquiring substantive skills or having a meaningful involvement in their work. It reveals, second, how data processors resist the alienating nature of this workflow by developing multiple tactics along the same four categories. Seen through this dual lens, data processors are therefore not only invisible workers, but also factory workers who follow and subvert a workflow organized as an assembly line. I conclude by proposing a four-step framework to better value the social contribution of data workers beyond the archive. ","",""
"2021","In search of ‘extra data’: Making tissues flow from personal to personalised medicine"," One of the key features of the contemporary data economy is the widespread circulation of data and its interoperability. Critical data scholars have analysed data repurposing practices and other factors facilitating the travelling of data. While this approach focused on flows provides great potential, in this article we argue that it tends to overlook questions of attachment and belonging. Drawing upon ethnographic fieldwork within a Danish data-linkage infrastructure, and building upon insights from archival science, we discuss the work of data practitioners enabling the repurposing of pathology samples extracted from patients for the conduct of ‘personal medicine’ – our term to discuss the so-called old-fashioned treatment of patients – towards personalised medicine. This first involves ‘getting to know’ the tissues and unpacking their previous uses and meanings, then detaching them from their original source to extract data from such tissues and making them flow towards a new container where they can be worked on and connected with other data. As data practitioners make these tissues travel, transforming them into research data, they organise the attachments of data to new agendas, persons and places. Crucially, in our case, we observe the prominence of national attachments, whereby managing tissues and data in and out of containers involves tying them to the nation to serve its interests. We thus expose how the building of data linkage infrastructures entails more than the accumulation and curation of data, but also involves crafting meanings, futures and belonging to specific communities and territories. ","",""
"2021","Productive myopia: Racialized organizations and edtech"," This paper reports on a two-year, field-based study set in a charter management organization (CMO-LAX), a not-for-profit educational organization that operates 18 public schools exclusively in the Black and Latinx communities of South and East Los Angeles. At CMO-LAX, the nine-member Data Team pursues the organization's avowed mission of making public schools data-driven, primarily through the aggregation, analysis, and visualization of digital data derived from quotidian educational activities. This paper draws on the theory of racialized organizations to characterize aspects of data-driven management of public education as practiced by CMO-LAX. I explore two examples of how CMO-LAX shapes data to support racial projects: the reconstruction of the figure of chronic truants and the incorporation of this figure in a calculative regime of student accomplishment. Organizational uses of data support a strategy I call productive myopia, a way of pursuing racial projects via seemingly independent, objective quantifications. This strategy allows the organization to claim to mitigate racial projects and, simultaneously, to accommodate them. This paper concludes by arguing for approaches to research and practice that center racial projects, particularly when data-intensive tools and platforms are incorporated into the provision of public goods and services such as education. ","",""
"2021","Dashboard stories: How narratives told by predictive analytics reconfigure roles, risk and sociality in education"," In this paper, we explore how the development and affordances of predictive analytics may impact how teachers and other educational actors think about and teach students and, more broadly, how society understands education. Our particular focus is on the data dashboards of learning support systems which are based on Machine Learning (ML). While previous research has focused on how these systems produce credible knowledge, we explore here how they also produce compelling, persuasive and convincing narratives. Our main argument is that particular kinds of stories are written by predictive analytics and written into their data dashboards. Based on a case study of a leading predictive analytics system, we explore how data dashboards imply causality between the ‘facts’ they are visualising. To do so, we analyse the stories they tell according to their spatial and temporal dimensions, characters and events, sequentiality as well as tellability. In the stories we identify, teachers are managers, students are at greater or lesser risk, and students’ sociality is reduced to machine-readable interactions. Overall, only data marked as individual behaviours becomes relevant to the system, rendering structural inequalities invisible. Reflecting on the implications of these systems, we suggest ways in which the uptake of these systems can interrupt such stories and reshape them in other directions. ","",""
"2021","Social determinants of health in the Big Data mode of population health risk calculation"," Amidst the climate of crisis surrounding the rise in opioid-related overdose in the USA, early in 2019, Google and Deloitte launched ‘Opioid360’. Here came a platform combining browser histories, credit, insurance, social media, and traditional survey data to sell the service of risk calculation in population health. Opioid360's approach to automating risk calculation not only promised to identify persons ‘at risk’ of opioid dependence, but also paved the way for broader applications anticipating common chronic diseases and coordinating logistical operations involved in pandemic response. Beginning with this experimental platform, this paper develops an analysis of the Big Data mode of risk calculation - an epistemological and political shift that involves technology companies, investors, insurers, governments, and public health institutions. The analysis focuses on the re-emergence of ‘social determinants of health’ (SDOH) in the rhetoric accompanying novel analytic platforms that estimate, calculate, and compute individual health risks. While the treatment of SDOH has always been a site of political contestation within the discipline of public health, powerful interests are crystallising around the concept and instrumentalising it in platforms that sell algorithmic prediction. Silicon Valley's breed of asset-oriented technoscience appears not only to be amplifying the behaviouralist elements of public health. Among the stakes of the Big Data mode is the paradoxical retreat from changing social conditions that contribute to the prevalence of health and illness in populations; and instead, the promotion of an apparatus for pricing and exchanging individual risk or excluding from services those who bear risk most acutely. ","",""
"2021","The cancer multiple: Producing and translating genomic big data into oncology care"," This article provides an ethnographic account of how Big Data biology is produced, interpreted, debated, and translated in a Big Data-driven cancer clinical trial, entitled “Personalized OncoGenomics,” in Vancouver, Canada. We delve into epistemological differences between clinical judgment, pathological assessment, and bioinformatic analysis of cancer. To unpack these epistemological differences, we analyze a set of gazes required to produce Big Data biology in cancer care: clinical gaze, molecular gaze, and informational gaze. We are concerned with the interactions of these bodily gazes and their interdependence on each other to produce Big Data biology and translate it into clinical knowledge. To that end, our central research questions ask: How do medical practitioners and data scientists interact, contest, and collaborate to produce and translate Big Data into clinical knowledge? What counts as actionable and reliable data in cancer decision-making? How does the explicability or translatability of genomic Big Data come to redefine or contradict medical practice? The article contributes to current debates on whether Big Data engenders new questions and approaches to biology, or Big Data biology is merely an extension of early modern natural history and biology. This ethnographic account will highlight how genomic Big Data, which underpins the mechanism of personalized medicine, allows oncologists to understand and diagnose cancer in a different light, but it does not revolutionize or disrupt medical oncology on an institutional level. Rather, personalized medicine is interdependent on different styles of (medical) thought, gaze, and practice to be produced and made intelligible. ","",""
"2021","Heritage-based tribalism in Big Data ecologies: Deploying origin myths for antagonistic othering"," This article presents a conceptual and methodological framework to study heritage-based tribalism in Big Data ecologies by combining approaches from the humanities, social and computing sciences. We use such a framework to examine how ideas of human origin and ancestry are deployed on Twitter for purposes of antagonistic ‘othering’. Our goal is to equip researchers with theory and analytical tools for investigating divisive online uses of the past in today’s networked societies. In particular, we apply notions of heritage, othering and neo-tribalism, and both data-intensive and qualitative methods to the case of people’s engagements with the news of Cheddar Man’s DNA on Twitter. We show that heritage-based tribalism in Big Data ecologies is uniquely shaped as an assemblage by the coalescing of different forms of antagonistic othering. Those that co-occur most frequently are the ones that draw on ‘Views on Race’, ‘Trust in Experts’ and ‘Political Leaning’. The framings of the news that were most influential in triggering heritage-based tribalism were introduced by both right- and left-leaning newspaper outlets and by activist websites. We conclude that heritage-themed communications that rely on provocative narratives on social media tend to be labelled as political and not to be conducive to positive change in people’s attitudes towards issues such as racism. ","",""
"2021","For a heterodox computational social science"," The proliferation of digital data has been the impetus for the emergence of a new discipline for the study of social life: ‘computational social science’. Much research in this field is founded on the premise that society is a complex system with emergent structures that can be modeled or reconstructed through digital data. This paper suggests that computational social science serves practical and legitimizing functions for digital capitalism in much the same way that neoclassical economics does for neoliberalism. In recognition of this homology, this paper develops a critique of the complexity perspective of computational social science and argues for a heterodox computational social science founded on the meta-theory of critical realism that is critical, methodological pluralist, interpretative and explanative. This implies diverting computational social science’ computational methods and digital data so as to not be aimed at identifying invariant laws of social life, or optimizing state and corporate practices, but to instead be used as part of broader research strategies to identify contingent patterns, develop conjunctural explanations, and propose qualitatively different ways of organizing social life. ","",""
"2021","Big data and Belmont: On the ethics and research implications of consumer-based datasets"," Consumer-based datasets are the products of data brokerage firms that agglomerate millions of personal records on the adult US population. This big data commodity is purchased by both companies and individual clients for purposes such as marketing, risk prevention, and identity searches. The sheer magnitude and population coverage of available consumer-based datasets and the opacity of the business practices that create these datasets pose emergent ethical challenges within the computational social sciences that have begun to incorporate consumer-based datasets into empirical research. To directly engage with the core ethical debates around the use of consumer-based datasets within social science research, I first consider two case study applications of consumer-based dataset-based scholarship. I then focus on three primary ethical dilemmas within consumer-based datasets regarding human subject research, participant privacy, and informed consent in conversation with the principles of the seminal Belmont Report. ","",""
"2021","Big data for climate action or climate action for big data?"," Under the banner of “data for good,” companies in the technology, finance, and retail sectors supply their proprietary datasets to development agencies, NGOs, and intergovernmental organizations to help solve an array of social problems. We focus on the activities and implications of the Data for Climate Action campaign, a set of public–private collaborations that wield user data to design innovative responses to the global climate crisis. Drawing on in-depth interviews, first-hand observations at “data for good” events, intergovernmental and international organizational reports, and media publicity, we evaluate the logic driving Data for Climate Action initiatives, examining the implications of applying commercial datasets and expertise to environmental problems. Despite the increasing adoption of Data for Climate Action paradigms in government and public sector efforts to address climate change, we argue Data for Climate Action is better seen as a strategy to legitimate extractive, profit-oriented data practices by companies than a means to achieve global goals for environmental sustainability. ","",""
"2021","Data as asset? The measurement, governance, and valuation of digital personal data by Big Tech"," Digital personal data is increasingly framed as the basis of contemporary economies, representing an important new asset class. Control over these data assets seems to explain the emergence and dominance of so-called “Big Tech” firms, consisting of Apple, Microsoft, Amazon, Google/Alphabet, and Facebook. These US-based firms are some of the largest in the world by market capitalization, a position that they retain despite growing policy and public condemnation—or “techlash”—of their market power based on their monopolistic control of personal data. We analyse the transformation of personal data into an asset in order to explore how personal data is accounted for, governed, and valued by Big Tech firms and other political-economic actors (e.g., investors). However, our findings show that Big Tech firms turn “users” and “user engagement” into assets through the performative measurement, governance, and valuation of user metrics (e.g., user numbers, user engagement), rather than extending ownership and control rights over personal data per se. We conceptualize this strategy as a form of “techcraft” to center attention on the means and mechanisms that Big Tech firms deploy to make users and user data measurable and legible as future revenue streams. ","",""
"2021","A view from data science"," For better and worse, our world has been transformed by Big Data. To understand digital traces generated by individuals, we need to design multidisciplinary approaches that combine social and data science. Data and social scientists face the challenge of effectively building upon each other’s approaches to overcome the limitations inherent in each side. Here, we offer a “data science perspective” on the challenges that arise when working to establish this interdisciplinary environment. We discuss how we perceive the differences and commonalities of the questions we ask to understand digital behaviors (including how we answer them), and how our methods may complement each other. Finally, we describe what a path toward common ground between these fields looks like when viewed from data science. ","",""
"2021","Discovering needs for digital capitalism: The hybrid profession of data science"," Over the last decade, ‘data scientists’ have burst into society as a novel expert role. They hold increasing responsibility for generating and analysing digitally captured human experiences. The article considers their professionalization not as a functionally necessary development but as the outcome of classification practices and struggles. The rise of data scientists is examined across their discursive classification in the academic and economic fields in both the USA and Germany. Despite notable differences across these fields and nations, the article identifies two common subjectivation patterns. Firstly, data scientists are constructed as hybrids, who combine generally conflictive roles as both generalists and specialists; technicians and communicators; data exploiters and data ethicists. This finding is interpreted as demonstrating a discursive distinction between data scientists and other competing and supposedly more one-dimensional professionals, such as statisticians or computer scientists. Secondly, the article uncovers a discursive construction that interpellates data scientists as discoverers of needs. They are imagined as explorative work subjects who can establish growth for digital capitalism by generating behavioural patterns that allow for personalization, customization and optimization practices. ","",""
"2021","Data diaries: A situated approach to the study of data"," This article adapts the ethnographic medium of the diary to develop a method for studying data and related data practices. The article focuses on the creation of one data diary, developed iteratively over three years in the context of a national centre for monitoring disasters and natural hazards in Brazil (Cemaden). We describe four points of focus involved in the creation of a data diary – spaces, interfaces, types and situations – before reflecting on the value of this method. We suggest data diaries (1) are able to capture the informal dimension of data-intensive organisations; (2) enable empirical analysis of the specific ways that data intervene in the unfolding of situations; and (3) as a document, data diaries can foster interdisciplinary and inter-expert dialogue by bridging different ways of knowing data. ","",""
"2021","Heritage transformations"," This special theme examines the dynamic relationships between production, availability, and usage of Big Data, laying out a research agenda for digital heritage at the time of the ‘data turn’. Over the past 15 years, a proliferation of heritage data has been generated by ‘ecosystems of distributed practices’ enacted by the co-working of bodies, cultural identities, organisational workflows, software, application programming interfaces, etc. The authors of research articles and commentaries in this collection explore the three macro-dimensions along which we can map transformations of and by heritage in Big Data ecologies: (a) ontologies or heritage as datified resources, (b) interactions and (c) methodologies and epistemologies. ","",""
"2021","Big Tech platforms in health research: Re-purposing big data governance in light of the General Data Protection Regulation’s research exemption"," The emergence of a global industry of digital health platforms operated by Big Tech corporations, and its growing entanglements with academic and pharmaceutical research networks, raise pressing questions on the capacity of current data governance models, regulatory and legal frameworks to safeguard the sustainability of the health research ecosystem. In this article, we direct our attention toward the challenges faced by the European General Data Protection Regulation in regulating the potentially disruptive engagement of Big Tech platforms in health research. The General Data Protection Regulation upholds a rather flexible regime for scientific research through a number of derogations to otherwise stricter data protection requirements, while providing a very broad interpretation of the notion of “scientific research”. Precisely the breadth of these exemptions combined with the ample scope of this notion could provide unintended leeway to the health data processing activities of Big Tech platforms, which have not been immune from carrying out privacy-infringing and socially disruptive practices in the health domain. We thus discuss further finer-grained demarcations to be traced within the broadly construed notion of scientific research, geared to implementing use-based data governance frameworks that distinguish health research activities that should benefit from a facilitated data protection regime from those that should not. We conclude that a “re-purposing” of big data governance approaches in health research is needed if European nations are to promote research activities within a framework of high safeguards for both individual citizens and society. ","",""
"2021","“The revolution will not be supervised”: Consent and open secrets in data science"," The social impacts of computer technology are often glorified in public discourse, but there is growing concern about its actual effects on society. In this article, we ask: how does “consent” as an analytical framework make visible the social dynamics and power relations in the capture, extraction, and labor of data science knowledge production? We hypothesize that a form of boundary violation in data science workplaces—gender harassment—may correlate with the ways humans’ lived experiences are extracted to produce Big Data. The concept of consent offers a useful way to draw comparisons between gender relations in data science and the means by which machines are trained to learn and reason. Inspired by how Big Tech leaders describe unsupervised machine learning, and the co-optation of “revolutionary” rhetoric they use to do so, we introduce a concept we call “techniques of invisibility.” Techniques of invisibility are the ways in which an extreme imbalance between exposure and opacity, demarcated along fault lines of power, are fabricated and maintained, closing down the possibility for bidirectional transparency in the production and applications of algorithms. Further, techniques of invisibility, which we group into two categories—epistemic injustice and the Brotherhood—include acts of subjection by powerful actors in data science designed to quell resistance to exploitative relations. These techniques may be useful in making further connections between epistemic violence, sexism, and surveillance, sussing out persistent boundary violations in data science to render the social in data science visible, and open to scrutiny and debate. ","",""
"2021","Data Management for Platform-Mediated Public Services: Challenges and Best Practices","Data harvesting and profiling have become a de facto business model for many businesses in the digital economy. The surveillance of individual persons through their use of private sector platforms has a well-understood effect on personal autonomy and democratic institutions. In this article, we explore the consequences of implementing data-rich services in the public sector and, specifically, the dangers inherent to undermining the universality of the reach of public services, the implicit endorsement of the platform operators by the government, and the inability of members of the public to avoid using the platforms in practice. We propose a set of good practices in the form of design principles that infrastructure services can adopt to mitigate the risks, and we specify a set of design primitives that can be used to support the development of infrastructure that follows the principles. We argue that providers of public infrastructure should adopt a practice of critical assessment of the consequences of their technology choices.","",""
"2021","The promise and the premise: How digital media present big data","This paper analyzes the thematic and discursive construction of big data by the Argentine digital press. Using text mining techniques — topic modelling and enriched associative networks — together with qualitative and quantitative content analysis — in both discourse and images — over 2,026 articles, we sought to identify the topics wherein big data is treated, the promises and risks it addresses, its definition within the semantic field in which is explicitly expressed, and the pictures that illustrate it. Results herein presented compare how big data is portrayed in news about politics, business, and technological innovations, as well as in focal pieces targeted to a generic and massive audience, and critical reflections about its risks. Although in each of those thematic contexts big data is anchored differently, there is a common idea that associates big data with a socio-technological premise and an epistemic promise: because of the availability of large volumes of data, something new that will allow better decisions can be known. Our exploration contributes to a more detailed knowledge on how the news media social systems make sense of novel phenomena such as big data.","",""
"2021","“Bodies not templates”: Contesting dominant algorithmic imaginaries"," Through an array of technological solutions and awareness-raising initiatives, civil society mobilizes against an onslaught of surveillance threats. What alternative values, practices, and tactics emerge from the grassroots which point toward other ways of being in the datafied society? Conversing with critical data studies, science and technology studies, and surveillance studies, this article looks at how dominant imaginaries of datafication are reconfigured and responded to by groups of people dealing directly with their harms and risks. Building on practitioner interviews and participant observation in digital rights events and surveying projects intervening in three critical technological issues of our time—the challenges of digitally secure computing, the Internet of Things, and the threat of widespread facial recognition—this article investigates social justice activists, human rights defenders, and progressive technologists as they try to flip dominant algorithmic imaginaries. In so doing, the article contributes to our understanding of how individuals and social groups make sense of the challenges of datafication from the bottom-up. ","",""
"2021","Terms of inclusion: Data, discourse, violence"," Inclusion has emerged as an early cornerstone value for the emerging domain of “data ethics.” On the surface, appeals to inclusion appear to address the threat that biased data technologies making decisions or misrepresenting people in ways that reproduce longer standing patterns of oppression and violence. Far from a panacea for the threats of pervasive data collection and surveillance, however, these emerging discourses of inclusion merit critical consideration. Here, I use the lens of discursive violence to better theorize the relationship between inclusion and the violent potentials of data science and technology. In doing so, I aim to articulate the problematic and often perverse power relationships implicit in ideals of “inclusion” broadly, which—if not accompanied by dramatic upheavals in existing hierarchical power structures—too often work to diffuse the radical potential of difference and normalize otherwise oppressive structural conditions. ","",""
"2021","Studying Reddit: A Systematic Overview of Disciplines, Approaches, Methods, and Ethics"," This article offers a systematic analysis of 727 manuscripts that used Reddit as a data source, published between 2010 and 2020. Our analysis reveals the increasing growth in use of Reddit as a data source, the range of disciplines this research is occurring in, how researchers are getting access to Reddit data, the characteristics of the datasets researchers are using, the subreddits and topics being studied, the kinds of analysis and methods researchers are engaging in, and the emerging ethical questions of research in this space. We discuss how researchers need to consider the impact of Reddit’s algorithms, affordances, and generalizability of the scientific knowledge produced using Reddit data, as well as the potential ethical dimensions of research that draws data from subreddits with potentially sensitive populations. ","",""
"2021","Data Perversion: a Psychoanalytic Perspective on Datafication","This article adopts a psychoanalytic perspective and argues that users are in a perverse relationship with contemporary platforms. Following a review of recent critical scholarship on datafication, which places too much emphasis on platforms and situates users as helpless, the psychoanalytic concept of perversion is introduced. Perversion describes a relationship that is characterised by dominance, exploitation and dehumanization as well as care, love, and idealization. While the pervert (the platform and its owners and developers) is the perpetrator, the other (the user) is also actively participating in the perverse relationship. Contemporary relations are thus marked by foregrounding connectivity, convenience and communication which mask the violence of datafication. Such relations are upheld, because users affirmatively reproduce them by using highly attractive platforms which are customized for each individual. Psychoanalysis can thus offer a complex conceptualisation of the interplay between affirmation, attraction and exploitation that is immanent to platforms and users today.    ","",""
"2021","From Open Data to “Grounded Openness”: Recursive Politics and Postcolonial Struggle in Hong Kong"," This article maps the parameters of an emerging field of struggle around “openness” pertaining to digital data in the postcolonial smart city. Whereas colonial governance operated in relative secrecy with archives not quite available to ordinary citizens, what do we make of current institutions from government departments to banks flaunting their commitment to Open Data? Looking at data activism in Hong Kong, this article highlights the (post)colonial histories that have shaped the reception of Open Data in this context. More so, it explores the ways in which the techno-materialities of data infrastructures affect and reconfigure postcolonial struggle. Building on Kelty’s discussion of “recursive publics” and Hui’s account of recursivity, my notion of recursive politics underscores the mutuality of social history and techno-materiality. While recursive politics can contribute to technodiversity, I analyze how such politics weigh up against the political and ethical investments of postcolonial struggle. ","",""
"2021","Decolonising “Data Colonialism” Propositions for Investigating the Realpolitik of Today’s Networked Ecology"," This article proposes a critique of “data colonialism” as elaborated by Nick Couldry and Ulises Mejias. The main limitation of this theory is the essentialist conception of “colonialism,” “quantifier sector” and “self,” which overlooks historical-materialist roots and hinders a comprehensive understanding of datafication as a socio-cultural process. By recontextualizing some of the authors’ major claims, especially with regard to China, it is advanced the need to think about datafication as emerging out of a complex networked ecology whose founding logic is one of abstracted digital rationality. Some propositions—in the forms of ethnographic research and teachings along the line of data activism—are also elaborated. ","",""
"2022","Towards responsible, lawful and ethical data processing: patient data in the UK","","",""
"2022","Informatic tactics: Indigenous activism and digital cartographies of gender-based violence","ABSTRACT The impact of crowdsourced data visualization in the Missing and Murdered Indigenous Women (#MMIW) movement over the last decade reveals how institutional systems of organizing and representing space present a key obstacle to the cause. Activists’ digital crowdmaps express an ethos of Indigenous data sovereignty, or self-determination in data collection and application, that interrogates settler data procedures relative to gender violence. These tactical maps resonate with the circulation of location-tagged photographs via social media campaigns like #ImNotNext and #RedDressProject to similarly critique the datasets of government agencies. This article conceptualizes both media forms as informatic images that intervene in settler cartographic practice as part of an ongoing decolonization of digital mapping tools. Informatic images precondition the ways that users interact with data through hypermediated visual systems. Here, digital mapping and locative media practices focalize a relationship between violence, biased data and space, through various methods of layering, compositing and linking. Settler computational structures undergird these affordances, yet in a tactical context mapped images are reconstituted by user interaction with an oppositional dataset to intervene in that framework. Users’ emergent data of presence and absence plot a distributed landscape of settler violence in accordance, instead, with relational Indigenous knowledges.","",""
"2022","Interrogating data justice on Hyderabad’s urban frontier: information politics and the internal differentiation of vulnerable communities","ABSTRACT How does data visibility affect vulnerable communities that face uncertainty over land tenure? Can data justice be realised in settings of acute resource injustice? These are the overarching questions that our case study interrogates by opening up the black box of the community in the volatile and fast-transforming peri-urban fringe of Hyderabad, India. We examine the unfolding of data and information processes through the lens of enumeration and community mapping exercises conducted in a low-income neighbourhood. We argue that the realisation of data justice is mediated by ‘information politics’, i.e., the ways in which informational resources, as well as the risks and rewards associated with them, are distributed across individual actors and identity groups within the community. The democratising potential of emerging digital technologies is severely constrained by structural inequities across gender, caste, class, and even linguistic lines. Our case study underlines the importance of such a structural understanding of data justice and also suggests directions for embedding justice in data processes. Our findings reveal an arena of stark informational disparities between vulnerable, indigent populations and the increasingly sophisticated digital data apparatuses used to encode them. Efforts to promote data justice must take explicit cognisance of these disparities and fragmentation and recognise the internal structural differentiation of vulnerable communities. We argue for an explicit mapping of the information flows and associated information politics that characterise such settings.","",""
"2022","The interactive field of open government data: inter-administrative dynamics, trans-local networks, and local geopolitics of environmental data activism in China","ABSTRACT Using an example of China’s environmental data activism, this study explores the state–society interactive mode of socialization in the politics of open government data. Drawing on an interactionist approach, this study argues that in this intermediate situation, NGOs are relatively autonomous, organizing their campaigns and initiatives independently instead of partnering with the state. However, these two sides both spur and exploit each other, shaping an ‘interactive field.’ Data actors use the state’s open data agenda as an opportunity to initiate spin-off data activism to counteract the deficiencies of data disclosure by the government. In response, state agencies adjust and enhance their data disclosure practices, thus performing reactive data governance. We identified several dynamics of this interactive field: (1) It involves multiple grassroots data actors in the form of NGOs that attempt to expand the autonomy of their data advocacy by forming activist networks to bargain with state bureaucracy. (2) The interactive strategies mainly involve tactics of ‘rightful resistance’ but are hybridized with other boundary-spanning strategies that straddle the demarcation of confrontation and non-confrontation. (3) Although the state and nonstate actors are not partnered, they exert mutual influence over each other’s actions and strategies. The shrinking of institutional space has caused NGOs to reorganize interactive strategies. Our study also highlights the local geopolitical dynamics that condition such interactions: besides the inter-administrative dynamics that afford political opportunities, the trans-local advocacy network coordinates actors and resources to exercise data counterpower. Also, the selection of advocacy strategies is varied with targeted government agencies.","",""
"2022","Data colonialism: compelling and useful, but whither epistemes?","ABSTRACT This commentary reviews the strengths of the concept of data colonialism, arguing that it makes a strong and useful contribution to the debates on how to make sense of the myriad effects of datafication. It points out, however, that the key decolonial insight about supposed European objectivity are weakly integrated into the concept: while it gestures to decoloniality, it is primarily about explaining datafication as resource extraction. As a result, the concept has non-decolonial implications as well.","",""
"2022","Education as a domain of natural data extraction: analysing corporate discourse about educational tracking","ABSTRACT Digital platforms and learning analytics are becoming increasingly widespread in the education sector: commercial corporations argue their benefits for teaching and learning, thereby endorsing the continuous automated collection and processing of student data for measurement, assessment, management, and identity formation. Largely missing in these discourses, however, are the potential costs of datafication for pupils’ and teachers’ agency and the meaning of education itself. This article explores the general discursive framing by which these surveillant practices in education have come to seem natural. Through a study of commercial suppliers of educational platforms, we show how the prevailing vision of datafication in their discourses categorises software systems, not teachers, as central to education, reimagining space, time, and agency within educational processes around the organisation of data systems and the demands of commercial data production. Not only does this legitimate the new connective environment of dataveillance (that is, surveillance through data processing), but it also naturalises a wider normative environment in which teachers and students are assigned new roles and responsibilities. In the process, the panoptic possibilities of ubiquitous commercial access to personal educational data are presented as part of a virtuous circle of knowledge production and even training for good citizenship. This broader rethinking of education through surveillance must itself be critiqued.","",""
"2022","Realizing the benefits of open government data: Journalists’ coverage of the NHS winter crisis, 2016–17","Abstract In the current literature on open government data (OGD) ecosystems, academics have paid little attention to the way data journalists realize the benefits of publicly-available data. To address this, in this study I use content analysis (n  = 65), thematic analysis, and interviews with journalists (n  = 5) to examine how the news media used data in their reporting during the NHS (National Health Service, UK) winter crisis of 2016–2017. The findings show that journalists to some extent realized the benefits of the OGD through the adoption of the population problem data-frame to criticize the government. But they were limited in their use of more informative and critical data-frames, even though they accessed the available data and had the relevant data skills. This was a product of the reification and naturalization of certain health data that rendered other data-informed news stories very hard to articulate. These findings suggest that data themselves – rather than just the motives of data producers – can limit the benefits that can be realized by data users.","",""
"2022","The ethics and politics of data sets in the age of machine learning: deleting traces and encountering remains"," Individuals and communities increasingly depend on, and fill their lives with, machine cultures, in the form of both interfaces and infrastructures. This global push for machine cultures has given rise to an increasing demand for data and engendered a proliferation of public, private and public-private dataset repositories. While datasets form a foundational element of machine cultures, they rarely come into focus as objects of critical study. But in recent years a critical discursive formation on datasets has begun to emerge, which disturbs the idea of datasets as operational instruments of digital knowledge production and seek to instead ‘bring people back in’. The present article identifies these preliminary explorations as ‘critical dataset studies’ and draws on critical archival studies to articulate the ethico-political surfaced by these studies. Specifically it argues that critical dataset studies shows the need for an expanded ethical and conceptual approach to datasets that not only relies on linear notions of deletion and accountability but also on iterative frameworks of remains and response-ability. ","",""
"2022","AI, big data, and the future of consent","","",""
"2022","Towards a political economy of technical systems: The case of Google"," This research commentary proposes a conceptual framework for studying big tech companies as “technical systems” that organize much of their operation around the mastery and operationalization of key technologies that facilitate and drive their continuous expansion. Drawing on the study of Large Technical Systems (LTS), on the work of historian Bertrand Gille, and on the economics of General Purpose Technologies (GPTs), it outlines a way to study the “tech” in “big tech” more attentively, looking for compatibilities, synergies, and dependencies between the technologies created and deployed by these companies. Using Google as example, the paper shows how to interrogate software and hardware through the lens of transversal applicability, discusses software and hardware integration, and proposes the notion of “data amalgams” to contextualize and complicate the notion of data. The goal is to complement existing vectors of “big tech” critique with a perspective sensitive to the specific materialities of specific technologies and their possible consequences. ","",""
"2022","Learning accountable governance: Challenges and perspectives for data-intensive health research networks"," Current challenges to sustaining public support for health data research have directed attention to the governance of data-intensive health research networks. Accountability is hailed as an important element of trustworthy governance frameworks for data-intensive health research networks. Yet the extent to which adequate accountability regimes in data-intensive health research networks are currently realized is questionable. Current governance of data-intensive health research networks is dominated by the limitations of a drawing board approach. As a way forward, we propose a stronger focus on accountability as learning to achieve accountable governance. As an important step in that direction, we provide two pathways: (1) developing an integrated structure for decision-making and (2) establishing a dialogue in ongoing deliberative processes. Suitable places for learning accountability to thrive are dedicated governing bodies as well as specialized committees, panels or boards which bear and guide the development of governance in data-intensive health research networks. A continuous accountability process which comprises learning and interaction accommodates the diversity of expectations, responsibilities and tasks in data-intensive health research networks to achieve responsible and effective governance. ","",""
"2022","Developing data capability with non-profit organisations using participatory methods"," In this paper, we explore the methodologies underpinning two participatory research collaborations with Australian non-profit organisations that aimed to build data capability and social benefit in data use. We suggest that studying and intervening in data practices in situ, that is, in organisational data settings expands opportunities for improving the social value of data. These situated and collaborative approaches not only address the ‘expertise lag’ for non-profits but also help to realign the potential social value of organisational data use. We explore the relationship between data literacy, data expertise and data capability to test the idea that collaborative work with non-profit organisations can be a practical step towards addressing data equity and generating data-driven social outcomes. Rather than adopting approaches to data literacy that focus on individuals – or ideal ‘data citizens’ – we target the organisation-wide data settings, goals and practices of the non-profit sector. We conclude that participatory methods can embed social value-generating data capability where it can be sustained at an organisational level, aligning with community needs to promote collaborative data action. ","",""
"2022","Performative innovation: Data governance in China's fintech industries"," The financial applications of data technology have enabled the rise of Chinese fintech industries. As part of people's everyday lives, fintech apps have helped companies collect vast amounts of user data for business profit and social good. This paper takes an open-systems approach to study the constructs of this emerging idea of data governance, particularly its operational logic, involved stakeholders, and socio-cultural consequences in the context of fintech industries in China. It asserts that data governance at the company level has been realized through three types of tasks: standardization, configuration, and monetization of big data. These tasks are oriented by the imperative of business innovation which is considered pivotal for the company to survive the competition. An ensemble of internal and external actors joined the governing process, but internal actors hold the stake. The goal of innovation drives the companies to speedily collect data from a wider variety of sources, thus having to establish more sophisticated systems to manage and utilize those data. These complicated systems, however, have urged the government to strengthen regulatory controls alongside the general support of business innovation. This study unveils the performative aspects of big-data-based innovation at fintech firms. It also helps to understand the pathology of the innovation-governance paradox shared in the data economy in the global context. ","",""
"2022","Tradeoffs all the way down: Ethical abduction as a decision-making process for data-intensive technology development"," Ample scholarship demonstrates that data-intensive technologies have the capacity to cause serious harm and that their developers are obliged to address ethics in their work. This ethnographic paper tells the story of data scientists attempting to instantiate a carefully considered ethical vision into a data infrastructure while balancing competing priorities, negotiating divergent interests, and wrestling with contrasting values. I use their story to develop the concept of “ethical abduction,” which I characterize as an exemplary process by which actors can intentionally and systematically address ethical issues that arise during their day-to-day actions by making decisions with consideration for a foundational ethical worldview. It entails tacking back and forth between divergent but complementary ways of thinking: between establishing ideals and making decisions given practical constraints; between understanding historical context and anticipating future consequences; between acknowledging structural dependencies and accepting responsibility for moral agency. ","",""
"2022","Social data governance: From reflective practices to comparative synthesis"," This special theme brings together reflections and deliberations regarding the design, implementation, and development of data governance. By addressing “social data governance” as the keyword of the special theme, we aim to further the discussion on a contextual understanding of both the governing foundations and effects of data, dataism, and datafication in different societies. Such a discussion reminds us to pay particular attention to—and thus account for—the social dynamics that underpin and contextualize the design, operation, and promotion of quantified governing mechanisms in which information on social behaviors is collected, datafied, manipulated, and represented. Essentially, the social dynamics of data governance have existed for a long time and in many forms, ranging from credit bureaus’ scrutiny, evaluation, and labeling of their customers to internet-enabled massive data collection and scoring systems used by governments, and to automated contact tracing techniques as a centerpiece of dataveillance and infection control amid the COVID-19 pandemic. Nevertheless, scholarly work from a wide range of disciplines like law, mathematics, and business and with diverse geographical foci has not yet been comparatively and reflectively articulated. Being rich and diverse, the special theme advances such a requisite understanding of the status and relevance of social dynamics of data governance mechanisms based on a wide range of empirical cases around the globe. To scrutinize the social dynamics helps illuminate and contrast divergent manifestations of data governance and their underlying mechanisms. ","",""
"2022","Ethnographic data in the age of big data: How to compare and combine"," Big data enables researchers to closely follow the behavior of large groups of individuals by using high-frequency digital traces. However, these digital traces often lack context, and it is not always clear what is measured. In contrast, data from ethnographic fieldwork follows a limited number of individuals but can provide the context often lacking from big data. Yet, there is an under-explored potential in combining ethnographic data with big data and other digital data sources. This paper presents ways that quantitative research designs can combine big data and ethnographic data and account for the synergies that such combinations can provide. We highlight the differences and similarities between ethnographic data and big data, focusing on the three dimensions: individuals, depth of information, and time. We outline how ethnographic data can validate big data by providing a “ground truth” and complement it by giving a “thick description.” Further, we lay out ways that analysis carried out using big data could benefit from collaboration with ethnographers, and we discuss the potential within the fields of machine learning and causal inference. ","",""
"2022","Taking a critical look at the critical turn  in data science: From “data feminism”  to transnational feminist data science"," Through a critical analysis of recent developments in the theory and practice of data science, including nascent feminist approaches to data collection and analysis, this commentary aims to signal the need for a transnational feminist orientation towards data science. I argue that while much needed in the context of persistent algorithmic oppression, a Western feminist lens limits the scope of problems, and thus—solutions, critical data scholars, and scientists can consider. A resolutely transnational feminist approach on the other hand, can provide data theorists and practitioners with the hermeneutic tools necessary to identify and disrupt instances of injustice in a more inclusive and comprehensive manner. A transnational feminist orientation to data science can pay particular attention to the communities rendered most vulnerable by algorithmic oppression, such as women of color and populations in non-Western countries. I present five ways in which transnational feminism can be leveraged as an intervention into the current data science canon. ","",""
"2022","Emotional labour in the collaborative data practices of repurposing healthcare data and building data technologies"," This article focuses on emotions, conceptualised as emotional labour, evoked during data practices used to repurpose and enable healthcare data journeys for Finnish public healthcare. Combined approaches from critical data studies and the sociology of emotions were used to contribute to a better understanding of the mundane but often invisible work of the emotions of experts involved in data practices, such as facilitating data journeys and building data technologies. The article is based on a two-and-a-half-year ethnographic study conducted in a Finnish regional public healthcare and social service organisation. The study results were derived from the analysis of 39 interviews and fieldnotes produced by observing 170 h of various meetings, events and work activities performed by experts. The results were organised into three forms of observed experts’ emotional labour related to three phases of healthcare data journeys: (a) caring for data production and preparing data for travel, (b) managing excitement and frustration in data processing for continually building the data management system, and (c) reassuring users in making sense of obtained data analytics. The results contribute to a greater understanding of the emotions and emotional labour generated by healthcare data journeys and in relation to the volatile nature of healthcare data and the collaborative character of data practices. This work advocates for a better recognition of the emotional aspects of data practices and their implications on data-based knowledge and datafication processes in healthcare. ","",""
"2022","Governing teachers through datafication: Physical–virtual hybridity and language interoperability in teacher accountability"," In this paper, we draw on Foucault's and Deleuze's theorisations of discipline and control, respectively, to understand a teacher accountability system in the US state of Texas: the Texas Teacher Evaluation and Support System (hereafter, T-TESS). Specifically, we focus on the interplay of physical and virtual modes of governance – which we develop here as physical– virtual hybridity – and the techniques that make these physical and virtual domains compatible via language interoperability, with T-TESS deployed as a representative empirical case to show how such technologies work to govern teacher subjectivity. First, in-person appraiser meetings and observations re-code teachers’ linguistic behaviours, so their physical bodies and practices can become legible to and interoperable with the hybrid T-TESS system. This avoids any possible syntax errors between the linguistic expression of physical teacher speech and the digital coding language of T-TESS. Second, these digital bodies of data can now be viewed as proxies for the physical teacher body in the classroom, allowing the constant modulation in physical space (teacher bodies) and digital space (bodies of data). This is the physical–virtual hybridity of T-TESS, whereby discipline and control work symbiotically to govern both the physical and the digital expressions of teachers and their teaching. In this way, the disciplining of teachers’ language has profound effects on teachers’ bodies, both corporeal and digital. ","",""
"2022","Why Personal Dreams Matter: How professionals affectively engage with the promises surrounding data-driven healthcare in Europe"," Recent buzzes around big data, data science and artificial intelligence portray a data-driven future for healthcare. As a response, Europe's key players have stimulated the use of big data technologies to make healthcare more efficient and effective. Critical Data Studies and Science and Technology Studies have developed many concepts to reflect on such overly positive narratives and conduct critical policy evaluations. In this study, we argue that there is also much to be learned from studying how professionals in the healthcare field affectively engage with this strong European narrative in concrete big data projects. We followed twelve hospital-based big data pilots in eight European countries and interviewed 145 professionals (including legal, governance and ethical experts, healthcare staff and data scientists) between 2018 and 2020. In this study, we introduce the metaphor of dreams to describe how professionals link the big data promises to their own frustrations, ideas, values and experiences with healthcare. Our research answers the question: how do professionals in concrete data-driven initiatives affectively engage with European Union's data hopes in their ‘dreams’ – and with what consequences? We describe the dreams of being seen, of timeliness, of connectedness and of being in control. Each of these dreams emphasizes certain aspects of the grand narrative of big data in Europe, makes particular assumptions and has different consequences. We argue that including attention to these dreams in our work could help shine an additional critical light on the big data developments and stimulate the development of responsible data-driven healthcare. ","",""
"2022","Erratum to Taking a critical look at the critical turn in data science: From “data feminism” to transnational feminist data science","","",""
"2022","In search of the citizen in the datafication of public administration"," The administrative reform of the datafied public administration places great emphasis on the classification, control, and prediction of citizen behavior and therefore has the potential to significantly impact citizen–state relations. There is a growing body of literature on data-oriented activism which aims to resist and counteract existing harmful data practices. However, little is known about the processes, policies, and political-economic structures that make datafication possible. There is a distinct research gap on situated and context-specific empirical research, which critically interrogates the premises, interests, and agendas of data-driven public administration and how stakeholders can impact them. This paper therefore studies the conditions of participation in public administration datafication. It asks the overall research question of how citizens are problematized and included in policy and practitioner discourse in the datafication of public administration. The paper takes Norway as its case and applies Cardullo and Kitchin’s scaffold of smart citizen participation at the system level. It makes use of a unique empirical insight into the field, consisting of a survey, interviews, and an extensive document analysis. Unexpectedly, we find that citizens and civil society are rarely engaged in this administrative reform. Instead, we identify a paternalistic, top-down, technocratic approach where the context, values, and agendas of datafication are obscured from the citizen. ","",""
"2022","Sharing precision medicine data with private industry: Outcomes of a citizens’ jury in Singapore"," Precision medicine is an emerging approach to treatment and disease prevention that relies on linkages between very large datasets of health information that is shared amongst researchers and health professionals. While studies suggest broad support for sharing precision medicine data with researchers at publicly funded institutions, there is reluctance to share health information with private industry for research and development. As the private sector is likely to play an important role in generating public benefits from precision medicine initiatives, it is important to understand what the concerns are and how they might be mitigated. This study reports outcomes of a deliberative method of citizen engagement in Singapore that asked whether sharing precision medicine data with private industry would be permissible, and if so, under what circumstances. Findings from this citizens’ jury suggest sharing with industry would be permissible under certain conditions that are set out in nine recommendations. Implications of the recommendations and their underlying assumptions for policy decision makers are discussed. This study aligns with prior international studies which found conditional acceptance for data sharing with private industry, a public benefit requirement, specific reluctance to share with insurance companies and an emphasis on accountability and transparency to demonstrate trustworthiness. However, our results differ from prior studies in that opt-in consent did not dominate the deliberations as jurors were able to set it aside as an assumed prerequisite for participation in a precision medicine programme. ","",""
"2022","Individual benefits and collective challenges: Experts’ views on data-driven approaches in medical research and healthcare in the German context"," Healthcare provision, like many other sectors of society, is undergoing major changes due to the increased use of data-driven methods and technologies. This increased reliance on big data in medicine can lead to shifts in the norms that guide healthcare providers and patients. Continuous critical normative reflection is called for to track such potential changes. This article presents the results of an interview-based study with 20 German and Swiss experts from the fields of medicine, life science research, informatics and humanities of digitalisation. The aim of the study was to explore expert opinions regarding current challenges and opportunities related to data-driven medicine and medical research and to provide a methodological framework for empirically grounded, continuous normative reflection. To this end, we developed a heuristic tool to map and structure empirical findings for normative analysis. Using this tool, our interview material points to a polarisation between individualistic and collectivistic orientated argumentations among experts. The study shows that a multilevel analysis is required to deal with complex normative implications of data-driven approaches in medical research and healthcare. ","",""
"2022","In data we (don't) trust: The public adrift in data-driven public opinion models"," This article seeks to address current debates comparing polls and opinion mining as empirically based figuration models of public opinion in the light of in-depth intellectual debates on the role and nature of public opinion that began after the French Revolution and the controversy over public opinion spurred by the invention of polls. Issues of historical quantification and re-conceptualisation of public opinion are addressed in four parts. The first summarises the history of the rise and fall of the concept of public opinion. The second re-examines the key controversies in the debates on the theoretical, empirical and social implications and consequences of the invention of polling. The third part scrutinises the datafication of public opinion that started with polling industry and continues in the age of big data and data mining. The final section discusses the controversial potentials of opinion-mining technology and suggests ways in which social scientists could critically respond to the big data and opinion-mining challenges in order to reintegrate the ideas of publicness, the public and public sphere into public opinion research. ","",""
"2022","Social data governance: Towards a definition and model"," With the surge in the number of data and datafied governance initiatives, arrangements, and practices across the globe, understanding various types of such initiatives, arrangements, and their structural causes has become a daunting task for scholars, policy makers, and the public. This complexity additionally generates substantial difficulties in considering different data(fied) governances commensurable with each other. To advance the discussion, this study argues that existing scholarship is inclined to embrace an organization-centric perspective that primarily concerns factors and dynamics regarding data and datafication at the organizational level at the expense of macro-level social, political, and cultural factors of both data and governance. To explicate the macro, societal dimension of data governance, this study then suggests the term “social data governance” to bring forth the consideration that data governance not only reflects the society from which it emerges but also (re)produces the policies and practices of the society in question. Drawing on theories of political science and public management, a model of social data governance is proposed to elucidate the ideological and conceptual groundings of various modes of governance from a comparative perspective. This preliminary model, consisting of a two-dimensional continuum, state intervention and societal autonomy for the one, and national cultures for the other, accounts for variations in social data governance across societies as a complementary way of conceptualizing and categorizing data governance beyond the European standpoint. Finally, we conduct an extreme case study of governing digital contact-tracing techniques during the pandemic to exemplify the explanatory power of the proposed model of social data governance. ","",""
"2022","Aiming at the good life in the datafied world: A co-productionist framework of ethics"," This article proposes an ethical framework to navigate life in the datafied world that combines the relational ethics approach of the philosopher Paul Ricoeur with the idiom of co-production from the field of Science and Technology Studies (STS). Mainstream data and computing ethics approaches, which tend to view ethics itself as a technology to produce particular outcomes, fail to adequately consider the context of the datafied world for ethics. The datafied world is a condition in which data and computing technologies form the ineluctable infrastructure for daily life, structuring social order, forming power relations, and supporting visions of desirable futures. I argue that the datafied world is not just a background upon which ethics unfolds, rather it demands a novel framework for ethics that understands the contexts of data and computing technologies and their consequences for human action. The idiom of co-production suggests how action gets tied to visions of the good in the datafied world. In particular, it draws attention to the evolution of these actions in the identities, institutions, representations, and discourses of the social world, creating specific forms of life and meaning in datafied societies. ","",""
"2022","A comparative analysis of data governance: Socio-technical imaginaries of digital personal data in the USA and EU  (2008–2016)"," Personal data are produced through our daily interactions with digital technologies like search engines, social media, and online shopping, and is often referred to as our “digital exhaust.” It has been characterized as the key resource or asset for our economies in the 21st century. This paper focuses on the socio-technical imaginaries of digital personal data as a way to understand how desired forms of data governance are co-produced with collective understandings of personal data as a political-economic asset. We examine the different socio-technical imaginaries that underpinned different developments in data regulations in the United States and EU from 2008 to 2016, focusing specifically on the mutual constitution of law, political economy, and technoscience. We do so in order to understand the “prehistories” of contemporary data governance. We analyze the institutional and legal context around the development of data privacy regulation and data commercialization in these two important jurisdictions and reflect on how this institutional and legal context configured their respective approaches to data governance. ","",""
"2022","Alternative data and sentiment analysis: Prospecting non-standard data in machine learning-driven finance"," Social media commentary, satellite imagery and GPS data are a part of ‘alternative data’, that is, data that originate outside of the standard repertoire of market data but are considered useful for predicting stock prices, detecting different risk exposures and discovering new price movement indicators. With the availability of sophisticated machine-learning analytics tools, alternative data are gaining traction within the investment management and algorithmic trading industries. Drawing on interviews with people working in investment management and algorithmic trading firms utilizing alternative data, as well as firms providing and sourcing such data, we emphasize social media-based sentiment analytics as one manifestation of how alternative data are deployed for stock price prediction purposes. This demonstrates both how sentiment analytics are developed and subsequently utilized by investment management firms. We argue that ‘alternative data’ are an open-ended placeholder for every data source potentially relevant for investment management purposes and harnessing these disparate data sources requires certain standardization efforts by different market participants. Besides showing how market participants understand and use alternative data, we demonstrate that alternative data often undergo processes of (a) prospecting (i.e. rendering such data amenable to processing with the aid of analytics tools) and (b) assetization (i.e. the transformation of data into tradable assets). We further contend that the widespread embracement of alternative data in investment management and trading encourages a financialization process at the data level which raises new governance issues. ","",""
"2022","The politics of data visualisation and policy making"," Data visualisation has become ubiquitous in everyday life, from seeing images in news media to tracking individual health indicators. While the effects of data visualisation on society and people have been explored within a range of literature, there has been far less attention paid to the interconnectedness of data visualisation and policy making. In this special issue, we explore how data visualisation matters for policy priorities, processes and outcomes; how it reflects the demands and constraints posed by specific policy problems; and finally, what data visualisations reveal about broader political, social, and cultural shifts and the implications for policy. ","",""
"2022","Beyond the scorecard diplomacy: From soft power rankings to critical inductive geography"," The article interrogates if data visualization, despite its inherited subjectivity, can be used not only as a tool for data representation but also as a research platform to facilitate an iterative exploratory process to identify new themes, raise new questions, and generate new knowledge. It addresses this task by pursuing a twofold research goal. On the one hand, it confirms previous findings that have documented the political power of data visualization specifically in the field of scorecard diplomacy. It critically discusses Portland Soft Power 30 Index that measures soft power of selected countries on the annual basis to reveal how the scorecard diplomacy works through the ranking dashboard. On the other hand, the article reflects on the experience of designing a geo-visualization system that, by contrast, intended to overcome shortcomings of data visualization’s politics to build a platform for an inductive academic research. It discusses a new deep mapping framework of soft power visualization that intended to address several critical problems of Portland’s measurements and shares research insights from the project “Deep Mapping: Creating a Dynamic Web Application Museum Soft Power Map.” ","",""
"2022","“It ain’t a compliment”: Feminist data visualisation and digital street harassment advocacy"," In an era of datafication, data visualisation is playing an increasing role in civic meaning-making processes. However, the conventions of data visualisation have been criticised for their reductiveness and rhetoric of neutrality and there have been recent efforts to develop feminist principles for designing data visualisations that are compatible with feminist epistemologies. In this article, we aim to examine how data visualisation is used in feminist activism and by feminist activists. Drawing on the example of digital street harassment activism, we analyse how street harassment is visualised in and through a selection of prominent activist social media accounts. We consider the platform affordances utilised by activists, and how these are harnessed in making street harassment ‘knowable'. Moreover, we critically interrogate which and whose experiences are ‘knowable’ via digital techniques, and what remains obscured and silenced. In analysing digital feminist activists’ practices, we argue that what constitutes ‘data visualisation’ itself must be situated within feminist epistemologies and praxis that centre lived experience as the starting point for knowledge production. Such an approach challenges and disrupts normative constructions of what constitutes data visualisation. Our findings demonstrate how feminist activists are adopting ‘traditional’ practices of speaking out and consciousness-raising to the digital sphere in the creation of a range of visualisations that represent the issue of street harassment. We consider the efficacy of these visualisations for achieving their intended purpose and how they might translate to policy and government responses, if this is indeed their goal. Further, we document a tension between feminist epistemologies and the prevailing logic of datafication or dataism and note how in an attempt to unite the two, some digital feminist activism has contributed to reproducing existing power structures, raising concerning implications at the policy level. ","",""
"2022","Ways of seeing: Peace process data-viz as a research practice"," This article uses John Berger’s idea (1972) that images are connected to ‘ways of seeing’ to reflect on the creation of interactive visualizations of peace agreement and peace process data. We reflect on three visualizations created during a three-year long collaboration. We first describe our data, the peacebuilding ambitions for its use, and why we produced interactive forms of visualization. Second, we describe how the process of producing these visualizations created an interdisciplinary conversation and collaboration, which also connected different epistemic and geographic communities involved in peace processes. We term this ‘visualization-as-scoping’. Third, we reflect on both ‘what we saw’, through the process of visualization, how it affected policy, and the lessons we learned regarding visualization in the peacebuilding field. In the article, we argue that our experience of ‘visualization-as-scoping’ inverts traditional assumptions about the connection of data visualization to policy influence. In place of the notion of visualization-as-communication, focused on transmitting clear policy ‘messages’, we point to visualization-as-scoping as a practice of interchange, critique and re-iteration. Using John Berger as inspiration, we suggest that the ‘ways of seeing’ that result can usefully disrupt the idea of a data producing singular policy prescriptions, and rather enable people to grapple better with the complex political processes they are involved in. ","",""
"2022","Seeking Liberation: Surveillance, Datafication, and Race","Critical data studies, a body of emergent research that draws on surveillance studies and other fields, investigates datafication, the increasing mediation of many forms of sociality by data-intensive, networked computation. Such research draws on well-trodden criticisms of the representational capacities of data and has recently offered the term “data justice” to direct this scholarly formation toward the harms of datafication. By failing to explicitly foreground the way that the capture and consultation of data constitutes a tactic by which the state sorts, controls, and limits the freedom of minoritized peoples, critical data studies substitutes an interest in describing forms of injustice for a commitment toward its undoing. I use McKittrick’s (2021) term “seeking liberation” to orient both surveillance studies and critical data studies scholarship away from mere description of the practices of data-intensive computation and surveillance and toward a shared project of justice for minoritized peoples.","",""
"2022","The view from somewhere","Recent scholarship has raised important critical questions about the ethical uses of big data scraped from social media platforms. Critical and feminist researchers have argued that big data can naturalize a “view from nowhere,” which ultimately reinscribes the status quo. In response, researchers have sought to incorporate critical reflexivity into their big data research and to include participants in their research through surveys and interviews. With surveys and interviews, researchers must engage in critically reflexive recruitment practices though, as reaching out to participants always reveals a “view from somewhere” that can (but does not always) function in the milieu of the dominant gaze. This article builds on scholarship that calls for more ethical data practices by offering three heuristics for critical reflexive recruitment practices. First, researchers should consider whether to recruit participants based on shifting boundaries of publicity and privacy. They should evaluate if posts were meant for their particular “view from somewhere.” Second, researchers should assess the names of research accounts, and how the names might be experienced as extractive. Finally, researchers should critically reflect on channels of recruitment and how those channels function in public/private binaries.","",""
"2022","Using data visualizations to study digital public spaces","This article reviews the history and current data visualizations in studying digital public spaces. I will discuss the recent development of visualizing raw data numerically, relationally, spatially, and textually. Each method involves different visual representations to integrate data collection with analysis and presentation of results. Through a case study of global Web use, this article also demonstrates a thinking process and analytical workflow to incorporate data visualizations when studying digital public spaces, particularly in the midst of a global crisis.","",""
"2022","Disclosure as a critical-feminist design practice for Web-based data stories","We present findings from design research on disclosure at the intersection of data visualization, digital storytelling, and feminism. While there is an increased awareness of power structures in data science, computing, and design, there is little design research to confront these. This work explores the potential of disclosing context information of data stories, i.e., digital storytelling formats utilizing data visualizations, to enable critical-feminist readings of and reflections on these stories. Drawing from a growing body of feminist scholarship in human-computer interaction, data science, and beyond, we identify key aspects and forms of disclosure for embedding them into visual data story interfaces. We devise and validate these aspects and forms within a case study: a Web-based scrollytelling article explaining the feminist concept of intersectionality using a combination of animated illustration, data visualization, and text. With this work, we demonstrate and discuss the potentials and pitfalls of disclosure practices in data storytelling.","",""
"2022","Public bodies’ access to private sector data","Public bodies’ access to private sector data of public interest (also referred to as business-to-government (B2G) data sharing) is still an emerging and sporadic practice. The article discusses the findings of a qualitative research that examined B2G data sharing in European local administrations. Drawing from semi-structured interviews with managers and project leaders of twelve municipalities, the study contextualizes access to private sector data in the perspectives of those working in the field. The findings examine the four operational models to access data that featured more prominently in the interviews: data donorship, public procurement of data, data partnerships and pools, and data sharing obligations. The analysis highlights the power unbalances embedded in B2G data sharing as perceived by representatives of local administrations. In particular, the findings address the gap between municipalities in the opportunities to access private sector data of public interest, the lack of negotiating power of local administrations vis-à-vis private sector data holders and the strategies envisioned to foster more inclusive forms of data governance.","",""
"2022","Feminist Data Studies and the emergence of a new Data Feminist knowledge domain","Mass participation in social networking sites and online life combined with the development of tracking technology facilitates gathering data on unprecedented scales. The uptake of data collecting during the 2010s coincided with the emergence of data science and data studies, along with critical perspectives such as critical data and critical algorithm studies. This paper explores one such critical perspective. Data Feminism merges the theories of intersectional feminism and critical data studies. Bibliometric text analysis of articles, conference papers, essays, and commentary was conducted in VOSviewer software, which found commonalities between terms within texts. The most prominent terms and keywords in the research area of Data Feminism identified in such a manner informed the close reading that followed. Six clusters of terms were identified, with the two largest clusters formed around the terms “big data” and “artificial intelligence” respectively. We also explored the boundaries, movements and centralities within the six clusters.","",""
"2022","Constraining context: Situating datafication in public administration"," The imaginary of data-driven public administration promises a more effective and knowing public sector. At the same time, corporate practices of datafication are often hidden behind closed doors. Critical algorithm studies, therefore, struggle to access and explore these practices, to produce situated accounts of datafication and possible entry points to reconfigure the emerging data-driven society. This article offers a unique empirical account of the inner workings of data-driven public administration, asking the overall question of how sociotechnical imaginaries of datafication are constrained in the context of public administration. Teams working on datafication in two Norwegian public sector entities have been followed and interviewed over the course of 2 years (2018–2020). While sociotechnical imaginaries thrive in organizational culture and policy discourse alike, the observed data teams struggle to realize data assemblages due to a variety of structural and institutional constraints. ","",""
"2022","Trust in open data applications through transparency"," Open data provide great potential for society, for example, in the field of smart cities, from which all citizens might profit. The trust of these citizens is important for the integration of various data, like sensitive user data, into an open data ecosystem. In the following study, we analyzed whether transparency about the application of open data promotes trust. Furthermore, we formulated guidelines on how to create transparency regarding open data in an ethical way. Using an open-data-based fictitious smart city app, we conducted an experiment analyzing to what extent communication of the technical open data application process and the ethical self-commitment for the transparent communication of data application affect trust in the app’s provider. The results indicate that the more information users obtain regarding the use of open data, the more trustworthy they perceive the app provider to be, and the more likely they are to use the app. ","",""
"2022","Bartleby: Procedural and Substantive Ethics in the Design of Research Ethics Systems"," The lack of consent or debriefing in online research has attracted widespread public distrust. How can designers create systems to earn and maintain public trust in large-scale online research? Procedural theories inform processes that enable individuals to make decisions about their participation. Substantive theories focus on the normative judgments that researchers and participants make about specific studies in context. Informed by these theories, we designed Bartleby, a system for debriefing participants and eliciting their views about studies that involved them. We evaluated this system by using it to debrief thousands of participants in a series of observational and experimental studies on Twitter and Reddit. We find that Bartleby addresses procedural concerns by creating new opportunities for study participants to exercise autonomy. We also find that participants use Bartleby to contribute to substantive, value-driven conversations about participant voice and power. We conclude with a critical reflection on the strengths and limitations of reusable software to satisfy values from both procedural and substantive ethical theories. ","",""
"2023","The decolonial turn is on the road to contingency","ABSTRACT In this short commentary, I reflect on the situated perspective that grounds data colonialism as a critique of the nature of control embedded in contemporary data-driven practices. I argue that data-driven practices represent particular configurations of control and contingency. While the data colonialism thesis is a consequential orienting principle to analyze control, the pursuit of the decolonial turn in critical data and technology studies also requires contending with the contingencies of designing, implementing, and appropriating data-driven practices.","",""
"2023","Data politics on the move: intimate work from the inside of a data-driven health system","ABSTRACT Social institutions increasingly appear as data-driven entities, with data analytics and information technology transforming social life across health care, education, and criminal justice. Social science scholarship characterizes the political nature of this paradigm by emphasizing technology’s role in the governance of life and the sociocultural values embedded within technical design. But little research has examined the intimate work taking place inside these very institutions, resulting in inadequate attention to everyday data practices as they intertwine with evolving technopolitics. Drawing on ethnographic fieldwork of the integration of Electronic Health Records at a large safety-net health system in the United States, in this article I emphasize the intimate work involved in becoming data-driven and how this work shapes the material contours of contemporary data politics. I compare the implementation of two health system initiatives, including a Complex Care Program for an algorithm-defined population and a Disparity Reduction Plan targeting Latinos with Type 2 diabetes, to demonstrate how on the ground actors make intimate decisions about what constitutes the ‘right data’ in becoming data-driven. As data analytics expands to transform organizational decision-making, redistribute resources, and reconfigure the professional gaze, social science must follow data politics on the move to fully account for the evolving technopolitics of data-driven society.","",""
"2023","Organisational and professional hierarchies in a data management system: public–private collaborative building of public healthcare and social services in Finland","ABSTRACT Nordic countries are considered international leaders in producing combinable data on their citizens’ encounters with public institutions, as well as the digitalisation of public services. Public-sector professionals increasingly collaborate with private IT companies in developing data analytics products for cost saving and cost-efficiency. This article presents the results of a two-year ethnographic study of a collaboration between the Knowledge Team of a public-sector organisation and a private-sector IT company for developing and maintaining a data management system in one Finnish regional healthcare and social service organisation. The data management system is defined as a data analytics product that provides management with information about clinical and financial aspects of organisation management. We combine perspectives of science and technology studies and the sociology of professions to situate our research on the data management system as a boundary object within the broader context of professional work. Via our theoretical framework, we examine the negotiation process through which the data management system becomes a boundary object in practice. This process includes not only the accommodation of diverse epistemic cultures but also organisational and professional hierarchies that empower some experts to shape the data management system towards their visions and interests. This article applies the ‘boundary object’ concept to elucidate structural power differentials in public–private partnerships and multi-professional collaborations.","",""
"2023","The decolonial turn in data and technology research: what is at stake and where is it heading?","ABSTRACT This article traces the emergence of a ‘decolonial turn’ in critical technology and data studies that analyzes the transformation of society through data extraction for profit. First, we offer a genealogy of concepts over the last decade from different fields related to this decolonial turn, including work that explores the connection between racism and data. Second, we discuss the commonalities and differences between these approaches and our own proposal, the data colonialism thesis (Couldry & Mejias, 2018, 2019) to clarify how, together, they provide a distinctive take on data and technology. Third, we summarize the most important advantages of the decolonial turn as a transhistorical tool to understand the continuities between colonialism and capitalism. Finally, some wider implications of a decolonial approach to data are explored, and broad theoretical and practical opportunities for resistance are identified.","",""
"2023","Response","The decolonial turn in critical technology and data studies has, over the past decade, brought together many scholars from different locations and disciplines. We are delighted therefore to have the chance to respond to the reflections on our article by Ranjit Singh and Densua Mumford, from the disciplines of Science and Technology Studies and International Relations respectively. Ranjit Singh rightly emphasizes that a general framework such as data colonialism faces two types of contingency: one related to the varying forces at play wherever it is reproduced and the other related to the inevitable gap between original colonial intent and its actual effects, intended or otherwise. Policy interventions and corporate strategies always have complex consequences and we would never deny this. It is particularly interesting, as Singh illustrates, that even a widely criticised state policy of data collection and dataveillance (India’s Aadhaar biometric system) can have unintended positive side effects for subjects whom it enables to be ‘read’ by states and markets, rather than remain unreadable. This is indeed a paradox of systems of datafication, insofar as they attempt to govern social space more comprehensively than before: they may end up, in some ways, including (even recognizing) those who fell outside the ambit of earlier attempts at governance. We agree therefore that the rollout of systems, policies, and strategies of datafication are likely, always, to end up messier than a general theory can envisage. And, as we emphasize (Couldry & Mejias, 2019, pp. 192–193), there is nothing bad per se about data collection. The target of data colonialism as a framework is the practice and ideology of extracting data from as many dimensions of life as possible in the interests of a small number of powerful actors. We can certainly imagine, and indeed hope for, platforms of data gathering and use more socially responsible and just than are currently dominant (Powell, 2021). But that, we suggest, is no reason to avoid taking at face value the extensive bad practices of data extraction by employers, governments, marketers, emotional AI designers, insurers, health companies, aid organizations, and so on across the world. The concept of data colonialism and the decolonial turn generally are designed to take these practices seriously as new and forceful acts of colonial appropriation. While examining our call to decolonize data, Densua Mumford emphasizes the complexity and variety of decolonial theory. We certainly want to acknowledge that variety, even if the purpose of this article was not to provide a detailed account of it. While it is true that in this new article we focus particularly on the work of Latin American scholar Anibal Quijano, in our book we draw on a wider range of decolonial and indigenous theorists, including Cesaire, Fanon, Mignolo, Nandy, and Betasamosake Simpson. As Mumford recognizes, we did not have space here to discuss the origins of decolonial thinking, although this is clearly important and we discuss it elsewhere (Couldry & Mejias, 2019,","",""
"2023","Big Data—A new medium?","This edited volume of essays explores questions arising from the contemporary phenomenon of Big Data. As data structures and algorithms become more and more dominant in determining the form and direction of our lives, the contributors to this work interrogate the problems posed by the increasing influence data have over modern life. Indeed, the book’s parts are structured around the concept of ‘patterning’; knowledge, time, culture, people all proceed in one sense or another according to patterns—we might say, with Heidegger, patterns of the unfolding of Being. But how is that unfolding, the collection of patterns by which we live our lives and the concepts by which we live them, altered in a world increasingly governed according to the abstract schemata of data structures? Do big data represent a fundamental change in the modalities of human existence? How should these data structures be characterized? What will be the contemporary relationship between the individual and the collective under data-driven regimes of surveillance and categorisation? Such questions motivate, in different ways, the authors of this volume. As Natasha Lushetich (ed.), channelling Derrida, represents the issue in her introduction, problems of big data can be thought in terms of the reduction of l’avenir (the unfolding future) to le futur (that which is programmed, patterned, by the present) (2021:, p. 2). And, without attempting to define and constrain in definite terms that which is still evolving, the book seeks to assay ‘big data as a constellation and a multifaceted process of transformation that... occurs largely beyond the realm of human consciousness.’ (8) This work, indeed, could be viewed as an exploratory ingress into territory new, fecund, and as yet barely trodden; for while much has been written already, the phenomenon remains hard to grasp in full, and so much more will be needed before all the implications of modern technical paradigms can be understood. The scope of the volume is, nevertheless, broad, and covers a wide range of questions arising from modern data-driven methodologies from how these affect the unfolding of knowledge and time to biometric security to creative AI’s. The volume is divided into four parts consisting of three essays, each connected with the overall theme of patterning. Part I considers the relationship between big data and knowledge and time; part II relates to use and extraction; part III interrogates the effects of modern datadriven paradigms on cultural heritage and memory; and part IV informs the scope of debate around people and the ineluctable effects of big data on their lives and how they live.","",""
"2023","The unhomed data subject: negotiating datafication in Latin America","ABSTRACT Critical scholarship about datafication reveals the implications of algorithmically driven digital transformations for both social processes and human experiences of subjectivity. Digital transformations embed ontological beliefs in the information systems that drive new organizational processes and are accompanied by techno-positivist discourses that promote the benefits of these schemes. The dual power of new information systems plus strong discursive influences has led to fears that data subjects will come to be defined by data and information systems – that their subjectivity will be subordinated by the algorithm. However, in this paper, we argue that real experiences of data sharing offer a means to reveal actual experiences with subjectification, and that often these experiences are multiple and complex. Drawing on the results of five digital literacy interventions carried out by partner organizations in Chile, Colombia, Paraguay, Peru, and Uruguay in 2021, we consider participants’ lived experiences with datafication. Our work reveals how people experience, negotiate, reject, and accept data power’s multiple manifestations in ways that strategically mobilize data resources, constituting a fractured data subjectivity that overlaps the bounds of any one information system. This leads us to suggest the idea of the ‘unhomed’ as a useful concept for understanding data subjectification in the contemporary moment.","",""
"2023","Towards a critical understanding of data visualisation in democracy: a deliberative systems approach","ABSTRACT Data and data visualisations – in the forms of graphs, charts and maps – are becoming an increasingly important feature of social, public and political life. Yet within existing scholarship, the democratic significance of data visualisations has thus far received minimal attention. This article offers a first systematic attempt to make sense of and scrutinise the role of data visualisation in democracy. We apply deliberative systems theory in the analysis of three original case studies to elucidate how data visualisation can integrate into the overall anatomy of democracy, and to normatively assess how data visualisation contributes towards key democratic ideals. Conclusively, we highlight how critical perspectives on power, ideology and epistemology problematise any simplistic account of how data visualisation matters for democracy.","",""
"2023","Truth in a sea of data: adoption and use of data search tools among researchers and journalists","ABSTRACT The increasing availability of data search tools brings opportunities for non-expert users. Among these users, interdisciplinary researchers and data journalists represent a growing population whose work can lead to societal benefit. Through in-depth interviews, we examine what strategies and approaches researchers and journalists adopt to search online data, how they apply current technology to facilitate dataset search, and the barriers and difficulties that they encounter in their work with data. Our findings reveal that with technological limitations in the aspects of searchability, interactivity and usability, dataset search for non-experts remains a challenge. We have found that little attention has been paid to non-experts’ emerging data need, significantly constraining the design and development of technological tools for supporting non-expert users. Our findings underline the critical impact of the design, development and deployment of technological tools to enable the meaningful use of today’s increasingly available data toward a civil society.","",""
"2023","The coloniality of collaboration: sources of epistemic obedience in data-intensive astronomy in Chile","ABSTRACT Data collaborations have gained currency over the last decade as a means for data- and skills-poor actors to thrive as a fourth paradigm takes hold in the sciences. Against this backdrop, this article traces the emergence of a collaborative subject position that strives to establish reciprocal and technical-oriented collaborations so as to catch up with the ongoing changes in research. Combining insights from the modernity/coloniality group, political theory and science and technology studies, the article argues that this positionality engenders epistemic obedience by bracketing off critical questions regarding with whom and for whom knowledge is generated. In particular, a dis-embedding of the data producers, the erosion of local ties, and a data conformism are identified as fresh sources of obedience impinging upon the capacity to conduct research attuned to the needs and visions of the local context. A discursive-material analysis of interviews and field notes stemming from the case of astronomy data in Chile is conducted, examining the vision of local actors aiming to gain proximity to the mega observatories producing vast volumes of data in the Atacama Desert. Given that these observatories are predominantly under the control of organisations from the United States and Europe, the adoption of a collaborative stance is now seen as the best means to ensure skills and technology transfer to local research teams. Delving into the epistemological dimension of data colonialism, this article warns that an increased emphasis on collaboration runs the risk of reproducing planetary hierarchies in times of data-intensive research.","",""
"2023","Ethical ambiguity and complexity: tech workers’ perceptions of big data ethics in China and the US","ABSTRACT Despite extensive studies on ethical data use and algorithms, little is known about the ethical perspectives of tech workers – insiders of a profession that heavily relies on data and algorithms. Nor have there been sufficient cross-national comparisons of their perspectives. Relying on interviews with 98 tech workers in China and the US, this paper is guided by two questions: (1) What are tech workers' perceptions of big data ethics, and (2) what are the cross-national similarities and differences in China and the US? The study found that there are cross-national similarities in tech workers’ cautious enthusiasm about the applications of big data in their work, as well as in their complex and ambivalent ethical perspectives on the use of big data in government digital surveillance. The main cross-national differences occur in tech workers’ perceptions of whether big data may reinforce social inequalities. US-based tech workers are concerned about the reinforcement of race and gender-based inequalities through the use of big data, whereas their colleagues in China are optimistic that the use of big data may reduce income-based inequalities across geographical regions. The study's findings have implications for how to leverage tech workers’ influence and promote the ethical use of data and algorithms.","",""
"2023","OPEN PUBLIC DATA: HOW WE USE IT AND HOW IT USES US","Data policy aims to understand how governments, industry, academia, and civil society understand data availability and use. Data policy studies are broad in scope and include theory and practice of open sources of data from traditional sources (e.g., statistics and public health government agencies); representation and interpretation of data; investigations of the social relations and impacts of open public data; and attitudes surrounding data stewardship and public data availability and use.  This study’s empirical research is based on two case studies of the Australian and New Zealand Open Data programs between 2010 and 2020. Based on current scholarship, some factors affecting open data supply were confirmed, and new insights were generated. Social psychology theorising concerning identity leadership was confirmed. When leaders promoted a sense of ‘us’ and ‘who we are’, data stewards were more likely to advance a shared vision for making data available for reuse. The concepts of _collateral peers_ and _collateral peer networks_ were introduced to data policy scholarship. Collateral peer networks engage in multistakeholder governance with no apparent leader-follower relationship. Instead, peers (in function but not necessary title) collaborate across the public service, at various levels of government, and with experts in research institutions (e.g., publicly funded scientific and applied research organisations).  Future areas for public interest technology, specifically data policy research, include how researchers and practitioners can prioritise data stewardship, open data communities, and multistakeholder governance, especially during prolonged and compounding crises.  ","",""
"2023","LOOKING FOR MONTREAL DIGITAL CITIZENS: FOR WHO ARE OPEN DATA MADE?","Municipalities' development of open data portals is part of a political drive to bring citizens and local governments closer together. However, despite significant investments, these initiatives rarely find their audience, because they respond primarily to an imperative of openness that places them in a logic of supply rather than demand. Also because citizens have a minimal understanding of the concrete implications of open data. In this context, one can legitimately ask for _whom_ are these open data portals created. Using the City of Montreal (Quebec, Canada) as a case study, we provide a nuanced answer to this question. If the socio-technical device set up seems to meet the needs of an """"imagined"""" public more technophile and entrepreneurial than most citizens are, this discrepancy is perceived and countered by many processes. Our longitudinal study over a decade allows us to detect a co-construction in tension of the web portal. On the one hand, we find preoccupations with municipal prerogatives, administrative routines, and open-data movement ideals - sometimes mixed with territorial branding strategies. On the other, we find attention to citizen appropriation, the search for a better understanding of empirical audiences and a willingness to design the portal for the nebulous public of """"Montrealers"""". We base our analysis on a three-tiered data: the _imagined_ publics in municipal discourses, the publics _configured_ by the digital device, and the publics _constructed_ through the actions and strategies of the actors. We discuss findings on the portal’s evolution, and on the clash between imaginary worlds.","",""
"2023","BELIEFS, VALUES AND EMOTIONS IN PRACTITIONERS’ ENGAGEMENTS WITH LEARNING ANALYTICS IN HIGHER EDUCATION","Internet entrepreneurs, EdTech companies, AI enthusiasts, and other powerful stakeholders around the world have promoted the idea that big data and learning analytics (LA) have the potential to revolutionise education. LA, defined as the continuous measurement, collection, analysis and reporting of data about learners and their context (Gašević et al., 2015, p. 1), is increasingly being used to track and evaluate what students do in internet-mediated environments. A growing body of literature has questioned the benefits attributed to the use of AI-based solutions and raised a number of concerns about the current developments in the education sector. Despite this growing interest among researchers, we know little about how the beliefs, values and feelings of different groups of educational practitioners shape how they engage with AI-driven learning analytics technologies and influence the evolution of the cultures of practice shaping the adoption of learning analytics. In this paper, we report on research that asks: how do culturally situated beliefs, values and emotions shape practitioners’ engagements with narrow AI in different contexts of practice? The research project as a whole examines these cultures of practice across three contrasting contexts. Here we will discuss early findings from one of these contexts – learning analytics in higher education. With insights from this research, we aim to contribute to empower practitioners in higher education and relevant stakeholders to foster the development of critical and reflective data cultures that are able to exploit the possibilities of learning analytics while being critically responsive to their societal implications and limitations.","",""
"2023","CREATIVE DESIGN METHODS FOR IOT DATA ETHICS IN HYBRID SPACES","This paper presents the use of creative methods including walking workshops, design fiction and policy prototyping to investigate questions of trust, security and ethics in public space Internet of Things (IoT) deployments.  We describe how the walking workshops, or 'walkshops', were developed to incorporate both real IoT deployments, and design fictions representing mundane speculations, in the context of a city in the North-West of England. The first event was held in the physical city, highlighting its hybrid nature as ubiquitous data collection becomes common. The event was also repeated in a digital hybrid space created for this purpose which replicated the features of the city walk virtually. These activities were used to engage with local council officers and cybersecurity experts, and supported the development of new local government policies for secure and ethical IoT deployment.  The outcomes of this work include reflections on the use of these methods, the delivery of policy recommendations, and the development of an online tool to support organizations in consideration of IoT deployments. Potential users of this tool include public bodies evaluating whether or not deployments conform to policy, those undertaking the design or procurement process for a deployment, and any other organizations assessing ethical and security aspects of IoT.  We reflect on how combining such creative methods with others such as speculative design allows us a deeper insight into questions of data ownership, ethical data practice and data governance.","",""
"2023","DO EMOTIONAL RESPONSES TO DATA VISUALISATION MOBILISE PEOPLE TO ACT? A CASE STUDY OF CLIMATE CHANGE VISUALISATIONS IN DIFFERENT NATIONAL CONTEXTS","This paper offers original insights into social media audiences’ emotional responses to data visualisations about climate change and how these responses play a role in mobilising participation in different national and geographical contexts. Understanding the role emotions play in engagements with graphic representations of data is important, because there is an increased circulation of data through visual representations in everyday life, and because emotions are vital components for making sense of data and for eliciting engagement. Despite this, sociological research has yet to explore emotional experiences of datavis and where they can lead.  This paper uses a comparative mixed qualitative methods approach, incorporating semiotic analysis of thirteen datavis about climate change, nine semi-structured interviews with ten data visualisation professionals from six organisations who design, commission and/or disseminate data visualisations about climate change, thirty-four semi-structured interviews and thirteen follow-up interviews with diverse audience participants from the United Kingdom and Poland who responded to these data visualisations on social media.  The paper argues that datavis can be seen as what I have called an ‘emotional repository’ of dynamic and complex emotional experiences. It can trigger multiple, simultaneous, and often contradictory emotions, relating mainly to the data that is the subject of the visualisation or aesthetic form. These emotions play an important role in mobilising audiences to participate in datafied democracies, more often on an individual and daily level, and less frequently on a collective and public scale. However, they do so in different ways, depending on geographical context and demographic characteristics. ","",""
"2023","DATA COLONIALISM AND DATA SOVEREIGNTY IN INDIGENOUS SPACES","This paper will discuss a topic of prioritized importance in contemporary Indigenous research: data sovereignty. In the light of the historical and cultural contexts in which we conduct our research, we need to drastically question and decenter research practices that could contribute to reiterating, maintaining, and amplifying colonial practices and perspectives. Data harvesting is such a practice, and an issue of immediate interest on the agenda of Indigenous researchers and allies. Efforts toward ethically valid and cultural-sensitive modes of data use are taking shape in Indigenous research, calling for an increased awareness about the topic among scholars within the interdisciplinary field of digital research.  This presentation takes its point of departure in Sápmi, the traditional area of settlement of the Indigenous Sámi people, and in ongoing research and initiatives in the area. The international research context constitutes the framework for contextualizing topical debates and issues in Sápmi. First, I will approach and examine practices and principles of data collection, data management and data curation through the lens of Indigenous research. Second, I will discuss examples of digital initiatives in curatorship of Indigenous traditional knowledge, for instance the labelling of cultural heritage, use of metadata and access to library and archive collections. Current debates and ongoing works about ethical guidelines and about the application of FAIR and CARE principles will be central in this discussion.  ","",""
"2023","DATA REFUSAL FROM BELOW: A FRAMEWORK FOR UNDERSTANDING, EVALUATING, AND ENVISIONING REFUSAL STRATEGIES","Amidst calls for public accountability over large data-driven systems, feminist and indigenous scholars have developed refusal as a practice that challenges the authority of data collectors. However, because data affects so many aspects of daily life, it can be hard to see seemingly different refusal strategies as part of the same repertoire. Furthermore, conversations about refusal often happen from the standpoint of designers and policymakers rather than the people and communities most affected by data collection. In this paper, we introduce a framework for data refusal from below—writing from the standpoint of people who refuse, rather than the institutions that seek their compliance. We characterize refusal strategies across four constituent facets common to all refusal, whatever tactics are used: autonomy, or how refusal accounts for individual and collective interests; time, or whether refusal reacts to past harm or proactively prevents future harm; power, or the extent to which refusal makes change possible; and cost, or whether or not refusal can reduce or redistribute penalties experienced by refusers. We illustrate each facet by drawing on cases of people and collectives that have refused data systems. Together, the four facets of our framework are designed to help scholars and activists describe, evaluate, and imagine new forms of refusal.","",""
"2023","OUR DATA BODIES. RE-FRAMING OUR CONCEPTUAL AND NORMATIVE RELATIONSHIP WITH PERSONAL DATA","The rapid development of data-driven technologies has led to manifold concerns on how to protect citizens from the effects of massive data exploitation, especially when “personal data” are at stake, since they are the object of a fundamental right. Personal data are legally defined as any information “relating to” an identified or identifiable natural person, the right holder. However, it is unclear in which particular sense personal data relate to a person: which is the specific type of direct connection between them. In our view, this is a crucial question both from a conceptual and a normative point of view that the academic literature has not yet addressed in enough depth. In light of this, our paper aims at advancing knowledge towards a more accurate conception of our relationship with personal data. To do so, we firstly discuss the main recent conceptions on the issue: data as property, data as raw material and data as labour. Secondly, we argue why none of them seems to be accurate from a conceptual point of view or desirable from a socio-political perspective. Finally, we propose to understand personal data as _part of oneself_ and our relationship with them as the one we have with our bodies or their parts, with _our data bodies_. We end up discussing the implications of the proposed conception, both from a conceptual and from a normative perspective.","",""
"2023","SUBORDINATED BY THE ALGORITHM: EXPLORING DATA COLONIALISM AMONG LATIN AMERICAN CITIZENS","Data colonialism refers to the processes by which extracted data is commodified to reproduce and expand capitalist and colonialist practices. As data colonialism transforms infrastructures and ideologies to exercise new ways of control, it has become a crucial approach to better understand how datafication transforms and impacts citizens' lives across the world—especially in the Global South. In this paper, we explore data colonialism as a lens to examine how Latin American citizens' are impacted by their engagement with different information systems. More specifically, we present findings from a collaboration with civic data organizations in five countries in Latin America. Overall, findings show how relying on data colonialism underscores the impacts to citizens when they engage with contemporary information systems, including material and physiological harm to individuals, fragmentation of communities, and various ideological shifts. However, findings also call attention to the value of integrating other theoretical approaches that emphasize discussions about agency, contextualization, and the benefits of datafication. Overall, this paper discusses how data colonialism hurts individuals, target communities, and transforms citizens' imaginaries about their place in society.","",""
"2023","LEVERAGING OR EXPLOITING? BREAKING THROUGH DATA COLONIALISM AND ETHNOCENTRISM WHEN BUILDING A DIVERSITY-AWARE SOCIAL PLATFORM.","The extractive logic of data-driven technology and knowledge production has raised serious concerns. While this discourse initially focused on the impact on Western societies, attention is increasingly turning to the consequences for countries and communities in the (Global) Souths. Criticism has mainly focused on the activities of the private sector. In this paper, however, we argue that publicly funded knowledge and technology production projects must also be examined through the lens of this critique. A research project designing and prototyping a diversity-aware social platform with pilot sites in China, Denmark, the United Kingdom, India, Italy, Mexico, Mongolia, and Paraguay is taken as a use case to ask the question: What do we need to do to meet diverse needs and develop innovative knowledge and products that benefit partners from the South and North alike? Our goal is to identify key efforts that are required to break the prevailing cycle of data colonialism and ethnocentric design. We present data from four different pilot sites and reflect on the original concept, as well as progress and results achieved to date. We then compare the experiences and draw five lessons that we believe will help future projects foster more equitable collaboration and achieve outcomes that benefit diverse local communities.","",""
"2023","DATA REPRESENTATION AS EPISTEMOLOGICAL RESISTANCE","Over the last two decades quantitative data representation has moved from a specialization of the sciences, economics, and statistics, to becoming commonplace in settings of democratic governance and community decision making. The dominant norms of those fields of origin are not connected to the governance and activism settings data is now used in, where practices emphasize empowerment, efficacy, and engagement. This has created ongoing harms and exclusion in a variety of well-documented settings. In this paper I critique the singular way of knowing embodied and charts and graphs, and apply the theories of epistemological pluralism and extended epistemology to argue for a larger toolbox of data representation. Through three concrete case studies of data representations created by activists I argue that social justice movements can embrace a broader set of approaches, practicing creative data representation as epistemological resistance. Through learning from these ongoing examples the fields of data literacy, open data, and data visualization can help create a broader toolbox for data representation. This is necessary to create a pluralistic practice of bringing people together around data in social justice settings.","",""
"2023","DEFENDING HUMAN RIGHTS IN THE ERA OF DATAFICATION","In this paper, we explore how activists and human rights defenders deal with datafication. This work demonstrates how data can be a valuable resource in activism and campaign planning. In addition, data and lack of data also complicate daily life for people in vulnerable positions, for example, when contacting government agencies, schools, and medical facilities .  Data from four types of human rights activism formed the basis of our analysis. They include volunteers and employees of NGOs dealing with refugee and migrant issues, homelessness, poverty, sexual minorities, and women's shelters. The study was done in Sweden, where the GDPR (General Data Protection Regulation) laws limit the handling and storage of personal data.  The following five major themes emerge from the analysis of data from our interview study: Affording personal integrity, Data poverty, Protective data practices, Drawing attention to data, and Systems and data routines.  In addition, this study shows how activists and the organizations that they support are exposed to contradictory aspects of data; on one hand, deliberately exposing data about marginalized/minoritized groups, while on the other, making sure those groups, along with activists themselves, are not exposed. Most important, the data laws and regulations are not adjusted to the needs of the most vulnerable in society, and therefore, actions of civil disobedience are necessary to care for vulnerable populations through data.","",""
"2023","A Code of Digital Ethics: laying the foundation for digital ethics in a science and technology company","AbstractThe rapid and dynamic nature of digital transformation challenges companies that wish to develop and deploy novel digital technologies. Like other actors faced with this transformation, companies need to find robust ways to ethically guide their innovations and business decisions. Digital ethics has recently featured in a plethora of both practical corporate guidelines and compilations of high-level principles, but there remains a gap concerning the development of sound ethical guidance in specific business contexts. As a multinational science and technology company faced with a broad range of digital ventures and associated ethical challenges, Merck KGaA has laid the foundations for bridging this gap by developing a Code of Digital Ethics (CoDE) tailored for this context. Following a comprehensive analysis of existing digital ethics guidelines, we used a reconstructive social research approach to identify 20 relevant principles and derive a code designed as a multi-purpose tool. Versatility was prioritised by defining non-prescriptive guidelines that are open to different perspectives and thus well-suited for operationalisation for varied business purposes. We also chose a clear nested structure that highlights the relationships between five core and fifteen subsidiary principles as well as the different levels of reference—data and algorithmic systems—to which they apply. The CoDE will serve Merck KGaA and its new Digital Ethics Advisory Panel to guide ethical reflection, evaluation and decision-making across the full spectrum of digital developments encountered and undertaken by the company whilst also offering an opportunity to increase transparency for external partners, and thus trust.","",""
"2023","Beyond data transactions: a framework for meaningfully informed data donation","AbstractAs we navigate physical (e.g., supermarket) and digital (e.g., social media) systems, we generate personal data about our behavior. Researchers and designers increasingly rely on this data and appeal to several approaches to collect it. One of these is data donation, which encourages people to voluntarily transfer their (personal) data collected by external parties to a specific cause. One of the central pillars of data donation is informed consent, meaning people should be adequately informed about what and how their data will be used. However, can we be adequately informed when it comes to donating our data when many times we don’t even know it is being collected and, even more so, what exactly is being collected? In this paper, we investigate how to foster (personal) data literacy and increase donors’ understanding of their data. We introduce a Research through Design approach where we define a data donation journey in the context of speech records, data collected by Google Assistant. Based on the data donation experiences of 22 donors, we propose a data donation framework that understands and approaches data donation as an encompassing process with mutual benefit for donors and researchers. Our framework supports a donation process that dynamically and iteratively engages donors in exploring and understanding their data and invites them to (re)evaluate and (re)assess their participation. Through this process, donors increase their data literacy and are empowered to give meaningfully informed consent.","",""
"2023","Clicks and particulates: Value, alienation, and attunement as unifying themes in big data studies"," Critiques of data colonialism and surveillance capitalism focus on data collected from online behavior. We propose that analytical concepts from these critiques—namely, regimes of value and patterns of alienation and attunement—could be applied more widely to better understand the threats that datafication poses to equity and democracy in the social and environmental realms. Regimes of value, which include the institutions and technologies that make data meaningful and render them selectively available for appropriation, are relevant both to for-profit companies’ data practices and to states’ participation in the datafication of the environment; examining regimes of value raises questions about how data are exploited and how they are neglected. Patterns of alienation associated with datafication include the potential for alienation from the environment; however, at least in some value regimes, alienation may be accompanied by possibilities for attunement to natural and social phenomena that might otherwise have escaped notice. ","",""
"2023","Diversity and neocolonialism in Big Data research: Avoiding extractivism while struggling with paternalism"," The extractive logic of Big Data-driven technology and knowledge production has raised serious concerns. While most criticism initially focused on the impacts on Western societies, attention is now increasingly turning to the consequences for communities in the Global South. To date, debates have focused on private-sector activities. In this article, we start from the conviction that publicly funded knowledge and technology production must also be scrutinized for their potential neocolonial entanglements. To this end, we analyze the dynamics of collaboration in an European Union-funded research project that collects data for developing a social platform focused on diversity. The project includes pilot sites in China, Denmark, the United Kingdom, India, Italy, Mexico, Mongolia, and Paraguay. We present the experience at four field sites and reflect on the project’s initial conception, our collaboration, challenges, progress, and results. We then analyze the different experiences in comparison. We conclude that while we have succeeded in finding viable strategies to avoid contributing to the dynamics of unilateral data extraction as one side of the neocolonial circle, it has been infinitely more difficult to break through the much more subtle but no less powerful mechanisms of paternalism that we find to be prevalent in data-driven North–South relations. These mechanisms, however, can be identified as the other side of the neocolonial circle. ","",""
"2023","Choreographing for public value in digital health?","Entanglements between public and private entities in digital health are not new, yet we do not have full insight into how these public-private dances are choreographed or what notions of public value drive governments’ appetite for investing into or collaborating with private digital health firms around health data. We examine key events, actors, public discussions, policy deliberations and regulations for over 30 years to find that European Union policy has paved an innovation-friendly path for technology companies entering healthcare. The recent pandemic has normalized these collaborations even further. The paper also finds that conceptualizations of public value in digital health mostly relate to economic aspects – markets, jobs and money. Other interpretations, such as public health, long-term sustainability or the common good, tend to be sidelined. The paper closes by considering whether the advent of the European Health Data Space will change this trajectory before giving suggestions on how a focus on public health value can be re-established.","",""
"2023","Big data for official migration statistics: Evidence from 29 national statistical institutions"," International migration statistics suffer from extensive gaps and shortcomings. Recently, national statistical institutions (NSIs) have started using big data to complement traditional statistics, including on migration. Although these are promising developments, we still lack answers on the extent to which NSIs are currently using big data for migration and to what extent it complements the gaps in traditional data. We gathered data by interviewing experts from 29 NSIs to investigate how big data is used for official migration statistics. We show that 15 out of 29 NSIs either used big data for migration, had a pilot project or have been involved in joint initiatives. We reveal the specific implications of big data in human migration (e.g. internal mobility, stocks, flows and mobility patterns, among others and the most common sources used to extract official statistics). Moreover, we discuss the challenges and barriers preventing NSIs from using such data. Factors deterring countries from utilising big data include limited data accessibility, an absence of legal frameworks for big data usage, ethical concerns, the possession of already high-quality data, a deficit in expertise and methodologies and a lack of perceived necessity for supplementary data or approaches. Moreover, many countries did not know which data to use and were concerned about the quality and accuracy of such data. Legal barriers were more of an issue than the ethical aspects, and overall, participating countries believe that there is a high potential for big data in the future. ","",""
"2023","Recording the ethical provenance of data and automating data stewardship"," Health organisations use numerous different mechanisms to collect biomedical data, to determine the applicable ethical, legal and institutional conditions of use, and to reutilise the data in accordance with the relevant rules. These methods and mechanisms differ from one organisation to another, and involve considerable specialised human labour, including record-keeping functions and decision-making committees. In reutilising data at scale, however, organisations struggle to meet demands for data interoperability and for rapid inter-organisational data exchange due to reliance on legacy paper-based records and on the human-initiated administration of accompanying permissions in data. The adoption of permissions-recording, and permissions-administration tools that can be implemented at scale across numerous organisations is imperative. Further, these must be implemented in a manner that does not compromise the nuanced and contextual adjudicative processes of research ethics committees, data access committees, and biomedical research organisations. The tools required to implement a streamlined system of biomedical data exchange have in great part been developed. Indeed, there remains but a small core of functions that must further be standardised and automated to enable the recording and administration of permissions in biomedical research data with minimal human effort. Recording ethical provenance in this manner would enable biomedical data exchange to be performed at scale, in full respect of the ethical, legal, and institutional rules applicable to different datasets. This despite foundational differences between the distinct legal and normative frameworks is applicable to distinct communities and organisations that share data between one another. ","",""
"2023","Exploring the impact of national culture on the development of open government data: A cross-cultural analysis"," The development of open government data has attracted interest from academics and practitioners. However, only a few studies have examined a culture-based account of open government data development. This study empirically investigates the impact of national culture on open government data. Through the data investigation and analysis of 55 countries, this research finds that the development of open government data is positively linked with national culture with respect to individualism, indulgence and long-term orientation and is negatively related to power distance. Furthermore, this study shows that economic development moderates the relationship between national culture and open government data development, especially with respect to individualism and long-term orientation. Practically, the findings of this research can help policymakers better understand the multifaceted impacts of national culture on the development of open government data, including the promotion of cultural values (i.e. high individualism, high indulgence, and high long-term orientation) and the change in the passive and conservative attitude of citizens toward the openness of government data in countries where power distance culture is high. ","",""
"2023","Everyday digital traces"," Our research responds to calls for more engagement with everyday personal data. We used a co-designed, fictional persona called Alex Smith to concretise and represent people's online information to help participants (through role-playing) reflect on data and digital traces. Drawing together four fields of scholarly research concerning personal data: digital traces and the digital self, datafication and dataveillance, mundane, everyday data and the data journey – our aim was to advance understandings of personal data by exploring ordinary people's seemingly innocuous digital traces generated through everyday online interactions. Our paper presents three key findings from our analysis: (1) how ordinary people cope with and manage everyday data; (2) the haunting effects and affects of peer-to-peer surveillance and (3) postdigital identities. We argue that greater attention needs to be paid to everyday digital traces – how they are understood, managed and revealed because this has implications for ordinary people, corporate entities and governments. We contribute to a gap in critical data studies literature that calls for further investigations into ordinary people's engagement with data. We also offer a method that can be adapted for and used with different participant groups, which also supports their awareness of cumulative functions of personal data and potential use by un/known actors. ","",""
"2023","Data arenas: The relational dynamics of data activism"," The article proposes the theoretical category of data arenas as a relational field for strategic actors in diverse areas of the contentious politics of data (Beraldo and Milan, 2019). The paper argues that the conceptualization of data activism needs to be related to the immediate data arena in which the action takes place, in order to select the interactive opportunities and threats for emerging data-driven repertoires of action. To fully work through the relational dynamics of data activism, it is necessary to move from a conceptualization of data infrastructure to the notion of data arenas as an ‘open-ended bundle of rules and resources that allows certain kinds of interaction to proceed’ (Jasper, 2006: 141). Using the case of environmental data activism, I highlight four key dimensions to study: (a) strategic use of data as capital that differentiates and positions actors, as well as influences their further choices; (b) practices of defining the boundaries of the problem on which the arena focuses and outlining the pool of actors who participate in the process of solving it; (3) sets of relationships among the outlined pool of actors which represent opportunities and threats for the actors, related to the position they occupy within an arena; and (4) power as the ability to control and shape an arena. Data arena approach shed new light on data activism as a relational practice, combining the latest developments in research on data contexts and the political situatedness of data with the emerging field of research on data activism. ","",""
"2023","On samples, data, and their mobility in biobanking: How imagined travels help to relate samples and data"," Biobanking involves the assembling, curating, and distributing of samples and data. While relations between samples and data are often taken as defining properties of biobanking, several studies have pointed to the challenges in relating them in practice. This article investigates how samples and data are curated, connected, and made mobile in practice. Building on an analysis of data collected at five hospital-based biobanks in Austria, the article describes and compares biobanking in three types of biobank collections: ‘departmental collections’, ‘project-specific collections’ and ‘hospital-wide collections’. It draws attention to the invisible work going into this infrastructure and highlights the central role of visions to make samples and data travel to a different location and thus support biomedical research. It shows that while visions of future travels are often epistemologically uncertain, they are informed by social ties and relationships between the collectives involved in the curation of samples and data on the one hand and the imagined users on the other. Finally, we point to the importance that policy actors in this domain consider the aspects we identified—and, in particular, reflect the temporalities inherent in such a research infrastructure. ","",""
"2023","Google, data voids, and the dynamics of the politics of exclusion"," This study deploys a critical approach to big data analytics to gauge the tentative contours of data voids in Google searches that reflect extreme-right dynamics of exclusion in the aftermath of the 2015 humanitarian crisis in Europe. The study adds complexity to the analysis of data voids, expanding the framework of investigation outside the USA context by concentrating on Germany and Sweden. Building on previous big data analytics addressing the politics of exclusion, the study proposes a catalogue of queries concerning the issue of migration in both Germany and Sweden on a continuum from mainstream to extreme-right vocabularies. This catalogue of queries enables specific and localized queries to identify data voids. The results show that a search engine's reliance on source popularity may lead to extreme-right sources appearing in top positions. Furthermore, using platforms for user-generated content provides a way for localized queries to gain top positions. ","",""
"2023","FAIR data sharing: An international perspective on why medical researchers  are lagging behind"," FAIR data, that is, Findable, Accessible, Interoperable, and Reusable data, and Big Data intersect across issues related to data storage, access, and processing. The solution-oriented FAIR principles serve an integral role in improving Big Data; yet to date, the implementation of FAIR in multiple sectors has been fragmented. We conducted an exploratory analysis to identify incentives and barriers in creating FAIR data in the medical sector using digital concept mapping, a systematic mixed methods approach. Thirty-eight principal investigators (PIs) were recruited from North America, Europe, and Oceania. Our analysis revealed five clusters rated according to perceived relevance: ‘Efficiency and collaboration’ (rating 7.23), ‘Privacy and security’ (rating 7.18), ‘Data management standards’ (rating 7.16), ‘Organization of services’ (rating 6.98), and ‘Ownership’ (rating 6.28). All five clusters scored relatively high and within a narrow range (i.e., 6.28–7.69), implying that each cluster likely influences researchers’ decision-making processes. PIs harbor a positive view of FAIR data sharing, as exemplified by participants highly prioritizing ‘Efficiency and collaboration’. However, the other four clusters received only modestly lower ratings and largely contained barriers to FAIR data sharing. When viewed collectively, the benefits of efficiency and collaboration may not be sufficient in propelling FAIR data sharing. Arguably, until more of these reported barriers are addressed, widespread support of FAIR data will not translate into widespread practice. This research lays the preliminary foundation for conducting targeted large-scale research into FAIR data practices in the medical research community. ","",""
"2023","Conditional trust: Citizens’ council on data-driven media personalisation and public expectations of transparency and accountability"," This article presents findings from a rigorous, three-wave series of qualitative research into public expectations of data-driven media technologies, conducted in England, United Kingdom. Through a range of carefully chosen scenarios and deliberations around the risks and benefits afforded by data-driven media personalisation technologies and algorithms, we paid close attention to citizens’ voices as our multidisciplinary team sought to engage the public on what ‘good’ might look like in the context of media personalisation. We paid particular attention to risks and opportunities, examining practical use-cases and scenarios, and our three-wave councils culminated in citizens producing recommendations for practice and policy. In this article, we focus particularly on citizens’ ethical assessment, critique and improvements proposed on media personalisation methods in relation to benefits, fairness, safety, transparency and accountability. Our findings demonstrate that public expectations and trust in data-driven technologies are, fundamentally, conditional, with significant emphasis placed on transparency, inclusiveness and accessibility. Our findings also point to the context dependency of public expectations, which appears more pertinent to citizens, in hard political as opposed to entertainment spaces. Our conclusions are significant for global data-driven media personalisation environments – in terms of embedding citizens’ focus on transparency and accountability, but equally, also, we argue that strengthening research methodology, innovatively and rigorously to build in citizen voices at the very inception and core of design – must become a priority in technology development. ","",""
"2023","Big ideas, small data: Opportunities and challenges for data science and the social services sector"," The social services sector, comprised of a constellation of programs meeting critical human needs, lacks the resources and infrastructure to implement data science tools. As the use of data science continues to expand, it has been accompanied by a rise in interest and commitment to using these tools for social good. This commentary examines overlooked, and under-researched limitations of data science applications in the social sector—the volume, quality, and context of the available data that currently exists in social service systems require unique considerations. We explore how the presence of small data within the social service contexts can result in extrapolation; if not properly considered, data science can negatively impact the organizations data scientists are trying to assist. We conclude by proposing three ways data scientists interested in working within the social services sector can enhance their contributions to the field: refining and leveraging available data, improving collaborations, and respecting data limitations. ","",""
"2023","Unveiling the layers of data activism: The organising of civic innovation to fight corruption in Brazil","Developed by tech-savvy citizens, Rosie is a bot that autonomously checks the public spending of elected representatives of the Brazilian Lower Chamber and uses Twitter to engage peoplein discussing suspicious findings. Rosie is the most visible face of Operação Serenata de Amor (Operation Love Serenade), a data-enabled activism initiative that revolves around the creation, use and dissemination of open data to hold politicians accountable and empower citizens to react against the misuse of public funds. The article draws on an original data set – including interviews, participant online observation notes and secondary qualitative materials – to examine Operação Serenata de Amor, focusing on how material and symbolic elements related to both human and non-human actors shape the organisational patterns of this type of initiative. The findings suggest that there are three organisational patterns, each with further specific challenges, based on the presence of three modes of participation that depend on different types of engagement with digital technologies and data. Findings indicate that data-enabled activism can emerge with typical characteristics and values of tech startups, such as the goal of creating a sustainable budget and providing strategic content by validating it with user feedback, while also retaining some traits of online activism, such as ad hoc and temporal networks of highly autonomous actors concerned with specific contentious issues. In this respect, the eventual demobilisation of Operação Serenata de Amor's initiators due to commercial values and struggles to maintain it active and engaging can be seen as a cautionary tale for data-enabled activism, particularly for initiatives closely associated with civic innovation and social tech startups.","",""
"2023","Data artivism and feminicide","Data has become a key format for activists to visibilizar (make visible/call attention to) and denounce social issues. Drawing on the concept of “artivism,” we name as data artivism those works that visually intervene in the contestation around an issue by mobilizing art and craft as a form of resistance and as a method to visualize data. In this commentary, we share three examples of data artivism on the issue of feminicide. Our aim is to inspire the fields of critical data and data visualization studies to engage more deeply with art and find common language with artists, activists and advocacy groups (particularly those in Latin America), who are going beyond conventional visualization to reveal a range of alternative ways to mobilize data.","",""
"2023","Critical data ethics pedagogies:  Three (non-rival) approaches"," In a moment of heightened ethical questioning concerning data-intensive analytics, “data ethics” has become a site of dispute over its very definition in teaching, research, and practice. In this paper, we contextualize this dispute based on the experience of teaching data ethics. We describe how the field of computer ethics has historically informed the training of computer experts and how, in recent years, the scholarship on science and technology studies has created opportunities for transforming the way we teach with the inclusion of critical scholarship on relational ethics and sociotechnical systems. The emergent literature on “critical data ethics” has created a space for interdisciplinary collaboration that integrates technical and social science research to examine digital systems in their design, implementation, and use through a hands-on approach. As a contribution to the recent efforts to reimagine and transform the field of data science, we conclude with a discussion of the approach we devised to bridge technology/society divides and engage students with questions of social justice, accountability, and openness in their data practices. ","",""
"2023","Fact signalling and fact nostalgia in the data-driven society"," Post-truth tells the story of a public descending into unreason, aided and abetted by platforms and other data-driven systems. But this apparent collapse of epistemic consensus is, I argue, also dominated by loud and aggressive commitment to the idea of facts and Reason – a site where an imagined modern past is being pillaged for vestigial legitimacy. This article identifies two common practices of such reappropriation and mythologisation. (1) Fact signalling involves performative invocations of facts and Reason, which are then weaponised to discredit communicative rivals and establish affective solidarity. This is often closely tied to (2) fact nostalgia: the cultivation of an imagined past when ‘facts were facts’ and we, the good liberal subjects, could recognise facts when we saw them. Both tendencies are underwritten by a myth of connection: the still enduring narrative that maximising the circulation of information regardless of provenance or meaning will eventually yield a more rational public – even as data-driven systems tend to undermine the very conditions for such a public. Drawing on examples from YouTube-amplified ‘alternative influencers’ in the American right, and the normative discourses around fact-checking practices, I argue that this continued reliance on the vestigial authority of the modern past is a pernicious obstacle in normative debates around data-driven publics, keeping us stuck on the same dead-end scripts of heroically suspicious individuals and ignorant, irrational masses. ","",""
"2023","Contextualizing realism: An analysis of acts of seeing and recording in Digital Twin datafication"," Digital Twins are conceptualized as real-time digital representations of real-life physical entities or systems. They are explored for a wide array of societal implementations, and in particular to help address fundamental societal challenges. As accurate digital equivalents of their real-life twin, Digital Twins substitute their physical twin in knowledge production and decision-making processes. They raise high expectations: they are expected to produce new knowledge, expose issues early, predict future behavior, and help to optimize the physical twin. Data play a key role here because they form the building blocks from which the Digital Twin representation is created. However, data are not neutral phenomena but products of human-technology interaction. In this article, we therefore raise the question of how a Digital Twin data collection is created, and what implications does this have for Digital Twins? To answer this question, we explore the data collection process in three cases of Digital Twin development at a university. Connecting to Jasanoff's theoretical framework of regimes of sight, we approach the creation of a data collection as acts of seeing and recording that influence how reality is represented in data, as well as give a certain legitimacy and authority to the data collection. By examining the acts of seeing and recording and their respective roles in producing the data collection, we provide insight into the struggles of representation in Digital Twins and their implications. ","",""
"2023","Intersectional approaches to data: The importance of an articulation mindset for intersectional data science","Data's increasing role in society and high profile reproduction of inequalities is in tension with traditional methods of using social data for social justice. Alongside this, ‘intersectionality’ has increased in prominence as a critical social theory and praxis to address inequalities. Yet, there is not a comprehensive review of how intersectionality is operationalized in research data practice. In this study, we examined how intersectionality researchers across a range of disciplines conduct intersectional analysis as a means of unpacking how intersectional praxis may advance an intersectional data science agenda. To explore how intersectionality researchers collect and analyze data, we conducted a critical discourse analysis approach in a review of 172 articles that stated using an intersectional approach in some way. We contemplated whether and how Collins’ three frames of relationality were evident in their approach. We found an over-reliance on the additive thinking frame in quantitative research, which poses limits on the potential for this research to address structural inequality. We suggest ways in which intersectional data science could adopt an articulation mindset to improve on this tendency.","",""
"2023","Judgments as bulk data"," Should court judgments be publicly available for text and data mining purposes? This article shows that the arguments for and against access to judgments conflate different understandings of what judgments are. On one view, judgments are seen as a ‘jurisprudential’ category, whereas the other view regards them as something ‘factual’. Once it is understood that these views and the claims based on them do not fight over the same territory, it should be easier to make judgments more widely available, including for the purposes of computational analysis of judgments as bulk data. The purpose of this article is to help to clear the ground for the debate around access to judgments as bulk data and highlight some relevant considerations for the preferred licencing regime concerning judgments. ","",""
"2023","Coloniality and frictions: Data-driven humanitarianism in North-Eastern Nigeria and South Sudan"," It is now over a decade since the proclamation of a humanitarian ‘data revolution’, with the rise of ‘innovation’ and the proliferation of ‘data solutions’ rendering data-based humanitarianism an important area of critical investigation. This article contributes to debates within the field by exploring the role of data in the provision of humanitarian assistance within camps for internally displaced persons (IDPs) across north-eastern Nigeria and South Sudan. It draws on qualitative interviews carried out with humanitarian practitioners specialising in data and information management, as well as with camp residents and stakeholders located in each region. The analysis focuses attention on the ways in which epistemic injustices have been further perpetuated by the ‘data revolution’ due to the intensification of paternalistic dynamics associated with the coloniality of humanitarianism. It shows how a logic of extractivism structures the humanitarian data ecosystem, while also generating a series of tensions and disagreements. Data-driven humanitarianism, the article concludes, is characterised by recurring colonial dynamics as well as intensified frictions that bring epistemic injustices into sharper focus. ","",""
"2023","Imaginaries of better administration: Renegotiating the relationship between citizens and digital public power"," This article investigates future visions of digital public administration as they appear within a particular regulatory process that aims to enable automated decision-making (ADM) in public administration in Finland. By drawing on science and technology studies, public administration studies, and socio-legal studies we analyze law in the making and identify four imaginaries of public digital administration: understandable administration, self-monitoring administration, adaptive administration, and responsible administration. We argue that digital administration is seen from the perspective of public authorities serving their current needs of legitimizing existing automation practices. While technology is pictured as unproblematic, the citizen perspective is missing. We conclude that the absence of an in-depth understanding of the diverse needs of citizens raises the question whether the relationship between public power and citizens is becoming a one-way street despite of the public administration ideals that express values of citizen engagement. ","",""
"2023","Data Surrogates as Hosts: Politics of Environmental Governance","Data-driven environmental governance within the standard regulatory regime routinely relies on unmeasurable, missing, or abjected data. Technocrats typically use data surrogates to alleviate this pervasive problem. By combining feminist technoscience and critical environmental justice approaches, this article argues that data surrogates are far more than fungible substitutes and rely on more than scientific rationality and transcendent objectivity. Through a case of intersecting environmental governance and justice work in the Portside Community in San Diego, this article exposits a broader conceptualization of data surrogates by developing a partial typology of operations they perform: calibrating, weighting, and validating. The politics and labors of these operations are crucial to analyze how data acquire material and discursive power in environmental governance. I propose an analytical shift from examining the work of data surrogates in terms of substituting to one of hosting. This shift reveals and better explains how data surrogates negotiate relationships between body, place, and property across state, market, and civil society actors. Moreover, it demonstrates how data surrogates interrupt the dominant regulatory regime by resisting fungibility through acts of social reproduction. Far from being subordinate to technocratic tools, the work of social reproduction makes governing with scientific and technical instruments both possible and contestable.  ","",""
"2023","Data as capital and ethical implications in digital sport business models"," Professional sport has entered the digital economy as organisations adopt data-driven business model innovations. The purpose of this article is to highlight the potential ethical vulnerabilities sport organisations and their leaders face when adopting digital sport business models. Here, we treat data as a species of capital that can be converted into economic capital once it undergoes a computational transformation via a data-driven business model innovation. We argue for two advantages in this approach. First, it helps make transparent the mechanisms through which digital sport business models work. Second, it reveals how the extraction and application of big data exacerbates inequitable power relationships between sport organisations and supporters – the big data divide – that leads to ethical vulnerabilities for sport organisations and their consumers. We suggest that sport consumers might be particularly vulnerable to digital data risk as a consequence of their high levels of brand loyalty and involvement, which tend to encourage trust in the sport properties soliciting, analysing, and monetising their data. Platform broadcasting partnerships, e-ticketing in smart stadiums, and cryptocurrency-based fan tokens are used as examples of data-driven business model innovations based on the conversion of data to capital, demonstrating how sport organisations risk violating the trust of supporters when using digital strategies. The article concludes with directions for future research to deliver an ethically informed data-driven sports industry. ","",""
"2023","Colonial Numbers: Quantification, Indigeneity, and the Politics of Fiscal Surveillance","This paper considers how processes of quantification are implicated in settler colonial political imperatives. I examine how colonial numbers operate as forms of governmentality that obfuscate, depoliticize, commensurate, fiscalize, promote transparency and visibility, and ultimately reduce the density of Indigenous Nations. The paper specifically focusses on how fiscal surveillance flows from colonial numbers to make Indigenous life legible to the state, markets, and settlers. The paper concludes by complicating the relationship between colonialism, numbers, governance, and ignorance.","",""
"2023","Undetermined: A semi-academic exploration of the future of European data spaces via science fiction","This paper concerns the future — a scenario that is not so distant in time, as the future starts today. With the increasing datafication of our society and the approval of the European Union Data Governance Act that establishes conditions and safeguards to encourage the free flow and reuse of data for scientific, economic and societal progress, we are left wondering whether the existing challenges surrounding personal data management will be solved by then — or whether they will only be exacerbated. This sci-fi short story depicts a future where individuals, since a young age, question whether they still retain agency over their lives and their destinies, given that data-hungry personalized services surveil them extensively and steer their personal development. Returning to science fiction narratives to explore a societal issue at the edge of technology and law has a threefold purpose, in: (1) developing critical skills and exploring future consequences safely through the imagination; (2) fostering foresight and proactivity in policy-making; and (3) democratizing the debate about technological developments that concern us all. If this story depicts a desirable or undesirable future is left to the readers to assess.","",""
"2023","A phenomenology of risks and trust in datafied media","As data collection and analysis have become essential to digital media, citizens are left with the task of evaluating the risks associated with their consumption. Drawing on Schütz and Giddens, this paper develops a phenomenological framework to explain how citizens assess risks regarding the datafication of their media experiences and give their trust to datafied media in the context of everyday life. We identify a continuum of four zones of relevance (from control, concern, distance to irrelevance) in which risks are moved around, documenting three main responses by which citizens assess risks of datafied media. The findings show that while citizens are encouraged to make a variety of risks relevant, they go through a process of ‘distanciation’ when they do not have the agency to control and mitigate these risks. We discuss these findings in relation to the development of data literacy and regulation.","",""
"2023","Data and/as activism: Community-based racial justice data repertoires"," This article maps the racial justice data repertoires of 11 community- and university-based projects at the nexus of racial and data justice. To examine them, I propose a typology of these co-occurring data activism strategies. Using a qualitative content analysis of organizations’ public statements ( n =  74), the typology allows me to examine the diverse, strategic nature of racial justice data repertoires. Their wide array reveals the contentious racial politics of data, or the ways data reproduces racial inequalities but can also be mobilized to contest them. ","",""
"2023","Regimes of justification in the datafied workplace: The case of hiring"," The uptake of data-driven hiring systems has introduced important questions about how decisions about who is eligible for jobs, and why, are changing. To explore this, the article draws on interviews with prominent providers of data-driven hiring systems and analyses the way they situate the provision of tools in relation to existing hiring processes, what problems they claim to solve, and the nature of the solutions they provide. While the ideological grounds of datafication have been well-established, privileging data-driven knowledge production as less biased, more objective, and with superior insights than other forms of information-gathering, in hiring, we find legitimisation frames extend to ways in which work and workers should be organised and assessed. Drawing on the notion of ‘regimes of justification’, we argue that such legitimisation frames in turn invoke certain normative expectations about what is just and unjust organised around a vision of the common good. ","",""
"2023","What are the risks of Virtual Reality data? Learning Analytics, Algorithmic Bias and a Fantasy of Perfect Data"," Virtual reality (VR) is an emerging technology with the potential to extract significantly more data about learners and the learning process. In this article, we present an analysis of how VR education technology companies frame, use and analyse this data. We found both an expansion and acceleration of what data are being collected about learners and how these data are being mobilised in potentially discriminatory and problematic ways. Beyond providing evidence for how VR represents an intensification of the datafication of education, we discuss three interrelated critical issues that are specific to VR: the fantasy that VR data is ‘perfect’, the datafication of soft-skills training, and the commercialisation and commodification of VR data. In the context of the issues identified, we caution the unregulated and uncritical application of learning analytics to the data that are collected from VR training. ","",""
"2023","Data and oil: Metaphor, materiality and metabolic rifts"," ‘Data is the new oil’ is a phrase that is frequently employed to indicate that digital technologies and data extraction have supplanted fossil fuels and geological extractivism as the central driver of the global economy. While this metaphor has been subject to discursive and ideological critique within media, communication and cultural studies, this article conducts a materialist analysis of the connections between data and oil. While claims that data is the new oil typically assume digital technologies to be clean, renewable and sustainable, an infrastructural approach reveals the vast quantities of oil and other fossil fuels necessary for digital capitalism, therefore repudiating claims that data can grow exponentially with no material costs. Consequently, the article explores how metabolic rifts and degrowth offer productive frameworks for outlining the contours of a sustainable and equitable digital future. ","",""
"2023","Researching publics in datafied societies: Insights from four approaches to the concept of ‘publics’ and a (hybrid) research agenda"," Datafication has become an all-encompassing infiltrator in societal processes, among other the formation of publics and the actors that support such processes (i.e. journalism and information technologies). This article reviews four approaches to the study of public formation. These are (1) public and civic connections, (2) issue publics, (3) networked publics and (4) algorithmic publics. The review is a point of departure to conceptually discuss how to study the formation of public in a datafied era and to present a hybrid research agenda with four entry points that can open up for critical analysis of how datafication challenges the relationship between journalism, platforms, algorithms and audiences. Our argument is that a holistic, interdisciplinary and hybrid research approach is needed if the complexity of datafication and its transformative effects on the formation of publics is to be fully grasped. ","",""
"2023","Datafication research: Mapping the field for a future agenda"," A growing body of research centers around the concept of “datafication” suggesting a buzz around data studies and, perhaps, the emergence of a research field. This article analyzes and discusses the current state of datafication research. Our dataset comprises 463 publications on datafication identified through a systematic literature search in Web of Science and Scopus, an explorative network analysis of keyword co-occurrences and a content analysis of these publications. We map datafication research interests in various research fields, find that the majority of studies are theoretically oriented, whereas empirical analyses largely apply qualitative approaches and rarely make use of data-driven methods. We suggest studies on datafication can be devised into categories reflecting research interests in either user understandings and practices or in infrastructure and technological processes of datafication. The latter strand is particularly sparse in empirical anchoring, and needs empirical and methodological attention. We conclude by outlining three paths for future datafication research to cross-pollinate infrastructural and user perspectives, highlighting the bridging role of communication research in such an endeavor. ","",""
"2023","The conventions and politics of migration data visualizations"," What visual features characterize online migration data visualizations, and what do they suggest for the politics of representing migration and informing public attitudes? Audiences increasingly encounter quantitative information through visualization, especially in digital environments. Yet visualizations have political dimensions that manifest themselves through “conventions,” or shared symbols and practices conveying meaning. Using content analysis, I identify patterns of representation in a sample of 277 migration data visualizations scraped from Google Images. I find evidence of several conventions including appeals to objectivity and traceability as well as perspectives and units of analysis centered on states—particularly higher income migrant destinations. Then, by locating my analysis within the growing field of digital migration studies, I argue these conventions potentially shape public attitudes and understandings about migrants, and contribute to broader migration politics involving categorization and quantification that have relevance both on- and off-line. ","",""
"2023","Setting data free: The politics of open data for food and agriculture"," Open data is increasingly being promoted as a route to achieve food security and agricultural development. This article critically examines the promotion of open agri-food data for development through a document-based case study of the Global Open Data for Agriculture and Nutrition (GODAN) initiative as well as through interviews with open data practitioners and participant observation at open data events. While the concept of openness is striking for its ideological flexibility, we argue that GODAN propagates an anti-political, neoliberal vision for how open data can enhance agricultural development. This approach centers values such as private innovation, increased production, efficiency, and individual empowerment, in contrast to more political and collectivist approaches to openness practiced by some agri-food social movements. We further argue that open agri-food data projects, in general, have a tendency to reproduce elements of “data colonialism,” extracting data with minimal consideration for the collective harms that may result, and embedding their own values within universalizing information infrastructures. ","",""
"2023","Utopian and Dystopian Sociotechnical Imaginaries of Big Data","Data feminism, a way of thinking about and “doing” data utilizing feminist tools and perspectives, has emerged in recent years as a part of a critical discourse surrounding datafication. The aim of this study is to analyze and identify shared perceptions of big data as expressed in a corpus of scholarly writings published in the domain of data studies and data feminism. We analyzed a set of 44 scholarly texts engaging in feminism concerned with the concept of big data. For the purpose of this article, we refer to this set of texts as data feminism and examine how authors frame and describe big data. We compare future visions in data feminist material with policies by the European Commission and explore what tensions arise among them. Furthermore, we explore and delineate social and political alternatives that emerge from data feminist texts. Both corpora describe futures inclusive of big data and imagine possible positive outcomes from different perspectives and with different ideas of the current role of big data. We found that sociotechnical imaginaries of big data within the data feminist corpus are considerably richer and more nuanced than those of the European Commission. In the data feminist corpus, big data is described as a multiplicity of things and often implicated in perpetuating power imbalances and large societal issues. The European Commission corpus employs the perspective of “data as a resource” to be exploited.","",""
"2023","Centralising Qualitative Research in Big Data Methods Through Algorithmic Ethnography","Responding to the challenge for qualitative researchers to claim a central place in conversations about big data, analytics, datafication, data mining and the role of algorithms, this article describes a mixed-method research partnership focused on algorithmic ethnography. In the debates about the opacity of online algorithms, qualitative researchers typically advocate for access to code. This standard discourse centralises the technical aspects of big data and networked ethnographies. Instead, this article outlines a research methodology that analyses algorithmic discourses by working alongside the technical expertise of data scientists and utilizes the affordability of big data methods to do qualitative work. The potential for qualitative research skills to investigate the underlying technical processes that frame online social interactions is proposed as a way to place how people understand the world at the centre of big data research.","",""
"2023","Data Worlds: An Introduction","Abstract                This introductory article calls attention to the shift from the “big data” discourse of the 2000s to the current focus on “AI” in its supposedly “responsible” and “human-centered” forms. Such rhetoric helps deflect attention from the profitable and surveillant accumulation of data and the worrisome concentration of power in a handful of companies. Alert to this problematic political economy, the issue's editors engage recent theories of data capitalism and argue that attention to processes of datafication helps to elude the pitfalls of data positivism, data universalism, and unintentional criti-hype. As the authors touch upon each contribution to this special issue, they call for critical AI studies to forge an interdisciplinary community of practice, alert to ontological commitments, design justice principles, and spaces of dissensus.","",""
"2024","Public value in the making of automated and datafied welfare futures","Across Europe, the public sector is expanding its efforts to introduce data-driven decision-support and intelligent systems in the administration of welfare. The growing body of research that highlights the impact and harms these systems have on citizens’ lives, raises questions about the guiding ideas, values, and norms that are at the heart of current transformations in welfare. Research in critical data studies contends a silent marketisation of social protection and governance. It implies an intricate entanglement between the procedures and output of service provision on the one hand and the normative outcomes in terms of the well-being and flourishing of society as a whole on the other hand. Thinking with the capabilities approach and buen vivir as well as with the concept of data justice, our paper asks how to conceptualise this relation. It discusses how (in)justice may become a sociomaterial component in automated welfare and emphasises that welfare outcomes and welfare practices, including their procedural aspects, are rather co-produced than just interdependent. We conclude that whether future infrastructures of welfare will create public value or not, depends on the institutional arrangements, policies, and norms built to distribute the emerging benefits and risks equally in society.","",""
"2024","Resistance in the data-driven society","Individuals and groups increasingly seek to resist the harms and risks of a data-driven society. This essay explores the possibility of individual and collective resistance vis-à-vis datafication, drawing on examples from across the globe. It shows how infrastructure, political agency, and tactics have changed in response to datafication. It reviews six resistance tactics, distinguishing between “defensive resistance” and “productive resistance”: self-defence, subversion, avoidance, literacy, counter-imagination, and advocacy campaigning. Investigating them offers insights on the ability of social actors to contribute to innovation in mobilising practices amidst intrusive surveillance.","",""
"2024","Fulfilling data access obligations: How could (and should) platforms facilitate data donation studies?","Research into digital platforms has become increasingly difficult. One way to overcome these difficulties is to build on data access rights in EU data protection law, which requires platforms to offer users a copy of their data. In data donation studies, researchers ask study participants to exercise this right and donate their data to science. However, there is increasing evidence that platforms do not comply with designated laws. We first discuss the obligations of data access from a legal perspective (with accessible, transparent, and complete data as key requirements). Next, we compile experiences from social scientists engaging in data donation projects as well as a study on data request/access. We identify 14 key challenges, most of which are a consequence of non-compliance by platforms. They include platforms’ insufficient adherence to (a) providing data in a concise and easily accessible form (e.g. the lack of information on when and how subjects can access their data); (b) being transparent about the content of their data (e.g. the lack of information on measures); and (c) providing complete data (e.g. the lack of all available information platforms process related to platform users). Finally, we formulate four central recommendations for improving the right to access.","",""
"2024","Who cares about data? Data care arrangements in everyday organisational practice","ABSTRACT The increasing datafication of social life has led to a growing body of research on data work which focusses on new data practices like self-tracking, new professions like data analysts or new occupational roles. In these new types of data work, people develop strong affective relations to data, and caring for data (quality) is key. This attention to ‘spectacular’ data work however leads to an important oversight: Much of the data work in everyday organisational practice is done by workers ‘somehow’, in addition to and alongside their existing tasks. This article sets out to better understand this mundane data work. It asks: Why and how do people in organisations care for data? Based on two qualitative case studies, we present the concept of data care arrangements. Data care arrangements are configured through the ascription of values to (specific) data sets and the work of generating, maintaining, and repairing data. This data care work is not necessarily homogeneous in organised settings but can become stabilised in data care arrangements. Thus, the notion of data care arrangements underlines that data in everyday organisational practice are not an object of care per se, but that data care is an accomplishment.","",""
"2024","Torquing patients into data: enactments of care about, for and through medical data in algorithmic systems","ABSTRACT The increasing digitisation of healthcare services has transformed healthcare provision into a data-centric enterprise. Thinking with Joan Tronto and her notion of care, we study medical data practices in the context of a health-tech company developing an algorithmically driven platform to match patients and their physicians with clinical trials. What does it mean to pose the patient in the centre in such a context? In this paper, we show how the enactments of patient-centrism translate to multidimensional enactments of data care for a diversity of domain experts handling medical data, informed by the values and backgrounds of each ‘data handler’ situated within the concerns of their domain expertise. Where data experts engage solely with the patients’ data to facilitate data creation for the platform’s algorithmic system, the quest for data quality depends on the preceding practices of care and affective labour about and for the patients. We show how patients get help to torque their medical records and histories into data to fit the demands of the system to ensure access to experimental treatments and clinical trials. We demonstrate how patient-centrism manifests as care for data quality, shaped throughout by differentiated concerns for regulatory compliance. Finally, we argue that regulatory compliance constitutes a care practice across data work that is diversified in its enactments by the experts’ domain concerns and backgrounds.","",""
"2024","Care-ful data studies: or, what do we see, when we look at datafied societies through the lens of care?","ABSTRACT In this special issue, we ask: What do we see when we look at datafied societies through the lens of care? Following the footsteps of feminist writers, activists, and academics who take care as a vantage point for scrutinising and reimaging technoscientific societies, this special issue brings together scholars from critical data studies who explore what we might learn (and see) when we apply care ethics to the study of datafication. To develop a view on datafied societies informed by ethics, concepts, and practices of care, we propose a move from critique to care in social studies of data-driven technologies. We specifically identify five moves in which a care lens provides a new perspective when studying datafication and datafied societies: (1) a move from data-driven technologies to socio-digital care arrangements, (2) a move from data science to data work and care, (3) a move from technical to situated modes of knowledge production, (4) a move from studying harms of datafication to the politics of vulnerability, and (5) a move towards building communities of care. Discussing how critical data studies and care ethics can mutually contribute to each other, this collection explores how this way of thinking can inform new ways of seeing datafied societies and imagine living and being well in more than human worlds nurtured by care.","",""
"2024","Sphere transgressions in medical research: tactical engagements with Apple’s ResearchKit","ABSTRACT In the last decade, large technology companies have started many initiatives to stimulate and innovate in the sphere of medical research. A prominent example is the ResearchKit software framework launched by tech giant Apple in 2015. This software framework enables medical researchers to develop research apps on the iPhone that collect and access diverse types of research data. The ‘sphere transgressions’ theoretical lens (Sharon, 2021a; 2021b) draws attention to the risks associated with such initiatives. For instance, that large technology companies could utilize the initiatives to change the sphere of medical research in line with their own values and interests. However, the theoretical lens risks portraying a simplistic one-directional understanding of Big Tech colonizing the sphere of medical research. This paper draws attention to medical researchers and their everyday interactions. Based on interviews with medical researchers using Apple’s ResearchKit in the Netherlands and the United States, the paper shows that researchers are not passive recipients of Big Tech’s initiatives. Instead, they respond to their initiatives in a variety of ways: not simply by welcoming or resisting Apple’s ResearchKit, but also by ‘making do’ using a variety of tactics (de Certeau, 1984). Thinking in terms of tactics, it is argued in the discussion, helps to identify needs and interests that are of crucial importance to researchers and the broader sphere of medical research. These insights can be used to strengthen the sphere of medical research and promote responsible innovation.","",""
"2024","Data phronesis and the duality of care in the air quality data politics","ABSTRACT This article delves into the intricate dynamics of air datafication as matters of care within the distinctive context of air quality data politics in Poland. It focuses on the implementation of data-mediated care for air quality, scrutinizing two interconnected dimensions: data practices and data phronesis. The former involves the meticulous handling of air quality data, while the latter explores the phronetic valuation of more-than-human realms, including data standards, air sensing technologies, and a diverse array of actors integral to the datafication process. Data phronesis is conceptualized as the situated and context-dependent practical wisdom demonstrated by various actors, shaping the definition of ‘good’ data-mediated care for air quality. The article emphasizes the duality of care, highlighting the interplay between data phronesis and data practices. It underscores the ongoing negotiation surrounding air quality concerns, intricately mediated through data, within relational and contextual dimensions. Through an in-depth qualitative examination and Reflexive Thematic Analysis, four key themes, related to data-mediated air quality care, are identified: ‘caring about data,’ involving the valuation of situated data practices; ‘caring for data,’ translating polluted air into reliable data, while considering dominant standards; ‘caring by data,’ defining data usage methods within dynamic contexts; and ‘data for caring,’ exploring practical applications, particularly activist practices integrating diverse local contexts with European air quality standards. The article enriches our understanding of datafication as matters for care, shedding light on the interconnections between hands-on data practices and the contextual wisdom steering strategic action.","",""
"2024","When data became big: revisiting the rise of an obsolete keyword","ABSTRACT This article unpacks the short-lived but momentous buzz around big data. Although talk about big data was once widespread, little is known about the efforts animating its semantics. Tracing this sociotechnical imaginary, we revisit how business insiders and IT commentators fueled the ephemeral yet potent excitement around the term. Our genealogical examination rests on a selection of publications from 2013 to 2017. We employ methods from critical discourse analysis to interrogate how big data was written into being and hyped into a topic of concern. In this aspirational discourse, tech evangelists and writers extrapolated from contexts in which large troves of data were already being harnessed to suggest that inescapable transformations were imminent. They sought to concretize abstract and unfathomable quantities while simultaneously overwhelming their readers with a sense of vastness that exceeds all contexts and outruns the most exuberant expectations. The term may have lost this luster, but big data technologies and practices are an integral part of today’s technological infrastructures.","",""
"2024","Care, collaboration, and service in academic data work: biocuration as ‘academia otherwise’","ABSTRACT This paper discusses the emergent field of biocuration, taking it as a case of academic data work. Biocurators organise, manage, and enrich the now vast quantities of data that are produced by the contemporary biosciences, but their work remains largely invisible to the scholarly communities that make use of it. Based on ethnographic engagement with the field and interviews with biocurators, and mobilising conceptual frames of care and epistemic justice, we examine how biocurators frame their data practices, arguing that biocuration can, in emphasising collaboration and care, be seen as an ‘academia otherwise’ that resists dominant narratives of scholarly excellence. At the same time this explicit framing of data work as care work involves a ‘dark side’ that elides the epistemic labour involved in it. In closing we suggest that engagement with biocuration leads us to attend to the ways in which care work constitutes technoscientific knowledge, and to the epistemic contributions it may make.","",""
"2024","The data subject and the myth of the ‘black box’ data communication and critical data literacy as a resistant practice to platform exploitation","ABSTRACT This conceptual paper explores the role of communication around data practices of Big Tech companies. By critiquing communication practices, we argue that Big Tech platforms shape users into data subjects through framing, influencing behaviour, and the black-boxing of algorithms. We approach communication about data from three perspectives: (1) current data communication constructs reductive data identities for users and contributes to the colonization of daily routines; (2) by strategically deploying the black box metaphor, tech companies try to legitimize abuses of power in datafication processes; (3) the logic in which communication is mediated through the interfaces of Big Tech platforms is normalizing this subjectification. We argue that critical data literacy can foster individual resilience and allows users to resist exploitative practices, but this depends on transparent communication. The opposite seems standard among tech companies that obfuscate their data practices. Current commercial appropriations of data ethics need to be critically assessed against the background of increasing competition in the digital economy.","",""
"2024","Challenging assumptions about the relationship between awareness of and attitudes to data uses amongst the UK public","Abstract This article advances understanding of the relationship between (a) people’s awareness of and (b) their attitudes toward the ways in which data about them is collected, analyzed, shared, and used. It draws on an online survey of 2000 adults in the UK, which found that people with greater awareness of data uses hold more negative attitudes toward them. This finding is important because it challenges the deficit model which underlies initiatives that seek to improve the public’s attitudes toward and trust in institutional data uses through improved transparency or better data literacy.","",""
"2024","Legal imagination and the US project of globalising the free flow of data","AbstractToday, the US pursues the global capture of data (understood as a significant engine of growth) by way of bi- and plurilateral trade agreements. However, the project of securing the global free flow of data has been pursued ever since the dawn of digital telecommunication in the 1960s and the US has made significant legal efforts to institutionalise it. These efforts have two phases: In the first 1970s and 80s “freedom of information” phase, the legal justification (and contestation) of the global free flow of data hinged on imagining data as information, and its exchange as a practice of liberty. The second phase began in the late 1990s and continues today. In this phase, the free flow of data is aligned with a free-trade agenda in the context of first e-commerce and, starting in the 2000s, through attempts at creating a global public domain of personal data for the platform economy. The global free flow of data is an intrinsic aspect of informational capitalism. Assuming a constitutive, but not commanding role for law in informational capitalism, we conclude that the US attempt at ensuring free flow for its informational corporations is neither an entirely contingent nor a necessary outcome. It is a product of legal imagination.","",""
"2024","Perspectives of patients and clinicians on big data and AI in health: a comparative empirical investigation","Abstract                 Background                 Big data and AI applications now play a major role in many health contexts. Much research has already been conducted on ethical and social challenges associated with these technologies. Likewise, there are already some studies that investigate empirically which values and attitudes play a role in connection with their design and implementation. What is still in its infancy, however, is the comparative investigation of the perspectives of different stakeholders.                                Methods                 To explore this issue in a multi-faceted manner, we conducted semi-structured interviews as well as focus group discussions with patients and clinicians. These empirical methods were used to gather interviewee’s views on the opportunities and challenges of medical AI and other data-intensive applications.                                Results                 Different clinician and patient groups are exposed to medical AI to differing degrees. Interviewees expect and demand that the purposes of data processing accord with patient preferences, and that data are put to effective use to generate social value. One central result is the shared tendency of clinicians and patients to maintain individualistic ascriptions of responsibility for clinical outcomes.                                Conclusions                 Medical AI and the proliferation of data with import for health-related inferences shape and partially reconfigure stakeholder expectations of how these technologies relate to the decision-making of human agents. Intuitions about individual responsibility for clinical outcomes could eventually be disrupted by the increasing sophistication of data-intensive and AI-driven clinical tools. Besides individual responsibility, systemic governance will be key to promote alignment with stakeholder expectations in AI-driven and data-intensive health settings.               ","",""
"2024","Blurring the moral limits of data markets: biometrics, emotion and data dividends","AbstractThis paper considers what liberal philosopher Michael Sandel coins the ‘moral limits of markets’ in relation to the idea of paying people for data about their biometrics and emotions. With Sandel arguing that certain aspects of human life (such as our bodies and body parts) should be beyond monetisation and exchange, others argue that emerging technologies such as Personal Information Management Systems can enable a fairer, paid, data exchange between the individual and the organisation, even regarding highly personal data about our bodies and emotions. With the field of data ethics rarely addressing questions of payment, this paper explores normative questions about data dividends. It does so by conducting a UK-wide, demographically representative online survey to quantitatively assess adults’ views on being paid for personal data about their biometrics and emotions via a Personal Information Management System, producing a data dividend, a premise which sees personal data through the prism of markets and property. The paper finds diverse attitudes based on socio-demographic characteristics, the type of personal data sold, and the type of organisation sold to. It argues that (a) Sandel’s argument regarding the moral limits of markets has value in protecting fundamental freedoms of those in society who are arguably least able to (such as the poor); but (b) that contexts of use, in particular, blur moral limits regarding fundamental freedoms and markets.","",""
"2024","Data communism: Constructing a national data ecosystem"," Over the past decade, China has gradually begun to take a more proactive approach to digital development, passing a range of policies that aim to restructure how data is treated within its national economic system. These policies reflect the construction of a new data ecology in which data is gradually reconceptualized as a quasi-public good, rather than a private good. Strategic interventions aim to increase data circulation and supply, with the goal of promoting high-quality economic growth. Central to these reforms is the designation of data as a factor of production, which accelerates the authority of the communist party to shape the allocation of data within the national economic system. Viewed holistically, these policies reflect an intentional effort to construct a more communal data ecosystem that facilitates increased data circulation in support of a state-led centralized approach to social and economic development. What emerges is a variety of data communism, in which data resources are increasingly conceptualized to serve collective interests rather than the interests of capital. ","",""
"2024","Enacting data context: Fixing meaning in transparency data initiatives"," This article documents the “context cultures” underpinning efforts to develop regulations for collecting and reporting data in a United States public database known as Open Payments. Open Payments is a dataset published annually by the US Center for Medicare and Medicaid Services that documents the transfers of value from pharmaceutical and medical device manufacturers to physicians, prescribing non-physicians, and teaching hospitals. In the article, I show context became a manifold concern as differentially-situated actors engaged in modes of public advocacy and social action around not only what data meant, but also what it meant to make data meaningful. I show how “context” took on multiple meanings as it was brought into relationship with certain concepts (such as “light,” “transparency,” and “interpretation”) and as stakeholders developed arguments for where they believed meaning should originate. In presenting this case, I call for further ethnographic attention to the ways in which meaning-making is enacted in relation to datasets—particularly those datasets intended to hold institutions accountable. I conclude the article meditating on the political significance of attending to various “context cultures” when putting data signification in context, along with the implications for how critical data studies scholars historicize big data epistemologies and rhetoric. ","",""
"2024","Responding to unusual government request for user data: How tech companies make sense of human rights"," Data sharing practices between governments and the private sector are characterized by a lack of transparency which has potential implications for human rights. Minimal scholarship exists investigating how companies address human rights risks stemming from government requests for user data. Understanding corporate response processes to government requests is central to advancing human rights research at the intersection of tech company conduct. This becomes even more pressing as emerging technologies gather increasing amounts of data. Scholarship demonstrates that transparency reporting cannot assist in analyzing data sharing practices between the private and the public sectors due to a variety of constraints. Using semi-structured interviews with senior staff at technology companies, this paper presents an empirical analysis of how technology company representatives and external advisors seek to align their processes when responding to government requests for user data. It describes a set of six themes using human rights terminology which company representatives aim to employ when responding to requests. ","",""
"2024","Health in data space: Formative and experiential dimensions of cross-border health data sharing","Healthcare is increasingly datafied, and a wide range of actors—patients, clinicians, administrators, policymakers, and industry lobbyists—want to be able to exchange and access health data internationally and use them for an increasing number of purposes. Therefore, competing initiatives aimed at fostering international data integration proliferate, with the proposed European Health Data Space as one of the most prominent examples. But how do legislators conceptualize a health data space? And what could they gain from rethinking the governmental object of this legislation? To explore these questions, we suggest taking the term “data space,” present in the European Health Data Space initiative, and develop it theoretically to establish a vocabulary fit for understanding international data-intensive health environments. Space is a concept with appealing affordances. It is a way of naming a mode of being which is simultaneously symbolic and material, abstract and concrete, social and physical. We show how these affordances of the concept of space can be helpful when exploring new ways of living in cross-border data-intensive healthcare settings. Whereas policy reports often describe data sharing as a matter of providing technical means and legal provisions to “wire together” existing data resources, we argue that data spaces should be understood as sociotechnical constructs enacted through three formative and four experiential dimensions.","",""
"2024","Mapping the discursive landscape of data activism: Articulations and actors in an emerging movement"," Growing awareness of the societal consequences of datafication in recent years has given rise to a new form of civil society engagement called data activism. This article examines the discourse surrounding data activism on the social media platform Twitter. Through a mixed-methods approach combining computational analysis of Twitter content and close readings of Twitter profiles, we explore how new forms of civil society action related to data justice are articulated and linked to other forms of activism, conflicts and problems, and the actors involved in these articulations. Our analysis reveals a distinction between two articulatory patterns in the data activism discourse. The first involves grassroots actors, such as community organisations and individual citizens, who challenge existing power structures and advocate for social change. The second, on the other hand, is associated with academics, capitalists and policymakers who already hold positions of power and influence. This asymmetry is consistent with previous findings in data activism research. We encourage future research to extend these patterns, using additional methods and case studies, to further refine and contextualise the understanding of data activism within the civil society realm. ","",""
"2024","Local government cultural economy data practices and futures: Capacity,  decision-making and partnerships"," This article investigates local government cultural economy data practices in England (UK). Engaging with academic literature and policy reports, it highlights the following issues relating to these data practices: types of data; the context and drivers for using data; the possibilities and challenges of data volume; and training and expertise required to position data in relation to strategic decision-making. Engaging with the authors’ research project with local government councillors and data officers working in local authorities in England, this article provides insights into situated experiences and working contexts. The analysis reveals specific challenges and opportunities around resources and capacity, decision-making and partnerships. These data practices and challenges are critically examined through perspectives from critical data studies and the data feminism principles of context and visibility. Insights and issues are raised around decision-making, intuition and capacity, expertise and gatekeeping and more encompassing concerns around data characteristics and social power. In response, approaches from data literacy, namely data biographies, are explored to inform interventions into local government cultural economy data practices. ","",""
"2024","Cleaning up data work: Negotiating meaning, morality, and inequality in  a tech startup"," Data work—the routinized, information-processing operations that support artificial intelligence systems—has been portrayed as a source of both economic opportunity and exploitation. Existing research on the moral economy of data work focuses on platforms where individuals anonymously complete one-off projects for as little as one cent per task. However, data work is increasingly performed inside organizational settings to promote more consistent and accurate output. How do technologists and data workers construct and morally justify these arrangements? This article is based on 19 months of participant-observation research inside a San Francisco-based startup. Drawing on theories of relational work, I show how managers in San Francisco and contractors in the Philippines collaborated to “clean up” the morally questionable status of data work. Managers attempted to engineer interactions with data workers to emphasize fun and friendship while obscuring vast inequalities. Filipino data workers framed American managers as benevolent patrons and themselves as grateful clients to reinforce managers’ sense of responsibility for their well-being. By shifting attention from the structure of roles to the structure of relationships in organization-based data work, this article demonstrates the function of culture and meaning-making in both generating reliable and accurate data and reproducing status hierarchies in the tech industry. Additionally, this article's examination of the complex and often contradictory dynamics of organizational attachment and marginalization has implications for debates about how the conditions of data work can be improved. ","",""
"2024","Strong or thin digital democracy? The democratic implications of Taiwan's open government data policy in the 2010s"," What kind of “democracy” do new government-led digital initiatives facilitate? This paper discusses the issue by investigating the open government data policy in Taiwan in the 2010s, asking whether the policy encouraged “strong democracy.” Using interviews, written records, and an analysis of platform design, I argue that the implementation of Taiwan's open data policy has not institutionalized the engagement of civil society groups or ordinary citizens in government decision-making processes, which is at odds with the claims that open government data encourages “strong democracy.” Instead, open government data in Taiwan has facilitated monitorial democracy, which presupposes watchful but not active citizens, and neoliberal democracy, which presupposes profit-pursuing citizens. Both are more in line with “thin democracy,” which focuses more on individual rights and private interests than on participation and political community. The finding sheds light on why conservative governments around the world often embrace open government initiatives. ","",""
"2024","‘Data saves lives’: Ideational-material drivers of health data journeys in the UK"," In this paper, we bring together the concepts of data valences and data journeys to examine how ideational and material factors work together to shape the movement of health data from the UK healthcare sector to universities for reuse in research. Specifically, we focus on the interaction of university-based researchers’ constructs about data with the material conditions of health data circulation in the UK and how these dynamics drive greater circulation of health data through the data sharing infrastructure. Building on our empirical research, we identify four data valences or expectations about data present in the discourses of university-based researchers – vanguard, discovery, truthiness and actionability – and three material factors – investment in data, infrastructure and labour. We argue that the interaction of these factors has created a favourable environment for making data flow from the healthcare sector into the hands of university-based researchers. This work contributes to a better understanding of why health data reuse practices are expanding and being sustained, and it challenges previous health data reuse research that treats the drivers shaping data flows as self-evident or already determined. ","",""
"2024","Problem-solving? No, problem-opening! A method to reframe and teach data ethics as a transdisciplinary endeavour"," Starting from the recognition of the limits of today's common essentialist and axiological understandings of data and ethics, in this article we make the case for an ecosystemic understanding of data ethics (for the city) that accounts for the inherent value-laden entanglements and unintended (both positive and negative) consequences of the development, implementation, and use of data-driven technologies in real-life contexts. To operationalize our view, we conceived and taught a master course titled ‘Ethics for the data-driven city’ delivered within the Department of Urbanism at the Delft University of Technology. By endorsing a definition of data as a sociotechnical process, of ethics as a collective practice, and of the city as a complex system, the course enacts a transdisciplinary approach and problem-opening method that compel students to recognize and tackle the unavoidable multifacetedness of all ethical stances, as well as the intrinsic open-endedness of all tech solutions, thus seeking a fair balance for the whole data-driven urban environment. The article discusses the results of the teaching experience, which took the form of a research-and-design workshop, alongside the students’ feedback and further pedagogical developments. ","",""
"2024","Data as environment, environment as data: One Health in collaborative data-intensive science"," This article analyses the operationalization of One Health in the context of data-intensive science in response to the COVID-19 outbreak. Building on ethnographic field research and revisiting the lives of a knowledge infrastructure of interdisciplinary collaboration set up online in the early phase of the COVID-19 health emergency, the article develops the notion of “data as environment.” This environment is a contact structure that entangles knowledge systems, subjects, processing tools, and mediated bio-socialities in processes of data-intensive knowledge co-production. Claims for new collaborative approaches between the biomedical, environmental, and social sciences are increasingly marked by the emergence of digital knowledge-making infrastructure that leverages data, knowledge, and expertise from different disciplines and sectors to increase scientific productivity via data-sharing technologies. Yet, digital knowledge-making infrastructures appear self-evident when they are in place, while data are often conceived as inert and disembodied information units separated from social relations of research. The argument that data are an environment expands anthropological thinking on data and digital knowledge-making infrastructures by enlightening political-ethical questions that are at stake in the emerging technoscientific worlds of the Anthropocene. ","",""
"2024","Digitalisation, democracy and the GDPR: The efforts of DPAs to defend democratic principles despite the limitations of the GDPR"," This article discusses the perspectives of European Union (EU) / European Economic Area Data Protection Authorities (DPAs) on their role in protecting democratic rights and freedoms in digitalised societies. Data Protection Authorities, which are independent regulators, are responsible for implementing the EU's General Data Protection Regulation in their respective countries. The views of DPAs are important given their special role in monitoring newly emerging digital technologies and how their use may impact on the functioning of democracies. The article highlights three key themes which emerged in interviews with 18 DPAs in answer to the question about what they consider to be the greatest challenges to democratic freedoms. These are: (1) threats to elections due to the manipulation of voters; (2) discriminatory effects of automated decision-making; and (3) broader chilling effects on democratic norms due to ubiquitous surveillance. The article then analyses the solutions named by DPAs to mitigate these challenges to identify their governing, or political, rationalities. The paper finds that the solutions available to DPAs to manage democratic harms tend to emphasise individual over collective responsibility and are connected to broader currents of neoliberal governance. The paper highlights the ways in which some DPAs act as important critical voices within their respective jurisdictions to draw political attention to potentially anti-democratic effects of certain practices, such as profiling, or to the model of digitalisation as it is currently constructed. ","",""
"2024","Official statistics and big data in Latin America: Data enclosures and counter-movements"," With the rise of the data-driven economy, the state-owned sector of official statistics has been pressurised to ‘modernise’ and engage with big data. However, most of these data sources are controlled by tech corporations. We address the conflicts this brings about from a Latin American perspective through three case studies involving national statistical offices, international organisations, and the private sector. We investigate strategies for enabling data markets for official statistics and analyse how the statistical field has acted in this context. In doing so, we contribute to understanding the political economy of big data in Latin America and debates on how digitalisation encompasses the reshaping of state-business relations. Supported by secondary data and semi-structured interviews, we appraise Bourdieu's theory of fields, Marxian readings on the enclosure of commons, and Polanyi's double movement to analyse how data commodification challenges data as public goods – a fundamental principle for official statistics. The findings demonstrate that data enclosures have prevented the state's access to compiling official statistics and show that the initiatives for introducing big data in Latin American national statistical offices have involved testing data markets through public–private partnerships supported by international organisations and big tech. As a result, the statistical field has reacted to the data market with a ‘double movement’: mobilising symbolic capital such as ‘trust’ for partnering with businesses to access data and technologies and, conversely, defending the public value of data in counter-movements protective of the relative autonomy of the national statistical offices and the state's control over informational capital. ","",""
"2024","Data, anecdotes, anecdotal data: Feminist data activism against gendered violence post #Metoo"," From critiques of baked-in sexism in data science, to the use of data in the service of feminism, feminist data activism has emerged as a new form of feminist activism. This paper approaches feminist data activism from a data imaginary perspective, focusing on a prominent feminist initiative from Australia called She's A Crowd, an organization that claims to have crowdsourced the world's largest dataset of gendered violence. Through interviews with 11 participants who volunteered their “datafied stories” to the organization, I explore the grassroots imaginaries about what data is and what it can do for the collective struggle against gendered violence. I show that participants’ experiences with not being believed led them to see data-driven stories as having superior epistemic value over qualitative narratives. Paradoxically, even when data is viewed as superior due to its detachment from the personal, concerns about its authenticity and quality persist. Consequently, participants advocated for increased data collection as the ultimate solution to address these limitations. Thus, if the imaginary of a binary between “data” and “stories” privileges data as a superior epistemic solution, the imaginary of limitation reinforces more data collection as the only solution imaginable. I argue that at stake is how these imaginaries locate the legitimacy of marginalized experiences within the dataset, obscuring how data collected from the grassroots might circulate within and be interpreted by hegemonic knowledge practices. This paper opens a conversation about feminist data activism and the power relations it is enmeshed within, an area that remains under explored. ","",""
"2024","Doing place through data: Proliferation, profiling and the perils of portrayal in local climate action"," Building on work which has shown the role of digital technologies in reframing environmental relations, this paper explores ethnographically how environmental data is reconfiguring the concept of place. The paper takes as its focus an action-research project within a UK based, citizen-oriented initiative called Newtown Energy Futures, in which we sought to enfold climate and energy data into a social-justice informed attempt at climate action. By exploring how the project used data as an invitation for citizens to engage with and participate in local infrastructural and environmental dynamics, the paper sheds light on how environmental data came to participate in the making of place and in doing so raised questions about how to rebuild the socio-material relations through which ‘a sense of place’ might be reproduced. As climate and energy data increasingly demand that places become enrolled into environmental projects our findings suggest that data enables place to emerge as a ‘socio-technical potentiality’ an observation that has implications both for both engagement with, and the study of data and place. In practical terms, we suggest that this refiguration of place has the effect of creating hopeful trajectories for change, whilst also posing difficult questions about the limits of participation in a data-infused form of place-based politics. ","",""
"2024","Adjusting expectations actionable: Personalised treatment plan in anticipation of data-driven healthcare"," Our paper is a case study of the making of data-driven healthcare and anticipation work done by developer-experts in a project for implementation of an integrated patient data management platform in Finland. We focus on ‘personalised treatment plan’, a trope that experts regularly use when talking about the objectives of data management reform and their wishes for datafication of healthcare. We conceive of the personalised plan not primarily as a future vision or an outcome, but rather a tool of anticipation of work. Our analysis demonstrates two purposes for which the developer-experts used this tool. First, the plan enabled them to reconfigure the general expectations of datafication actionable and adoptable in the actual world of healthcare and to articulate datafication technology-to-come as concrete hopes and wishes, plans and assessments in the contexts of clinical practices and administration. Second, experts used the idea of a personalised plan for reasoning over and management of their own work. Among the fuzziness and commotion of the complex project, the plan helped them to create and maintain a workable order between the expectations, tasks and functions that the datafication technology should accomplish in healthcare in the future. Furthermore, we discuss the limitations of anticipation to take the specific political and economic contexts into account, which made the developers unprepared for the political interruption of the project. ","",""
"2024","With great (statistical) power comes  great responsibility: A comment on the ethics of using administrative data to investigate marginalised populations"," As health data infrastructure improves, we have the opportunity to link increasing volumes of data in order to investigate important health problems. This is perhaps most pertinent when looking at the experiences and outcomes of our most disadvantaged groups, who are often invisible in data obtained through primary research. Whilst these data offer enormous opportunity, there are also ethical implications in their use, which are less frequently discussed than in relation to their qualitative counterparts. As a diverse group of clinicians and academics working across public health, we share our experience and understanding of how we can improve our reflexivity in health data science and ensure that research in this area is ethically conducted in co-production with the people whose data we are using. We discuss the potential opportunities, challenges and impacts of using administrative data to investigate marginalised populations. ","",""
"2024","Asserting the public interest in health data: On the ethics of data governance for biobanks and insurers"," Recent reporting has revealed that the UK Biobank (UKB)—a large, publicly-funded research database containing highly-sensitive health records of over half a million participants—has shared its data with private insurance companies seeking to develop actuarial AI systems for analyzing risk and predicting health. While news reports have characterized this as a significant breach of public trust, the UKB contends that insurance research is “in the public interest,” and that all research participants are adequately protected from the possibility of insurance discrimination via data de-identification. Here, we contest both of these claims. Insurers use population data to identify novel categories of risk, which become fodder in the production of black-boxed actuarial algorithms. The deployment of these algorithms, as we argue, has the potential to increase inequality in health and decrease access to insurance. Importantly, these types of harms are not limited just to UKB participants: instead, they are likely to proliferate unevenly across various populations within global insurance markets via practices of profiling and sorting based on the synthesis of multiple data sources, alongside advances in data analysis capabilities, over space/time. This necessitates a significantly expanded understanding of the publics who must be involved in biobank governance and data-sharing decisions involving insurers. ","",""
"2024","Critical data studies with Latin America: Theorizing beyond data colonialism"," The article aims to theorize about critical data studies with Latin America beyond the framework of data colonialism, arguing that the long history of social thought in the region can contribute to a more nuanced understanding of the datafication. It discusses views around dependence, oppressions, and liberation, debating how Latin American authors can be useful for current critical data studies, in a more nuanced and complex vision. It presents the theoretical contributions of Lelia Gonzalez, dependency theorists and Enrique Dussel. Dependency theorists criticize evolutionary frameworks of development and can contribute to discussions around data sovereignty and overexploitation of labor. Gonzalez contributes to a complex vision of Amefrica Ladina, articulating multiple forms of oppression. Enrique Dussel presents a theory of technology considering totality and proposes an ethics of liberation that can be related to alternatives toward data justice and data commons. All theoretical frameworks contribute to thinking about datafication with Latin America not as an isolated phenomenon, but in relation to other countries in the world, and as an analytical key for the construction of alternatives. All perspectives are related to current debates on critical data studies and can make an important contribution to the construction of critical theories about data that consider Latin America also as a site of knowledge production. ","",""
"2024","How people connect fairness and equity when they talk about data uses"," As a mechanism for addressing data-related harms, fairness has been subjected to considerable criticism, seen as failing to acknowledge the power relationships that produce said harms, or as a ‘floating signifier’ devoid of specific meaning. In contrast to fairness, it is argued that equity does a better job of recognising data-related harms. Criticisms such as these emerge in specific cultural contexts and rarely acknowledge everyday understandings of terms and concepts. This paper engages with these criticisms, drawing on research exploring how 112 UK residents perceive data uses in specific public service organisations. We found that participants perceive fairness and equity to be interwoven with each other, a finding which shows that who gets to define what is fair matters and which challenges assumptions about what does and does not constitute thinking and talking data politics. We conclude by proposing that linking fairness with equity can be seen as a kind of everyday data solidarity. ","",""
"2024","Against decolonial reductionism: The impact of Latin American thinking on the data decolonization project"," This essay argues that Latin American scholarship and movement practice are key to understanding the dynamics of the datafied society and countering its inequities. Examining the sources of inspiration of a frontrunner seeking to decolonize the datafied society – the Big Data from the South Initiative ( BigDataSur) – we review Martín-Barbero's ontological shift from media to mediations, Freire's methodology centring individual agency and empowerment as a structural task of society, Mignolo's invite to take decoloniality as a praxis rather than merely an idea, Rodríguez's first-hand engagement with technology at the margins, Escobar's autonomous design for the pluriverse, and the critical ecology of eco-social movements. We engage with a new generation of Latin American thinkers who turn their gaze to core problems of today's systems of knowledge production, be they media or academia. Learning from these scholars, we warn against decolonial reductionism, namely the trend to evoke decolonial ideas and theories without fully committing to putting them into practice. We maintain that to decolonize datafication, we ought to also change how we generate knowledge about the datafied society. We outline three practical strategies that foster an open-ended dialogue on alternative approaches to datafication and scientific practice: multilingualism, public scholarship, and mentorship. ","",""
"2024","Workers’ right to the subject: The social relations of data production"," The use of data to profile and make decisions about data subjects for citizenship, targeted advertising, job recruitment and other reasons, has been eminently normalised, which is an emerging threat to protected spaces for personal subjectivation and identity formation. The ‘right to the subject’; or to agency via personal subject formation outside bilateral profiling; is at stake. This is especially true for workers. Algorithmic management infused with worker control mechanisms occurs in structurally and objectively unequal conditions within subjective, and unequal, social relations. Data harms protections in European privacy and data protection law, despite being heralded as the strongest in the world, are insufficient to protect workers’ right to the subject. Indeed, structural features of inequality within the capitalist data political economy mean that workers experience different power relations to consumers and citizens. Analysing the social relations surrounding policy features of ‘consent’, and ‘risk’, with focus on the General Data Protection Regulation (GDPR) and the negotiations for the AI Act, it is not difficult to see that these policies do not protect all data subjects’ rights to the subject identically. Indeed, workers never have the capacity to truly consent at work; and the risks workers face are different from that of other data subjects, such as consumers. Data subjects do not, across categories, have equal access to equality, within, and because of, the social relations of data production. From a cross-disciplinary perspective and with contributions to sociology, critical theory, media and policy studies, this article argues that workers’ right to the subject is at stake, in datafied social relations. ","",""
"2024","From permissive to resistive tactics: How audience members engage with and make sense of datafied journalism"," While audience data are pivotal to producing journalism, audiences’ perspectives on the issue have received relatively little attention. Addressing this gap, the paper examines audience members’ tactics for making sense of and engaging with the datafied journalism into which they contribute with their data. Empirically grounded in group interviews and instant-messaging group chats with 21 readers of prominent Finnish tabloid Iltalehti, the author identified four tactics, along a continuum from permissive to resistive: an audience member may 1) happily benefit from datafied journalism; 2) be resigned to it yet reflect critically on it; 3) act to prevent effects on personal news-consumption patterns, by curating the content; or 4) entirely restrain themselves from engaging with it. Awareness of these tactics, which help individuals cope with and navigate the datafied-journalism landscape, facilitates grasping the factors in audiences’ relations to datafied journalism and, thereby, understanding their consumption of news and their relationship with journalism. ","",""
"2024","Data reflexivity as work-in-progress: A relational, life-course approach to people’s encounters with datafication"," Datafication, across private and public sectors demonstrably touches upon, and indeed, alters, with profound consequences, diverse domains of people’s daily lives. However, also, increasingly, critical scholarship on datafication is the locus of careful attention to not solely platform and algorithmic power but also people’s sociocultural practices to make sense of, cope with, feel and show new literacies with data and datafied systems. It is in this context of genuinely listening to what people do with, through and around data, and to what end, that this special issue invites us to ponder the notion of data reflexivity. In this paper, I adopt a working definition of data reflexivity as – a vernacular and relational set of practices and strategies in relation to data and data infrastructures, working with, within and sometimes against platforms, where, such practices and strategies morph and change across the life course, through a web of cross-cutting relationships with individuals, communities and institutions. I draw upon illustrative instances from a project in England which explored parents’ perspectives on personal data and algorithms in the context of raising children. First – I suggest that we approach data reflexivity through a relational lens rather than as an individual and inward-looking strategy, where such relationality is experienced in relation to institutions, individuals, families, friendships, and networks. Second – I suggest that we look at data reflexivity as a fluid, lifelong journey – where a life course approach enables us to consider how data reflexivity morphs, adapts and transitions through the course of life, involving numerous acts of unspectacular, ephemeral agency. I conclude with a reminder that attention to data reflexivity, or indeed, more broadly, people’s agency, must not mean a shift of focus away from scrutinising and holding accountable, powerful institutions, both public and private. ","",""
"2024","What ifs: The role of imagining in people’s reflections on data uses"," This paper explores how non-experts reflect on and come to understand ‘data uses’, a phrase we used to refer to data collection, analysis and sharing. In recent years, research into what people think and feel about data uses has proliferated, whereas this paper focuses on how they do their thinking and feeling. We argue that imagining – that is, building or creating a mental image of something that is not present – is an important aspect of reflecting on data uses. We challenge the proposition that imagining takes place when there is a gap in knowledge or a lack of information, arguing instead that imagining plays an agentic role in reflection, enabling critical questioning of data uses. We draw on qualitative research carried out in the UK, in which we provided information about specific public sector data uses and asked participants how they felt about them. We found that imaginings, or ‘what ifs’, exist in a complex entanglement with different knowledges, including experiential knowledge. ","",""
"2024","Critical data studies meets discard studies: Waste data reflectivity in digital urban waste tracking system"," The article critically examines the implementation and impact of the Digital Urban Waste Tracking System (DUWTS), a ‘smart’ waste management technology deployed in several towns in Poland to enhance urban waste segregation practices. By integrating critical discard studies with critical data studies, the article introduces the concept of ‘waste data reflectivity’ to investigate how data representation in DUWTS influences perceptions and responsibilities within waste management. The study highlights how DUWTS employs advanced dataveillance technologies to monitor waste disposal, creating distorted reflections that obscure the complexities of municipal waste management. These distortions are analyzed through the metaphorical lenses of three mirrors – concave, kaleidoscopic, and ceiling – which reveal the illusory effects on municipalities, waste disposal companies, and residents. Additionally, the article discusses how DUWTS exemplifies ‘technologies of (un)knowing’, which systematically obscure or misrepresent waste management issues, leading to the marginalization of true responsibilities and challenges. The findings demonstrate that while DUWTS represents a technological advancement, it can also perpetuate the existing challenges in waste management by masking the true nature of waste issues and obscuring the responsibilities of different stakeholders. The article concludes by emphasizing the socio-technological consequences of such systems and the importance of a critical analysis in evaluating the effectiveness and ethics of data-driven waste management technologies. ","",""
"2024","Diagrammatic thinking and audience reading of COVID-19 data visualisations: A UK case study"," This article examines whether, how, and to what extent eighteen UK audience participants developed diagrammatic thinking while reading eleven COVID-19 data visualisations published by UK newspapers. Despite data visualisations being a prominent feature in COVID-19 news coverage, audience perception of data visualisations is a relatively new field of study. This study reveals the presence of Stuart Hall’s three types of reading (dominant, opposition or negotiated reading) in the participants’ reading, with the prominent role played by their reflections and the influence cast by their levels of data literacy and familiarity with terminologies. As an experience of reflection and reflexivity, reading data visualisations prompted the participants to rethink the pandemic-related issues posed in data visualisations and reflect on their personal experiences and views. Their reflections confirmed or developed their understanding of these issues or led them to reject the message they perceived. This process suggests their diagrammatic thinking is in practice. ","",""
"2024","Dreaming with data: Cultivating critical consciousness in datafied living research"," This paper addresses data reflexivity in terms of critical consciousness-raising by linking people’s everyday encounters with data to their speculative visions about datafied futures. We suggest everyday encounters with data about oneself might play an important role in facilitating both personal and collective imagination about data and devising future paths towards legitimate and meaningful datafied living. Lending inspiration from the figure of the researcher as critical companion and from speculative design, we posit that critical consciousness-raising is not something generated purely by way of informing people about datafication, but built from below, through people’s everyday experiences with datafying themselves and being datafied by others. Furthermore, it is deeply intertwined with datafication research itself, and the way we seek to establish links between individual and collective experiences and evaluations of data practices. Based on this, the paper offers three methodological entry points for exploring how critical consciousness can be cultivated and collectivized: longitudinal fieldwork with repeated interviews, data visualization derived from people’s own phones, and speculative workshops on future data practices. ","",""
"2024","Data-driven Management and Taylorist Fantasies: A Case Study of Performance Quantification in the Indian IT Services Industry","Human capital management (HCM) software applications are being widely used to assess the performance of knowledge workers in various sectors of the Indian economy. The use of data-driven performance management systems is claimed to make the performance appraisals fairer and more transparent to the worker, and their supposed objectivity is used to justify their deployment in the workplace as instruments of remote surveillance. This paper presents insights from the case study of a performance management system that was installed at an Indian IT services organisation following the transition to remote work. Despite its mobilisation around greater accuracy and objectivity in performance appraisals, the paper demonstrates that techniques of quantification in the system generated information that was empty of any managerial value. The dichotomous understanding of productivity encoded in the system also entrenched the subjective interests of managers into performance appraisals, creating conflicts of interest in supervision that eroded the interests of the workers. As the system misread and distorted the everyday realities of work, the workers governed by it were compelled to engage in “meta work” (Maggiori 2023) that effectively undermined their productivity. By staging the empirical insights from this case study within the politically fraught character of digital Taylorism, the paper seeks to understand why the performance management system failed to meet the sanguine promises of the digital that are often marshalled around data-driven management. Based on evidence from the Indian IT sector, it argues that the translation of worker activities into egregiously oversimplified productivity data, and the eventual normalization of the data using statistical techniques, enabled the organisation to translate the worker population into a fleet of disposable human capital. This, it further argues, has been a strategy that has been in place not only to control alienated labour but also to protect the IT industry’s ability to arbitrage labour costs amidst the vagaries of informational capitalism.","",""
"2024","Counter-practices: Understanding sensor datafication through subversive action"," Sensors have become embedded in all kinds of environments. Their ubiquity has prompted a boom in scholarly engagement centered around the effects of digitally interconnected sensor media and the data traces they ceaselessly produce. This research generally focuses either on theoretical or philosophical macro-perspectives—approaching the topic “from above,” so to speak—or it is ethnographic, “from below,” analyzing the practices of sensory (self-)surveillance, for example in the context of the quantified self-movement. In this article, we propose a situated, praxeological approach that combines both foci: expanding on the epistemically productive concepts of glitches and breakdowns, we follow three strands of what we call “counter-practices”—hiding in plain sight, dis/simulation, and the exploitation of sensor logics—through which we explore the inherent operations of technological sensing and sensemaking. We trace these counter-practices through historic and recent contexts, considering the interrelation of bodies, media and environments, and extrapolating epistemological conclusions that are meaningful for critiquing the codes, logics, and logistics of recent sensor-media societies. Asking how certain practices elude and subvert intended processes of sensor datafication provides a methodological blueprint for media studies and cultural theory that are faced with an algorithmic and technological situation that has rendered itself largely unobservable. ","",""
"2024","When friction becomes the norm: Antagonism, discourse and planetary data turbulence"," The ideal of unfettered data circulation has fallen into crisis. As of today, a growing number of actors are introducing measures to ensure a greater degree of control over the global data pipeline. Combining critical data studies and political theory, this article conceptualises the current technopolitical conjuncture as one of ‘planetary data turbulence’ in which divergences regarding the production and circulation of data have become the norm. The concept of data turbulence emerges from studies on data friction, but this article contends that the current state of affairs requires expanding the emphasis on technosciences and materiality in these works. Drawing on Ernesto Laclau and Chantal Mouffe, the article shows that attending to antagonism and discourse makes it possible to account for the eminently political forces shaping the circulation of data. The strengths of this framework are illustrated by looking at the articulation of digital sovereignty in different geographies. ","",""
"2024","Care as (re)capture: Data colonialism and race during times of crisis"," This article examines the role that data-driven technologies play in expanding and reasserting the legitimacy of the US racial state during times of crisis. Specifically, I examine how prison officials used a software called Verus to reinforce the perceived necessity of penal institutions during the COVID-19 pandemic. Government officials used Verus to produce narratives that (1) recast criminalized communities as dangerous and therefore disposable and (2) shielded carceral institutions from liability for systematic neglect. Ultimately, the aim of this article is to contribute to emerging critical concepts such as “data colonialism,” a term that has largely been used to describe the social and economic consequences of parasitic data extraction and monopoly control of digital infrastructure. In addition to these issues, I argue that data-driven technologies are used as vehicles for movement capture and the reproduction of prison logics that enable modes of racialized economic exploitation that extend far beyond the high-tech innovation economy. ","",""
"2024","Opening up mediation opportunities by engaging grassroots data: Adaptive and resilient feminist data activism in China"," This article explores the dynamics and practices of feminist data activism that engages with grassroots data to archive cases of sexual violence in China. Drawing on Cammaert’s notion of the mediation opportunity structure, we investigate the mediation process of a feminist data campaign and activists’ communicative practices in contemporary China. By practicing data-activist research, our study shows that the data-based action repertoire opens up hybrid and contingent mediation opportunities for an anti-sexual violence campaign under the current political opportunity structure. We find the paradox of seeking visibility while refusing mainstream media coverage in activist tactics, which embodies a form of adaptive and resilient feminist data activism in the authoritarian context of China. This case study suggests that the dynamics of feminist data activism in China are configured by the tripartite interaction among the disruptive action repertoire, mediation opportunity structure, and political conditions. ","",""
"2024","How do we speak about algorithms and algorithmic media futures? Using vignettes and scenarios in a citizen council on data-driven media personalisation"," ‘New’ media and algorithmic rules underlying many emerging technologies present particular challenges in fieldwork, because the opacity of their design, and, sometimes, their real or perceived status as ‘not quite here yet’ – makes speaking about these challenging in the field. In this article, we use insights from a three-stage citizens council investigating citizens’ views on developments in data-driven media personalisation to reflect on the potentials of using future-orientated vignettes and scenarios in data collection on user experiences, expectations and the ethics of algorithms. We present the possibilities and potentials of using vignettes as part of a data collection approach in user-centric algorithm studies which invites users’ contextual experiences of algorithms but also enables more normative reflections on what good looks like in contemporary datafied societies. ","",""
"2024","Tactics of invisibility: How people in vulnerable positions make datafied everyday life livable"," Various data platforms force the individual into constant presence and visibility. However, the ways in which datafied environments relate to experienced vulnerabilities in our everyday lives remain unclear. Through diaries produced by and interviews with participants from three groups who occupy presumably vulnerable positions and who currently live in Finland, we explore the ways in which people challenge expectations and prior assumptions related to forced visibility. Using the concept of tactics developed by de Certeau, we aim to understand how individuals make everyday surveillance culture livable through what we call tactics of invisibility. Based on our analysis, we identify three kinds of tactics in this context: keeping worlds apart, cropping oneself out of the frame, and sidestepping. We interpret tactics of invisibility as ways of shaping a space for oneself illustrate fractures in what previous research has framed as digital resignation. ","",""
"2024","Beyond extraction: Data strategies from the Global South"," This article draws upon a desk-based review and expert interviews with practitioners in the Global South to understand the diverse forms of data mediation that have become increasingly visible in the wake of the global coronavirus disease-19 pandemic. In contrast to accounts that frame the Global South solely as a site for the extraction of data and cheap, unskilled digital labor, we explore alternative accounts of the ways in which individuals and organizations in the Global South are asserting their role as active mediators of data who carve out spaces for value creation that are meaningful in their local and national contexts. From data collection and “refining” to the analysis of data for local needs and markets, these forms of data mediation demonstrate some of the changing dynamics of data practices globally and reflect the necessity of more nuanced analyses of value and power within and across regions. ","",""
