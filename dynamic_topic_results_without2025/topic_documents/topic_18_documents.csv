"year","title","abstract","journal","doi"
"2001","Transaction costs and the social cost of online privacy","Economically, privacy can be understood as a problem of social cost, where the actions of one agent (e.g., a mailing list broker) impart a negative externality on another agent (e.g., an end consumer). Problems in social cost can be understood by modeling the liabilities, transaction costs and property rights assigned to various economic agents within the system, and can be resolved by reallocating property rights and liability to different agents as needed to achieve economic equilibrium. This article examines how advances in high speed networking and data storage have radically reduced the costs to businesses of collecting, storing, manipulating and exchanging large amounts of personally identifying information on consumers, and the policy implications that these cost reductions have on property rights over personal information. A complementary economic and legal system that recognizes individual property rights over personal information is suggested as a way in which to greatly accelerate the adoption of electronic commerce and to extract inefficiencies from the already existing marketplace for personal information.","",""
"2001","An empirical study of the causal antecedents of customer confidence in e-tailers","Why is it that consumers are very confident with an e-tailer such as Amazon.com and lack the same confidence when it comes to a smaller e-tailer such as supremevideo.com? In this paper, we attempt to answer this important question by examining the antecedents to customer confidence in e-tailers, using secondary data. Our findings indicate that the ease of use of a site, the level of online shopping resources, and the presence of a trusted third party seal all positively impact the level of customer confidence. Interestingly, online relationship services did not have an impact on consumer confidence. Larger firms may have a small edge. We also find that there are no large differences in the results across different product categories.","",""
"2002","Privacy, Surveillance, Trust and Regulation: Individual and Collective Dilemmas of Online Privacy Protection","As we noted in our overall introduction to this series of papers, September 11 has in many ways brought into sharper public focus a number of enduring dilemmas about the nature, value and priority of privacy when set against other desired social ‘goods’ – such as protection from terrorism or crime. In a range of contexts, individual rights, duties and freedoms have been more publicly and explicitly weighed against collective goals, such as security and public safety. Particularly in the USA and UK, there seems to have developed a greater public willingness to subordinate long-cherished individual freedoms to such collective goals. The rhetoric of ‘war’ has been explicitly invoked to justify ‘exceptional’ measures in the defence of global security. Yet, a moment’s re ection will show that the dilemmas, contradictions and trade-offs involved are not new. Not only have they been central to earlier wars, they have been regularly invoked in the ght against crime, child pornography and racism. Moreover, they are embedded in the very conception of privacy itself. For, whatever the contextual variety, in no society is privacy conceived as embodying a degree of autonomy from collective norms that would legitimize any and every private act. In addition, privacy is not conceived solely in terms of its value to the individual. Privacy, then, both conceptually and practically, has both individual and collective dimensions. In their different ways, each of the papers in the series appearing in this issue confronts the interface of individual and public dimensions of privacy. Both also seek to question and illuminate the extent to which the problems posed by online privacy differ from those of privacy in physical space. Priscilla Regan notes that,","",""
"2002","Privacy as a Common Good in the Digital World","This article seeks to broaden our understanding of online privacy in three ways: first, by drawing out the differences between the physical world and the digital world as those differences affect privacy; second, by exploring how the concept of the 'commons' might help us to understand social and economic relationships in cyberspace; and third, by analysing two contrasting views of privacy: privacy as a private or individual good and privacy as a common good. In order to analyse similarities and differences in privacy in the physical world and the online world, each is assessed in three ways: the obvious level of privacy available; the possibility of modifying that level of privacy to create or choose more or less privacy for oneself; and the degree to which the, prior or contemporaneous, privacy decisions of others affect the amount of privacy that is available to all. Applying an analysis based on the 'tragedy of the commons', the article concludes that at least part of cyberspace can be conceived as a 'commons' and that personal information flows could be considered a 'common pool resource' within that commons. Based on the likely calculations that individuals and organizations will make about collection and uses of personal information, the article next evaluates what would be the most effective policy approach to ensure that the common pool resource of personal information is not overused and degraded. The article concludes that a policy approach of providing individuals with a private means, either through property rights or some means of redressing their grievances, is unlikely to provide an effective means of protecting the common pool resource of personal information. A policy approach that acknowledges the common good basis of privacy and views personal information as a common pool resource provides an alternative view of the policy problems and offers suggestions in terms of rules and institutions that may be effective in addressing those problems.","",""
"2002","Data Retention and the Panoptic Society: The Social Benefits of Forgetfulness","Modern information systems not only capture a seemingly endless amount of transactional data, but also tend to retain it for indefinite periods of time. We argue that privacy policies must address not only collection and access to transactional information, but also its timely disposal. One unintended side effect of data retention is the disappearance of social forgetfulness, which allows individuals a second chance, the opportunity for a fresh start in life. We examine three domains in which social policy has explicitly recognized the importance of such a principle: bankruptcy law, juvenile crime records, and credit reports. In each case, we frame the issue in terms of the social benefits of forgetfulness, rather than in terms of individual privacy protection. We examine how different policy approaches to privacy might handle the retention of data and propose a comprehensive policy that includes a variety of strategies. The broad conclusion of the article is that data retention and disposal should be addressed as a part of a broader and comprehensive policy approach, rather than in a piecemeal fashion or as an afterthought.","",""
"2002","Toward a Typology of Internet Users and Online Privacy Concerns","Traditional typologies of consumer privacy concern suggest that consumers fall into three distinct groups: One-fourth of consumers are not concerned about privacy, one-fourth are highly concerned, and half are pragmatic, in that their concerns about privacy depend on the situation presented. This study examines online users to determine whether types of privacy concern online mirror the offline environment. An e-mail survey of online users examined perceived privacy concerns of 15 different situations involving collection and usage of personally identifiable information. Results indicate that the vast majority of online users are pragmatic when it comes to privacy. Further analysis of the data suggested that online users can be segmented into four distinct groups, representing differing levels of privacy concern. Distinct demographic differences were seen. Persons with higher levels of education are more concerned about their privacy online than persons with less education. Additionally, persons over the age of 45 years tended to be either not at all concerned about privacy or highly concerned about privacy. Younger persons tended to be more pragmatic. Content and policy implications are provided.","",""
"2002","Using the Content of Online Privacy Notices to Inform Public Policy: A Longitudinal Analysis of the 1998-2001 U.S. Web Surveys","In the United States, Congress has had a long-standing interest in consumer privacy and the extent to which company practices are based on fair information practices. Previously, public policy was largely informed by anecdotal evidence about the effectiveness of industry self-regulatory programs. However, the Internet has made it possible to unobtrusively sample web sites and their privacy disclosures in a way that is not feasible in the offline world. Beginning in 1998, the Federal Trade Commission relied upon a series of three surveys of web sites to assess whether organizations post online privacy disclosures and whether these disclosures represent the U.S. definition of fair information practices. While each year's survey has provided an important snapshot of U.S. web-site practices, there has been no longitudinal analysis of the multiyear trends. This study compares a subset of equivalent individual-level web-site data for the 1998, 1999, 2000, and 2001 web surveys. Implications for using this type of research to inform public policy are discussed.","",""
"2002","Understanding the Privacy Space"," This paper reports on an ongoing research project focusing on privacy tools, and services available on the Internet. A detailed examination of 133 different privacy-related software tools and services rendered a list of 1,241 features relating to privacy. Based on the data gathered, the ongoing work is to formulate a framework to describe this """"privacy space"""" using grounded theory and content analytic techniques. Here, we discuss some of more interesting preliminary findings garnered from a descriptive statistical analysis of the raw data. This paper discusses what can be learned from a user-centric analysis of this increasingly important class of software tools.  ","",""
"2004","Situating Privacy Online","Media and research reports point to the issue of privacy as the key to understanding online behaviour and experience. Yet it is well recognized within privacy-advocacy circles that ‘privacy’ is a loose concept encompassing a variety of meanings. In this article we view privacy as mediating between individuals and their online activities, not standing above them, and as being constantly redefined in actual practice. It is necessary to examine, therefore, what individuals are reacting to when asked about online privacy and how it affects their online experience. This article is based on data generated in the Everyday Internet study, a neighbourhood- based, ethnographic project being conducted in Toronto, Canada, that investigates how people integrate online services in their daily lives. We propose that there are three organizing ‘moments’ of online privacy: the moment of sitting in front of the computer, the moment of interaction with it, and the moment after the data has been released.","",""
"2004","International Differences in Information Privacy Concerns: A Global Survey of Consumers","We examine three possible explanations for differences in Internet privacy concerns revealed by national regulation: (1) These differences reflect and are related to differences in cultural values described by other research; (2) these differences reflect differences in Internet experience; or (3) they reflect differences in the desires of political institutions without reflecting underlying differences in privacy preferences. Using a sample of Internet users from 38 countries matched against the Internet population of the United States, we find support for (1) and (2), suggesting the need for localized privacy policies. Privacy concerns decline with Internet experience. Controlling for experience, cultural values were associated with differences in privacy concerns. These cultural differences are mediated by regulatory differences, although new cultural differences emerge when differences in regulation are harmonized. Differences in regulation reflect but also shape country differences. Consumers in countries with sectoral regulation have less desire for more privacy regulation.","",""
"2004","How public opinion polls define and circumscribe online privacy","The advent of new communications technologies and the integration of such technologies into individuals’ lives have resulted in major changes to society. Responding to such privacy concerns is of key interest to legislators, policy–makers, and business leaders as these groups seek to balance consumer privacy needs with the realities of this new society. These groups, and others, use public opinion polls and surveys to measure the current climate of opinion among citizens. This study examines the language of 43 opinion polls and surveys dealing with privacy and the Internet to understand how these polls define and assess online privacy. Results suggest that polls treat the complex construction of privacy in an overly simplistic way. Additionally, pollsters present many poll questions in a way that may lead survey respondents to express stronger negative feelings about privacy than really exist.","",""
"2004","Privacy policy and PETs"," ‘Privacy’is an ambiguous notion, encompassing personal autonomy, democratic participation, identity management, and social coordination. Each of these privacy ideals reflect different sets of social concerns. Laws operationalize privacy in terms of ‘personally identifiable information’. Technologies reify that definition. This has implications for the constitution of identity and social life. It may empower data holders to rationalize populations and create selfserving social categories, while permitting individuals to negotiate these categories outside of panoptic vision. It may facilitate public awareness of, and resistance to, these created social categories. A more expansive understanding of identification and privacy should inform policy discourse. ","",""
"2005","Information Privacy and Mobile Phones"," Renewed concerns about information privacy and mobile phones have surfaced with the early deployment of location-based services in North America, and specifically with the Federal Communications Commission (FCC) led public safety initiative known as Wireless E9-1-1. Initial scholarly research in this area has focussed on the use and disclosure of geographic location information of mobile phone subscribers and on the terms and conditions by which this information can be made available for lawful access or commercial purposes. This paper refers to this body of research as the 'first domain' of information privacy research, and describes some of the key findings and contributions for policy research on customer proprietary information and customer consent. The paper then turns to introduce and describe an emerging 'second domain' of information privacy concerned with the popular adoption of anonymous prepaid mobile phone services. The distinguishing characteristic of this second domain of research is its focus on debates about the legitimacy of regulatory requirements to collect and verify customer details at the point of purchase. This paper draws on findings from an empirical study undertaken in Canada to identify some initial parameters of this second domain of information privacy research with the intent of informing a wider debate about the entitlement to anonymity for customers who elect to use prepaid services over commercial networks. ","",""
"2006","Privacy and security disclosures on telecardiology Web sites","This article discusses telemedicine providers’ online privacy and security disclosures. It presents the results of an exploratory study of a number of telecardiology companies’ Web sites, providing insight in some of the current strategies towards data protection and information security in the international telemedicine market. The paper concludes that the online privacy notices in our sample are far from being standardized and complete. In view of privacy risks, as well as the transitory stage of the telemedicine sector, the underdeveloped state of online privacy notifications is disappointing — and a missed chance for those who are interested in the successful future development of Internet privacy and telemedicine–based healthcare.","",""
"2006","Privacy Protection: Time to Think and Act Locally and Globally (originally published in June 1998)","This paper is included in the First Monday Special Issue: Commercial Applications of the Internet, published in July 2006.  What sorts of privacy can consumers expect on the Internet? How havepolicies been evolving - or not evolving - in the past twelve months? This article examines the unique aspects on online communications and interactivity and analyzes the real meaning of community in the context of the Internet.[1]","",""
"2006","A privacy paradox: Social networking in the United States","Teenagers will freely give up personal information to join social networks on the Internet. Afterwards, they are surprised when their parents read their journals. Communities are outraged by the personal information posted by young people online and colleges keep track of student activities on and off campus. The posting of personal information by teens and students has consequences. This article will discuss the uproar over privacy issues in social networks by describing a privacy paradox; private versus public space; and, social networking privacy issues. It will finally discuss proposed privacy solutions and steps that can be taken to help resolve the privacy paradox.","",""
"2006","Your privacy is assured - of being disturbed: websites with and without                 privacy seals"," Privacy seals were developed to address concerns about online privacy. However, seals are widely misinterpreted by consumers as privacy protection. This research assessed how well privacy policies matched the standards promised by the seal authorities and compared the privacy protection practices of participating and non-participating sites. Privacy policy statements were interpreted as a form of persuasive communication that attempts to minimize the risks of providing personal information while emphasizing the benefits of personal disclosure. There were few differences in the privacy practices between seal authorities: TRUSTe and BBBOnLine participants offered about the same degree of privacy protection assurances and they were equal with regard to the amount or depth of personal information they requested. Notably, unsealed sites offered nearly equal privacy assurances and made fewer personal information requests than the sealed sites. However, seal program participants did provide superior access to information and assurances of data security. ","",""
"2006","The right not to be identified: privacy and anonymity in the interactive                 media environment"," This article explores how the development of information technology, especially interactive computers, changes the privacy environment as experienced by individuals and the policy implications of these changes. External entities, such as governments and commercial industries, that ‘invade’ people’s rights to be left alone are of less concern now than individuals who voluntarily give up their privacy by willingly providing personal information for other benefits on the internet. Also, in the interactive environment, intended and unintended activities of more diversified and less easily identifiable entities have become more of a threat to individual privacy. In this new environment, rather than ‘providing’ privacy for passive individuals, a more user-oriented, active approach is needed to help users to protect themselves from more diversified and unknown forces and potential loss of control. This article suggests that focusing on the right not to be identified on the network by allowing affirmative acts of secrecy and deception regarding identity and identification might be the most effective-and sometimes only practically viable-way of ensuring privacy in the interactive environment. ","",""
"2007","Who Searches the Searchers? Community Privacy in the Age of Monolithic Search Engines","Privacy has largely been equated with every individual's right to privacy. Accordingly, current efforts to protect privacy on the Internet have sought anonymity by breaking, where possible, links with personally identifiable information (PII)—all uses of aggregated data stripped of PII are considered legitimate. This article argues that we need to use a broader concept, general or group identifying information (GII), because even aggregated data stripped of PII violate privacy at the community level. The search engine companies, or anyone else with access to their log files, can use these data to generate a moment-by-moment view of what is on the collective mind. Such a view can be used in a variety of ways, some with deep economic and even political impact. In order to frame this discussion, it is necessary to examine some of the realities of the search engine-mediated associative interface to the World Wide Web. While this interface has enormous benefits for the networked world, it also fundamentally changes a number of issues underlying various current debates about Internet governance.","",""
"2007","Read at your own risk"," This article discusses how interactive media threaten informational privacy, especially in a legal environment that fails to protect individuals' right to receive and use content without being scrutinized by private and government institutions.The article observes that as information about media consumption habits make up an increasingly large share of the stock of data that institutions can use in order to make inferences about individuals, it becomes increasingly more difficult for individuals to determine which types of behaviors would cause them to be assigned to a high-risk category. In the light of this observation, the article concludes by proposing that in order to address the uncertainty that individuals face in trying to figure out how institutions use personal information to categorize them into different risk groups, a privacy protection scheme that increases the accountability of these automated and manual interpretation processes is needed. ","",""
"2007","Internet privacy and institutional trust"," What does the US public believe about the credibility of institutional actors when it comes to protecting information privacy online? Drawing on perspectives of environmental risk, this article addresses the question through a nationally representative telephone survey of 1200 adults who go online at home. A key result is that a substantial percentage of internet users believes that major corporate or government institutions will both help them to protect information privacy and take that privacy away by disclosing information to other parties without permission. This finding and others raise questions about the dynamics of risk-perception and institutional trust on the web. ","",""
"2007","Online privacy as legal safeguard: the relationship among consumer, online portal, and privacy policies"," Several surveys attest to growing public concerns regarding privacy, aggravated by the diffusion of information technologies. A policy of self-regulation that allows individual companies to implement self-designed privacy statements is prevalent in the United States. These statements rarely provide specific privacy guarantees that personal information will be kept confidential. This study provides a discourse analysis of such privacy statements to determine their overall efficacy as a policy measure. The in-depth analysis of privacy statements revealed that they offer little protection to the consumer, instead serving to authorize business practices which allow companies to profit from consumer data. Using public good theory as a foundation, policy implications are discussed. ","",""
"2008","SOFTWARE DEFAULTS AS DE FACTO REGULATION The case of the wireless internet","Today's internet presumes that individuals are capable of configuring software to address issues such as spam, security, indecent content, and privacy. This assumption is worrying – common sense and empirical evidence state that not everyone is so interested or so skilled. When regulatory decisions are left to individuals, for the unskilled the default settings are the law. This article relies on evidence from the deployment of wireless routers and finds that defaults act as de facto regulation for the poor and poorly educated. This paper presents a large sample behavioral study of how people modify their 802.11 (‘Wi-Fi’) wireless access points from two distinct sources. The first is a secondary analysis of WifiMaps.com, one of the largest online databases of wireless router information. The second is an original wireless survey of portions of three census tracts in Chicago, selected as a diversity sample for contrast in education and income. By constructing lists of known default settings for specific brands and models, we were then able to identify how people changed their default settings. Our results show that the default settings for wireless access points are powerful. Media reports and instruction manuals have increasingly urged users to change defaults – especially passwords, network names, and encryption settings. Despite this, only half of all users change any defaults at all on the most popular brand of router. Moreover, we find that when a manufacturer sets a default 96–99 percent of users follow the suggested behavior, while only 28–57 percent of users acted to change these same default settings when exhorted to do so by expert sources. Finally, there is also a suggestion that those living in areas with lower incomes and levels of education are less likely to change defaults, although these data are not conclusive. These results show how the authority of software trumps that of advice. Consequently, policy-makers must acknowledge and address the power of software to act as de facto regulation.","",""
"2008","SETTING ONLINE POLICY WITH SOFTWARE DEFAULTS","Software is increasingly seen as a policy tool to influence societal concerns such as privacy, freedom of speech and intellectual property protection. A necessary step in this process is deciding what the ‘settings’ should be for the relevant software. One powerful setting in software is defaults. This article puts forth a framework for how default settings should be determined. This normative approach towards software settings stands apart from most previous scholarship, which focuses on the effect of software. The framework is illustrated with an example of an incorrectly set default in Apple's Airport Extreme wireless access point. Policymakers can influence competition, security, and privacy by relying on this framework. We believe that the manipulation of software to enhance social welfare is a powerful tool and a useful complement to traditional legal methods. This material is based upon work supported by the National Science Foundation under Grant No. IIS-0429217. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.","",""
"2008","Facebook's Privacy Trainwreck"," Not all Facebook users appreciated the September 2006 launch of the `News Feeds' feature. Concerned about privacy implications, thousands of users vocalized their discontent through the site itself, forcing the company to implement privacy tools. This essay examines the privacy concerns voiced following these events. Because the data made easily visible were already accessible with effort, what disturbed people was primarily the sense of exposure and invasion. In essence, the `privacy trainwreck' that people experienced was the cost of social convergence. ","",""
"2009","U.S. and EU Privacy Policy: Comparison of Regulatory Approaches","While the Internet can be viewed as a global network of networks, many elements of Internet law remain delineated by sovereign nations, creating the potential for regulatory conflict and spillover. In particular, national governments have different views on the regulation of private information, and to whom it should be available. Concerns arise about how personal data and identifiers should be handled on the Internet. The US and EU are each other’s largest trading partners yet follow vastly different approaches in their attempt to regulate personal information and the digital economy. This article explores the cross-border variation in privacy policy in the US and EU and discusses how differences in countries’ values, social norms, and interests account for the variance in regulation. Distinct regulatory approaches and priorities between the US and EU profoundly affect numerous industries in both regions. The article analyzes the example of the passenger name records in the travel industry as a case study in these privacy policy contrasts.","",""
"2009","Daniel J. 2008. Understanding Privacy. Cambridge and London: Harvard University Press.","","",""
"2009","Privacy in the digital world: Towards international legislation","In today’s digital world, personal privacy has become the number one issue for consumers [9]. Consumers' confidence in personal privacy is directly affecting and limiting the growth of the Internet commercial development. Therefore, it has become a necessity to address the consumers privacy concerns for the interests of the parties involved.  Examples of the different ways of penetrating the consumers' privacy are reviewed. The national and international efforts to formulate regulatory and self-regulatory programs to protect the consumers' privacy are demonstrated. The different privacy enhancing technologies are presented. The problems and shortages of the current national and international consumers' privacy protection regulatory effort including privacy enhancing technologies are addressed. The argument of the need for an international efforts and the proposed role of the United Nations (UN) towards enforced international privacy legislation is established. The complexity and the multi dimensional factors that affect the proposed international legislation are discussed.","",""
"2009","The privacy box: A software proposal","The contradiction of social networks is that revealing of personal, private information can have harmful consequences, yet users continue to disclose such information at an alarming rate. Ironically, the advent of social network sites opens the possibility of a relatively safe place to disclose private information. This article proposes a “privacy box” application to be used within social network sites that would require users to accept a pre–written promise of confidentiality before gaining access to personal information. Although it would not serve as a universal remedy for privacy harms on social network sites, it could serve to carve out a space for relatively safe self–disclosure online.","",""
"2009","A multinational study on online privacy: global concerns and local responses"," This study surveyed 1261 internet users from five cities (Bangalore, Seoul, Singapore, Sydney and New York) to examine multinational internet users' perceptions and behavioural responses concerning online privacy. It identified a set of individual-level (demographics and internet-related experiences) and macro-level factors (nationality and national culture), and tested the extent to which they affected online privacy concerns and privacy protection behaviours. The results showed that individual differences (age, gender and internet experience), nationality and national culture significantly influenced internet users' privacy concerns to the extent that older, female internet users from an individualistic culture were more concerned about online privacy than their counterparts. The study also identified three underlying dimensions of privacy protection behaviour — avoidance, opt-out and proactive protection — and found that they distinctly related to the individual and macro-level factors. Overall, the findings highlight the conditional and multicultural nature of online privacy. ","",""
"2010","NONE OF US IS AS LAZY AS ALL OF US","In this paper we apply theory and research from sociology and social psychology to the problem of collective information sharing and exchange on the internet. We investigate the relationships between pre-existing dispositions to be cautious towards others, the propensity to exert more or less effort as a function of group affiliation, and contribution towards a collective goal. We find that individuals with average or lower levels of general caution are more likely to contribute to a collective pool of information, providing support for Yamagishi's (2001) argument that less cautious individuals exhibit a type of social intelligence by engaging in risky but potentially rewarding social interactions. Consistent with the literature on social loafing, we find that abstract group affiliations have a negative effect on information sharing behaviour. However, the effect of group affiliation is mediated by one's level of general caution. We argue that pre-dispositions to engage in socially risky situations are a critical element of individuals’ decisions to contribute to online information sharing systems or not.","",""
"2010","Facebook privacy settings: Who cares?","With over 500 million users, the decisions that Facebook makes about its privacy settings have the potential to influence many people. While its changes in this domain have often prompted privacy advocates and news media to critique the company, Facebook has continued to attract more users to its service. This raises a question about whether or not Facebook's changes in privacy approaches matter and, if so, to whom. This paper examines the attitudes and practices of a cohort of 18- and 19-year-olds surveyed in 2009 and again in 2010 about Facebook's privacy settings. Our results challenge widespread assumptions that youth do not care about and are not engaged with navigating privacy. We find that, while not universal, modifications to privacy settings have increased during a year in which Facebook's approach to privacy was hotly contested. We also find that both frequency and type of Facebook use as well as Internet skill are correlated with making modifications to privacy settings. In contrast, we observe few gender differences in how young adults approach their Facebook privacy settings, which is notable given that gender differences exist in so many other domains online. We discuss the possible reasons for our findings and their implications.","",""
"2011","A Comprehensive Theoretical Framework for Personal Information-Related Behaviors on the Internet","Although there is near consensus on the need for privacy, the reality is that people's attitude toward their personal information privacy is complex. For instance, even when people claim that they value their information privacy, they often trade their personal information for tangible or intangible benefits. In this article, the research on different ways in which people respond to risks to privacy is examined. They include information seeking to reduce uncertainty, the withholding of information, and the provision of fabricated information. The impact of trust and inducements on Internet users’ willingness to share personal information is also examined. Thereafter, important postulates from theories in communication, social psychology, and sociology are synthesized into a comprehensive theoretical framework for personal information-related behaviors in the online environment.","",""
"2011","Why parents help their children lie to Facebook about age: Unintended consequences of the &amp;lsquo;Children&amp;rsquo;s Online Privacy Protection Act&amp;rsquo;","Facebook, like many communication services and social media sites, uses its Terms of Service (ToS) to forbid children under the age of 13 from creating an account. Such prohibitions are not uncommon in response to the Children’s Online Privacy Protection Act (COPPA), which seeks to empower parents by requiring commercial Web site operators to obtain parental consent before collecting data from children under 13. Given economic costs, social concerns, and technical issues, most general–purpose sites opt to restrict underage access through their ToS. Yet in spite of such restrictions, research suggests that millions of underage users circumvent this rule and sign up for accounts on Facebook. Given strong evidence of parental concern about children’s online activity, this raises questions of whether or not parents understand ToS restrictions for children, how they view children’s practices of circumventing age restrictions, and how they feel about children’s access being regulated. In this paper, we provide survey data that show that many parents know that their underage children are on Facebook in violation of the site’s restrictions and that they are often complicit in helping their children join the site. Our data suggest that, by creating a context in which companies choose to restrict access to children, COPPA inadvertently undermines parents’ ability to make choices and protect their children’s data. Our data have significant implications for policy–makers, particularly in light of ongoing discussions surrounding COPPA and other age–based privacy laws.","",""
"2012","The Internet, the Law, and Privacy in New Zealand: Dignity with Liberty?","Early participants in the Internet experienced very little legal or social pressure with respect to either data privacy or regulation. However, the innovations of Web 2.0 are symptomatic of a re-creation of cyberspace from an original “free for all,” in which websites had no normative constraints, toward a significant shift to website management that addresses privacy concerns. If the laws of the non-virtual world are difficult to apply to the online world, must the non-virtual world create new laws to control the online world? Should a balance be made between laws of the non-virtual and virtual worlds, or should a new set of laws be created specifically to govern the Internet? Concordant with this dilemma is the issue that although precedent may create new laws, when the law changes with the possibilities for uses and abuses of new online technologies, to what extent can it be said to either perpetuate or create to any internally consistent system?","",""
"2012","The Review of Privacy Online: Three Questions","--","",""
"2012","The Future of Privacy Online","Full Text of the debate section on the future of online privacy featuring Laura Huey, Micheal Vonn, Reg Whitaker, Paul Rosenzweig, danah boyd, Steve T. Margulis, and Gary T. Marx, and Judith Rauhofer","",""
"2012","Caveat Emptor: A Perspective on Consumer Privacy Online","--","",""
"2012","Privacy by design: Networked computing, 1969–1979"," Discourse analysis of the technical document series that records the internet design history, the RFCs, shows that those involved during the first decade saw privacy as a multi-dimensional and interactive problem requiring use of a suite of solutions at the network, individual, and data levels that had to take into account the need to balance privacy against experimentation and innovation. Internet designers were sophisticated in their pragmatic thinking about privacy when evaluated vis-a-vis theoretical developments since that time, viewing privacy as a contextual matter involving boundary setting, and using information architecture and metadata as tools for privacy protection. Those in the social science and legal communities think about the privacy effects of communication on humans, while those in the technical design community must focus on privacy as a set of logistical problems. Bringing these diverse communities into a single conversation can considerably enrich and strengthen the work of all. ","",""
"2013","Online privacy concerns and legal assurance: A user perspective","","",""
"2013","PRIVACY PROTECTION STRATEGIES ON FACEBOOK","The privacy paradox describes people's willingness to disclose personal information on social network sites despite expressing high levels of concern. In this study, we employ the distinction between institutional and social privacy to examine this phenomenon. We investigate what strategies undergraduate students have developed, and their motivations for using specific strategies. We employed a mixed-methods approach that included 77 surveys and 21 in-depth interviews. The results suggest that, in addition to using the default privacy settings, students have developed a number of strategies to address their privacy needs. These strategies are used primarily to guard against social privacy threats and consist of excluding contact information, using the limited profile option, untagging and removing photographs, and limiting Friendship requests from strangers. Privacy strategies are geared toward managing the Facebook profile, which we argue functions as a front stage. This active profile management allows users to negotiate the need for connecting on Facebook with the desire for increased privacy. Thus, users disclose information, because they have made a conscious effort to protect themselves against potential violations. We conclude that there is a tilt toward social privacy concerns. Little concern was raised about institutional privacy and no strategies were in place to protect against threats from the use of personal data by institutions. This is relevant for policy discussions, because it suggests that the collection, aggregation, and utilization of personal data for targeted advertisement have become an accepted social norm.","",""
"2013","Captive But Mobile: Privacy Concerns and Remedies for the Mobile Environment","We use the legal framework of captive audience to examine the Federal Trade Commission 2012 privacy guidelines as applied to mobile marketing. We define captive audiences as audiences without functional opt-out mechanisms to avoid situations of coercive communication. By analyzing the current mobile marketing ecosystem, we show that the Federal Trade Commission's privacy guidelines inspired by the Canadian “privacy by design” paradigm fall short of protecting consumers against invasive mobile marketing in at least three respects: (a) The guidelines overlook how, in the context of data monopolies, the combination of location and personal history data threatens autonomy of choice; (b) the guidelines focus exclusively on user control over data sharing, while ignoring control over communicative interaction; and (c) the reliance on market mechanisms to produce improved privacy policies may actually increase opt-out costs for consumers. We conclude by discussing two concrete proposals for improvement: a “home mode” for mobile privacy and target-specific privacy contract negotiation.","",""
"2013","Transaction costs, privacy, and trust: The laudable goals and ultimate failure of notice and choice to respect privacy online","The goal of this paper is to outline the laudable goals and ultimate failure of notice and choice to respect privacy online and suggest an alternative framework to manage and research privacy.  This paper suggests that the online environment is not conducive to rely on explicit agreements to respect privacy. Current privacy concerns online are framed as a temporary market failure resolvable through two options:  (a) ameliorating frictions within the current notice and choice governance structure or (b) shifting from a contract-governed exchange to a focus on implicit, negotiated rules within a long-term relationship. Importantly for firms, examining privacy in practice shifts the firm’s responsibility from adequate notice to identifying and managing the cost-benefit analysis within a specific context. ","",""
"2013","Propagation of unintentionally shared information and online tracking","Various pieces of information are being shared online while users browse the Internet. Previous studies have demonstrated that as social networking sites (SNS) became popular, the information being leaked or shared is becoming more personal (including names and e-mail addresses). Users’ information is being shared or leaked from visited sites (both SNS and non-SNS) to third party sites (such as advertisers) in a number of ways including via the HTTP header. The intent of this study is identify the privacy implications of browsing the Internet within a single browsing session of a group of commonly visited sites (both SNS and non-SNS) doing activities common among most online users. We analysed the HTTP headers resulting from the first author’s browsing and reported on the types of information being shared or leaked, and to whom. We observed that within just a single browsing session of some sites, both the user’s identifiable and non-identifiable information are being leaked to various third party sites and also propagated to more than just one level of third party site. We also found that some SNS are also able to track user’s browsing activities not only within the SNS but also beyond it -particularly among web sites that use SNS widgets.","",""
"2013","Privacy online: Perspectives on privacy and self-disclosure in the social web","","",""
"2014","The unbearable lightness of user consent","The article discusses challenges to privacy protection in social media platforms, focusing in particular on the principle of user consent. Based on a Danish study, the article argues that in relation to Facebook, user consent de facto served as the price for participating and for gaining access to a social infrastructure. The article opens with a brief introduction to privacy as a human right, followed by a discussion of some of the critique that has been raised towards social media platforms vis-à-vis the right to privacy. Second, it presents the findings from a study conducted amongst 68 Danish high school students in October 2013 concerning their privacy perceptions and practices when using social media platforms. Thirdly, it discusses the implications of these findings in relation to the principle of user consent as a means of providing individuals with control over their personal information in the context of social media platforms.","",""
"2014","A Strategy for Operationalizing Privacy by Design","Recent controversies surrounding privacy have sparked a move by regulators toward the idea of privacy by design (PbD), a concept pioneered by Ontario Information and Privacy Commissioner Ann Cavoukian. Industry has also started to recognize the importance of taking privacy seriously, with various PbD corporate initiatives currently underway. However, some commentators have criticized PbD for being too vague. Using three case studies and a range of best practice examples of PbD, privacy impact assessments (PIAs), and privacy-enhancing technologies (PETs), this article addresses the gap between the abstract principles of PbD and their operationalization into more concrete implementation guidelines for software engineers.","",""
"2014","Pricey privacy: Framing the economy of information in the digital age","As new information technologies become ubiquitous, individuals are often prompted rethinking disclosure. Available media narratives may influence one’s understanding of the benefits and costs related to sharing personal information. This study, guided by frame theory, undertakes a Critical Discourse Analysis (CDA) of media discourse developed to discuss the privacy concerns related to the corporate collection and trade of personal information. The aim is to investigate the frames — the central organizing ideas — used in the media to discuss such an important aspect of the economics of personal data. The CDA explored 130 articles published in the New York Times between 2000 and 2012. Findings reveal that the articles utilized four frames: confusion and lack of transparency, justification and private interests, law and self-regulation, and commodification of information. Articles used episodic framing often discussing specific instances of infringements rather than broader thematic accounts. Media coverage tended to frame personal information as a commodity that may be traded, rather than as a fundamental value.","",""
"2014","Networked privacy: How teenagers negotiate context in social media"," While much attention is given to young people’s online privacy practices on sites like Facebook, current theories of privacy fail to account for the ways in which social media alter practices of information-sharing and visibility. Traditional models of privacy are individualistic, but the realities of privacy reflect the location of individuals in contexts and networks. The affordances of social technologies, which enable people to share information about others, further preclude individual control over privacy. Despite this, social media technologies primarily follow technical models of privacy that presume individual information control. We argue that the dynamics of sites like Facebook have forced teens to alter their conceptions of privacy to account for the networked nature of social media. Drawing on their practices and experiences, we offer a model of networked privacy to explain how privacy is achieved in networked publics. ","",""
"2015","Culturally Specific Privacy Practices on Social Network Sites: Privacy Boundary Permeability Management in Photo Sharing by American and Chinese College-Age Users","This article explores the cultural specificity of privacy practices on social network sites (SNSs) by comparing 10 college-age American Facebook users’ and 10 college-age Chinese Renren users’ in their photo sharing of significant events during winter vacation. Using communication privacy management theory, we show that Chinese participants more tightly controlled their privacy boundary permeability than American participants. Also, Chinese participants’ relationships with Renren friends—potential information co-owners—featured more distance and formality than American participants’ close interactions with Facebook friends. We interpret the findings in light of American and Chinese cultures to contemplate the cultural manifestation in SNS privacy practices.","",""
"2015","COMPASS| How Safe are Safe Harbors? The Difficulties of Self-Regulatory Children’s Online Privacy Protection Act Programs","As communication technology continues to evolve, legal landscapes shift in an attempt to regulate new and emerging media. One pervasive public concern in the digital age is the regulation of online collection of private data. This is by no means a novel concern; for decades academics and practitioners have debated the advantages and disadvantages (and all that falls between) of technological advancement, surveillance, privacy rights, and so forth (Campbell & Carlson, 2002; Dinev, Hart, & Mullen, 2008; Fuchs et al., 2013; Kearns, 1999; Southard IV, 1989). Communication scholarship has been particularly bountiful on these topics because data collection on the Internet is intimately intertwined with questions of communication patterns (Fuchs, 2013; Krontiris, Langheinrich, & Shilton, 2014; Park, 2011). Although concerns over online data collection are varied, the issue of children’s information privacy is of particular concern for legal practitioners, communication scholars, and the public at large.","",""
"2015","‘I don't have anything to hide, but … ': the challenges and negotiations of social and mobile media privacy for non-dominant youth","Drawing from interviews and focus groups with teens in a low-income and ethnically diverse high school in central Texas, this paper explores the unique social privacy challenges and strategies of low-income and non-dominant youth. Situating the research in a broader context in which non-dominant teens are increasingly surveilled, I demonstrate how teens manage social privacy in at least three ways. First, they negotiate liminal boundaries of what constitutes a communal or shareable mobile device, which are structured around financial constraints. Second, through nonuse, they actively resist the ways mobile and social media reconfigure social and physical spaces. Third, they deliberately use multiple platforms as a way to cope with evolving privacy settings, social norms, and technological affordances; this is a deliberate strategy intended to resist social convergence. Because low-income and non-dominant youth are increasingly surveilled by adults, peers, and institutions, it is imperative that they find spaces that afford greater freedom of expression, interest-based communities, and privacy.","",""
"2015","Social media, small businesses, and the control of information","Much of the discussion regarding privacy and social media has focused on consumers of social media, but social media is also popular among businesses. This article explores the privacy tensions of small business owners using social media to disseminate and gather information to better engage and serve their customers while maintaining customer trust. Drawing on Communication Privacy Management theory [Petronio, S. (2002). Boundaries of privacy: Dialectics of disclosure. Albany, NY: SUNY Press, Petronio, S. (2007). Translational research endeavors and the practices of communication privacy management. Journal of Applied Communication Research, 35(3), 218–222], we argue that there is a dialectical tension between control and engagement. As information is disclosed via social media, it creates new opportunities for engagement, surveillance, and commodification. Based on group interviews with small business owners, we identify the kinds of information that small businesses must manage as participants on social media platforms and the privacy rules they develop.","",""
"2015","Youth, privacy and online media: Framing the right to privacy in public policy-making","The right to privacy is a fundamental human right defined in international and regional human rights instruments. As such it has been included as a core component of key legislature and policy proceedings throughout the brief history of the World Wide Web. While it is generally recognized in public policy making that the right to privacy is challenged in new ways in a structurally transformed online public sphere, the way in which it has been framed does not seem to acknowledge this transformation. This paper therefore argues for a reformulation of “online privacy” in the current global policy debate. It presents the results of a qualitative study amongst 68 Danish high school students concerning how they perceive, negotiate and control their private sphere when using social media and builds a case for utilizing the results of studies as this to inform the ongoing policy discourses concerning online privacy.","",""
"2015","Privacy 2.0"," We live in the era of change. In this world, privacy is not a static concept, but instead has a dynamic component. Overall, it becomes clear that the public and private are not defined in the same manner as in the past and as in the actual world, while our personal information has become a commodity that can raise our visibility in the social media driven world. ","",""
"2015","Older and Wiser? Facebook Use, Privacy Concern, and Privacy Protection in the Life Stages of Emerging, Young, and Middle Adulthood"," A large part of research conducted on privacy concern and protection on social networking sites (SNSs) concentrates on children and adolescents. Individuals in these developmental stages are often described as vulnerable Internet users. But how vulnerable are adults in terms of online informational privacy? This study applied a privacy boundary management approach and investigated Facebook use, privacy concern, and the application of privacy settings on Facebook by linking the results to Erikson’s three stages of adulthood: emerging, young, and middle adulthood. An online survey was distributed among 18- to 65-year-old Dutch-speaking adults ( N = 508, 51.8% females). Analyses revealed clear differences between the three adult age groups in terms of privacy concern, Facebook use, and privacy protection. Results indicated that respondents in young adulthood and middle adulthood were more vulnerable in terms of privacy protection than emerging adults. Clear discrepancies were found between privacy concern and protection for these age groups. More particularly, the middle adulthood group was more concerned about their privacy in comparison to the emerging adulthood and young adulthood group. Yet, they reported to use privacy settings less frequently than the younger age groups. Emerging adults were found to be pragmatic and privacy conscious SNS users. Young adults occupied the intermediate position, suggesting a developmental shift. The impact of generational differences is discussed, as well as implications for education and governmental action. ","",""
"2015","FCJ-195 Privacy, Responsibility, and Human Rights Activism","In this article, we argue that many difficulties associated with the protection of digital privacy are rooted in the framing of privacy as a predominantly individual responsibility. We examine how models of privacy protection, such as Notice and Choice, contribute to the ‘responsibilisation’ of human rights activists who rely on the use of technologies for their work. We also consider how a group of human rights activists countered technology-mediated threats that this ‘responsibilisation’ causes by developing a collective approach to address their digital privacy and security needs. We conclude this article by discussing how technological tools used to maintain or counter the loss of privacy can be improved in order to support the privacy and digital security of human rights activists. doi: 10.15307/fcj.26.195.2015 issue 26: Entanglements Activism and Technology","",""
"2016","“What Can I Really Do?” Explaining the Privacy Paradox with Online Apathy","Based on focus group interviews, we considered how young adults’ attitudes about privacy can be reconciled with their online behavior. The “privacy paradox” suggests that young people claim to care about privacy while simultaneously providing a great deal of personal information through social media. Our interviews revealed that young adults do understand and care about the potential risks associated with disclosing information online and engage in at least some privacy-protective behaviors on social media. However, they feel that once information is shared, it is ultimately out of their control. They attribute this to the opaque practices of institutions, the technological affordances of social media, and the concept of networked privacy, which acknowledges that individuals exist in social contexts where others can and do violate their privacy.","",""
"2016","Putting mobile application privacy in context: An empirical study of user privacy expectations for mobile devices","ABSTRACT Users increasingly use mobile devices to engage in social activity and commerce, enabling new forms of data collection by firms and marketers. User privacy expectations for these new forms of data collection remain unclear. A particularly difficult challenge is meeting expectations for contextual integrity, as user privacy expectations vary depending upon data type collected and context of use. This article illustrates how fine-grained, contextual privacy expectations can be measured. It presents findings from a factorial vignette survey that measured the impact of diverse real-world contexts (e.g., medical, navigation, music), data types, and data uses on user privacy expectations. Results demonstrate that individuals’ general privacy preferences are of limited significance for predicting their privacy judgments in specific scenarios. Instead, the results present a nuanced portrait of the relative importance of particular contextual factors and information uses, and demonstrate how those contextual factors can be found and measured. The results also suggest that current common activities of mobile application companies, such as harvesting and reusing location data, images, and contact lists, do not meet users’ privacy expectations. Understanding how user privacy expectations vary according to context, data types, and data uses highlights areas requiring stricter privacy protections by governments and industry.","",""
"2016","The emotional context of information privacy","ABSTRACT Why are ongoing legal, design, and policy debates around information privacy often divorced from the lived experience of everyday digital media use? This article argues that human emotion is a critical but undertheorized element in users' subjective sense of information privacy. The piece advocates for a greater attention to the phenomenology of feeling and to the concept of “visceral” design in information privacy scholarship, policy, and design practice.","",""
"2016","I see you, you see me: Mobile advertisements and privacy","We present a summary of our own research, showing that mobile advertisements collect and use significant private data, including personally identifiable information. We examine uses of this information beyond ad targeting. We then explore the privacy implications of this practice, and evaluate various potential technical and regulatory responses. We conclude that both regulatory attention and technical measures are needed to avoid potential serious harm to users.","",""
"2016","Simple online privacy for Australia","Simple Privacy provides a system for Australian organisations to create privacy policies for the personal information they collect online. The privacy policies it creates are legally compliant and easy to understand. We developed this system because small Australian organisations seemed to find privacy policies too complicated to manage with the resources they have available.This paper describes the framework behind Simple Privacy and discusses the choices that we made during development. These choices balance the requirements of the privacy legislation and the needs of both organisations and customers.","",""
"2016","Lurkers, creepers, and virtuous interactivity: From property rights to consent and care as a conceptual basis for privacy concerns and information ethics","Exchange of personal information online is usually conceptualized according to an economic model that treats personal information as data owned by the persons these data are ‘about.’ This leads to a distinct set of concerns having to do with data ownership, data mining, profits, and exploitation, which do not closely correspond to the concerns about privacy that people actually have. A post-phenomenological perspective, oriented by feminist ethics of care, urges us to figure out how privacy concerns arrive in fundamentally human contexts and to speak to that, rather than trying to convince people to care about privacy as it is juridically conceived and articulated. By considering exchanges of personal information in a human-to-human online informational economy — being friends on social networking sites — we can identify an alternate set of concerns: consent, respect, lurking, and creepiness. I argue that these concerns will provide a better guide to both users and companies about prudence and ethics in information economies than the existing discourse around ‘privacy.’","",""
"2016","Disclosure Management on Social Network Sites: Individual Privacy Perceptions and User-Directed Privacy Strategies"," The social web and specifically social network sites (SNS) have offered new opportunities for interaction and communication, but have also increased the risk of privacy violations. In this study, we investigated how far users imply different disclosure management strategies in status updates and chat conversations. We hypothesized that users perceive specific information as differently private depending on their personal privacy preference, but generally show the same disclosure management pattern: the higher the perceived privacy level of an information, the less frequently it will be shared. We tested the hypothesis using an online survey with 316 German SNS users. The findings suggest that respondents engaged in disclosure management taking both communication channel and type of information into account. We further found that trust toward SNS contacts and use of privacy settings significantly influenced disclosure management in one-to-many (status updates) but not in one-to-one communications situations (chat conversations). The results complement existing research by showing the pivotal role of individual privacy perceptions in explaining users’ privacy management in the social web. ","",""
"2016","Athenian University Students on Facebook and Privacy: A Fair “Trade-Off ”?"," This article explores how Athenian university students “manage” their privacy on Facebook while socially interacting with other users. Survey data of undergraduate students in Athens reveal that the social network site use “validates” and enhances the pre-existing social context and that the relationship level has an impact on the way users contact other users on it. We find that Facebook users feel that they are able to use most of the privacy settings to protect their personal data. Yet, they are concerned about the disclosure of their personal information which is perceived to be their primary responsibility. Despite these concerns, they appear to feel in control of their privacy through the abilities they are offered by the social networking site (SNS). We also argue that even if they realize that they are disclosing their personal information, this doesn’t cause a great deal of insecurity. ","",""
"2017","Understanding and explaining online personal information-sharing behaviours of New Zealanders: a new taxonomy","ABSTRACT Although research evidence shows that people have strong concerns about their privacy online, this does not necessarily mean that they do not share their personal information in varying online relationships. This paper presents New Zealand-based empirical research findings into people’s actual online information-sharing behaviours rather than their attitudes: the motivations, extent, and conditions under which individuals share their personal information in varying online relationships with commercial providers, with government, and on social networking sites. A grounded theory methodology and an abductive analysis were used to identify patterns in the findings and construct a new taxonomy of online information-sharing behaviours: contrary to existing taxonomies, all participants in this study are very privacy aware and make quite deliberate choices about what personal information they share online, with whom, to what extent, and under what circumstances. Four distinctive classifications of people’s online information-sharing behaviours were derived from this study: privacy pragmatists, privacy victims, privacy optimists, and privacy fatalists.","",""
"2017","The reliance on recognition and majority vote heuristics over privacy concerns when selecting smartphone apps among German and US consumers","ABSTRACT The smartphone app market is a prime example of a digital market where consumers are tasked with selecting one option among a plethora of alternatives, at times indistinguishable from one another. Building upon findings on information processing and decision-making, we postulate that consumers follow simple (rather than complex) heuristic rules to navigate the app market. In particular, we focus on two such strategies: the recognition heuristic and the majority vote heuristic. App privacy information was also considered as a potentially salient cue in the decision-making process, given the personal data stored on smartphones. Results of a mixed-method design (behavioral analysis and think-aloud protocols) study with German (N = 18) and US (N = 25) students find a dominance of the recognition heuristic. Decisions are further supported by majority vote heuristics. Privacy information is largely disregarded, particularly by US participants. Implications for app market design and engagement are discussed.","",""
"2017","Caring is not enough: the importance of Internet skills for online privacy protection","ABSTRACT This article explains Internet users’ self-help activities in protecting their privacy online using structural equation modeling. Based on a representative survey of Swiss Internet users, it reveals past experiences with privacy breaches as a strong predictor of current protective behavior. Further, in line with the ‘privacy paradox’ argument, caring about privacy (privacy attitudes) alone does not necessarily result in substantial self-protection. Most strikingly, however, general Internet skills are key in explaining users’ privacy behavior. These skills enable users to reduce risks of privacy loss while obtaining the benefits from online activities that increasingly depend on the revelation of personal data. Consequently, Internet skills are an essential starting point for public policies regarding users’ self-help in privacy protection.","",""
"2017","Am I my IP address's keeper? Revisiting the boundaries of information privacy","ABSTRACT Whether the Internet Protocol address should be seen as personal data or not remains a contested issue with regard to information privacy. This article explores the question by looking at the technical attributes of the Internet Protocol address, European Union (EU) and U.S. case law, and how the EU's advisory data protection body, the Article 29 Working Party, and some of the world's most influential information and communication technology (ICT) companies consider the IP address. The notion of contextual integrity is then used to show that information privacy regulation must stipulate concrete technical mandates instead of guiding principles, contrary to the ideal of technology neutrality in Internet regulation.","",""
"2017","Being publicly intimate: teenagers managing online privacy"," Adults usually suspect teenagers not to care about their online privacy, although it has been shown that they manage privacy settings more frequently. Actually, adolescents develop a strategic management of privacy in order to translate it to social prestige. This article empirically shows how they rely on strong ties and get advantage on their online privacy in order to produce social and symbolic capital, namely, to show to peers that they grew out of childhood. It also shows that this production relies on a subtle balance between the public and private spheres. Indeed, they must conduct a representation of their private life on a public sphere in order to convince peers, who serve as an authority of legitimation, that they have an exclusive privacy. ","",""
"2017","Towards A Networked Privacy Paradigm: Assumptions And Implications","There is a long tradition of research on why and to whom people disclose information and manage their privacy, especially since the emergence of social media. Recently, there has been a push to conceptualize privacy in relation to social media as ‘networked privacy’, where privacy is framed in terms of networks, relationships or people. Despite the popular term it is unclear what makes networked privacy new and how it relates to other privacy conceptualizations. In this paper, we therefore analyze networked privacy together with the following privacy theories; Warren and Brandeis’ right to be left alone, Westin’s privacy control, Nissenbaum’s theory of contextual integrity and Petronio’s communication privacy management theory. Each theory refers (implicitly or explicitly) to different ontological and epistemological claims and we will clarify these and illustrate how fundamentally different the networked privacy paradigm is from its counterparts. The analysis serves as a first step towards defining fundamental principles for a paradigm of networked privacy.","",""
"2017","Privacy protection and self-disclosure across societies: A study of global Twitter users"," Privacy is a culturally specific phenomenon. As social media platforms are going global, questions concerning privacy practices in a cross-cultural context become increasingly important. The purpose of this study is to examine cultural variations of privacy settings and self-disclosure of geolocation on Twitter. We randomly selected 3.3 million Twitter accounts from more than 100 societies. Results revealed considerable cultural and societal differences. Privacy setting in collectivistic societies was more effective in encouraging self-disclosure; whereas it appeared to be less important for users in individualistic societies. Internet penetration was also a significant factor in predicting both the adoption of privacy setting and geolocation self-disclosure. However, we did not find any direct relationships between cultural values and self-disclosure. ","",""
"2017","Critical multimodal studies of popular discourse","concerned users can now add to the bookshelf. Without doubt, this line of research will continue to grow. National and international media coverage on news topics revolving around the unearthing of intelligence agencies’ far-reaching surveillance programmes in collaboration with powerful corporations will ensure that the issue of online privacy remains on the public agenda. A recent Pew poll on privacy and cybersecurity revealed that 91% of US adults felt they have lost control over how personal data are collected and used (Madden, 2015). Even in the European Union with stricter data protection regulations, 85% of citizens are concerned about not having complete control over their personal information online (European Commission, 2015). Time will tell whether Obfuscation is the starting point of the ‘big little revolution’ it proclaimed for ‘the small players, the humble, the stuck, those not in a position to decline or opt out or exert control over our data emanations’ (p. 1).","",""
"2017","A Cross-Cultural Perspective on the Privacy Calculus"," The “privacy calculus” approach to studying online privacy implies that willingness to engage in disclosures on social network sites (SNSs) depends on evaluation of the resulting risks and benefits. In this article, we propose that cultural factors influence the perception of privacy risks and social gratifications. Based on survey data collected from participants from five countries (Germany [ n = 740], the Netherlands [ n = 89], the United Kingdom [ n = 67], the United States [ n = 489], and China [ n = 165]), we successfully replicated the privacy calculus. Furthermore, we found that culture plays an important role: As expected, people from cultures ranking high in individualism found it less important to generate social gratifications on SNSs as compared to people from collectivist-oriented countries. However, the latter placed greater emphasis on privacy risks—presumably to safeguard the collective. Furthermore, we identified uncertainty avoidance to be a cultural dimension crucially influencing the perception of SNS risks and benefits. As expected, people from cultures ranking high in uncertainty avoidance found privacy risks to be more important when making privacy-related disclosure decisions. At the same time, these participants ascribed lower importance to social gratifications—possibly because social encounters are perceived to be less controllable in the social media environment. ","",""
"2017","Social Media Users’ Legal Consciousness About Privacy"," This article explores the ways in which the concept of privacy is understood in the context of social media and with regard to users’ awareness of privacy policies and laws in the ‘Post-Snowden’ era. In the light of presumably increased public exposure to privacy debates, generated partly due to the European “Right to be Forgotten” ruling and the Snowden revelations on mass surveillance, this article explores users’ meaning-making of privacy as a matter of legal dimension in terms of its violations and threats online and users’ ways of negotiating their Internet use, in particular social networking sites. Drawing on the concept of legal consciousness, this article explores through focus group interviews the ways in which social media users negotiate privacy violations and what role their understanding of privacy laws (or lack thereof) might play in their strategies of negotiation. The findings are threefold: first, privacy is understood almost universally as a matter of controlling one’s own data, including information disclosure even to friends, and is strongly connected to issues about personal autonomy; second, a form of resignation with respect to control over personal data appears to coexist with a recognized need to protect one’s private data, while respondents describe conscious attempts to circumvent systems of monitoring or violation of privacy, and third, despite widespread coverage of privacy legal issues in the press, respondents’ concerns about and engagement in “self-protecting” tactics derive largely from being personally affected by violations of law and privacy. ","",""
"2017","“Nobody Sees It, Nobody Gets Mad”: Social Media, Privacy, and Personal Responsibility Among Low-SES Youth"," While few studies examine the online privacy practices or attitudes of young people of low socio-economic status (SES), they are often at the most risk of and most susceptible to privacy violations. This participatory, collaborative study of 28 low-SES young adults in the New York City area investigates how they view online information sharing. Like most Americans, our participants viewed online privacy as an individual responsibility. We make two primary contributions. First, participants revealed extensive awareness of the risks of sharing information online, and many avoided social media, self-censored, or obfuscated their contributions as a result. Second, many participants had extensive experience with policing and physical surveillance and were aware they could not avoid such encounters through their own efforts. This window into structural discrimination provides an alternate frame to that of “individual responsibility” that educators and researchers can use to conceptualize how privacy is violated online. Framing online privacy violations as inevitable and widespread may not only help foster activist anger and strategic resistance but also avoid the victim-blaming narratives of some media literacy efforts. By examining the experiences of these young people, who are often left out of mainstream discussions about privacy, we hope to show how approaches to managing the interplay of on- and offline information flows are related to marginalized social and economic positions. ","",""
"2018","The Contextual Accomplishment of Privacy","This study illustrates how different genres of social media use relate to contextual accomplishment of privacy. Information on privacy attitudes and behaviors and the uses and gratifications (U&G) of social media was gathered through a survey from 353 social media users and analyzed using multivariate multiple regression. Results indicate that social media privacy activities take place at multiple levels, are engaged at points of Internet and application access, and are socially enacted and technologically reinforced. Further, we demonstrate that certain contexts of social media use result in specific privacy-producing behaviors within this hierarchy. These findings provide empirical support for Nissenbaum’s framework of privacy as a contextual practice, as they demonstrate that privacy behaviors adapt to the situated use of social media.","",""
"2018","Privacy at the Margins| Concerns, Skills, and Activities: Multilayered Privacy Issues in Disadvantaged Urban Communities","Little attention has been given to how members of economically, socially, and digitally disadvantaged groups experience privacy. Using a door-to-door paper-and-pencil household census of public housing communities in a major American city, this study examined three layers of digital privacy experiences among public housing residents—privacy concerns, privacy skills, and privacy-compromising activities. Results showed that privacy concerns are one of the major reasons that hinder residents from adopting the Internet. Regression analysis revealed significant gaps in digital privacy skills among residents by generation and by having private Internet access or not. Moreover, higher levels of privacy skills and relatively private Internet access contribute to more frequent engagement in digital activities that can compromise privacy. This research provides valuable insights on how privacy concerns and skills affect digital inclusion in a marginalized population.","",""
"2018","Privacy encounters in Teledialogue","ABSTRACT Privacy is a major concern when new technologies are introduced between public authorities and private citizens. What is meant by privacy, however, is often unclear and contested. Accordingly, this article utilises grounded theory to study privacy empirically in the research and design project Teledialogue aimed at introducing new ways for public case managers and placed children to communicate through IT. The resulting argument is that privacy can be understood as an encounter, that is, as something that arises between implicated actors and entails some degree of friction and negotiation. An argument which is further qualified through the philosophy of Gilles Deleuze. The article opens with a review of privacy literature before continuing to present privacy as an encounter with five different foci: what technologies bring into the encounter; who is related to privacy by implication; what is entailed by the spaces of Teledialogue; how privacy relates to projected futures; and how privacy is also an encounter between authority and care. In the end, it is discussed how privacy conceptualised as an encounter is not already there surrounding people or places but rather has to be traced in the specific and situated relations between implicated actors, giving rise to different normative concerns in each case.","",""
"2018","The role of privacy concerns in the sharing economy","ABSTRACT Internet-mediated sharing is growing quickly. Millions of users around the world share personal services and possessions with others ‒ often complete strangers. Shared goods can amount to substantial financial and immaterial value. Despite this, little research has investigated privacy in the sharing economy. To fill this gap, we examine the sharing–privacy nexus by exploring the privacy threats associated with Internet-mediated sharing. Given the popularity of sharing services, users seem quite willing to share goods and services despite the compounded informational and physical privacy threats associated with such sharing. We develop and test a framework for analyzing the effect of privacy concerns on sharing that considers institutional and social privacy threats, trust and social-hedonic as well as monetary motives.","",""
"2018","Citizens’ Online Surveillance Concerns in Croatia","This paper explores citizens’ privacy concerns and online surveillance perceptions by using the survey data of 2,060 internet users in Croatia. Respondents can be categorised into two groups with significant differences in their perceptions of online surveillance, quality of regulation, trust in institutions, and trust in other people. The more online-privacy concerned group consists of on average less educated, older people, who spend less time online. Also, there are more females in this cluster. The main finding is that internet users who are very concerned about online surveillance tend to have limited trust in both the government and other people and limited faith in the ability of regulation to protect them. More concerned people tend to adopt countersurveillance strategies such as providing false data on the internet.","",""
"2018","Social media cultivating perceptions of privacy: A 5-year analysis of privacy attitudes and self-disclosure behaviors among Facebook users"," In light of the omnipresence of personal information exchange in the virtual world, this study examines the effects of Facebook use on privacy perceptions and self-disclosure behaviors across a 5-year period from 2010 to 2015. Findings at the global level support the socializing role of Facebook in cultivating more relaxed privacy attitudes, subsequently increasing self-disclosure in both offline and online contexts. However, longitudinal trends indicate that while risk perceptions increased for heavy users, they remained stable for light users. Furthermore, the negative relationship between privacy concerns and self-disclosure weakened across time. Implications for the application of cultivation theory to a contemporary social media context and the year-to-year changes in the impact of Facebook use on privacy attitudes and self-disclosure are discussed. ","",""
"2018","Platform privacies: Governance, collaboration, and the different meanings of “privacy” in iOS and Android development"," Mobile application design can have a tremendous impact on consumer privacy. But how do mobile developers learn what constitutes privacy? We analyze discussions about privacy on two major developer forums: one for iOS and one for Android. We find that the different platforms produce markedly different definitions of privacy. For iOS developers, Apple is a gatekeeper, controlling market access. The meaning of “privacy” shifts as developers try to interpret Apple’s policy guidance. For Android developers, Google is one data-collecting adversary among many. Privacy becomes a set of defensive features through which developers respond to a data-driven economy’s unequal distribution of power. By focusing on the development cultures arising from each platform, we highlight the power differentials inherent in “privacy by design” approaches, illustrating the role of platforms not only as intermediaries for privacy-sensitive content but also as regulators who help define what privacy is and how it works. ","",""
"2018","Managing the virtual boundaries: Online social networks, disclosure, and privacy behaviors"," Online social networks are designed to encourage disclosure while also having the ability to disrupt existing privacy boundaries. This study assesses those individuals who are the most active online: “Digital Natives.” The specific focus includes participants’ privacy beliefs; how valuable they believe their personal, private information to be; and what risks they perceive in terms of disclosing this information in a fairly anonymous online setting. A model incorporating these concepts was tested in the context of communication privacy management theory. Study findings suggest that attitudinal measures were stronger predictors of privacy behaviors than were social locators. In particular, support was found for a model positing that if an individual placed a higher premium on their personal, private information, they would then be less inclined to disclose such information while visiting online social networking sites. ","",""
"2018","Privacy in Mediated and Nonmediated Interpersonal Communication: How Subjective Concepts and Situational Perceptions Influence Behaviors"," New communication media such as social networking sites (SNSs) and instant messengers (IMs) challenge users’ privacy perceptions. Technical infrastructures and the flow of digital information lead to novel privacy risks that individuals are often not acquainted with. Users’ subjective perceptions of privacy may thus be flawed and lead to irrational behavior. In this work, we investigated a concept that has been addressed only implicitly in academic research on privacy: the user’s subjective perception of a given level of privacy. We examined the literature on how privacy perceptions have been conceptualized in traditional theories of privacy and how these conceptualizations are challenged in social media communication. We first qualitatively explored laypeople’s privacy concepts and investigated their subjective perceptions of privacy levels and subsequent private disclosures in different mediated and nonmediated communication settings. Interviews with N = 33 Germans revealed that, similar to academic privacy theories, they tend to conceptualize privacy as control over social, physical, and psychological boundaries. However, trust and other-dependent privacy emerged as important novel aspects for understanding privacy regulation in online communication. We further found that individuals consistently perceived a high level of privacy in face-to-face situations and a low level of privacy in public communication on SNSs. With regard to IMs, however, their answers were mixed: Uncertainty regarding digital communication properties and audiences as well as limited control over the communication setting prevented a reliable and shared perception of the privacy level. With regard to privacy behavior and private disclosures, we found that people tend to adapt their sharing of private information to the perceived level of privacy. ","",""
"2019","Risk Perception and Privacy Regulation Preferences From a Cross-Cultural Perspective. A Qualitative Study Among German and U.S. Smartphone Users","Following the notion that both individual privacy attitudes and (national) privacy regulation need to be addressed when understanding the privacy governance system, this article focuses on the relationship between information privacy risk perceptions and regulation preferences in two regulatory systems: Germany and the United States. Empirically, the study relies on semistructured interviews with German and U.S. smartphone users ( N  = 55). We analyze privacy risk perceptions and perceived control over privacy (RQ1), carving out four domains of privacy risks (governmental, criminal, and commercial misuse, as well as social risks). Furthermore, we focus on preferences for privacy regulation (RQ2), investigating preference for do-it-yourself privacy, as well as state- and market-based regulation. Findings support the notion that while privacy risks are shared among German and U.S. participants, U.S. users feel more in control over their data. A discrepancy between German and U.S. users with respect to their preferences for state- versus market-based regulation also exists.","",""
"2019","Control Responsibility: The Discursive Construction of Privacy, Teens, and Facebook in Flemish Newspapers","This study explores the discursive construction of online privacy through a critical discourse analysis of Flemish newspapers’ coverage of privacy, teens, and Facebook between 2007 and 2018 to determine what representation of (young) users the papers articulate. A privacy-as-control discourse is dominant and complemented by two other discourses: that of the unconcerned and reckless teenager and that of the promise of media literacy. Combined, these discourses form an authoritative language on privacy that we call “control responsibility.” Control responsibility presents privacy as an individual responsibility that can be controlled and needs to be learned by young users. We argue that the discourses contribute to a neoliberal rationality and have a disciplinary effect that strengthens various forms of responsibilization.","",""
"2019","Who Decides What Is Personal Data? Testing the Access Principle with Telecommunication Companies and Internet Providers in Hong Kong","Do personal data protection laws allow citizens to access their personal data? We answer this question by testing the data access principle of the Personal Data Privacy Ordinance (PDPO) with telecommunication companies and Internet providers in Hong Kong. In our study, we submitted data access requests to telecommunication companies and Internet providers for a range of information, including subscriber information, call logs, IP addresses, geolocation data, and whether they had shared any of this data with third parties. We argue that the telecommunication companies failed to (1) let users see their personal information in a comprehensive manner, including IP addresses or geolocations; (2) tell users whether they indeed process such information; (3) offer the possibility of correction or deletion; and (4) tell users whether they have shared this data with third parties, including law enforcement.","",""
"2019","Material Mediations Complicate Communication Privacy Management. The Case Of Wilma In Finnish High Schools","Increasingly, school settings are implementing digital technologies to coordinate teachers’ work. This article examines the role of these technologies in teachers’ boundary regulation processes through the lens of communication privacy management theory, and it provides empirical insight into the renegotiation of being a teacher in the presence of rules formalized in software code. The case of Finnish high school teachers exposed to the use of Wilma, a distributed computing system used to store, process, and transmit student data, revealed experiences of a need to renegotiate formalized and trackable work processes, faster and more colloquial communication, and intensified day-to-day work. These influence modes of accountability and the need to negotiate visibility, along with understandings of rules as a central coordination mechanism for interpersonal boundary regulation. The authors suggest in addition that these technologies inure various social stakeholders to constant technical monitoring and regular accounting, thereby advancing the normalization of surveillance practices. This creates good reason to pay closer attention to how rules of engagement may be coordinated.","",""
"2019","Relational privacy and the networked governance of the self","ABSTRACT The self today is networked, and governed through networks. This paper examines the four functions of privacy as set out by privacy theorist Alan Westin [1967. Privacy and freedom. New York: Atheneum] and works to construct a revised view of the functions of privacy in a networked world by drawing on feminist theories of relationality. Many basic ideas about privacy, drawn from the Western liberal tradition, have been challenged, redrawn, and re-conceptualized by feminist philosophers of relationality. In section one, this paper defines the ‘networked governance of the self’ and outlines the feminist relational approach, drawing the concepts of networked governance and relationality together. In section two, the paper elaborates a relational perspective on networked privacy, set up against Westin’s traditional formulation of the roles that privacy plays in democratic society. According to Westin, privacy (1) provides a realm of personal autonomy; (2) creates opportunities for emotional release; (3) permits a zone of self-evaluation; and (4) permits limited and protected forms of communication. The paper elaborates a relational perspective on the functions of privacy, emphasizing the importance of relational privacy to the networked governance of the self.","",""
"2019","Translating privacy: developer cultures in the global world of practice","ABSTRACT This paper makes the case for considering the role of cross-cultural encounters in shaping developers’ notions of information privacy. Recent studies on privacy by design shed light on developer practices yet tend to regard these workers as a generic category. The paper draws on two interviews with workers in a late-stage Israeli startup as a step toward localizing developers and the global products they design. The analysis identifies four narratives that juxtapose the local, the global and the commodification of users’ personal information: (1) the origin myth of the company; (2) workers’ personal and professional biographies; (3) reports on external regulations; and (4) accounts of work practices, rituals and communication formats. The analysis suggests how the globalization of the startup was implicated in changing ideas and practices relating to users’ information. The paper concludes by discussing some of the challenges facing a culturally-sensitive study of developers as mediators of privacy.","",""
"2019","Nothing to hide, nothing to lose? Incentives and disincentives to sharing information with institutions online","ABSTRACT What incentives and disincentives do Internet users weigh as they consider providing information to institutional actors such as government agencies and corporations online? Focus group participants list several benefits to sharing information including convenience, access to information, personalization, financial incentives, and more accurate health information, but also recognize that not all sharing may be in their interest. Disincentives to sharing include skepticism, distrust, and fears of discrimination. Decisions about sharing are related to the information type, the context in which information is revealed, and the institution to which they are – or think they are – providing information. Significantly, many participants were mistrustful of both governmental and corporate actors. Participants displayed awareness of privacy risks, but frequently mischaracterized the extent to which information could be aggregated and mined. They displayed resignation towards privacy violations, suggesting that they perceived little control over their ability to protect their privacy, which may influence their privacy behaviors. This calls into question the privacy calculus, as individuals misunderstand the risks of their information provision and do not believe opting out of information-sharing is possible.","",""
"2019","Privacy nudges as policy interventions: comparing US and German media users’ evaluation of information privacy nudges","ABSTRACT The protection of individuals’ online privacy is one of the main challenges for Internet policy. As the informed consent paradigm has largely failed to ensure privacy protection online, we examine nudging as a tool of soft paternalism as an alternative intervention to sensitize users towards online privacy. Building upon the criticism that nudging is considered being manipulative and reducing people’s autonomy in decision-making, we inquire how media users themselves evaluate nudges’ effectiveness and intrusiveness. In particular, we distinguish nudges either as targeting heuristic decision-making (system 1) or deliberate decision-making through education and information (system 2). Empirically, we carried out an interview study among German and US media users (N = 52) to address cross-cultural differences in the evaluation of privacy interventions. Our results point to a preference for system 2 nudges. Germans in particular perceive state interventions addressing privacy awareness as more acceptable and helpful than US participants.","",""
"2019","Engineering Privacy by Design: Are engineers ready to live up to the challenge?","Abstract Organizations struggle to comply with legal requirements as well as customers’ calls for better data protection. On the implementation level, incorporation of privacy protections in products and services depends on the commitment of the engineers who design them. We interviewed six senior engineers, who work for globally leading IT corporations and research institutions, to investigate their motivation and ability to comply with privacy regulations. Our findings point to a lack of perceived responsibility, control, autonomy, and frustrations with interactions with the legal world. While we increasingly call on engineers to go beyond functional requirements and be responsive to human values in our increasingly technological society, we may be facing the dilemma of asking engineers to live up to a challenge they are currently not ready to embrace.","",""
"2019","PERSONAL INFORMATION ARCHIVING: BEHAVIOURAL RESPONSES TO THE PERCEPTION OF RISK","The paper investigates the factors that influence perceptions of online risk and the consequential behavioural responses to those perceptions. Using Bates’ theory of information behaviour, we focus on online protection strategies and digital archiving as a specific instantiation and manifestation of information behaviour and analyze how factors, such as perceptions of online risk and self-reported internet skills, have consequences for information behaviours.&#x0D; The study uses semi-structured interview data (n=101) collected from East York, Toronto. We asked about individuals’ perception of risk online, self-reported internet skills, protective measures when going online, and digital archiving practices. Our findings identify a nuanced relationship between perceptions and behaviours. The results offer an alternate perspective on online information behaviour that departs from traditional classifications that rely on _demographics_. We offer a refinement to the definitions of information behaviour by Bates (2010) and Fisher and Julien (2009) to include factors that modify behaviours, and develop a user typology relating specifically to perceptions of risk online.","",""
"2019","MAKING SENSE OF SOCIAL MEDIA PRIVACY: A FRAMING EXPERIMENT","As individuals trade information to access social media products and services, privacy has become increasingly valuable. Elite discourses have tended to frame privacy in terms of its vertical or institutional dimensions, but much less attention has been given to how users individually interpret and make sense of this complex notion. How do privacy sense-making processes intersect with privacy concerns and self-efficacy? What happens to these outcomes when an individual’s ideas about privacy collide with framing by an authoritative source? This project poses a 2x2 survey-based experiment with 628 subjects to explore these questions. We examine differences in privacy concerns and self-efficacy resulting from an individual’s own conceptualization of privacy, as well as from the presentation of similar and alternative framing of the concept. Preliminary results indicate that while individual conceptualizations show no differences in outcomes, higher levels of privacy self-efficacy result from the framing of privacy in horizontal terms and lower levels of privacy concern result when framing is consistent with the individual’s conceptualization. Strategic and practical implications of these findings are discussed.","",""
"2019","Terms of public service: Framing mobile privacy discourses","Engaging normative theories of the press and research examining the evolution of privacy coverage, this study examines press coverage of mobile app privacy issues between 2013 and 2016. The research sheds light on how the press frames privacy concerns within the mobile app context. Since such coverage can define the norms circumscribing the flows of users’ personal information, this study contributes to the debate about the role of the press in alerting the public to privacy issues that carry significant public interest implications. Ultimately, mobile privacy coverage favors certain solutions over others, emphasizes privacy tradeoffs over privacy rights, and balances user powerlessness with mobile app convenience and innovation, with implications for privacy discourses in public and policy arenas.","",""
"2019","Improving privacy choice through design: How designing for reflection could support privacy self-management","In today’s society online privacy is primarily regulated by two main regulatory systems: (command-and-control) law and notice and consent (i.e., agreeing to terms of agreement and privacy policies). Both systems prohibit reflection on privacy issues from the public at large and restrict the privacy debate to the legal and regulatory domains. However, from a socio-ethical standpoint, the general public needs to be included in the privacy debate in order to make well-informed decisions and contribute to the law-making process. Therefore, we argue that privacy regulation must shift from a purely legal debate and simple one-time yes/no decisions by ‘data subjects’ to public (debate and) awareness and continuous reflection on privacy and privacy decisions by users of IT systems and services. In order to allow for this reflective thinking, individuals need to (1) understand what is at stake when interacting with digital technology; (2) have the ability to reflect on the consequences of their privacy decisions; and (3) have meaningful controls to express their privacy preferences. Together, these three factors could provide for knowledge, evaluation and choice within the context of online privacy. In this paper, we elaborate on these factors and provide a design-for-privacy model that introduces friction as a central design concept that stimulates reflective thinking and thus restores the privacy debate within the public arena.","",""
"2019","Toward a transnational model of social media privacy: How young Saudi transnationals do privacy on Facebook"," Previous models of cross-cultural differences fail to adequately account for transnational patterns of social media use, especially as it relates to notions of privacy. Based on our study of young transnational Saudis, we propose a new model, the rubber band model of transnational privacy, to account for the way social media users stretch their conceptualization of privacy as practiced in their societies of origin to include new norms and practices in their hosting society. We explore how this process unfolds through a series of ethnographic interviews conducted with young Saudis at different stages of their migratory journey from Saudi Arabia to the United States and back. Our findings hold important implications for viewing privacy as a dynamic concept related to the fluid production of identities in online spaces. The model of privacy we put forth seeks to inform the culturally sensitive development of information and communications technology (ICTs). ","",""
"2019","Awareness of Indirect Information Disclosure on Social Network Sites"," This research investigates user awareness and attitudes toward potential inferences of information posted on social network sites (SNSs). The study reports how user attitudes change after exposure to inferences made based upon information they have disclosed on an SNS, namely, on Facebook. To demonstrate this, two sub-studies involving three focus group sessions were conducted with Facebook users. In the first sub-study, the users received a general introduction to information that can be inferred from posts by using a prototypical privacy-enhancement tool called DataBait. Then, the second sub-study allowed the users to witness the potential inferences of their own Facebook photos and posts by using the DataBait tool. Next, qualitative content analysis was conducted to analyze the results, and these showed that the participants’ attitudes toward privacy on SNSs changed from affective to cognitive when they became aware of potential inferences from actual information posted on their own Facebook accounts. The results imply that end users require more cognitive awareness regarding their genres of disclosure and the effect of their disclosures on their privacy. Moreover, as privacy awareness is contextual, there is a need for more research and development of online tools that will allow users to manage and educate themselves. ","",""
"2019","Privacy Management Among Social Media Natives: An Exploratory Study of Facebook and Snapchat"," Guided by communication privacy management theory, this study tested network size, network diversity, privacy concerns, and privacy management practices in and between Facebook and Snapchat for social media natives. A cross-sectional survey of 273 college students (predominately Caucasian, female, 18- to 20 years old) showed that audiences were larger and more diverse in Facebook than Snapchat. Snapchat users with larger friend lists and lower privacy concerns reported more shared boundary ownership, whereas those with more diverse networks reportedly used more open friending practices to expand their connections. Higher privacy concerns were related to more restrictive privacy management practices in both mediums, and participants were overall more open on Snapchat than on Facebook. Theoretical and practical implications were presented in efforts to inform future research. ","",""
"2019","We Care About Different Things: Non-Elite Conceptualizations of Social Media Privacy"," This study explores privacy from the perspective of the user. It leverages a “framing in thought” approach to capture how users make sense of privacy in their social media use. It builds on a unique dataset of privacy definitions collected from a representative sample of 608 US social media users. The data are analyzed using topic modeling and semantic network analysis to unpack the multidimensionality of social media privacy. These dimensions are further examined in relation to established demographic antecedents of privacy concerns and behaviors. Results indicate the dominance of frames related to horizontal dimensions of privacy, or privacy vis-à-vis peers, as compared with the vertical dimensions, or privacy vis-à-vis institutions. In addition, the findings suggest that user conceptualization of privacy reflects a cognate-based approach that emphasizes control and limits to information access. Implications for privacy research, policy, and technology design are discussed. ","",""
"2019","Reputation Anxiety: Consumer Background Checks and the Cultivation of Risk","AbstractThis article examines the role consumer background check companies play in the construction of reputation anxiety. Through an examination of corporate blogs and sponsored stories, this article argues these companies cultivate risk along two related axes: (a) fear of dangerous others; and (b) fear of the threat posed by personal information available to others. Through sponsored stories and promotional material, these companies encourage people to mitigate risk by using consumer background check services to seek out information about others and review available details about themselves. Consistent with other forms of risk anxiety in modern cultures, the advice offered by these companies encourages the acceptance of personal responsibility around the acquisition of and response to this information. This article concludes by arguing the cultivation of reputation anxiety around digital skeletons—belonging both to others and to oneself—is rooted in gendered notions of safety and personal responsibility.","",""
"2020","Practicing privacy on other networks: network structures, economic arrangements, and identity strategies before cookies","Abstract Building on recent work revealing pre-web and alternative-internet networks, as well as legal research in comparative privacy, this article analyzes and compares identification protocols and practices on computer networks in Europe and the U.S. beyond the TCP/IP internet and contemporary web. These networks will include packet-switched networks, BBSs, videotex, online services, and early web browsers. In each, we describe privacy as practiced through network architecture, authentication and economic structures, and user anonymity and control. The article intends to contribute not only to our understanding of an older digital Europe but also present disputes and future policies.","",""
"2020","Privacy self-management and the issue of privacy externalities: of thwarted expectations, and harmful exploitation","This article argues that the self-management of one's privacy is impossible due to privacy externalities. Privacy externalities are the negative by-product of the services offered by some data controllers, whereby the price to """"pay"""" for a service includes not just the provision of the user's own personal data, but also that of others. This term, related to similar concepts from the literature on privacy such as """"networked privacy"""" or """"data pollutio"""", is used here to bring to light the incentives and exploitative dynamics behind a phenomenon which, I demonstrate, benefits both the user and the data controller to the detriment of third-party data subjects. Building on these novel elements and on the relevant concepts and examples found in the existing literature, this article draws a comprehensive picture of the phenomenon, and offers two promising paths to address it-better enforcing the principle of data protection by design and by default, and relying on the framework of joint controllership.","",""
"2020","The biggest lie on the Internet: ignoring the privacy policies and terms of service policies of social networking services","ABSTRACT This paper addresses ‘the biggest lie on the internet’ with an empirical investigation of privacy policy (PP) and terms of service (TOS) policy reading behavior. An experimental survey (N = 543) assessed the extent to which individuals ignored PP and TOS when joining a fictitious social networking service (SNS), NameDrop. Results reveal 74% skipped PP, selecting the ‘quick join’ clickwrap. Average adult reading speed (250–280 words per minute), suggests PP should have taken 29–32 minutes and TOS 15–17 minutes to read. For those that didn’t select the clickwrap, average PP reading time was 73 seconds. All participants were presented the TOS and had an average reading time of 51 seconds. Most participants agreed to the policies, 97% to PP and 93% to TOS, with decliners reading PP 30 seconds longer and TOS 90 seconds longer. A regression analysis identifies information overload as a significant negative predictor of reading TOS upon sign up, when TOS changes, and when PP changes. Qualitative findings suggest that participants view policies as nuisance, ignoring them to pursue the ends of digital production, without being inhibited by the means. Implications are revealed as 98% missed NameDrop TOS ‘gotcha clauses’ about data sharing with the NSA and employers, and about providing a first-born child as payment for SNS access.","",""
"2020","LAYERS OF “NETWORKED PRIVACY”: CONTEXT COLLAPSES ACROSS RELATIONS,   TECHNOLOGIES, INSTITUTIONS, AND DATA","This paper identifies different layers of “networked privacy,"""" expanding the original concept's focus on (1) networked relations (Marwick and boyd, 2014) to further include (2) networked technologies, (3) networked institutions, and (4) networked data. It teases out various moments of “collision of information norms” or “context collapse” (Marwick and boyd, 2014, p. 1054), which complicate privacy and regulations thereof in recent years. As we are at a critical juncture where information norms are being enshrined in different parts of the world including the EU's GDPR (General Data Protection Regulation) and the CCPA (California Consumer Privacy Act) in the U.S., understanding complex layers of context collapses can shed light on the legal grey areas that would need further examination. This study investigated the U.S. news coverage on digital privacy between January 2018 and June 2020 to explore any layers/moments of “context collapses” with regard to privacy. I conducted a Critical Discourse Analysis (CDA) (Fairclough, 2013), closely examining 300 samples out of 5,874 articles. Rethinking the framework of “networked privacy,” I argue, can help us ensure the """"similar minimum levels of privacy"""" (Regan, 1996) across networked relations, technologies, institutions, and data in the current digital era.","",""
"2020","UNDER THE WATCHFUL EYE: USERS’ PERCEPTIONS OF ONLINE PRIVACY AND   SURVEILLANCE","This project seeks to contribute to the question, “How do internet users navigate data privacy in a digitally surveilled online world?” I augment this ongoing discussion by examining the perceptions and practices concerning privacy and self-representation in digital spaces among young adults, 18-22. This qualitative work utilizes in-depth interviews of college students in the United States to collect both behavioral and attitudinal patterns. Specifically, I consider the impact of the strategic interventions of corporate and governmental platforms to collect, distribute, and utilize individual level data on research participants’ information consumption, individual identity representation, and group affiliation. A preliminary analysis of the data finds participants engage in narrative rationalizations to help them navigate the cultural expectations of online engagement within a surveilled environment. Patterns of strategic self-representation are shaped by such rationalizations and justifications, including a fundamental shift in what the concept """"privacy"""" means in an online world.","",""
"2020","Normative Paradoxes of Privacy: Literacy and Choice in Platform Societies","Privacy scholars, advocates, and activists repeatedly emphasize the fact that current measures of privacy protection are insufficient to counter the systemic threats presented by datafication and platformization (van Dijck, de Waal, and Poell 2018: 24). These threats include discrimination against underprivileged groups, monopolization of power and knowledge, as well as manipulation. In this paper, we take that analysis one step further, suggesting that the consequences of inappropriate privacy protection online possibly even run counter to the normative principles that underpinned the standard clause for privacy protection in the first place. We discuss the ways in which attempts at protection run the risk of producing results that not only diverge from but, paradoxically, even distort the normative goals they intended to reach: informational self-determination, empowerment, and personal autonomy. Drawing on the framework of “normative paradoxes,” we argue that the ideals of a normatively increasingly one-sided, liberal individualism create complicities with the structural dynamics of platform capitalism, which in turn promote those material-discursive practices of digital usage that are ultimately extremely privacy-invasive.","",""
"2020","Contextualizing how teens manage personal and interpersonal privacy on social media"," Many researchers have been studying teens’ privacy management on social media, and how they individually control information. Employing the theoretical framework of communication privacy management (CPM) theory, I argue that individual information control in itself is desirable but insufficient, giving only a limited understanding of teens’ privacy practices. Instead, I argue that research should focus on both personal and interpersonal privacy management to ultimately understand teens’ privacy practices. Using a survey study ( n = 2000), I investigated the predictors of teens’ personal and interpersonal privacy management on social media and compared different types of boundary coordination. The results demonstrate that feelings of fatalism regarding individual control in a networked social environment, which I call networked defeatism, are positively related with interpersonal privacy management. Also, interpersonal privacy management is less important when coordinating boundaries with peers than it is when coordinating sexual materials, and dealing with personal information shared by parents. ","",""
"2020","Data capitalism and the user: An exploration of privacy cynicism in Germany"," Ever since empirical studies found only a weak, if any, relationship between privacy concerns and privacy behavior, scholars have struggled to explain the so-called privacy paradox. Today, a number of theoretical arguments illuminate users’ privacy rationales, including the privacy calculus, privacy literacy, and contextual differentiations. A recent approach focuses on user resignation, apathy, or fatigue. In this piece, we concentrate on privacy cynicism, an attitude of uncertainty, powerlessness, mistrust, and resignation toward data handling by online services that renders privacy protection subjectively futile. We discuss privacy cynicism in the context of data capitalism, as a coping mechanism to address the tension between digital inclusion and a desire for privacy. Moreover, we introduce a measure for privacy cynicism and investigate the phenomenon based on a large-scale survey in Germany. The analysis highlights the multidimensionality of the construct, differentiating its relationships with privacy concerns, threat experience, Internet skills, and protection behavior. ","",""
"2020","Markers of Online Privacy Marginalization: Empirical Examination of Socioeconomic Disparities in Social Media Privacy Attitudes, Literacy, and Behavior"," This study explores how traditional socioeconomic markers of the digital divide interact with new markers of marginalization when it comes to online privacy protecting behaviors. To do this, we analyze data from a representative sample of social media users in the United States. Using hierarchical linear regression, we explore the relationships between established components of the digital divide, antecedents of privacy concerns, privacy-protecting behaviors, and privacy literacy. Our analysis highlights privacy literacy as a potentially understudied dimension of the digital divide and unpacks how traditional markers of marginalization explain distinct dimensions of privacy-protecting behaviors. Moreover, our findings suggest that the privacy literacy divide can amplify aspects of the second- and third-level digital divides, when translated into privacy-protecting behaviors. ","",""
"2020","Cybervetting and the Public Life of Social Media Data"," The article examines whether and how the ever-evolving practice of using social media to screen job applicants may undermine people’s trust in the organizations that are engaging in this practice. Using a survey of 429 participants, we assess whether their comfort level with cybervetting can be explained by the factors outlined by Petronio’s communication privacy management theory: culture, gender, motivation, and risk-benefit ratio. We find that respondents from India are significantly more comfortable with social media screening than those living in the United States. We did not find any gender-based differences in individuals’ comfort with social media screening, which suggests that there may be some consistent set of norms, expectations, or “privacy rules” that apply in the context of employment seeking—irrespective of gender. As a theoretical contribution, we apply the communication privacy management theory to analyze information that is publicly available, which offers a unique extension of the theory that focuses on private information. Importantly, the research suggests that privacy boundaries are not only important when it comes to private information, but also with information that is publicly available on social media. The research identifies that just because social media data are public, does not mean people do not have context-specific and data-specific expectations of privacy. ","",""
"2020","Default effects in app selection: German adolescents’ tendency to adhere to privacy or social relatedness features in smartphone apps"," Cognitive biases such as default effects impact on user preferences for a broad range of different choices. This paper investigates these default effects among adolescents configuring apps that either satisfy relatedness or enhance autonomy by protecting privacy. Relatedness and privacy are two innate needs that adolescents can satisfy with the use of smartphone apps. This study argues that adolescents’ choice of features supporting either privacy protection or social relatedness is a consequence of default effects, so that adolescents adhere to preselected defaults. We test this assumption in an experimental survey design including four app configuration tasks with N = 280 German adolescents aged 11 to 20 years. The study finds support for default effects for privacy as well as social relatedness. Effects for further variables, particularly age are discussed. ","",""
"2021","Does Perceived Privacy Influence Patient Satisfaction Among College Students? A Comparative Study of Students at a Kenyan University and at a Large American Midwestern University","Guided by the communication privacy management theory (CPM), the overarching goal of this study was to examine the extent to which perceived privacy influences patient satisfaction among students at a Kenyan university and at a large Midwestern university. Data were collected using surveys with 349 Kenyan students and 420 U.S. students, recruited using convenience sampling. Privacy was measured using a multidimensional Likert privacy scale, while patient satisfaction was measured using a patient satisfaction scale. Data were analyzed using descriptive statistics, correlation analysis, multiple linear regression, two-way MANOVA, and moderation analysis. The results revealed that all three types of privacy (psychological, physical, and informational) had a strong positive correlation with patient satisfaction. Perceived privacy predicted perceived patient satisfaction, and men and women did not have different concerns for privacy. Participant country moderated the relationship between privacy and patient satisfaction. These results suggest that physicians and hospitals should emphasize effective patient privacy in spaces where medical interactions occur.","",""
"2021","Technology use and norm change in online privacy: experimental evidence from vignette studies","ABSTRACT We suggest that explaining privacy behaviors requires understanding not only individual attitudes, but also norms and trust. We propose: (1) the popularity of a potentially privacy-violating technology leads individuals to expect that others approve of privacy violations and simultaneously increases their trust in the technology provider; (2) the frequency of privacy violations by other similar providers leads individuals to expect that a specific provider will engage in privacy-violating behaviors and decreases trust in that provider; (3) trust in a specific provider and expectations that others approve of the provider violating users’ privacy increase, and expectations that other similar providers are likely to violate privacy decrease, willingness to use a technology. We test our propositions using two vignette experiments in the context of a household energy app. Our results are generally consistent with our hypotheses. Our findings have implications for understanding privacy norms and highlight the potential consequences of major technology roll-outs.","",""
"2021","“This is capitalism. It is not illegal”: Users’ attitudes toward institutional privacy following the Cambridge Analytica scandal","Abstract In this study, we seek to understand the considerations of young adults who chose to continue their active engagement with Facebook even after Cambridge Analytica scandal laid bare the mechanics of economic surveillance. We base our analysis on two sets of in-depth face-to-face interviews we conducted with young adults in Israel—26 before the Cambridge Analytica scandal, which we had already conducted for a study on privacy, and 24 after the scandal erupted. To analyze our respondent’s rationales, we employ Boltanski and Thévenot’s regimes of justification framework. Before the scandal, our respondents largely saw privacy as a commodity, a tradeoff made by the individual—information disclosure in exchange for free personalized digital services. However, there were some respondents who rejected the notion of privacy as a commodity and advanced an alternative perspective that considers it to be a human right. After the Cambridge Analytica scandal, there was a marked shift away from understanding of privacy as a right, which our respondents neither saw an unconditional right nor something enforceable by regulators. Instead, they largely saw economic surveillance as something inherent to the digital world, which one needs to accept if one wants to participate in it.","",""
"2021","A market-based rationale for the privacy paradox"," Moving beyond the current focus on the individual as the unit of analysis in the privacy paradox, this article examines the misalignment between privacy attitudes and online behaviors at the level of society as a collective. I draw on Facebook’s market performance to show how despite concerns about privacy, market structures drive user, advertiser and investor behaviors to continue to reward corporate owners of social media platforms. In this market-oriented analysis, I introduce the metaphor of elasticity to capture the responsiveness of demand for social media to the data (price) charged by social media companies. Overall, this article positions social media as inelastic, relative to privacy costs; highlights the role of the social collective in the privacy crises; and ultimately underscores the need for structural interventions in addressing privacy risks. ","",""
"2021","VERTICAL OR HORIZONTAL? AN EMPIRICAL INVESTIGATION OF THE ROLE OF        PRIVACY LITERACY AND PRIVACY SELF-EFFICACY ON THE DIMENSIONALITY OF PRIVACY","The goals of this study are two-fold. We extend established models linking attitudes related to privacy concerns and privacy protecting behavior (PPB) by (a) differentiating between horizontal (social) and vertical (institutional) orientations of PPB as capturing an aspect of privacy multidimensionality, and (b) introducing additional explanatory factors such as privacy literacy and privacy self-efficacy into the modeling of PPB. We survey a representative sample of 686 US social media users to test relationships between privacy concern, trust, privacy self-efficacy, privacy literacy, and vertical and horizontal PPB. We find privacy concerns contribute to horizontal and vertical PPB at different levels, reinforcing the dimensionality of privacy. We also find that privacy literacy and privacy self-efficacy are important factors in explaining dimensional privacy behaviors and moderate the established relationships between privacy concerns and PPB.","",""
"2021","THE QUALITY OF SURVEY SCALES FOR MEASURING INFORMATION PRIVACY CONCERNS        ON SOCIAL NETWORK SITES: A SYSTEMATIC REVIEW","Information privacy concerns (IPCs) play an important role in user behavior on social network sites (SNSs). They are associated with self-disclosure behavior, enjoyment, and, perhaps most importantly, a user’s intention and ability to form and sustain social ties on SNSs. While conceptual integration of different approaches to studying IPCs has already been pursued, prior research has pointed to potential problems with respect to the survey measurements of IPCs. More specifically, a plethora of self-assessment scales have been developed but the differences among them have not yet been systematically elaborated, and this is further complicated by many methodologically questionable adaptations of existing IPC survey scales to ever-emerging online contexts and SNS platforms. Accordingly, this study comprises a systematic literature review based on the COSMIN methodology to comprehensively examine the quality of survey scales used for measuring IPCs among SNS users. The results have unveiled significant variety with 35 uni- or multidimensional survey scales used in 71 articles published since 2009. Many of the scales are of questionable quality in terms of structural validity, and only a few of the studies tested them for measurement invariance. Nevertheless, we identified some scales that are promising candidates for future use, although further testing and potential improvements are needed. Our findings could also act as the foundation for a unified measurement approach to IPCs that could be used across different SNSs platforms.","",""
"2021","CHOICE AND CONTROL: AN ANALYSIS OF PRIVACY VALUES AND PRIVACY        CONTROLS","There is incredible and intrinsic, though hidden, power in technology settings, including those set by online platforms. The hidden levers of control embedded within the default settings influence users’ overall experience on platforms and with technology, especially in regard to issues of privacy and security. This paper examines the embedded assumptions and implications of technology and technical design on society. To this end, this study addresses the role and power of social media platforms in developing and applying privacy and security policies and norms for their users. The privacy and security choices by social media platforms affect billions of users worldwide. Further, this study will consider how platforms’ public-facing rhetoric aligns or differs with the actual implementation of privacy policies and privacy and security user settings. The implications of this research may have profound impact in the governance, policy, and regulation of platforms.","",""
"2021","Behind passwords: An analysis of preliminary results in order to understand how users protect their privacy","Nowadays, the Internet is the most common source of information, it is the means of almost any activity, such as shopping, online banking, getting informed or keeping contacts. Users need to know privacy regulations, read privacy and cookie policies to protect themselves against illegal or unwanted data use. The answers obtained to our questionnaire have been analyzed and they prove our hypothesis that users’ privacy awareness is low, and highlight that users need a deeper education in privacy protection. In our questionnaire people were asked general questions, such as “Do you always read cookie policies?” or “Do you have deep knowledge of privacy regulations?”, and more specific questions, such as “Have you ever used the Hungarian National eHealth Infrastructure (EESZT)?” or “Do you know that Facebook plugins follow all your online activities?”.","",""
"2021","Linking loose ends: An interdisciplinary privacy and communication model"," In the recent decades, privacy scholarship has made significant progress. Most of it was achieved in monodisciplinary works. However, privacy has a deeply interdisciplinary nature. Most importantly, societies as well as individuals experience privacy as being influenced by legal, technical, and social norms and structures. In this article, we hence attempt to connect insights of different academic disciplines into a joint model, an Interdisciplinary Privacy and Communication Model. The model differentiates four different elements: communication context, protection needs, threat and risk analysis, as well as protection enforcement. On the one hand, with this model, we aim to describe how privacy unfolds. On the other hand, the model also prescribes how privacy can be furnished and regulated. As such, the model contributes to a general understanding of privacy as a theoretical guide and offers a practical basis to address new challenges of the digital age. ","",""
"2021","Understanding third-person perception about Internet privacy risks"," This study aims to test the third-person effect (TPE) in the perception of Internet privacy risks. Support was found for a TPE model suggesting that users report greater perceived Internet privacy risks on others than on themselves, based on a sample ( N = 613) from Amazon MTurk. In particular, the differential perception of Internet privacy risks between self and others increased people’s willingness to recommend protective measures to others but decreased their willingness to adopt protective measures themselves. Moreover, social distance, perceived Internet privacy knowledge, negative online privacy experiences, and Internet use activities emerged as significant predictors of TPE perceptions about Internet privacy risks. Study findings indicated that third-person perception is one of the major barriers inhibiting the adoption of privacy protection measures. The antecedents of TPE perceptions detected here provide valuable implications about how to enable Internet users to protect their privacy security. ","",""
"2021","Privacy attitudes and behaviors in the age of post-privacy: An empirical approach","The digital world is a field of information and entertainment for users and a field of extraction of the most valuable good of recent years: personal data. How much of a threat to privacy is the collection and processing of data by third parties and what do people think about it? On the occasion of the extensive methods of surveilling citizens and collecting their data, this study attempts to contribute new empirical data evidence from the international research on the use of the Internet by the World Internet Project on attitudes and behaviors of individuals regarding online privacy and surveillance. The aim is to determine whether and to what extent the recorded concerns about the violation of privacy intersects with a growing acceptance of its very absence.","",""
"2022","Session replay scripts: A privacy analysis","Abstract Session replay scripts record a user’s actions while visiting a website or using a computer application. These recordings are typically sent to third party companies whose stated purpose is to analyze the recordings to help correct bottlenecks and illuminate problems that are difficult for users to navigate. We examine how session replay scripts are being marketed and how they are used by application developers. The extent of gathered data is intrusive, often going beyond the stated objectives, and often collected without users’ knowledge. Using Nissenbaum’s privacy as contextual integrity framework, we demonstrate how replay scripts violate the norms of both appropriateness and distribution, and hence the privacy of the user. We examine two scenarios: one where the session replay data are sent back to the application developer, and another where captured data are sent to third party companies. We compare the scenarios to two analogous situations: surveys taken at a museum and video surveillance in a brick-and-mortar store. We analyze in detail the case of FullStory, a vendor of session replay scripts. In conclusion, we offer suggestions on how to preserve private information in both scenarios.","",""
"2022","Prototyping policy: Visualizing impact for better regulation"," A stark divide often exists between a policy’s goals and its implementation. This policy “implementation gap,” signals a failure to take into consideration the complexity of a system or issue. Failure often results in policy that is a misfit for the issue of concern and is lacking in the hoped for remedial or preventative impacts. This study explores policy prototyping as a remedy for policy failures in bills aimed at privacy protection. After selecting three privacy-related bills, we created prototypes that represented one of many ways that privacy policy could be translated into features in online platforms. Using the prototypes, we conducted 41 semi-structured interviews to gather feedback and insights on the challenges with the laws. Our findings illustrate how different roles emphasize protections, harms, and word choice when communicating levers of change like civil rights protections in law to privacy design elements. This solidified the opportunities to better bridge policy and practice by outlining common and distinct bill themes. ","",""
"2022","Conceptions of Privacy in the Digital Era: Perceptions of Slovak Citizens","In the digital era, citizens’ daily lives are taking place both in the physical and digital realms. At the same time, even the most mundane activities are increasingly affected by offline as well as online surveillance. The privacy paradigm suggests that there is a difference between the private and public spheres of life, and that with technological advancement the demarcation lines between these spheres have become blurred. As a consequence, citizens’ conceptions of privacy are becoming more fluid, nuanced, context-dependent, and socially determined. This gives rise to a need to reconceptualize what privacy means and how citizens think about its boundaries. To investigate citizens’ conceptions of privacy, we conducted six focus groups in Slovakia aimed at exploring people’s attitudes toward privacy and encompassing their experiences and rationalizations (including possible alterations) of behavior in a variety of everyday environments. The analysis suggests that privacy is a complex phenomenon that is understood as an interplay between different privacy norms guiding specific contexts and more general approaches to privacy. We identify four privacy environments (a controlled private space, a [voluntarily] shared private space, a transactional public space, and a non-controllable public space) and three privacy approaches (the reservations approach, the trade-off approach, and the death of privacy approach) whose interplay constitutes individuals’ conceptions of privacy. In addition, the acceptance of loss of privacy seems to depend on a perception of legitimacy, control over the mechanisms of surveillance that individuals encounter, and trust toward the data processor.","",""
"2022","The posthumous privacy paradox: Privacy preferences and behavior regarding digital remains"," Scholars have observed a gap between users’ stated preferences to protect their privacy and their actual behavior. This is the privacy paradox. This article queries the persistence of the privacy paradox after death. A survey of a representative sample of Israeli Internet users inquired of perceptions, preferences, and actions taken by users regarding their digital remains. The analysis yielded three distinct groups: (1) users interested in preserving privacy posthumously but do not act accordingly; for these users, the privacy paradox persists posthumously; (2) users who match their behavior to their preferences; for these users, the privacy paradox is resolved; and (3) users interested in sharing their personal data posthumously but do not make the appropriate provisions. This scenario is the inverted privacy paradox. This new category has yet to be addressed in the literature. We present some explanations for the persistence of the posthumous privacy paradox and for the inverted privacy paradox. ","",""
"2022","Everybody wants some: Collection and control of personal information, privacy concerns, and social media use"," As the utility of social media platforms for interacting with large populations, as well as understanding how they interact, becomes an increasingly interesting area, privacy concerns could present a barrier to engagement. This study employs a survey method to explore social media user frustrations with terms of service agreements and concerns over privacy and personal information shared on them. Findings support that concerns over control, collection, and access to personal information associate with decreased intensity of social media use and correlate to frustration with terms of service agreements regarding personal information use. Given the relationship between use and privacy concerns, leaving privacy concerns unaddressed might also lead to a reduction of use if these concerns continue to grow among users. ","",""
"2022","Twitter Users’ Privacy Behavior: A Reasoned Action Approach"," Social networking sites have become a predominant means of communication across the globe. Activities on these sites generate massive amounts of personal information and raise concerns about its potential abuse. Means designed to protect the user’s privacy and prevent exploitation of confidential data often go unused. In this study, we draw on the theory of planned behavior, a reasoned action approach, to explain intentions to adopt privacy behaviors on social networking sites, with a focus on Twitter users. Consistent with the theory, an online survey of Twitter users ( n = 1,060) found that instrumental and experiential attitudes and descriptive and injunctive subjective norms regarding these behaviors were direct predictors of intentions. Perceived behavioral control had a moderating effect, such that subjective norm was a better predictor of intentions for participants high as opposed to low in perceived control. We briefly discuss the implications of these results for developing theory-driven and evidence-based interventions to promote privacy behavior. ","",""
"2023","Correcting overconfidence in online privacy: experimenting with an educational game","ABSTRACT Widespread use of the Internet means that online privacy, or how to protect one’s private information while engaging in online activity, has become a concern for many individuals. Research has investigated people’s online privacy experience, including online privacy attitudes, confidence, and behaviors. However, not much attention has been paid to how online privacy confidence could be misperceived and how educational tools can correct such overconfidence. Guided by the protection motivation theory, this research examines online privacy confidence and is composed of two studies: Study 1 reveals that online users misrepresent their online knowledge and may have overconfidence as a result. Inspired by this finding and previous research, Study 2 avoids self-reported measures of online knowledge and instead directly evaluates online privacy knowledge (using OPLIS) and its impact on online privacy confidence. Using a survey experiment, we find playing an online privacy educational game increases confidence overall and, importantly, corrects overconfidence. Despite this, we do not find any evidence that correction leads to increased information-seeking. The findings shed light on what online users themselves and organizations, such as universities, industry, and government agencies, can do to better educate individuals about online privacy while calling attention to the need for continued research regarding the underlying mechanisms and downstream behavioral consequences.","",""
"2023","Understanding the effects of conceptual and analytical choices on ‘finding’ the privacy paradox: A specification curve analysis of large-scale survey data","ABSTRACT The privacy paradox suggests that privacy concerns do not relate to privacy-related behavior. Although it has inspired numerous studies, findings remain inconclusive. Some of the inconsistencies in published findings may be explained by a strong heterogeneity in the conceptual and analytical choices that researchers implement when investigating the privacy paradox. Based on representative survey data of the 27 EU member states (2011: n = 8,962; 2015: n = 10,526; 2019: n = 11,428), I investigated the effect of conceptual and analytical decisions on ‘finding’ the privacy paradox. Specification curve analyses revealed that the magnitude and statistical significance of the relationship between privacy concerns and information disclosure is contingent on the operationalization of the independent variable, the inclusion of covariates, and the age of the studied population. The relationship between online privacy concerns and using social media privacy settings, in contrast, was less influenced by analytical decisions. Yet, the relationship was stronger in younger people and increased over time. The findings call for more transparency in analyzing research data. Evaluating the implications of analytical choices will help to establish best practices and advance cumulative knowledge creation in privacy research.","",""
"2023","Fair privacy: how college students perceive fair privacy protection in online datasets","ABSTRACT With the wide use of social media and other online services, people are getting more concerned about online privacy. Social media platforms and other online companies are collecting users’ information for various purposes, including targeted advertising. While these data are anonymous, it is possible to identify people through publicly available information and machine learning algorithms. Members of some groups are more vulnerable to such privacy attacks and more likely to be identified. This raises a concern regarding the fair or equitable protection of online privacy, or the protection of all online users’ instead of most users’ private information. This research addresses this relatively new topic from the sociological perspective and focuses on fair privacy protection in online datasets. Questionnaire data show that college students rate the current privacy protection in online datasets low, but they have great support for general privacy protection and greater support for fair privacy protection. Factors that affect their support for general and fair privacy protection include prior cautious online behavior and how essential they rate company practice and government policies that ensure fair privacy. When they perceive a lack of fair privacy in online datasets, most of them would reduce or stop using certain online services. Factors affecting such reactions include prior cautious online behavior, hours on social media, the perception of being included in online datasets, and perceived importance of fair privacy policies. The findings highlight the pivotal role of institutional privacy measures, namely fair privacy company practice and government policies, especially the latter.","",""
"2023","RULE BY DEFAULT: A CROSS-PLATFORM ANALYSIS OF PRIVACY SETTINGS","Privacy settings are a critical space of research. Settings are uniquely positioned at the intersection between users and digital platforms and regulation, providing a visible privacy architecture (unlike backend privacy infrastructure and code) as well as an opportunity for users to interact with privacy choices (unlike terms of service and privacy policy documents which offer only all-or-nothing options). This paper examines the structural power relations and hierarchies inherent within privacy settings. We address the conference theme of decolonizing the internet through a comprehensive analysis of privacy controls, a critical site of power for the “new colonising forces in the form of multinational tech giants who are re-fashioning the world in their own image” (#AoIR2022 CFP).  This paper applies a theoretical framework of science &amp; technology studies (STS) to analyze the affordances of social media platforms’ privacy settings. Further, we apply Ian Bogost’s theory of procedural rhetoric to examine how platforms apply “the art of using processes persuasively” (Bogost, 2007). We conduct a comparison study of privacy settings across the most popular social media platforms: Facebook, YouTube, WhatsApp, WeChat, Instagram, TikTok, Snapchat, Pintrest, Twitter, and Reddit. The purpose of this qualitative analysis is to examine how privacy is presented to users. How does each platform define privacy? Where do they locate different kinds of privacy settings? What kinds of privacy choices are offered? How do these choices differ? How a platform designs their choice architecture for privacy shapes a user’s understanding of what privacy is and means.","",""
"2023","IDENTIFYING WITH PRIVACY: REFERENCES TO PRIVACY IN DEVELOPERS’ GITHUB PROFILES","The proposed presentation explores the ways in which developers use the notion of privacy in their GitHub biographies. Initially a code-sharing platform, GitHub has become in recent years a major recruitment site. In that environment, a valuable potential worker is one who knows how to extract and make the most of users’ personal information. At the same time, in an open source platform, “privacy” maintains its romantic allure as a worthwhile endeavor. How do developers manage this tension? And what may its negotiation imply for the production of privacy? Analyzing the 2025 GitHub bios in which developers use the word “privacy,” we explore two articulations of privacy in developers’ self-presentation: privacy as a profession, and privacy as a passion.","",""
"2023","ANTECEDENTS OF PRIVACY PROTECTION BEHAVIORS AT THE VERTICAL AND HORIZONTAL LEVELS","Internet users face privacy threats when using online services. Privacy protection behaviors, such as adjusting privacy settings, can alleviate some of these threats. Research shows that individuals’ privacy protection behaviors (PPBs) depend on their socio-demographics characteristics, digital engagement, privacy concerns, and online privacy literacy (OPL). In addition, it has been suggested that due to the complexity of privacy issues online, an adequate level of OPL is required to translate privacy concerns into protective actions. Although previous research examined the antecedents of PPBs at a general level, it has rarely made a clear distinction and comparison between PPBs aimed toward the practices of institutions (vertical level) and those aimed toward other internet users (horizontal level). This is somewhat surprising given that many scholars underscored the importance of context in online privacy-related matters. Therefore, this study compared the antecedents of PPBs at the general, vertical, and horizontal levels. To this end, we tested three models to examine how socio-demographic characteristics, digital engagement, privacy concerns, and OPL influence PPBs at the general, vertical, and horizontal levels, and assessed whether OPL moderates the relationship between privacy concerns and PPBs at different levels. The models were tested using linear regression on a nation-wide sample of 1,015 internet users aged 18+ from Slovenia. The analysis revealed important differences between the levels in case of gender, age, and privacy concerns, but not OPL.","",""
"2023","VOICES FROM THE MARGINS: PRIVACY DISCOURSE IN GITHUB README FILES","Most digital products use technologies that enable the collection, analysis and transfer of a considerable amount of personal information to the cloud, where it is stored and processed. Thus much of the responsibility for the users’ personal information is in the hands of the developers and the code that they author. This research adopts a materialist perspective to study developers’ discourse around the privacy solutions they embed in the code. Defining GitHub as a discursive platform, we draw on a sample of almost 60,000 README files to analyze the ways in which developers present code to other developers. We find that the files promote two approaches, privacy-by-policy and privacy-by-design. We suggest that the distinction between the two is in fact a distinction between developers who uphold privacy as a value and developers who regard it as an imposition to comply with.","",""
"2023","The after party: Cynical resignation in Adtech's pivot to privacy"," Digital advertising and technology companies are resigned to a new privacy imperative. They are bracing for a world where third-party tracking will be restricted by design or by law. Digital resignation typically refers to how companies cultivate a sense of powerlessness about privacy among internet users. Our paper looks through this optic from the other end of the lens: How is the digital advertising industry coping with the increasing salience of privacy? Recent developments have forced companies to implement “privacy-preserving” designs—or at least promise some semblance of privacy. Yet, the industry remains dependent on flows of data and means of identification to enable still-desired targeting, measurement, and optimization. Our paper analyzes this contradiction by looking at systems that aim to replicate existing functionalities while protecting user “privacy.” We call this a form of “cynical resignation” and characterize its key maneuvers as follows: (a) sanitizing surveillance; (b) party-hopping; and (c) sabotage. We argue that this “cynical resignation” to a privacy imperative represents a policy failure. In the absence of decisive interventions into the underlying business models of data capitalism, companies offer techno-solutionism and self-regulations that seem to conform to new laws and norms while reinforcing commitments to data-driven personalization. This may benefit the largest tech companies, since their privileged access to first-party data will make more companies reliant on them, and their computational power will be even more valuable in a world where modeling is used to compensate for the loss of third-party data and traditional methods of personal identification. ","",""
"2023","Dimensionalizing privacy to advance the study of digital disempowerment"," In this essay, we call attention to privacy as the foundational construct that underpins digital disempowerment. We argue that to better understand the processes of disempowerment, scholars must critically engage with the dimensionality of privacy conceptualizations and privacy-dependent constructs such as privacy concerns and privacy-protecting behavior, and the way in which these are measured. We focus on privacy's horizontal and vertical dimensions as a way to offer a more nuanced understanding of power in computationally mediated environments and potentially enable a more refined and meaningful understanding of privacy resignation and disengagement. ","",""
"2023","Private attributes: The meanings and mechanisms of “privacy-preserving” adtech"," This study analyzes the meanings and technical mechanisms of privacy that leading advertising technology (adtech) companies are deploying under the banner of “privacy-preserving” adtech. We analyze this discourse by examining documents wherein Meta, Google, and Apple each propose to provide advertising attribution services—which aim to measure and optimize advertising effectiveness—while “solving” some of the privacy problems associated with online ad attribution. We find that these solutions define privacy primarily as anonymity, as limiting access to individuals’ information, and as the prevention of third-party tracking. We critique these proposals by drawing on the theory of privacy as contextual integrity. Overall, we argue that these attribution solutions not only fail to achieve meaningful privacy but also leverage privacy rhetoric to advance commercial interests. ","",""
"2023","How teens negotiate privacy on social media proactively and reactively"," Privacy management can be dichotomized into proactive and reactive behaviors. The former indicates avoiding information leakage beforehand. The latter occurs in the form of recovery efforts and it thus involves interpersonal dynamics. Past studies often focus on proactive privacy management without taking social interaction into account. The current study adopts coping and threat appraisal in the Protection Motivation Theory to compare the factors related to distinct types of privacy management with a stratified sample of teenagers in Taiwan (N = 1956). Controlling the pattern of social networking site use, the empirical results highlight the necessity of differentiating the privacy management. In addition, self-efficacy interacted with perceived vulnerability. Teenagers might ignore their vulnerability perceptions when they perceive themselves as having inferior self-efficacy, constituting disengagement from privacy protection. While it is never easy to prevent privacy breaches, suggestions for instructional designs are made on the basis of the behavioral types and empirical results. ","",""
"2023","Communication privacy management for smart speaker use: Integrating the role of privacy self-efficacy and the multidimensional view"," Smart speakers can transform interactions with users into retrievable data, posing new challenges to privacy management. Privacy management in smart speakers can be more complex than just making decisions about disclosure based on the risk–benefit analysis. Hence, this study attempts to integrate privacy self-efficacy and the multidimensional view of privacy management behaviors into the privacy calculus model and proposes an extended privacy calculus model for smart speaker usage. The study explicates three types of privacy management strategies in smart speaker usage: privacy disclosure, boundary linkage, and boundary control. A survey of smart speaker users ( N = 474) finds that perceived benefits are positively associated with privacy disclosure and boundary linkage, whereas perceived privacy risks are negatively related to these two strategies. Also, perceived privacy risks are positively related to boundary control. Finally, privacy self-efficacy promotes all three strategies while mitigating the impact of perceived privacy risks and boosting the impact of perceived benefits on privacy management. ","",""
"2023","A longitudinal analysis of the privacy paradox"," The privacy paradox states that people’s concerns about online privacy are unrelated to their online sharing of personal information. On the basis of a representative sample of the German population, which includes 1,403 respondents interviewed at three waves separated by 6 months, we investigate the privacy paradox from a longitudinal perspective. Using a cross-lagged panel model with random intercepts, we differentiate between-person relations from within-person effects. Results revealed that people who were more concerned about their online privacy than others also shared slightly less personal information and had substantially more negative attitudes toward information sharing (between-person level). People who were more concerned than usual also shared slightly less information than usual (within-person level). We found no long-term effects of privacy concerns on information sharing or attitudes 6 months later. The results provide further evidence against the privacy paradox, but more research is needed to better understand potential causal relations. ","",""
"2023","How Subjective Norms Relate to Personal Privacy Regulation in Social Media: A Cross-National Approach","The growing body of research on privacy documents cross-cultural differences in the way people manage their privacy in social media. Yet, cultural values do not provide a consistent account for these differences. Drawing on communication privacy management theory, this work argues that different governmental approaches of privacy regulation shape users’ subjective norms in the form of perceived rules about how to manage personal and collective boundaries. These subjective privacy norms may better explain cross-national differences in people’s online privacy behavior. We conducted a survey (N = 1,060) among Facebook users in two countries in which privacy regulation policies vary significantly: the United States and Germany. While US users self-disclose more than German users do, they also take more measures to protect their privacy on Facebook. US users perceive stronger norms to protect themselves than German users. These findings inform communication privacy management theory and the influence of privacy rules within and across national borders.","",""
"2024","Does the type of privacy-protective behaviour matter? An analysis of online privacy protective action and motivation","","",""
"2024","Identifying undefined risks: A risk model and a privacy risk identification measure in the privacy impact assessment process","Abstract Privacy impact assessment (PIA) has attracted the attention of privacy watchdogs and researchers for decades. This study focuses on a risk model and risk identification method, which are two crucial elements of the risk identification step in the PIA process. As a preparatory work, this article reviews national and international organizations’ current templates and guidelines and finds that PIA guidance includes multiple domains but rarely provide a risk model or a systematic risk identification method. Based on the analysis, our study offers a risk model that can capture various privacy risk realization processes. It further proposes a combination of risk identification methods that correspond to the main target domains in the PIA and the proposed risk model. This combination consists of privacy principles of a given personal information or privacy rule to check compliance with the rule, and our suggested list of risk factors is useful in inductively finding potential risk scenarios that violate social expectations of privacy.","",""
"2024","The privacy dependency thesis and self-defense","AbstractIf I decide to disclose information about myself, this act may undermine other people’s ability to conceal information about them. Such dependencies are called privacy dependencies in the literature. Some say that privacy dependencies generate moral duties to avoid sharing information about oneself. If true, we argue, then it is sometimes justified for others to impose harm on the person sharing information to prevent them from doing so. In this paper, we first show how such conclusions arise. Next, we show that the existence of such a dependency between the moral significance you are inclined to attribute to privacy dependencies and judgments about permissible self-defense puts pressure on at least some ways of spelling out the idea that privacy dependencies ought to constrain our data-sharing conduct.","",""
"2024","The interplay of rational evaluation and motivated reasoning in privacy helplessness: An integrative approach"," This study investigated the factors that influence individuals’ privacy helplessness in the context of social media and mobile application use. An integrative research model was proposed, simultaneously examining both rational evaluation processes and directional motivated reasoning. The integrative research model was tested using national survey data collected from Facebook users (Study 1, n = 660) and mobile application users (Study 2, n = 385) in the US. The findings demonstrated significant associations between privacy helplessness and factors related to directional motivated reasoning (e.g. perceived rewards, costs, and benefits) as well as the rational evaluation model (e.g. perceived privacy control, trust in the provider, and response efficacy). Moreover, the interaction effects observed in the studies suggest that the two mechanisms either reinforced or attenuated each other's influence. In conclusion, the results emphasize that privacy research should explore both theoretical mechanisms concurrently, as opposed to independently, since they not only operate in conjunction but also interact to define boundary conditions for one another. ","",""
"2024","Inequalities in privacy cynicism: An intersectional analysis of agency constraints"," A growing body of research highlights a trend toward widespread attitudes of privacy cynicism, apathy and resignation among Internet users. In this work, we extend these discussions by concentrating on the concept of user agency. Specifically, we examine how five types of structural constraints—interpersonal, cultural, technological, economic and political—restrict user agency and contribute to the prevalence of privacy cynicism as a common response. Drawing on critical data studies and adopting an intersectional lens, we demonstrate how these constraints disproportionately impact various social groups unequally, leading to a disparate distribution of agency and privacy cynicism. Furthermore, we contend that the sense of powerlessness engendered by excessive constraints on user agency can, in turn, exacerbate user vulnerability to such constraints, potentially initiating a vicious cycle of disempowerment. The article enriches the field of privacy research by linking the traditionally individual-focused and psychological dimensions of privacy with critical surveillance studies and by proposing potential interventions to mitigate privacy cynicism. ","",""
"2024","Privacy cynicism and diminishing utility of state surveillance: A natural experiment of mandatory location disclosure on China's Weibo"," This article examines the public response to mandatory location disclosure (MLD), a new surveillance technology implemented on China's Sina Weibo. Initially introduced to geo-tag posts related to the Ukraine War, the MLD eventually expanded to encompass all posts and comments on the platform. Drawing on a large-scale dataset comprising over 0.6 million posts and 24 million comments, this study uncovers political asymmetry observed during the initial implementation of MLD. Users with different political orientations were subjected to different levels of geo-tagging. Pro-Ukraine users were most frequently geo-tagged, followed by Pro-Russia and liberal-leaning users, while conservative-leaning users are least likely to be tagged. This selective surveillance approach, however, backfired among Pro-Ukraine and Pro-Russia users, pushing them to publish more war-related content, while its impact on liberal- and conservative-leaning users appeared to be minimal. When selective surveillance was replaced by universal surveillance, the backfire effects ceased to exist and people's interest in war-related topics declined. Furthermore, privacy cynicism prevails among commenters across opinion groups. Neither the introduction nor the expansion of MLD deterred audiences from engaging with the geo-tagged posts. These findings suggest that prolonged surveillance makes people less sensitive to privacy threats and more experienced in neutralizing surveillance's influence on themselves. Privacy cynicism, though widely considered toxic to democracy, can function as a source of resilience that shields people from the fear of coercion and undercuts the marginal utility of state surveillance in an authoritarian context. ","",""
"2024","Role-based privacy cynicism and local privacy activism: How data stewards navigate privacy in higher education"," This study examines the impact of role-based constraints on privacy cynicism within higher education, a workplace increasingly subjected to surveillance. Using a thematic analysis of 15 in-depth interviews conducted between 2017 and 2023 with data stewards in the California State University System, the research explores the reasons behind data stewards’ privacy cynicism, despite their knowledge of privacy and their own ability to protect it. We investigate how academic data custodians navigate four role-based tensions: the conflict between the institutional and personal definitions of privacy; the mutual reinforcement between their privacy-cynical attitudes and their perceptions of student privacy attitudes; the influence of role constraints on data stewards’ privacy-protective behaviors; and the contrast between the negatively valued societal surveillance and the positively valued university surveillance. The findings underscore the significance of considering organizational privacy cultures and role-based expectations in studying privacy cynicism. The study contributes to the theoretical understanding of privacy cynicism and offers practical implications for organizations, emphasizing the importance of aligning organizational definitions of privacy with employees’ understanding. Future research should further explore the mutual reinforcement of privacy cynicism in the relationship between data providers and data consumers (which we call the “spiral of resignation”) and consider the impact of role-based constraints in other organizational contexts. ","",""
"2024","Privacy resignation, apathy, and cynicism: Introduction to a special theme"," The growing trend of collecting data about individuals to track past actions and infer future attitudes and behaviors has fueled popular and scholarly interest in the erosion of privacy. Recent shifts in technologies around machine learning and artificial intelligence have intensified these concerns. This editorial introduces the articles in the special theme on digital resignation and privacy cynicism: concepts developed in the past decade to explain the growing powerlessness individuals feel in relation to their digital privacy even as they continue to experience consternation over the collection and use of their personal information. The papers in this special theme engage and extend existing research on these topics. The original articles and commentaries pose theoretical and practical questions related to the ways people confront the powerful institutional forces that increasingly shape many aspects of the information environment. They employ several methodologies and theoretical perspectives and extend the range of geographic, political, cultural, and institutional contexts in which privacy cynicism and digital resignation can be identified and examined. In addition to contextualizing these contributions, this editorial maps a range of related concepts including digital resignation, privacy cynicism, privacy apathy, surveillance realism, privacy fatigue, and privacy helplessness. It concludes by identifying key themes across the papers in this collection and provides directions for future research. ","",""
"2024","The access control double bind: How everyday interfaces regulate access and privacy, enable surveillance, and enforce identity"," Access controls are an inescapable and deceptively mundane requirement for accessing digital applications and platforms. These systems enable and enforce practices related to access, ownership, privacy, and surveillance. Companies use access controls to dictate and enforce terms of use for digital media, platforms, and technologies. The technical implementation of these systems is well understood. However, this paper instead uses digital game software and platforms as a case study to analyze the broader socio-technical, and often inequitable, interactions these elements regulate across software systems. Our sample includes 200 digital games and seven major digital gaming platforms. We combine close reading and content analysis to examine the processes of authentication and authorization within our samples. While the ubiquity of these systems is a given in much academic and popular discourse, our data help empirically ground this understanding and examine how these systems support user legibility and surveillance, and police identities in under-examined ways. We suggest changes to the policies and practices that shape these systems to drive more transparent and equitable design. ","",""
"2024","Oversharing the super safe stuff: “Privacy-washing” in Apple iPhone and Google Pixel commercials","Inspired by the ever-evolving concerns surrounding data privacy, this study analyzes Apple’s and Google’s ads for their iPhone and Android devices, respectively, as well as each company’s privacy policies. Findings via critical discourse analysis reveal that the ads conflate privacy with security, relying on powerful imageries that depict the phones as safes from which data cannot travel. These depictions, however, do not align with the policies that provide separate sections for privacy and security. With these findings in mind, I propose a widespread adoption of “privacy-washing” to promote a newfound literacy of granular data types.","",""
"2024","A longitudinal examination of Internet users’ privacy protection behaviors in relation to their perceived collective value of privacy and individual privacy concerns"," People’s perception of privacy can primarily be directed to themselves or to the value of privacy for society. Likewise, privacy protection can repel both individual and collective privacy threats. Focusing on this distinction, the present article examines Internet users’ privacy protection behaviors in relation to individual privacy concerns and their perceived collective value of privacy over time. We conducted a longitudinal panel study with three measurement points ( N = 1790) to investigate relations between and within persons. The results of a random-intercept cross-lagged panel model revealed positive relations between the perceived value of privacy, privacy concerns, and privacy protection between persons. At the within-person level, only a temporal increase in the perceived value of privacy was related to increased protection behaviors. This suggests that individual privacy concerns are not as important for temporal protection as assumed, but that a recognition of collective privacy may temporarily change people’s privacy behavior. ","",""
"2024","“Track every move”: Analyzing developers’ privacy discourse in GitHub README files"," We adopt a socio-material perspective to examine how developers translate privacy, as a social value, into user applications. Our comprehensive survey of the research on developers’ privacy highlights their key position as privacy mediators and their forums as productive settings for unobtrusive studies of their discourse. The open-source code-sharing platform GitHub contains both discourse and code; by focusing on GitHub, we analyzed nearly 60,000 README files created between 2008 and 2020 that include the term “privacy,” studying quantitatively and qualitatively how discourse is translated into code. Using VOSviewer.com, we identified two main word clusters: “security” and “privacy policy.” Voyant-tools.org confirmed these findings, suggesting that some references elaborate on practices that safeguard privacy, while others discuss policy as a means of complying with both public and, ironically, commercial regulations. A closer reading of the files reveals that even privacy enthusiasts may inadvertently promote code that poses threats to privacy. ","",""
"2024","Who is afraid of dataveillance? Attitudes toward online surveillance in a cross-cultural and generational perspective"," This article compares surveillance-related experiences and attitudes of two generations of media users in countries with different historical surveillance regimes (Estonia, Portugal, and Sweden) and analyzes the predictors of the attitudes toward contemporary surveillance. A large-scale online survey ( N = 3221) reveals that attitudes toward online state and corporate surveillance are interrelated; the two attitudinal components are, however, generation-specific, having different predictors. Tolerance toward state surveillance is more characteristic of the older group, being predicted by trustful and obedient attitudes toward state authorities and institutions. Tolerance toward corporate dataveillance is more characteristic of the younger group, being predicted by active and self-confident media use. While the socio-historical context molds the intergenerational gaps in surveillance-related experiences and attitudes, individual-level experiences of state surveillance do not predict tolerance toward either type of contemporary surveillance, suggesting that global techno-cultural developments are probably more powerful factors than past experiences in forming generation-specific attitudes. ","",""
"2024","Protecting Privacy on Social Media: Mitigating Cyberbullying and Data Heist Through Regulated Use and Detox, with a Mediating Role of Privacy Safety Motivations"," Information theft and cyberbullying pose significant threats to users’ privacy on social media. This study applies Protection Motivation Theory (PMT) to explore how online information disclosure awareness and privacy concerns influence protective actions, such as regulated social media usage and detoxification, in response to negative experiences like data heist and cyberbullying. Analyzing survey responses from 1,000 social media users in Pakistan, ranging in age from 18 years to over 50, and using the snowball sampling technique, our findings reveal that awareness of online information disclosure mediates the relationship between data theft and regulated social media use. Privacy concerns similarly mediate the relationship between cyberbullying experiences and social media detoxification, aligning with PMT. In addition, negative online experiences directly correlate with privacy safety behaviors, indicating that motivations may not always drive protective actions. This research sheds light on the intricate dynamics between privacy concerns, negative online experiences, and protective behaviors, offering insights for interventions and policies to enhance users’ digital privacy and safety. Understanding these relationships is crucial for addressing the challenges of information theft and cyberbullying in the digital landscape. ","",""
"2024","Understanding the Motivations of Young Adults to Engage in Privacy Protection Behavior While Setting Up Smartphone Apps: A Cross-Country Comparison Between Romania and Germany"," Smartphones have become daily companions and store many personal information, including contact lists, photos, and videos. Even though users download smartphone apps for various purposes, they are also data collection instruments. Within the Protection Motivation Theory research streamline, the present research focuses from a comparative perspective on young adults’ concerns and engagement with privacy protection behaviors while setting up smartphone apps. Aiming to assess how threat and coping appraisals relate to privacy protection behavior from a comparative perspective, we conducted an online survey ( N = 931) in Germany ( n = 479) and Romania ( n = 452) with young adults (age 18–26 years). Findings showed differences between the two countries in the sense that individuals’ overarching privacy attitudes transfer to and manifest in the context-specific behavior of setting up apps. For German young adults, susceptibility and severity of the data collection by companies are positively related to privacy protection behavior while setting up apps. Romanians are confident that they can protect their data by setting up apps. For German and Romanian young adults, self-efficacy in online communication was related to response efficacy of privacy protection while configuring apps. ","",""
"2024","Online Privacy, Young People, and Datafication: Different Perceptions About Online Privacy Across Antigua &amp; Barbuda, Australia, Ghana, and Slovenia"," Children and young people’s online privacy is increasingly challenged by the datafication of the digital world, and this is an increasingly important area of policy concern. Understanding what young people understand online privacy to be, and what they want done to protect it, is key to creating effective and rights-realizing policy responses. This article explores young people’s perceptions across four countries and finds they have nuanced understandings about online privacy and clear, robust ideas about how to improve it. Context mattered, and their online privacy concerns and ideal protections were often informed by their socio-political context and awareness of and trust in datafication. ","",""
