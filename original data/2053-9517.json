[
  {
    "id": "22aed76e-2adf-4173-86b3-e56a4f582be6",
    "title": "Toward cultural interpretability: A linguistic anthropological framework for describing and evaluating large language models",
    "abstract": "<jats:p> This article proposes a new integration of linguistic anthropology and machine learning (ML) around convergent interests in both the underpinnings of language and making language technologies more socially responsible. While linguistic anthropology focuses on interpreting the cultural basis for human language use, the ML field of interpretability is concerned with uncovering the patterns that Large Language Models (LLMs) learn from human verbal behavior. Through the analysis of a conversation between a human user and an LLM-powered chatbot, we demonstrate the theoretical feasibility of a new, conjoint field of inquiry, cultural interpretability (CI). By focusing attention on the communicative competence involved in the way human users and AI chatbots coproduce meaning in the articulatory interface of human-computer interaction, CI emphasizes how the dynamic relationship between language and culture makes contextually sensitive, open-ended conversation possible. We suggest that, by examining how LLMs internally “represent” relationships between language and culture, CI can: (1) provide insight into long-standing linguistic anthropological questions about the patterning of those relationships; and (2) aid model developers and interface designers in improving value alignment between language models and stylistically diverse speakers and culturally diverse speech communities. Our discussion proposes three critical research axes: relativity, variation, and indexicality. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241303118",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Graham M Jones",
        "Shai Satran",
        "Arvind Satyanarayan"
      ],
      "url": "https://doi.org/10.1177/20539517241303118",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 81,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "88acdc82-3842-4b22-be6e-cff718de4a14",
    "title": "Geopolitics of reproduction: Investigating technological mediation of maternity tourism on the Russian web",
    "abstract": "<jats:p> Investigating maternity tourism to the United States from Russia through the lens of technological mediation, this study foregrounds the geopolitical patterns of human reproduction that shape, and are shaped by, individual choices of maternal healthcare in a neoliberal healthcare market. Following the history of a highly popular Russian-language forum, I demonstrate how this online community gets imbricated into communicative biocapitalism – a neoliberal logic that commodifies the voice of an online user, turning networked publics into markets for medical services. Adding to the literature on data colonialism, I explore a case in which data-driven algorithms effectively alter geographical distribution of reproductive bodies, outsourcing the production of new generations of neoliberal subjects through regimes of technological mediation. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719868491",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Olga Boichak"
      ],
      "url": "https://doi.org/10.1177/2053951719868491",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171986849",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 30,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b963c5e3-f3f6-4acf-8189-1f5ad3fdc327",
    "title": "Corrigendum to Editorial: The personalisation of insurance: Data, behaviour and innovation",
    "abstract": "",
    "metadata": {
      "doi": "10.1177/2053951720988208",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [],
      "url": "https://doi.org/10.1177/2053951720988208",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "not available"
    }
  },
  {
    "id": "094744a1-92e6-4cb2-a7a7-d24ef35a4ef9",
    "title": "“Make our communities better through data”: The moral economy of smart city labor",
    "abstract": "<jats:p> Smart cities are now an established context in which data and digital technologies shape urban politics. Despite increased scholarly focus on algorithmic governance, smart cities and their data production still heavily rely on human labor, raising questions about how that labor is recruited and the implications of different recruitment strategies. In this paper, we illuminate the relations and practices mobilized to recruit the labor required to produce, analyze, and enact data that (re)produce smart cities. We argue that smart cities recruit such digital labor by producing and circulating moral values and sentiments to claim that such participation is a social good. In this article we draw on a 6-year ongoing project in Calgary, Canada to explore how these “moral economies” underwrite smart city ecosystems. We explore three projects related to data and digital labor in the Calgary smart city: a wearable technology collaborative project, a civic hacking group, and the community social media platform Nextdoor. We suggest that moral economies of smart cities signal a new juncture between urban planning and profiting from data, with the potential for creating new socio-political risks. These moral economies signal a shift toward a “new spirit of capitalism” in which labor is managed through indirect persuasion rather than direct compulsion and mandate. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221106381",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Ryan Burns",
        "Preston Welker"
      ],
      "url": "https://doi.org/10.1177/20539517221106381",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 90,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "233840ce-4679-48bc-ab13-9fee23a62612",
    "title": "Critical companionship: Some  sensibilities for studying the lived experience of data subjects",
    "abstract": "<jats:p> What are the challenges of turning data subjects into research participants—and how can we approach this task responsibly? In this paper, we develop a methodology for studying the lived experiences of people who are subject to automated scoring systems. Unlike most media technologies, automated scoring systems are designed to track and rate specific qualities of people without their active participation. Credit scoring, risk assessments, and predictive policing all operate obliquely in the background long before they come to matter. In doing so, they constitute a problem not only for those subject to these systems but also for researchers who try to study their experience. Specifically, we identify three challenges that are distinct to studying experiences of automated scoring: limited awareness, embeddedness, and ongoing inquiry. Starting from the observation that coming to terms with one's position as a data subject constitutes a form of learning in its own right, we propose a research strategy called critical companionship. Originally articulated in the context of nursing research, critical companionship invites us to accompany a data subject over time, paying critical attention to how the participant's and the researcher's inquiries complicate and constitute each other. We illustrate the strengths and limitations of this methodology with materials from a recent study we conducted about people's credit repair practices and sketch a set of sensibilities for studying contemporary scoring systems from the margins. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211061122",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Malte Ziewitz",
        "Ranjit Singh"
      ],
      "url": "https://doi.org/10.1177/20539517211061122",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 62,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2bb5c429-16e0-4657-88e0-d018c679f1be",
    "title": "The multifaceted and situated data center imaginary of Dutch Twitter",
    "abstract": "<jats:p> Data centers are material structures that take up space, use resources like water and energy, and possess a large carbon footprint. This paper examines the broader long-term discussion around data centers during the period 2020–2022 in the Dutch Twittersphere. Through an analysis of tweets and images, it identifies and reflects on the communities active in the discussion and the range of visions and imaginaries of data centers they produce. Unpacking these tweets and images over time traces not only the emergence of a ‘reactive imaginary’, critical of the promises of information technology (IT) industry and (local) governments, but also the blind spots of the discussion. It furthermore reveals an important role for journalism in the discussion by questioning the claims of the industry and contributing to a ‘visibility expansion’ of data center’s impact on Earth's resources. The paper shows the multifaceted and situated nature of imaginaries and their role in shaping decision-making and policy. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231155064",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Karin van Es",
        "Daan van der Weijden",
        "Jeroen Bakker"
      ],
      "url": "https://doi.org/10.1177/20539517231155064",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 50,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2b150f6d-5a4e-4368-aa2e-755ad1468e0f",
    "title": "Situating data relations in the datafied home: A methodological approach",
    "abstract": "<jats:p> Studying datafication focusing on the microlevel of everyday life poses epistemological and methodological challenges. Indeed, the black-boxed nature of algorithms makes data inaccessible and unintelligible to the researcher. Therefore, this paper aims to advance a methodological proposal for addressing the situatedness of datafication in everyday life by framing mediatised relations as a proxy for data relations. In particular, this research adopts a “non-media-centric” approach and frames families as communicative figurations. By reporting a qualitative longitudinal study on the datafication of childhood and family life involving 20 families with at least 1 child aged 8 years or younger in Italy and by employing a mixed method constructivist grounded theory methodology that includes network methods, we analyse three families as exemplary of different network articulations. Such an approach, we argue, can help materialise the mediatised relations through, about, and around data that emerge in contemporary family life. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241234268",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Gaia Amadori",
        "Giovanna Mascheroni"
      ],
      "url": "https://doi.org/10.1177/20539517241234268",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 50,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "91646f31-883c-4113-aeb0-9ebdd223ea4c",
    "title": "Enforcing public data archiving policies in academic publishing: A study of ecology journals",
    "abstract": "<jats:p> To improve the quality and efficiency of research, groups within the scientific community seek to exploit the value of data sharing. Funders, institutions, and specialist organizations are developing and implementing strategies to encourage or mandate data sharing within and across disciplines, with varying degrees of success. Academic journals in ecology and evolution have adopted several types of public data archiving policies requiring authors to make data underlying scholarly manuscripts freely available. The effort to increase data sharing in the sciences is one part of a broader “data revolution” that has prompted discussion about a paradigm shift in scientific research. Yet anecdotes from the community and studies evaluating data availability suggest that these policies have not obtained the desired effects, both in terms of quantity and quality of available datasets. We conducted a qualitative, interview-based study with journal editorial staff and other stakeholders in the academic publishing process to examine how journals enforce data archiving policies. We specifically sought to establish who editors and other stakeholders perceive as responsible for ensuring data completeness and quality in the peer review process. Our analysis revealed little consensus with regard to how data archiving policies should be enforced and who should hold authors accountable for dataset submissions. Themes in interviewee responses included hopefulness that reviewers would take the initiative to review datasets and trust in authors to ensure the completeness and quality of their datasets. We highlight problematic aspects of these thematic responses and offer potential starting points for improvement of the public data archiving process. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719836258",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Dan Sholler",
        "Karthik Ram",
        "Carl Boettiger",
        "Daniel S Katz"
      ],
      "url": "https://doi.org/10.1177/2053951719836258",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 93,
      "is_referenced_by_count": 31,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "90bb7983-a752-42ef-ad01-99ebafeeae66",
    "title": "Hacking the social life of Big Data",
    "abstract": "<jats:p> This paper builds off the Our Data Ourselves research project, which examined ways of understanding and reclaiming the data that young people produce on smartphone devices. Here we explore the growing usage and centrality of mobiles in the lives of young people, questioning what data-making possibilities exist if users can either uncover and/or capture what data controllers such as Facebook monetize and share about themselves with third-parties. We outline the MobileMiner, an app we created to consider how gaining access to one’s own data not only augments the agency of the individual but of the collective user. Finally, we discuss the data making that transpired during our hackathon. Such interventions in the enclosed processes of datafication are meant as a preliminary investigation into the possibilities that arise when young people are given back the data which they are normally structurally precluded from accessing. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715616649",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Jennifer Pybus",
        "Mark Coté",
        "Tobias Blanke"
      ],
      "url": "https://doi.org/10.1177/2053951715616649",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 40,
      "is_referenced_by_count": 44,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "38a44402-e07f-4d6d-a39e-4743f8a79ac7",
    "title": "Thinking about measuring Augé’s non-places with Big                     Data",
    "abstract": "<jats:p> Augé describes non-places as quantifiable and measureable physical space, but does not give an appropriate measure to do so. This contribution thinks about using crowd-harvested photo data, a specific kind of Big Data, to measure non-places in the context of tourism by giving a theory based discussion on Augé’s non-places, photography as key element of “doing” tourism, and the selection processes of photography and uploading photos. Solely using theoretical thoughts and propositional logic, this contribution indicates that it could be possible to do so. Yet, there are plenty of empirical studies needed in order to verify the built hypothesis. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716665130",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Michael Bauder"
      ],
      "url": "https://doi.org/10.1177/2053951716665130",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 23,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a27ccc7f-f410-4108-b162-a2c50d165423",
    "title": "Erratum to The digital life of the #migrantcaravan: Contextualizing  Twitter as a spatial technology",
    "abstract": "",
    "metadata": {
      "doi": "10.1177/20539517211056375",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [],
      "url": "https://doi.org/10.1177/20539517211056375",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "not available"
    }
  },
  {
    "id": "90ac7f82-46ff-43c5-8223-b7c81e409afc",
    "title": "A reflective commentary of teaching critical thinking of privacy and surveillance in UK higher education",
    "abstract": "<jats:p> The importance of data literacy and the need of raising and improving it through formal educational channel or public engagement has repeatedly been flagged up in each of the past Economic and Social Research Council-funded Data-Psst! Seminar I attended in 2014–2016. There is a real demand for action taking. I took advantage of the knowledge I learned from the Data-Psst seminars and devised a module teaching Level 5 undergraduate media students about critical issues in today’s data-centric digital society, including privacy and surveillance. In this article, I share how the class activities were devised and carried out, and how guided engagement with the current debate in privacy and surveillance were realised. I also draw on relevant pedagogical theories to discuss my educational approaches, student performance, the challenges of the project, and evaluate and reflect upon the outcomes. This report from the field provides fresh first-hand information about the data ethics of the younger public who are practising media arts and their behaviours and attitudes towards privacy and surveillance. This article shall open up the discussion about the role educators play in enriching public engagement with critical thinking about Big Data. The lessons learned can also contextualise the pedagogical implication of the recent scholarly research on Big Data and privacy, and provide a framework for constructing future collaborative or creative projects. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717694054",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Yu-Wei Lin"
      ],
      "url": "https://doi.org/10.1177/2053951717694054",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 31,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b4ee8a6a-52f9-4603-ac73-41a2fc410b97",
    "title": "Digital failure: Unbecoming the “good” data subject through entropic, fugitive, and queer data",
    "abstract": "<jats:p> This paper explores the political potential of digital failure as a refusal to work in service of today’s dataveillance society. Moving beyond criticisms of flawed digital systems, this paper traces the moments of digital failure that seek to break, rather than fix, existing systems. Instead, digital failure is characterized by pesky data that sneaks through the cracks of digital capitalism and dissipates into the unproductive; it supports run-away data prone to misidentifications by digital marketers, coders, and content moderators; and it celebrates data predisposed to “back-talk” with playful irreverence toward those that seek to bring order through normative categorization and moderation. I call these data entropic, fugitive, and queer and explore their mischievous practices through three case studies: the unaccountable data in identity resolution, public shaming of the ImageNet training data, and reading practices of sex worker and influencer, @Charlieshe. Together these case studies articulate the political potential of digital failure as a process of unbecoming the good data subject by pushing past the margins of legibility, knowability, and thinkability, to reveal what is made illegible, unknowable, and unthinkable to data’s seeing eye. As predictive analytics, automated decision-systems, and artificial intelligence take on increasingly central roles in public governance, digital failure reveals how data itself is a flawed concept prone to political abuse and social engineering to protect the interests of the powerful, while keeping those marginalized over-surveilled and underrepresented. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720977882",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Lauren E Bridges"
      ],
      "url": "https://doi.org/10.1177/2053951720977882",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 87,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7e05383e-4c98-495c-89b4-dd8d7b289633",
    "title": "Towards a United Nations Internal Regulation for Artificial Intelligence",
    "abstract": "<jats:p> This article sets out the rationale for a United Nations Regulation for Artificial Intelligence, which is needed to set out the modes of engagement of the organisation when using artificial intelligence technologies in the attainment of its mission. It argues that given the increasing use of artificial intelligence by the United Nations, including in some activities considered high risk by the European Commission, a regulation is urgent. It also contends that rules of engagement for artificial intelligence at the United Nations would support the development of ‘good artificial intelligence’, by giving developers clear pathways for authorisation that would build trust in these technologies. Finally, it argues that an internal regulation would build upon the work in artificial intelligence ethics and best practices already initiated in the organisation that could, like the Brussels Effect, set an important precedent for regulations in other countries. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211039493",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Eleonore Fournier-Tombs"
      ],
      "url": "https://doi.org/10.1177/20539517211039493",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 26,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "17be76d8-753d-4b78-a752-85de29dc9499",
    "title": "Assessing the consequences of decentralizing biomedical research",
    "abstract": "<jats:p> Advancements in technology are shifting the ways that biomedical data are collected, managed, and used. The pervasiveness of connected devices is expanding the types of information that are defined as ‘health data.’ Additionally, cloud-based mechanisms for data collection and distribution are shifting biomedical research away from traditional infrastructure towards a more distributed and interconnected ecosystem. This shift provides an opportunity for us to reimagine the roles of scientists and participants in health research, with the potential to more meaningfully engage in partnership across the research process. At the same time, these emerging practices present a potential to expose research participants to unanticipated and unintended consequences. Social norms and policy can help to mitigate these risks, but their development is often slow relative to the pace of technological advances and, as such, they can become reactive rather than prospective. As an alternative, the integrated development of data governance structures within technological advancements, supports their effective implementation, evaluation and evolution in a manner that can balance the benefits and risks of biomedical researcher in a decentralized ecosystem. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719853858",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Brian M Bot",
        "John T Wilbanks",
        "Lara M Mangravite"
      ],
      "url": "https://doi.org/10.1177/2053951719853858",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 21,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "14785e7c-d54f-4ec1-a832-260153329eb7",
    "title": "Cooling down AI regulation controversies: Three closure processes in the Chilean legislative arena",
    "abstract": "<jats:p> According to social studies of artificial intelligence (AI), public AI controversies tend to dissipate relatively quickly despite well-documented risks and harms. The reasons for this lack of controversiality are beginning to be studied. Drawing on the framework of sociotechnical controversies, we analyze the de-escalation of contentious discussions observed in the AI legislative process by Chile's National Congress. Utilizing a qualitative approach, we tracked the deliberations hosted by the Chamber of Deputies and the Senate of Chile across 51 sessions between 2023 and 2024. We describe three processes of cooling down in the AI debates: (1) deflection of technology liability, (2) instrumentalization of technology policy, and (3) moralization of technology use. However, constructive exchanges appear in some circumstances, which allow us to foresee some favorable conditions for participation in the debates on AI regulation. This paper contributes to AI controversy studies by outlining cooling-down processes and conditions that foster dialogue and providing a critical perspective on the formation of AI regulation. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241311067",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Mónica Humeres",
        "Dusan Cotoras",
        "Renato Moretti",
        "Iñaki Oyarzún-Merino",
        "Teresa Correa",
        "Claudia López"
      ],
      "url": "https://doi.org/10.1177/20539517241311067",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1d227763-ef0f-4e43-85d5-998f97107c60",
    "title": "Artificial intelligence as planetary assemblages of coloniality: The new power architecture driving a tiered global data economy",
    "abstract": "<jats:p> We present a framework for viewing artificial intelligence (AI) as planetary assemblages of coloniality that reproduce dependencies in how it co-constitutes and structures a tiered global data economy. We use assemblage thinking to map the coloniality of power to demonstrate how AI stratifies across knowledge, geographies, and bodies to influence development and economic trajectories, impact workers, reframe domestic industrial policies, and reconfigure the international political economy. Our post-colonial framework unpacks AI through its (1) global, (2) meso, and (3) local layers, and further dissects how these layers are vertically integrated, each with its horizontal dependencies. At (1) the global layer of international political economy maps a new digital bipolarity expressing Sino and American global digital corporations’ strategic and dominant positions in shaping a tiered global data economy. Then, at (2) the meso layer, we have a mosaic of domestic industrial policies that fund, frame markets, and develop AI talent across industries, sectors, and organizations to competitively integrate into AI value chains. Finally, incorporating into these are (3) the localized labor processes and tasks, where workers and users enact various AI-mediated tasks and practices driving further value extraction. We traced how AI is an interlaced system of power that reshapes knowledge, geographies, and bodies into dependencies that reinforce stratifications in developing underdevelopment. This commentary maps the current digital realities by laying out an uneven techno-geoeconomic power architecture driving a tiered global data economy and opening new research avenues to examine AI as planetary assemblages of coloniality. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241289443",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Kai-Hsin Hung"
      ],
      "url": "https://doi.org/10.1177/20539517241289443",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 54,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6ee305b3-bdf2-40bb-8fbb-d1ba429a6470",
    "title": "Big Data and government: Evidence of the role of Big Data for smart cities",
    "abstract": "<jats:p> Scholars are becoming increasingly interested in whether and how government use of Big Data will affect public policy outcomes. Despite such growing scholarly interests, however, little evidence exists on the role Big Data can play in improving government service. We undertake one of the first quantitative studies revealing the potential utility and limitations of “Big Data-based policymaking” by exploring its recent use by the Seoul Metropolitan Government. In 2013, the government introduced the “Owl Bus”—a late-night bus system—the routes of which were selected based on government analyses of Big Data relating to citizens’ late-night taxi and mobile phone use. The findings suggest that the average number of passengers utilizing the Owl Bus routes was significantly greater than that on other daytime bus routes with comparable characteristics. That said, we also present the potential limitations of evidence-based policymaking in general, especially when politics and equity considerations are factored in. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719842543",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Sounman Hong",
        "Sun Hyoung Kim",
        "Youngrok Kim",
        "Jeongin Park"
      ],
      "url": "https://doi.org/10.1177/2053951719842543",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 42,
      "is_referenced_by_count": 28,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5e2fe25c-4cc3-4df5-918e-652693ffe16c",
    "title": "Data that warms: Waste heat, infrastructural convergence and the computation traffic commodity",
    "abstract": "<jats:p> This article explores the ways in which data centre operators are currently reconfiguring the systems of energy and heat supply in European capitals, replacing conventional forms of heating with data-driven heat production, and becoming important energy suppliers. Taking as an empirical object the heat generated from server halls, the article traces the expanding phenomenon of ‘waste heat recycling’ and charts the ways in which data centre operators in Stockholm and Paris direct waste heat through metropolitan district heating systems and urban homes, and valorise it. Drawing on new materialisms, infrastructure studies and classical theory of production and destruction of value in capitalism, the article outlines two modes in which this process happens, namely infrastructural convergence and decentralisation of the data centre. These modes arguably help data centre operators convert big data from a source of value online into a raw material that needs to flow in the network irrespective of meaning. In this conversion process, the article argues, a new commodity is in a process of formation, that of computation traffic. Altogether data-driven heat production is suggested to raise the importance of certain data processing nodes in Northern Europe, simultaneously intervening in the global politics of access, while neutralising external criticism towards big data by making urban life literally dependent on power from data streams. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716684144",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Julia Velkova"
      ],
      "url": "https://doi.org/10.1177/2053951716684144",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 54,
      "is_referenced_by_count": 40,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2ae4689a-4df9-456e-8016-b3a1f817cc6e",
    "title": "Repairing the harm: Toward an algorithmic reparations approach to hate speech content moderation",
    "abstract": "<jats:p> Content moderation algorithms influence how users understand and engage with social media platforms. However, when identifying hate speech, these automated systems often contain biases that can silence or further harm marginalized users. Recently, scholars have offered both restorative and transformative justice frameworks as alternative approaches to platform governance to mitigate harms caused to marginalized users. As a complement to these recent calls, in this essay, I take up the concept of reparation as one substantive approach social media platforms can use alongside and within these justice frameworks to take actionable steps toward addressing, undoing and proactively preventing the harm caused by algorithmic content moderation. Specifically, I draw on established legal and legislative reparations frameworks to suggest how social media platforms can reconceptualize algorithmic content moderation in ways that decrease harm to marginalized users when identifying hate speech. I argue that the concept of reparations can reorient how researchers and corporate social media platforms approach content moderation, away from capitalist impulses and efficiency and toward a framework that prioritizes creating an environment where individuals from marginalized communities feel safe, protected and empowered. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241245333",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Chelsea Peterson-Salahuddin"
      ],
      "url": "https://doi.org/10.1177/20539517241245333",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 85,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "87086303-538e-4aa6-a00a-89984770f7cb",
    "title": "Modeling COVID-19 with big mobility data: Surveillance and reaffirming the people in the data",
    "abstract": "<jats:p> To better understand the COVID-19 pandemic, public health researchers turned to “big mobility data”—location data collected from mobile devices by companies engaged in surveillance capitalism. Publishing formerly private big mobility datasets, firms trumpeted their efforts to “fight” COVID-19 and researchers highlighted the potential of big mobility data to improve infectious disease models tracking the pandemic. However, these collaborations are defined by asymmetries in information, access, and power. The release of data is characterized by a lack of obligation on the part of the data provider towards public health goals, particularly those committed to a community-based, participatory model. There is a lack of appropriate reciprocities between data company, data subject, researcher, and community. People are de-centered, surveillance is de-linked from action while the agendas of public health and surveillance capitalism grow closer. This article argues that the current use of big mobility data in the COVID-19 pandemic represents a poor approach with respect to community and person-centered frameworks. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231164115",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Thomas Walsh"
      ],
      "url": "https://doi.org/10.1177/20539517231164115",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 90,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4d12cf66-39f0-4f3e-a04c-50d7ffb3e8a7",
    "title": "Towards a political economy of technical systems: The case of Google",
    "abstract": "<jats:p> This research commentary proposes a conceptual framework for studying big tech companies as “technical systems” that organize much of their operation around the mastery and operationalization of key technologies that facilitate and drive their continuous expansion. Drawing on the study of Large Technical Systems (LTS), on the work of historian Bertrand Gille, and on the economics of General Purpose Technologies (GPTs), it outlines a way to study the “tech” in “big tech” more attentively, looking for compatibilities, synergies, and dependencies between the technologies created and deployed by these companies. Using Google as example, the paper shows how to interrogate software and hardware through the lens of transversal applicability, discusses software and hardware integration, and proposes the notion of “data amalgams” to contextualize and complicate the notion of data. The goal is to complement existing vectors of “big tech” critique with a perspective sensitive to the specific materialities of specific technologies and their possible consequences. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221135162",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Bernhard Rieder"
      ],
      "url": "https://doi.org/10.1177/20539517221135162",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 12,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0f6798f4-07b4-417a-8e0f-79e724145a6d",
    "title": "The fabrics of machine moderation: Studying the technical, normative,  and organizational structure  of Perspective API",
    "abstract": "<jats:p> Over recent years, the stakes and complexity of online content moderation have been steadily raised, swelling from concerns about personal conflict in smaller communities to worries about effects on public life and democracy. Because of the massive growth in online expressions, automated tools based on machine learning are increasingly used to moderate speech. While ‘design-based governance’ through complex algorithmic techniques has come under intense scrutiny, critical research covering algorithmic content moderation is still rare. To add to our understanding of concrete instances of machine moderation, this article examines Perspective API, a system for the automated detection of ‘toxicity’ developed and run by the Google unit Jigsaw that can be used by websites to help moderate their forums and comment sections. The article proceeds in four steps. First, we present our methodological strategy and the empirical materials we were able to draw on, including interviews, documentation, and GitHub repositories. We then summarize our findings along five axes to identify the various threads Perspective API brings together to deliver a working product. The third section discusses two conflicting organizational logics within the project, paying attention to both critique and what can be learned from the specific case at hand. We conclude by arguing that the opposition between ‘human’ and ‘machine’ in speech moderation obscures the many ways these two come together in concrete systems, and suggest that the way forward requires proactive engagement with the design of technologies as well as the institutions they are embedded in. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211046181",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Bernhard Rieder",
        "Yarden Skop"
      ],
      "url": "https://doi.org/10.1177/20539517211046181",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 48,
      "is_referenced_by_count": 42,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1792aef0-32a3-4a13-86d3-a327b7f7dbd3",
    "title": "Low on trust, high on use: Datafied  media, trust and everyday life",
    "abstract": "<jats:p> This article explores yet another paradox – aside from the privacy paradox – related to the datafication of media: citizens trust least the media they use most It investigates the role that daily life plays in shaping the trust that citizens place in datafied media. The study reveals five sets of heuristics guiding the trust assessments of citizens: (1) characteristics of media organisations, (2) old media standards, (3) context of use and purpose, (4) experiences of datafication and (5) understandings of datafication. The article discusses the use of these heuristics and the value that everyday life holds in assessing trust in datafied media. It concludes that, guided by a partial ‘structure of perception’ and enticed into trusting datafied media in the context of their daily lives, citizens may be highly concerned by the datafication of media but use them nevertheless. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211059480",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "David Mathieu",
        "Jannie Møller Hartley"
      ],
      "url": "https://doi.org/10.1177/20539517211059480",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 31,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1731a970-81b7-406d-96cb-db610b9df65d",
    "title": "Data, democracy and school accountability: Controversy over school evaluation in the case of DeVasco High School",
    "abstract": "<jats:p> Debate over the closure of DeVasco High School shows that data-driven accountability was a methodological and administrative processes that produced both transparency and opacity. Data, when applied to a system of accountability, produced new capabilities and powers, and as such were political. It created second-hand representations of important objects of analysis. Using these representations administrators spoke on behalf of the school, the student and the classroom, without having to rely on the first-person accounts of students, teachers or principals. They empowered one group—central city administrators—over another—teachers and principals. After analyzing the form these policies took, this article concludes that it is necessary to rethink the processes that create visibility and invisibility. Public data obscured the voices, experiences and collective traumas of students and faculty within the school. A narrow focus on activities within the schools rendered invisible the structural decisions made by the Department of Education in New York City—to favor small schools over large, comprehensive ones. In order to create understanding, and a sense of common purpose, those who are spoken for in simplified data must also be given the opportunity to debate the representations of their performance and quality. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717702408",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "John West"
      ],
      "url": "https://doi.org/10.1177/2053951717702408",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6632df54-a334-4839-9050-16800ad6616b",
    "title": "Forensic devices for activism: Metadata tracking and public proof",
    "abstract": "<jats:p> The central topic of this paper is a mobile phone application, ‘InformaCam’, which turns metadata from a surveillance risk into a method for the production of public proof. InformaCam allows one to manage and delete metadata from images and videos in order to diminish surveillance risks related to online tracking. Furthermore, it structures and stores the metadata in such a way that the documentary material becomes better accommodated to evidentiary settings, if needed. In this paper I propose InformaCam should be interpreted as a ‘forensic device’. By using the conceptualization of forensics and work on socio-technical devices the paper discusses how InformaCam, through a range of interventions, rearranges metadata into a technology of evidence. InformaCam explicitly recognizes mobile phones as context aware, uses their sensors, and structures metadata in order to facilitate data analysis after images are captured. Through these modifications it invents a form of ‘sensory data forensics'. By treating data in this particular way, surveillance resistance does more than seeking awareness. It becomes engaged with investigatory practices. Considering the extent by which states conduct metadata surveillance, the project can be seen as a timely response to the unequal distribution of power over data. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715612823",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Lonneke van der Velden"
      ],
      "url": "https://doi.org/10.1177/2053951715612823",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 51,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1c35890e-43bd-4920-9446-b2ddae2bd41b",
    "title": "Viral Data",
    "abstract": "<jats:p> We are experiencing a historical moment characterized by unprecedented conditions of virality: a viral pandemic, the viral diffusion of misinformation and conspiracy theories, the viral momentum of ongoing Hong Kong protests, and the viral spread of #BlackLivesMatter demonstrations and related efforts to defund policing. These co-articulations of crises, traumas, and virality both implicate and are implicated by big data practices occurring in a present that is pervasively mediated by data materialities, deeply rooted dataist ideologies that entrench processes of datafication as granting objective access to truth and attendant practices of tracking, data analytics, algorithmic prediction, and data-driven targeting of individuals and communities. This collection of papers explores how data (and their absences) is figuring in the making of the discourses, lived realities, and systemic inequalities of the uneven impacts of the coronavirus pandemic. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720971009",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Agnieszka Leszczynski",
        "Matthew Zook"
      ],
      "url": "https://doi.org/10.1177/2053951720971009",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 28,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "423bc113-8449-4635-8dd5-3adb079ba325",
    "title": "Data communism: Constructing a national data ecosystem",
    "abstract": "<jats:p> Over the past decade, China has gradually begun to take a more proactive approach to digital development, passing a range of policies that aim to restructure how data is treated within its national economic system. These policies reflect the construction of a new data ecology in which data is gradually reconceptualized as a quasi-public good, rather than a private good. Strategic interventions aim to increase data circulation and supply, with the goal of promoting high-quality economic growth. Central to these reforms is the designation of data as a factor of production, which accelerates the authority of the communist party to shape the allocation of data within the national economic system. Viewed holistically, these policies reflect an intentional effort to construct a more communal data ecosystem that facilitates increased data circulation in support of a state-led centralized approach to social and economic development. What emerges is a variety of data communism, in which data resources are increasingly conceptualized to serve collective interests rather than the interests of capital. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241275888",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Brett Aho"
      ],
      "url": "https://doi.org/10.1177/20539517241275888",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 90,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ef1e9e7e-7c93-4da5-a3db-f96fd20ef087",
    "title": "Political affiliation moderates subjective interpretations of COVID-19 graphs",
    "abstract": "<jats:p> We examined the relationship between political affiliation, perceptual (percentage, slope) estimates, and subjective judgements of disease prevalence and mortality across three chart types. An online survey (N = 787) exposed separate groups of participants to charts displaying (a) COVID-19 data or (b) COVID-19 data labeled ‘Influenza (Flu)’. Block 1 examined responses to cross-sectional mortality data (bar graphs, treemaps); results revealed that perceptual estimates comparing mortality in two countries were similar across political affiliations and chart types (all ps &gt; .05), while subjective judgements revealed a disease x political party interaction ( p &lt; .05). Although Democrats and Republicans provided similar proportion estimates, Democrats interpreted mortality to be higher than Republicans; Democrats also interpreted mortality to be higher for COVID-19 than Influenza. Block 2 examined responses to time series (line graphs); Democrats and Republicans estimated greater slopes for COVID-19 trend lines than Influenza lines ( p &lt; .001); subjective judgements revealed a disease x political party interaction ( p &lt; .05). Democrats and Republicans indicated similar subjective rates of change for COVID-19 trends, and Democrats indicated lower subjective rates of change for Influenza than in any other condition. Thus, while Democrats and Republicans saw the graphs similarly in terms of percentages and line slopes, their subjective interpretations diverged. While we may see graphs of infectious disease data similarly from a purely mathematical or geometric perspective, our political affiliations may moderate how we subjectively interpret the data. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221080678",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Jonathan D Ericson",
        "William S Albert",
        "Ja-Nae Duane"
      ],
      "url": "https://doi.org/10.1177/20539517221080678",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 78,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bf821cba-60eb-43af-bdd5-8bbb596cb2ad",
    "title": "Enacting data context: Fixing meaning in transparency data initiatives",
    "abstract": "<jats:p> This article documents the “context cultures” underpinning efforts to develop regulations for collecting and reporting data in a United States public database known as Open Payments. Open Payments is a dataset published annually by the US Center for Medicare and Medicaid Services that documents the transfers of value from pharmaceutical and medical device manufacturers to physicians, prescribing non-physicians, and teaching hospitals. In the article, I show context became a manifold concern as differentially-situated actors engaged in modes of public advocacy and social action around not only what data meant, but also what it meant to make data meaningful. I show how “context” took on multiple meanings as it was brought into relationship with certain concepts (such as “light,” “transparency,” and “interpretation”) and as stakeholders developed arguments for where they believed meaning should originate. In presenting this case, I call for further ethnographic attention to the ways in which meaning-making is enacted in relation to datasets—particularly those datasets intended to hold institutions accountable. I conclude the article meditating on the political significance of attending to various “context cultures” when putting data signification in context, along with the implications for how critical data studies scholars historicize big data epistemologies and rhetoric. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241270656",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Lindsay Poirier"
      ],
      "url": "https://doi.org/10.1177/20539517241270656",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 58,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9476e37a-b0ae-44b4-8e6c-1b1d12604210",
    "title": "Algorithmic paranoia and the convivial alternative",
    "abstract": "<jats:p> In a time of big data, thinking about how we are seen and how that affects our lives means changing our idea about who does the seeing. Data produced by machines is most often ‘seen’ by other machines; the eye is in question is algorithmic. Algorithmic seeing does not produce a computational panopticon but a mechanism of prediction. The authority of its predictions rests on a slippage of the scientific method in to the world of data. Data science inherits some of the problems of science, especially the disembodied ‘view from above’, and adds new ones of its own. As its core methods like machine learning are based on seeing correlations not understanding causation, it reproduces the prejudices of its input. Rising in to the apparatuses of governance, it reinforces the problematic sides of ‘seeing like a state’ and links to the recursive production of paranoia. It forces us to ask the question ‘what counts as rational seeing?’. Answering this from a position of feminist empiricism reveals different possibilities latent in seeing with machines. Grounded in the idea of conviviality, machine learning may reveal forgotten non-market patterns and enable free and critical learning. It is proposed that a programme to challenge the production of irrational pre-emption is also a search for the possibility of algorithmic conviviality. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716671340",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Dan McQuillan"
      ],
      "url": "https://doi.org/10.1177/2053951716671340",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 46,
      "is_referenced_by_count": 23,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d180c9a5-bed4-4fdb-b810-85296f688a84",
    "title": "Ecological ethics and the smart circular economy",
    "abstract": "<jats:p> The corporate discourse on the circular economy holds that the growth of the electronics industry, driven by continuous innovation, does not imperil ecological sustainability. To achieve sustainable growth, its advocates propose optimizing recycling by means of artificial intelligence and sets of interrelated datacentric and algorithmic technologies. Drawing on critical data and algorithm studies, theories of waste, and empirical research, this paper investigates ecological ethics in the context of the datacentric and algorithmically mediated circular economy. It foregrounds the indeterminate and fickle material nature of waste as well as the uncertainties inherent in, and stemming from, datafication and computation. My question is: how do the rationalities, affordances, and dispositions of datacentric and algorithmic technologies perform and displace notions of corporate responsibility and transparency? In order to answer this question, I compare the smart circular economy to the informal recycling practices that it claims to replace, and I analyze relations between waste matter and data as well as distributions of agency. Specifically, I consider transitions and slippages between response-ability and responsibility. Conceptually, I bring process-relation or immanence-based philosophies such as Bergson's and Deleuze's into a debate about relations between waste matter and data and the ambition of algorithmic control over waste. My aim is not to demand heightened corporate responsibility enacted through control but to rethink responsibility in the smart circular economy along the lines of Amoore's cloud ethics to carve out a position of critique beyond either a deontological perspective that reinforces corporate agency or new-materialist denunciation of the concept. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231158996",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Rolien Hoyng"
      ],
      "url": "https://doi.org/10.1177/20539517231158996",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 73,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8b9d232a-0ccc-490b-8e79-bc4000bc4811",
    "title": "The corporate cultivation of digital resignation in policymaking: How weak US regulations enable data trafficking to China",
    "abstract": "<jats:p> Studies of digital resignation focus on the idea of the corporate cultivation of digital resignation among users, an area of intense importance when examining user data sharing with corporations. To best appreciate the implications of digital resignation in a transnational context, it is important to consider not just resignation by users, but by policymakers. Weak digital policymaking in the US context enables continued digital resignation by users. It also allows for data trafficking, or government directed movement of user data across borders without clear user consent. This paper compares digital policymaking using three cases of national, regional, and sector-based digital policymaking. The commentary argues that while US policymakers often cast concerns on Chinese influence in the US, such arguments obscure the systematic resignation of US policymakers to a weak and ineffectual domestic digital oversight system. Examining digital resignation through a national government lens enables a more complete view of the transnational implications of this important concept. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241289441",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Aynne Kokas"
      ],
      "url": "https://doi.org/10.1177/20539517241289441",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 36,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "342e5541-31e2-4528-bfae-a1df9518fce5",
    "title": "Linguistic justice as a framework for designing, developing, and managing natural language processing tools",
    "abstract": "<jats:p> As natural language processing tools powered by big data become increasingly ubiquitous, questions of how to design, develop, and manage these tools and their impacts on diverse populations are pressing. We propose utilizing the concept of linguistic justice—the realization of equitable access to social and political life regardless of language—to provide a framework for examining natural language processing tools that learn from and use human language data. To support linguistic justice, we argue that natural language processing tools (along with the datasets that are used to train and evaluate them) must be examined not only from the perspective of a privileged, majority language user, but also from the perspectives of minoritized language users. Considering such perspectives can help to surface areas in which the data used within natural language processing tools may be (often inadvertently) working against linguistic justice by failing to provide access to information, services, or opportunities in users’ language of choice, underperforming for certain linguistic groups, or advancing harmful stereotypes that can lead to negative life outcomes for members of marginalized groups. At the same time, this framework can help to illuminate ways that these shortcomings can be addressed and allow us to use inclusive language data and approaches to leverage natural language processing technologies that advance linguistic justice. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221090930",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Julia Nee",
        "Genevieve Macfarlane Smith",
        "Alicia Sheares",
        "Ishita Rustagi"
      ],
      "url": "https://doi.org/10.1177/20539517221090930",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 27,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e8acbbe6-b275-4c74-8575-6ffd0c0d6a73",
    "title": "Beyond artificial intelligence controversies: What are algorithms doing in the scientific literature?",
    "abstract": "<jats:p> Mounting critique of the way AI is framed in mainstream media calls for less sensationalist coverage, be it jubilant or apocalyptic, and more attention to the concrete situations in which AI becomes controversial in different ways. This is supposedly achieved by making coverage more expert-informed. We therefore explore how experts contribute to the issuefication of AI through the scientific literature. We provide a semantic, visual network analysis of a corpus of 1M scientific abstracts about machine learning algorithms and artificial intelligence. Through a systematic quali-quantitative exploration of 235 co-word clusters and a subsequent structured search for 18 issue-specific queries, for which we devise a novel method with a custom-built datascape, we explore how algorithms have agency. We find that scientific discourse is highly situated and rarely about AI in general. It overwhelmingly charges algorithms with the capacity to solve problems and these problems are rarely about algorithms in their origin. Conversely, it rarely charges algorithms with the capacity to cause problems and when it does, other algorithms are typically charged with the capacity to solve them. Based on these findings, we argue that while a more expert-informed coverage of AI is likely to be less sensationalist and show greater attention to the specific situations where algorithms make a difference, it is unlikely to stage AI as particularly controversial. Consequently, we suggest conceptualising AI as a political situation rather than something inherently controversial. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241255107",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Anders Kristian Munk",
        "Mathieu Jacomy",
        "Matilde Ficozzi",
        "Torben Elgaard Jensen"
      ],
      "url": "https://doi.org/10.1177/20539517241255107",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 77,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "20079b29-e3b2-4185-8b11-c1a540ddb628",
    "title": "Data anxieties: Finding trust in everyday digital mess",
    "abstract": "<jats:p> Digital data is an increasing and continual presence across the sites, activities and relationships of everyday life. In this article we explore what data presence means for the ways that the everyday is organised, sensed, and anticipated. While digital data studies have demonstrated how data is deeply entangled with the way in which everyday life is lived out and valued, at the same time our relationships with data are riddled with anxieties or small niggles or tricky trade-offs and their use is often chaotic and muddled, part of the inevitable uncertainty about what will happen next. If the presence of data is part of the environments we inhabit, this raises the question of how and why data is valuable to us and what forms of hope and trust enable this value to further develop. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718756685",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Sarah Pink",
        "Debora Lanzeni",
        "Heather Horst"
      ],
      "url": "https://doi.org/10.1177/2053951718756685",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 47,
      "is_referenced_by_count": 72,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d37224ee-3654-4774-be4f-d86b8dcd1f74",
    "title": "Learning accountable governance: Challenges and perspectives for data-intensive health research networks",
    "abstract": "<jats:p> Current challenges to sustaining public support for health data research have directed attention to the governance of data-intensive health research networks. Accountability is hailed as an important element of trustworthy governance frameworks for data-intensive health research networks. Yet the extent to which adequate accountability regimes in data-intensive health research networks are currently realized is questionable. Current governance of data-intensive health research networks is dominated by the limitations of a drawing board approach. As a way forward, we propose a stronger focus on accountability as learning to achieve accountable governance. As an important step in that direction, we provide two pathways: (1) developing an integrated structure for decision-making and (2) establishing a dialogue in ongoing deliberative processes. Suitable places for learning accountability to thrive are dedicated governing bodies as well as specialized committees, panels or boards which bear and guide the development of governance in data-intensive health research networks. A continuous accountability process which comprises learning and interaction accommodates the diversity of expectations, responsibilities and tasks in data-intensive health research networks to achieve responsible and effective governance. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221136078",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Sam HA Muller",
        "Menno Mostert",
        "Johannes JM van Delden",
        "Thomas Schillemans",
        "Ghislaine JMW van Thiel"
      ],
      "url": "https://doi.org/10.1177/20539517221136078",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 88,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fb5e1203-26b6-46c5-8a63-3e2b3316136d",
    "title": "The valorization of interactions. Gift exchange, power and value creation on digital platforms",
    "abstract": "<jats:p> Technology companies are often worth billions, but they still must make their money through advertising. The research literature on the value creation of data-driven platform companies often refers to the expropriation of data or the exploitation of users. This article proposes a relational approach to the understanding of value creation on digital platforms such as social media channels or free internet services. To this end, it combines Marxian and anthropological value theory. Accordingly, the interactions of platform users are understood as asymmetrical practices of gift exchange. This exchange of digital gifts forms the condition of production for the value creation of internet platforms, and is reproduced continuously by their asymmetrical field of interaction. Here it is not the individual who is exploited, but rather the community of those who interact in a particular field. This condition is anchored in these platforms’ terms and conditions, which stipulate that users share their data not only with each other, but also with the company, thereby enabling a three-step process of data commodification by the platform. First, the data are appropriated as use values by the platforms in order to optimize their own services. Subsequently, a secondary commodification takes place, which, unlike other value creation processes, is decoupled from the use value of the data. Third, there is a process of cybernetization, in which the ability to influence users is sold to third parties as a commodity. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241259639",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Oliver Nachtwey",
        "Simon Schaupp"
      ],
      "url": "https://doi.org/10.1177/20539517241259639",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 83,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7d440e5a-14ca-4ebc-a0b1-7ea7b582a76a",
    "title": "An alternative planetary future? Digital sovereignty frameworks and the decolonial option",
    "abstract": "<jats:p> The frameworks of cyber, technology and data sovereignty have become some of the most influential alternative technological imaginaries. Developed by states and civil society groups, such frameworks are seducing a broad range of actors seeking to reassert their autonomy and self-determination in relation to digital technology and infrastructure. Against this backdrop, this article interrogates the alleged transformative character of digital sovereignty. Do these frameworks support alternative planetary futures, or do they involve a mere change in the actors who are privileging from the technological status quo? To answer this question, I examine the rhetoric and realisation of digital sovereignty frameworks by the Chinese state, the European Union (EU) and Latin American civil society in light of Walter Mignolo's decolonial option. The decolonial option gets inspiration from decolonial praxis and aims at enabling polycentric, noncapitalist and nonanthropocentric planetary futures. As I show, there is some degree of alignment between digital sovereignty frameworks and the decolonial option in the sphere of international politics, but less so in the world economy and the environment. While in some areas the formulations by the Chinese state and the EU can exacerbate coloniality, the Latin American civil society one constitutes a promising attempt at appropriating digital sovereignty from below and promoting peaceful forms of coexistence with the environment although needs further development. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231221778",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Sebastián Lehuedé"
      ],
      "url": "https://doi.org/10.1177/20539517231221778",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 65,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "689edeb2-8373-46fd-8a59-223176f8ce22",
    "title": "‘Real-time’ air quality channels: A technology review of emerging environmental alert systems",
    "abstract": "<jats:p> Poor air quality is a pressing global challenge contributing to adverse health impacts around the world. In the past decade, there has been a rapid proliferation of air quality information delivered via sensors, apps, websites or other media channels in near real-time and at increasingly localized geographic scales. This paper explores the growing emphasis on self-monitoring and digital platforms to supply informational interventions for reducing pollution exposures and improving health outcomes at the individual level. It presents a technological case study that characterizes emerging air quality information communication mechanisms, or ‘AQ channels’, while drawing upon examples throughout the literature. The questions are posed: which air quality channels are ‘freely’ available to individuals in London, UK, and when and where are they accessed? Digital trace data and metadata associated with 54 air quality channels are synthesized narratively and graphically. Results reveal air quality channels derive air pollution estimates using common data sources, display disparate messaging, adopt variable geographic scales for reporting ‘readings’ and maintain psychosocial barriers to access and adoption of exposure-reducing behaviours. The results also point to a clear association between the publication of a high-profile news article about air pollution and increased air quality channel access. These findings illuminate a need for greater transparency around how air quality channels generate personalized air pollution exposure estimates and tailor messaging. The paper concludes by calling for air quality channel developers to exercise co-creative methods that can support sustainable, democratic data and knowledge production around air quality, while critically approaching disproportionate patterns of both pollution and information exposure. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221101346",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Kayla Schulte"
      ],
      "url": "https://doi.org/10.1177/20539517221101346",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 70,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a0a4bf57-21aa-4c05-ba78-c16beaf8c9dc",
    "title": "Pushback: Critical data designers and pollution politics",
    "abstract": "<jats:p> In this paper, we describe how critical data designers have created projects that ‘push back’ against the eclipse of environmental problems by dominant orders: the pioneering pollution database Scorecard, released by the US NGO Environmental Defense Fund in 1997; the US Environmental Protection Agency’s EnviroAtlas that brings together numerous data sets and provides tools for valuing ecosystem services; and the Houston Clean Air Network’s maps of real-time ozone levels in Houston. Drawing on ethnographic observations and interviews, we analyse how critical data designers turn scientific data and findings into claims and visualisations that are meaningful in contemporary political terms. The skills of critical data designers cross scales and domains; they must identify problems calling for public consideration, and then locate, access, link, and create visualisations of data relevant to the problem. We conclude by describing hazards ahead in work to leverage Big Data to understand and address environmental problems. Critical data designers need to understand what counts as a societal problem in a particular context, what doesn’t, what is seen as connected and not, what is seen as ethically charged, and what is exonerated and discounted. Such recognition is produced through interpretive, ‘close reading’ of the historical moment in which they operate. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716668903",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Kim Fortun",
        "Lindsay Poirier",
        "Alli Morgan",
        "Brandon Costelloe-Kuehn",
        "Mike Fortun"
      ],
      "url": "https://doi.org/10.1177/2053951716668903",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 48,
      "is_referenced_by_count": 19,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a8e60ede-d7ca-4470-a5bb-1c4d2a611c8d",
    "title": "Municipal surveillance regulation and algorithmic accountability",
    "abstract": "<jats:p> A wave of recent scholarship has warned about the potential for discriminatory harms of algorithmic systems, spurring an interest in algorithmic accountability and regulation. Meanwhile, parallel concerns about surveillance practices have already led to multiple successful regulatory efforts of surveillance technologies—many of which have algorithmic components. Here, we examine municipal surveillance regulation as offering lessons for algorithmic oversight. Taking the 2017 Seattle Surveillance Ordinance as our primary case study and surveying efforts across five other cities, we describe the features of existing surveillance regulation; including procedures for describing surveillance technologies in detail, requirements for public engagement, and processes for establishing acceptable uses. Although the Seattle Surveillance Ordinance was not intended to address algorithmic accountability, we find these considerations to be relevant to the law’s aim of surfacing disparate impacts of systems in use. We also find that in notable cases government employees did not identify regulated algorithmic surveillance technologies as reliant on algorithmic or machine learning systems, highlighting definitional gaps that could hinder future efforts toward algorithmic regulation. We argue that (i) finer-grained distinctions between types of information systems in the language of law and policy, and (ii) risk assessment tools integrated into their implementation would strengthen future regulatory efforts by rendering underlying algorithmic components more legible and accountable to political and community stakeholders. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719868492",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Meg Young",
        "Michael Katell",
        "P. M. Krafft"
      ],
      "url": "https://doi.org/10.1177/2053951719868492",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171986849",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 27,
      "is_referenced_by_count": 29,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a18963b4-750a-4285-8ee0-68c5af012a2f",
    "title": "Organizing an “organizationless” protest campaign in the WeChatsphere",
    "abstract": "<jats:p> The introduction of digital technologies in collective actions seems to have transformed the dynamics of movement organizing and enabled divergent forms of protest organizing. While some studies emphasize “organizationless” organizing in which traditional organizational forms—social movements organizations and formal-bureaucratic structures—have been pushed into the margins, other studies showcase how traditional forms have assumed alternative features, for example, connective leadership and organizations with fluid boundaries. While existing research correctly points out the evolving organizing dynamics and forms in digital activism, few studies have accounted for why digitally enabled protests take certain organizing forms over others among multiple modes of interaction between protesters and digital technologies. Using a case study of a protest campaign organized by Chinese American immigrants, this study illustrates why immigrant activists struggled to keep the campaign “organizationless” on WeChat, a China-based digital platform that afforded other forms of organizing over such an organizing mode. Building on the mechanism-based approach in social movement studies, the findings show that immigrant activists’ emotional–cognitive responses to the changing digital environments became the driving force behind the relational choices to maintain the protest “organizationless.” The study, therefore, may not only inform future studies to explore why certain structures of protest networks emerge and develop but also contribute to the mechanism-based approach by foregrounding emotional–cognitive mechanisms, which mediate environmental and relational mechanisms. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221078823",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Hao Cao"
      ],
      "url": "https://doi.org/10.1177/20539517221078823",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 57,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5df885dd-c5cb-48d7-bf78-0c873bb6ad8e",
    "title": "Disruption and dislocation in post-COVID futures for digital health",
    "abstract": "<jats:p> In this piece we explore the COVID pandemic as an opportunity for the articulation and realization of digital health futures. Our discussion draws on an engagement with emergent discourse around COVID-19 and ongoing work on imaginaries of future care associated with digital tools for the detection of cognitive decline and the risk of dementia. We describe how the post-COVID futures of digital health are narrated in terms of the timing and speed with which they are being brought into being, as market actors attempt to establish the scale and durability of the COVID transformation. However, we also point to the particularly spatial changes to medical practice they envisage. In a time of distancing and isolation, the ability to operate effectively at a distance has become integral to the future of medical assessment, diagnosis and care. However, spatialized promises of digital health and the ability to act remotely are unevenly spread – some organizations and entities inevitably have greater reach. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720949567",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Richard Milne",
        "Alessia Costa"
      ],
      "url": "https://doi.org/10.1177/2053951720949567",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 29,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7ebdc934-d1fb-4834-864e-627f33650461",
    "title": "Broken loops, open futures: The building and breaking of behavioural insurance",
    "abstract": "<jats:p> Digital looping effects between algorithmic technologies and users are promoted as reshaping various industries by optimizing operations, improving predictions and creating new market opportunities. Insurers are exploring these promises by collecting customer-generated data and testing its use in risk calculations and behavioural interventions. However, these novel insurance technologies have been criticized for enabling totalizing forms of surveillance, control and discrimination, potentially leading to the foreclosure of future actions. This study tests the argument that emerging insurance technologies ‘narrow the future’ by analysing Finnish life insurers’ efforts to build a digital feedback loop into their behavioural policies. It centralizes breakages in these new data practices as the locus of analysis, showing how the feedback loop dissolves at various points or is never established due to shortcomings in the new technologies, regulatory barriers and aspects inherent to insurance logic itself, thereby undermining the policies’ aims; yet, the insurers’ experimentations cannot be simply framed as failures because they produce knowledge that can inform future practices. The present study illustrates the importance of examining how versions of dominant technological visions are reworked in local, field-specific practices. It shows that instead of producing ‘guaranteed outcomes’, these novel insurance operations raise new questions and uncertainties that can have harmful effects beyond the totalizing scenarios. Focusing on breakages challenges techno-deterministic perspectives, keeping the future open while enabling a more precise critique of the harms associated with these visions and their often-imperfect implementation. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241309885",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Maiju Tanninen"
      ],
      "url": "https://doi.org/10.1177/20539517241309885",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 58,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c7ed7f79-81e5-4f9e-92a7-091d4fa4bd1c",
    "title": "Digital/computational phenotyping: What are the differences in the science and the ethics?",
    "abstract": "<jats:p> The concept of ‘digital phenotyping’ was originally developed by researchers in the mental health field, but it has travelled to other disciplines and areas. This commentary draws upon our experiences of working in two scientific projects that are based at the University of Oxford’s Big Data Institute – The RADAR-AD project and The Minerva Initiative – which are developing algorithmic phenotyping technologies. We describe and analyse the concepts of digital biomarkers and computational phenotyping that underlie these projects, explain how they are linked to other research in digital phenotyping and compare and contrast some of their epistemological and ethical implications. In particular, we argue that the phenotyping paradigm in both projects is grounded on an assumption of ‘objectivity’ that is articulated in different ways depending on the role that is given to the computational/digital tools. Using the concept of ‘affordance’, we show how specific functionalities relate to potential uses and social implications of these technologies and argue that it is important to distinguish among them as the concept of digital phenotyping is increasingly being used with a variety of meanings. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211062885",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Federica Lucivero",
        "Nina Hallowell"
      ],
      "url": "https://doi.org/10.1177/20539517211062885",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 10,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4f3edc61-8051-46f1-b6c8-b56086f625fd",
    "title": "Cities, COVID-19, and counting",
    "abstract": "<jats:p> The COVID-19 pandemic had immediate and potentially long-lasting impacts on cities. Yet, the ability to assess, monitor, and analyze the wide-ranging effects of the pandemic has been stymied by data challenges. The pandemic elevated the need for, and reliance on, a wide range of data sources. We discuss four data challenges related to understanding the impact of the pandemic on cities. First, we explore how shifts in public policy and the decisions of private companies altered data collection priorities, availability, and reliability. Second, we discuss temporal dimensions, including the speed of data retrieval and frequency of data collection. Third, we identify the growing use of unexpected sources, which often feature a lack of rigor and consistency. Fourth, we explore the spatial scale of study and highlight questions about the interpretation of boundaries constituting the city. We use examples from the City of Toronto to ground our observations while also pointing to broader issues. We note that the tension between rapid, novel data and slow, consistent data continues to evolve and argue that a deeper appreciation and analysis of, and access to, myriad sources of data are necessary to understand the immediate and long-term impacts of COVID-19 on cities. Beyond the pandemic, our essay contributes to ongoing and emerging debates regarding the use of big data to understand the challenges facing cities and society. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231188724",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Tara Vinodrai",
        "Shauna Brail"
      ],
      "url": "https://doi.org/10.1177/20539517231188724",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 24,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4aff32ad-6cce-4ee9-a175-7758f040c14b",
    "title": "Clicks and particulates: Value, alienation, and attunement as unifying themes in big data studies",
    "abstract": "<jats:p> Critiques of data colonialism and surveillance capitalism focus on data collected from online behavior. We propose that analytical concepts from these critiques—namely, regimes of value and patterns of alienation and attunement—could be applied more widely to better understand the threats that datafication poses to equity and democracy in the social and environmental realms. Regimes of value, which include the institutions and technologies that make data meaningful and render them selectively available for appropriation, are relevant both to for-profit companies’ data practices and to states’ participation in the datafication of the environment; examining regimes of value raises questions about how data are exploited and how they are neglected. Patterns of alienation associated with datafication include the potential for alienation from the environment; however, at least in some value regimes, alienation may be accompanied by possibilities for attunement to natural and social phenomena that might otherwise have escaped notice. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231184891",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Gwen Ottinger",
        "Kelly Bronson",
        "Dawn Nafus"
      ],
      "url": "https://doi.org/10.1177/20539517231184891",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 26,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d53a09a0-7c19-4002-80d5-c84b199183a5",
    "title": "Music on-demand: A commentary on the changing relationship between music taste, consumption and class in the streaming age",
    "abstract": "<jats:p> From providing on-demand access to vast catalogues of recorded music at little or no cost to the use of Big Data to personalise the experience of consuming music, music streaming platforms, such as Spotify and Apple Music, have the potential to disrupt the part that music taste plays in the performance of class identities and the reproduction of class privilege in ways not previously encountered. The influential sociologist, Pierre Bourdieu , demonstrated that cultural taste – what and how people consume cultural goods, such as music, food and fashion – is shaped by class background and in doing so serves to mark and reproduce class differences in everyday life. In this commentary, I consider how sociologists might address the important but challenging question of if and how are music streaming platforms shaping the part that music taste plays in the performance of class identities and the cultural reproduction of class privilege. I discuss some ways in which music streaming platforms may be shaping how class identities are performed through how people consume music, drawing attention to consumption practices that have the potential to both involve and resist the use of music streaming platforms in the pursuit of social distinction. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719888770",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Jack Webster"
      ],
      "url": "https://doi.org/10.1177/2053951719888770",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171988877",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 16,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "eebb79e1-26e1-4ee9-a135-50293df3f9a3",
    "title": "Shareable and un-sharable knowledge",
    "abstract": "<jats:p> This article focuses on what it means to generate actionable but non-sharable information, and how this might relate to our understanding of what counts as knowledge, which typically entails some form of explanation. As automated systems sort and classify us for the purposes of dating, education, employment, health care, security, and more, we are going to want to know how and why these decisions are being made. Or, failing that, we will at least want to know, with as much clarity as possible, under what circumstances and to what uses, automated systems are being put to use. In either case, the role of narrative is inseparable from the call for transparency. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720933917",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Mark Andrejevic"
      ],
      "url": "https://doi.org/10.1177/2053951720933917",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172093391",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 4,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "dc61f4c0-6daa-448a-b2b3-f7772f957455",
    "title": "Social media and the social sciences: How researchers employ Big Data analytics",
    "abstract": "<jats:p> Social media posts are full of potential for data mining and analysis. Recognizing this potential, platform providers increasingly restrict free access to such data. This shift provides new challenges for social scientists and other non-profit researchers who seek to analyze public posts with a purpose of better understanding human interaction and improving the human condition. This paper seeks to outline some of the recent changes in social media data analysis, with a focus on Twitter, specifically. Using Twitter data from a 24-hour period following The Sisters in Spirit Candlelight Vigil, sponsored by the Native Women’s Association of Canada, this article compares three free-use Twitter application programming interfaces for capturing tweets and enabling analysis. Although recent Twitter data restrictions limit free access to tweets, there are many dynamic options for social scientists to choose from in the capture and analysis of Twitter and other social media platform data. This paper calls for critical social media data analytics combined with traditional, qualitative methods to address the developing ‘data gold rush.’ </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716645828",
      "type": "journal-article",
      "published": [
        2016,
        6,
        1
      ],
      "authors": [
        "Mylynn Felt"
      ],
      "url": "https://doi.org/10.1177/2053951716645828",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 48,
      "is_referenced_by_count": 99,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a95b1198-1b3c-4adb-bd37-80eb046b9454",
    "title": "Responding to unusual government request for user data: How tech companies make sense of human rights",
    "abstract": "<jats:p> Data sharing practices between governments and the private sector are characterized by a lack of transparency which has potential implications for human rights. Minimal scholarship exists investigating how companies address human rights risks stemming from government requests for user data. Understanding corporate response processes to government requests is central to advancing human rights research at the intersection of tech company conduct. This becomes even more pressing as emerging technologies gather increasing amounts of data. Scholarship demonstrates that transparency reporting cannot assist in analyzing data sharing practices between the private and the public sectors due to a variety of constraints. Using semi-structured interviews with senior staff at technology companies, this paper presents an empirical analysis of how technology company representatives and external advisors seek to align their processes when responding to government requests for user data. It describes a set of six themes using human rights terminology which company representatives aim to employ when responding to requests. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241232638",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Isabel Ebert"
      ],
      "url": "https://doi.org/10.1177/20539517241232638",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 51,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a2274386-9ead-4ccd-8786-6095521249fd",
    "title": "Big and broad social data and the sociological imagination: A collaborative response",
    "abstract": "<jats:p> In this paper, we reflect on the disciplinary contours of contemporary sociology, and social science more generally, in the age of ‘big and broad’ social data. Our aim is to suggest how sociology and social sciences may respond to the challenges and opportunities presented by this ‘data deluge’ in ways that are innovative yet sensitive to the social and ethical life of data and methods. We begin by reviewing relevant contemporary methodological debates and consider how they relate to the emergence of big and broad social data as a product, reflexive artefact and organizational feature of emerging global digital society. We then explore the challenges and opportunities afforded to social science through the widespread adoption of a new generation of distributed, digital technologies and the gathering momentum of the open data movement, grounding our observations in the work of the Collaborative Online Social Media ObServatory (COSMOS) project. In conclusion, we argue that these challenges and opportunities motivate a renewed interest in the programme for a ‘public sociology’, characterized by the co-production of social scientific knowledge involving a broad range of actors and publics. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714545135",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "William Housley",
        "Rob Procter",
        "Adam Edwards",
        "Peter Burnap",
        "Matthew Williams",
        "Luke Sloan",
        "Omer Rana",
        "Jeffrey Morgan",
        "Alex Voss",
        "Anita Greenhill"
      ],
      "url": "https://doi.org/10.1177/2053951714545135",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 48,
      "is_referenced_by_count": 62,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3b8be8a4-8016-4f54-aaa3-1838e8816ec9",
    "title": "Co-designing algorithms for governance: Ensuring responsible and accountable algorithmic management of  refugee camp supplies",
    "abstract": "<jats:p> There is increasing criticism on the use of big data and algorithms in public governance. Studies revealed that algorithms may reinforce existing biases and defy scrutiny by public officials using them and citizens subject to algorithmic decisions and services. In response, scholars have called for more algorithmic transparency and regulation. These are useful, but ex post solutions in which the development of algorithms remains a rather autonomous process. This paper argues that co-design of algorithms with relevant stakeholders from government and society is another means to achieve responsible and accountable algorithms that is largely overlooked in the literature. We present a case study of the development of an algorithmic tool to estimate the populations of refugee camps to manage the delivery of emergency supplies. This case study demonstrates how in different stages of development of the tool—data selection and pre-processing, training of the algorithm and post-processing and adoption—inclusion of knowledge from the field led to changes to the algorithm. Co-design supported responsibility of the algorithm in the selection of big data sources and in preventing reinforcement of biases. It contributed to accountability of the algorithm by making the estimations transparent and explicable to its users. They were able to use the tool for fitting purposes and used their discretion in the interpretation of the results. It is yet unclear whether this eventually led to better servicing of refugee camps. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221087855",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Rianne Dekker",
        "Paul Koot",
        "S. Ilker Birbil",
        "Mark van Embden Andres"
      ],
      "url": "https://doi.org/10.1177/20539517221087855",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 82,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "90a4c6da-ef3f-45c7-81e2-1b5684debce0",
    "title": "New geographies of platform capitalism: The case of digital monopolization in Turkey",
    "abstract": "<jats:p> The rise of digital platforms is growingly acknowledged as a pivotal characteristic of contemporary capitalism. A subset of the literature on digital platforms scrutinized the political economy of platform companies, their data-driven business models along with the economic, social, and political consequences of platformization. Yet, this strand has been overwhelmingly interested in Big Tech companies in the United States and China. In this article, I aim to expand the geographical span of this emerging literature by scrutinizing platformization dynamics in Turkey, a middle-income country that has not been systematically examined so far along these lines. To this end, I present an assessment on the overall platform landscape in Turkey by focusing on three highlight digital platforms (Trendyol, Hepsiburada, and Getir). My analysis on the trajectory of these three platforms indicates the following. First, these platforms have exhibited meteoric growth rates and have risen among the most valuable companies in Turkey in a tremendously short period of time. Second, their aggressive growth strategies based on data extraction and network externalities have led to a strong monopolization drive. Third, they have rapidly expanded into adjacent business areas, transforming themselves into infrastructural components of the domestic economy, with profound impacts on production, trade, and labor relations. Fourth, they remain dependent on the infrastructure laid by Big Techs. These findings suggest that platformization is rapidly transforming economic landscapes other than the United States and China as well, yet in an uneven and dependent form, underlining the need to broaden the geographical focus of the concerned literature. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221124585",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Melih Yeşilbağ"
      ],
      "url": "https://doi.org/10.1177/20539517221124585",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 77,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "83b50e99-6df2-4207-b29a-5d314c4a144b",
    "title": "Logged out: Ownership, exclusion and public value in the digital data and information commons",
    "abstract": "<jats:p> In recent years, critical scholarship has drawn attention to increasing power differentials between corporations that use data and people whose data is used. A growing number of scholars see digital data and information commons as a way to counteract this asymmetry. In this paper I raise two concerns with this argument: First, because digital data and information can be in more than one place at once, governance models for physical common-pool resources cannot be easily transposed to digital commons. Second, not all data and information commons are suitable to address power differentials. In order to create digital commons that effectively address power asymmetries we must pay more systematic attention to the issue of exclusion from digital data and information commons. Why and how digital data and information commons exclude, and what the consequences of such exclusion are, decide whether commons can change power asymmetries or whether they are more likely to perpetuate them. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719829773",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Barbara Prainsack"
      ],
      "url": "https://doi.org/10.1177/2053951719829773",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 64,
      "is_referenced_by_count": 77,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bcbd3ba6-2612-478a-87cf-fc66b4387ec0",
    "title": "Deconstructing the cloud: Responses to Big Data phenomena from social sciences, humanities and the arts",
    "abstract": "<jats:p> The era of Big Data comes with the omnipresent metaphor of the Cloud, a term suggesting an ephemeral and seemingly endless storage space, unhindered by time and place. Similar to the satellite image of the Whole Earth, which was the icon of technological progress in the late 60s, the Cloud as a metaphor breathes the promise of technology, whilst obfuscating the hardware reality of server farms and software infrastructure necessary to enable the proliferation of (big) data. This article presents projects from the fields of humanities, social sciences and the arts that formulate a response to Big Data and its human and automated practices, from data analytics dashboards to critical reflections on smart technologies and objects. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715594635",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Sabine Niederer",
        "Raymond Taudin Chabot"
      ],
      "url": "https://doi.org/10.1177/2053951715594635",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 30,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "47b2ae2b-6e7e-40af-848c-5972593731d2",
    "title": "Mundane data: The routines, contingencies and accomplishments of digital living",
    "abstract": "<jats:p> This article develops and mobilises the concept of ‘mundane data’ as an analytical entry point for understanding Big Data. We call for in-depth investigation of the human experiences, routines, improvisations and accomplishments which implicate digital data in the flow of the everyday. We demonstrate the value of this approach through a discussion of our ethnographic research with self-tracking cycling commuters. We argue that such investigations are crucial in informing our understandings of how digital data become meaningful in mundane contexts of everyday life for two reasons: first because there is a gap in our understanding of the contingencies and specificities through which big digital data sets are produced, and second because designers and policy makers often seek to make interventions for change in everyday contexts through the presentation of mundane data to consumers but with little understanding of how people produce, experience and engage with these data. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717700924",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Sarah Pink",
        "Shanti Sumartojo",
        "Deborah Lupton",
        "Christine Heyes La Bond"
      ],
      "url": "https://doi.org/10.1177/2053951717700924",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 46,
      "is_referenced_by_count": 141,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "191f3c15-e9d6-44ae-b82b-7b83f9f9e421",
    "title": "Epistemologies of missing data: COVID dashboard builders and the production and maintenance of marginalized COVID data",
    "abstract": "<jats:p>During COVID-19, countless dashboards served as the central media for people to learn critical information about the pandemic. Varied actors, including news organizations, government agencies, universities, and nongovernmental organizations, created and maintained these dashboards, through the onerous labor of collecting, categorizing, and circulating COVID data. This study uncovers different forms of labor and data practices—the work of “COVID data builders”—behind the construction of these dashboards based on in-depth interviews with volunteers and practitioners across the United States and India who participated in COVID dashboard projects. Specifically, we examine projects focused on marginalized and missing COVID data that aimed to show the pandemic's disproportionate and unjust impact. Through an investigation of data builders’ encounters and experiences with missing COVID data in mediating the pandemic, we ask: What data problems did COVID data builders encounter? How did they produce missing COVID data while questioning its representational capacity? And lastly, what “alternative epistemologies of data” beyond representation do their data practices suggest? Through our analysis, we surfaced three types of epistemological ambiguities COVID data builders encountered within their datasets: disappearing and ephemeral data, obscuring data, and disregarded data. By highlighting these different epistemological dimensions of missing data, we conclude that focusing on the performative and infrastructural aspects of what makes datasets “work” builds a new vocabulary for addressing missing data beyond representation. We argue that the politics of counting COVID cases is grounded in the material and affective labor of confronting, navigating, and negotiating with data's epistemological ambiguities.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241259666",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Youngrim Kim",
        "Megan Finn",
        "Amelia Acker",
        "Bidisha Chaudhuri",
        "Stacey Wedlake",
        "Ryan Ellis",
        "Janaki Srinivasan"
      ],
      "url": "https://doi.org/10.1177/20539517241259666",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "34d2bb64-10ac-4387-aef1-854b96dfa5a5",
    "title": "Conceptualizations of Big Data and their epistemological claims in healthcare: A discourse analysis",
    "abstract": "<jats:p> In recent years, the healthcare field welcomed an emerging field of practices captured under the umbrella term ‘Big Data’. This term is surrounded with positive rhetoric and promises about the ability to analyse real-world data quickly and comprehensively. Such rhetoric is highly consequential in shaping debates on Big Data. While the fields of Science and Technology Studies and Critical Data Studies have been instrumental in elaborating the neglected and problematic dimensions of Big Data, it remains an open question how and to what extent such insights become embedded in other fields. In this paper, we analyse the epistemological claims that accompany Big Data in the healthcare domain. We systematically searched scientific literature and selected 206 editorials as these reflect on developments in the domain. Through an interpretive analysis, we construct five ideal-typical discourses that all frame Big Data in specific ways. Three of the discourses (the modernist, instrumentalist and pragmatist) frame Big Data in positive terms and disseminate a compelling rhetoric. Metaphors of ‘capturing’, ‘illuminating’ and ‘harnessing’ data presume that Big Data are benign and leading to valid knowledge. The scientist and critical-interpretive discourses question the objectivity and effectivity claims of Big Data. Metaphors of ‘selecting’ and ‘constructing’ data illustrate another political message, framing Big Data as limited. We conclude that work in the critical-interpretive discourse has not broadly infiltrated the medical domain. Ways to better integrate aspects of the discourse in the healthcare domain are urgently needed. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718816727",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Marthe Stevens",
        "Rik Wehrens",
        "Antoinette de Bont"
      ],
      "url": "https://doi.org/10.1177/2053951718816727",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 27,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2be53ad1-db8e-415f-a601-82d097eff932",
    "title": "Reactionary sensemaking: Mapping the micropolitics of online oppositional subcultures",
    "abstract": "<jats:p>Internet memes used to be funny, but somewhere in the mid-2010's, a darker dimension surfaced. This editorial explores this ‘reactionary turn’ in digital culture through a collection of articles and commentaries on ‘the micropolitics of online oppositional subcultures’. In the special theme, these range from commentaries on how misogyny and hate speech exploit platform affordances to articles tracing the growth and spread of arcane memes and anti-vaccine discourse on Reddit and Telegram. While these phenomena might elsewhere be labeled as instances of misinformation, the editorial frames them in terms of ‘reactionary sensemaking’, in which digital subcultures form communities in reaction to a perceived loss of meaning and out of a shared antipathy to ‘mainstream’ culture. Methodologically, the editorial situates these studies in terms of a broader ‘micropolitical’ research tradition that extends from Latour and Deleuze back to Tarde.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241235879",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Marc Tuters",
        "Melody Devries",
        "Tommaso Venturini",
        "Daniël de Zeeuw",
        "Tom Willaert"
      ],
      "url": "https://doi.org/10.1177/20539517241235879",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 39,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0ca7e69e-4a96-4052-83df-7ae57c06f225",
    "title": "Unsupervised by any other name: Hidden layers of knowledge production in artificial intelligence on social media",
    "abstract": "<jats:p> Artificial Intelligence (AI) in the form of different machine learning models is applied to Big Data as a way to turn data into valuable knowledge. The rhetoric is that ensuing predictions work well—with a high degree of autonomy and automation. We argue that we need to analyze the process of applying machine learning in depth and highlight at what point human knowledge production takes place in seemingly autonomous work. This article reintroduces classification theory as an important framework for understanding such seemingly invisible knowledge production in the machine learning development and design processes. We suggest a framework for studying such classification closely tied to different steps in the work process and exemplify the framework on two experiments with machine learning applied to Facebook data from one of our labs. By doing so we demonstrate ways in which classification and potential discrimination take place in even seemingly unsupervised and autonomous models. Moving away from concepts of non-supervision and autonomy enable us to understand the underlying classificatory dispositifs in the work process and that this form of analysis constitutes a first step towards governance of artificial intelligence. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718819569",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Anja Bechmann",
        "Geoffrey C Bowker"
      ],
      "url": "https://doi.org/10.1177/2053951718819569",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 72,
      "is_referenced_by_count": 74,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b73e2197-866d-44ed-b77b-3cf4a0f27593",
    "title": "Communicating public health during COVID-19, implications for vaccine rollout",
    "abstract": "<jats:p> A large body of information and opinion related to COVID-19 is being shared via social media platforms. Recent reports have raised concerns about the reliability and verifiability of said information being disseminated and the way systems, processes and design of the platforms facilitates such spread. This, alongside other areas of concern, has resulted in several social media platforms taking steps towards tackling the spread of mis- and dis-information. Here we discuss approaches to online public health messaging from a range of sources during COVID-19, with a focus on official and non-official sources in the United Kingdom (UK). We highlight issues for ongoing public health decisions, and the potential impact for the future course of the pandemic. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211023534",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Peter S Bloomfield",
        "Josefine Magnusson",
        "Maeve Walsh",
        "Annemarie Naylor"
      ],
      "url": "https://doi.org/10.1177/20539517211023534",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 30,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "79d7713c-570b-4fc3-a5a8-9b9db0e14d53",
    "title": "All WARC and no playback: The materialities of data-centered web archives research",
    "abstract": "<jats:p> This paper examines the Web ARChive (WARC) file format, revealing how the format has come to play a central role in the development and standardization of interoperable tools and methods for the international web archiving community. In the context of emerging big data approaches, I consider the sociotechnical relationships between material construction of data and information infrastructures for collecting and research. Analysis is inspired by Star and Griesemer's historical case of the Museum of Vertebrate Zoology which reveals how boundary objects and methods standardization are used to enroll actors in the work of collecting for natural history. I extend these concepts by pairing them with frameworks for studying digital materiality and the representational qualities of data artifacts. Through examples drawn from fieldwork observations studying two data-centered research projects, I consider how the materiality of the WARC format influences research methods and approaches to data extraction, selection, and transformation. Findings identify three modalities researchers use to configure WARC data for researcher needs: using indexes to support search queries, constructing derivative formats designed for certain types of analysis, and generating custom-designed datasets tailored for specific research purposes. Findings additionally reveal similarities in how these distinct methods approach automated data extraction by relying upon the WARC's standardized metadata elements. By interrogating whose information needs are being met and taken into account in the design of the WARC's underlying information representation, I reveal effects on the emerging field of web history, and consider alternative approaches to knowledge production with archived web data. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231163172",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Emily Maemura"
      ],
      "url": "https://doi.org/10.1177/20539517231163172",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 50,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "de199fde-0af9-40df-a25a-cb339ecc54dd",
    "title": "Children’s digital playgrounds as data assemblages: Problematics of privacy, personalization, and promotional culture",
    "abstract": "<jats:p> Children’s digital playgrounds have evolved from commercialized digital spaces such as websites and games to include an array of convergent digital media consisting of social media platforms, mobile apps, and the internet of toys. In these digital spaces, children’s data is shared with companies for analytics, personalization, and advertising. This article describes children’s digital playgrounds as a data assemblage involving commercial surveillance of children, ages 3–12. The privacy sweep is used as a method to follow the personal information traces that can be expected to be disclosed through typical use of two children’s digital playgrounds: the YouTube Kids app and Fisher-Price Smart Toy plush animal and companion app. To trace the data flows, privacy policies and other publicly available documents were analyzed using political economy and privacy informed indicators. This article concludes by reflecting upon the dataveillance and commercialization practices that trouble the privacy rights of the child and parent when data assemblages in children’s digital playgrounds are surveillant. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718805214",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Karen Louise Smith",
        "Leslie Regan Shade"
      ],
      "url": "https://doi.org/10.1177/2053951718805214",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 66,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "09ac191d-60b0-42a8-ba6d-bed6cf2ed6fa",
    "title": "Critical Data Studies: A dialog on data and space",
    "abstract": "<jats:p> In light of recent technological innovations and discourses around data and algorithmic analytics, scholars of many stripes are attempting to develop critical agendas and responses to these developments (boyd and Crawford 2012). In this mutual interview, three scholars discuss the stakes, ideas, responsibilities, and possibilities of critical data studies. The resulting dialog seeks to explore what kinds of critical approaches to these topics, in theory and practice, could open and make available such approaches to a broader audience. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716648346",
      "type": "journal-article",
      "published": [
        2016,
        6
      ],
      "authors": [
        "Craig M Dalton",
        "Linnet Taylor",
        "Jim Thatcher (alphabetical)"
      ],
      "url": "https://doi.org/10.1177/2053951716648346",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 63,
      "is_referenced_by_count": 139,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "09241c56-7dbd-406c-8be6-36541ea7851a",
    "title": "Contrasting medium and genre on Wikipedia to open up the dominating definition and classification of geoengineering",
    "abstract": "<jats:p> Geoengineering is typically defined as a techno-scientific response to climate change that differs from mitigation and adaptation, and that includes diverse individual technologies, which can be classified as either solar radiation management or carbon dioxide removal. We analyse the representation of geoengineering on Wikipedia as a way of opening up this dominating, if contested, model for further debate. We achieve this by contrasting the dominating model as presented in the encyclopaedic article texts with the patterns of hyper-link associations between the articles. Two datasets were created tracing the geoengineering construct on Wikipedia, shedding light on its boundary with its context, as well as on its internal structure. The analysis shows that the geoengineering category tends to be associated on Wikipedia primarily with atmospheric solar radiation management rather than land-based carbon dioxide removal type technologies. The results support the notion that the dominant model of defining and classifying geoengineering technology has been beneficial for solar radiation management type technologies more than for land-based carbon dioxide removal ones. The article also demonstrates that controversy mapping with Wikipedia data affords analysis that can open up dominating definitions and classifications of technologies, and offer resistance to their frequent naturalising and decontextualising tendencies. This work is in line with recent work on digital sociology, but the article contributes a new methodology and reports on the first empirical application of controversy mapping using Wikipedia data to a technology. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716666102",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Nils Markusson",
        "Tommaso Venturini",
        "David Laniado",
        "Andreas Kaltenbrunner"
      ],
      "url": "https://doi.org/10.1177/2053951716666102",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 63,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7c5819a6-26d6-4c6c-89a2-1c28b526cd83",
    "title": "Computational ethnography:  A view from sociology",
    "abstract": "<jats:p> This commentary elaborates on the ideas and projects outlined in this special issue, from a specifically sociological perspective. Much recent work in sociology proposes ‘methods mashups’ of ethnography and digital data/computational tools in different and diverse ways. However, typically, these have taken the form of applying (with or without tweaks) the principles of ethnography to new domains and data types, as if ethnography itself is stable and immutable; that it has a universal set of methodological principles that unify ethnographic practice. Returning to anthropology (whence, arguably, ethnography originally came) is, therefore, a useful way to extend our methodological thinking to (re)consider what ethnography is and how it operates, and from there think more clearly about how it may be effectively combined with digital data/computational tools in an emerging ‘Computational Anthropology’. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211069892",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Phillip Brooker"
      ],
      "url": "https://doi.org/10.1177/20539517211069892",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 37,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1772066a-a09a-431b-a296-4d653e368ccf",
    "title": "Algorhythmic governance: Regulating the ‘heartbeat’ of a city using the Internet of Things",
    "abstract": "To date, research examining the socio-spatial effects of smart city technologies have charted how they are reconfiguring the production of space, spatiality and mobility, and how urban space is governed, but have paid little attention to how the temporality of cities is being reshaped by systems and infrastructure that capture, process and act on real-time data. In this article, we map out the ways in which city-scale Internet of Things infrastructures, and their associated networks of sensors, meters, transponders, actuators and algorithms, are used to measure, monitor and regulate the polymorphic temporal rhythms of urban life. Drawing on Lefebvre, and subsequent research, we employ rhythmanalysis in conjunction with Miyazaki’s notion of ‘algorhythm’ and nascent work on algorithmic governance, to develop a concept of ‘algorhythmic governance’. We then use this framing to make sense of two empirical case studies: a traffic management system and sound monitoring and modelling. Our analysis reveals: (1) how smart city technologies computationally perform rhythmanalysis and undertake rhythm-making that intervenes in space-time processes; (2) distinct forms of algorhythmic governance, varying on the basis of adaptiveness, immediacy of action, and whether humans are in-, on-, or, off-the-loop; (3) and a number of factors that shape how algorhythmic governance works in practice.",
    "metadata": {
      "doi": "10.1177/2053951717742418",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Claudio Coletta",
        "Rob Kitchin"
      ],
      "url": "https://doi.org/10.1177/2053951717742418",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171774241",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 50,
      "is_referenced_by_count": 85,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c2088f2e-dbe2-4d7e-8400-18a71035b643",
    "title": "Scaling down",
    "abstract": "<jats:p> While “scaling up” is a lively topic in network science and Big Data analysis today, my purpose in this essay is to articulate an alternative problem, that of “scaling down,” which I believe will also require increased attention in coming years. “Scaling down” is the problem of how macro-level features of Big Data affect, shape, and evoke lower-level features and processes. I identify four aspects of this problem: the extent to which findings from studies of Facebook and other Big-Data platforms apply to human behavior at the scale of church suppers and department politics where we spend much of our lives; the extent to which the mathematics of scaling might be consistent with behavioral principles, moving beyond a “universal” theory of networks to the study of variation within and between networks; and how a large social field, including its history and culture, shapes the typical representations, interactions, and strategies at local levels in a text or social network. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715602497",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Ronald L Breiger"
      ],
      "url": "https://doi.org/10.1177/2053951715602497",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 26,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "50d6d492-1337-4059-8145-2c09deaee3a8",
    "title": "Clickbait or conspiracy? How Twitter users address the epistemic uncertainty of a controversial preprint",
    "abstract": "<jats:p> Many scientists share preprints on social media platforms to gain attention from academic peers, policy-makers, and journalists. In this study we shed light on an unintended but highly consequential effect of sharing preprints: Their contribution to conspiracy theories. Although the scientific community might quickly dismiss a preprint as insubstantial and ‘clickbaity’, its uncertain epistemic status nevertheless allows conspiracy theorists to mobilize the text as scientific support for their own narratives. To better understand the epistemic politics of preprints on social media platforms, we studied the case of a biomedical preprint, which was shared widely and discussed controversially on Twitter in the wake of the coronavirus disease 2019 pandemic. Using a combination of social network analysis and qualitative content analysis, we compared the structures of engagement with the preprint and the discursive practices of scientists and conspiracy theorists. We found that despite substantial engagement, scientists were unable to dampen the conspiracy theorists’ enthusiasm for the preprint. We further found that members from both groups not only tried to reduce the preprint's epistemic uncertainty but sometimes deliberately maintained it. The maintenance of epistemic uncertainty helped conspiracy theorists to reinforce their group's identity as skeptics and allowed scientists to express concerns with the state of their profession. Our study contributes to research on the intricate relations between scientific knowledge and conspiracy theories online, as well as the role of social media platforms for new genres of scholarly communication. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231180575",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Mareike Bauer",
        "Maximilian Heimstädt",
        "Carlos Franzreb",
        "Sonja Schimmler"
      ],
      "url": "https://doi.org/10.1177/20539517231180575",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 45,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "859b6626-11d7-4ab8-8a12-a95d41ac0cbb",
    "title": "Digital marketing as digital methods: Repurposing Google Ads for controversy mapping",
    "abstract": "<jats:p> Digital advertising is central to the business models and technological affordances of digital platforms, creating marketplaces for user attention. Despite the keen theoretical attention to the commodification of audiences in critical new media and data studies, there has been little exploration of how digital marketing can also be understood as a methodological lens to study both controversies and the practices involved in the commodification of attention around the issues that animate such controversies. Addressing this gap in knowledge by drawing on the digital methods approach, this article proposes repurposing the tools, data and practices of digital marketing – what we coin digital marketing epistemology – as new methodological points of observation in controversy mapping. Focusing empirically on Google Ads, we scrutinize the building blocks of advertising campaigns on the platform and their metrics and measurements. We then offer a set of methodological ‘recipes’ for repurposing the Google Ads platform for controversy mapping and illustrate through a series of data sprints how this can contribute not only to a better understanding of the measurement and valuation practices that are involved in converting attention into a tradable asset but also the role these practices play in the unfolding of techno-social controversies. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231216955",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Òscar Coromina",
        "Alexei Tsinovoi",
        "Anders Kristian Munk"
      ],
      "url": "https://doi.org/10.1177/20539517231216955",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 65,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3ea37827-ca87-486c-866f-338683334b26",
    "title": "Super SDKs: Tracking personal data and platform monopolies in the mobile",
    "abstract": "<jats:p> In this article we address the question ‘what is tracking in the mobile ecosystem’ through a comprehensive overview of the Software Development Kit (SDK). Our research reveals a complex infrastructural role for these technical objects connecting end-user data with app developers, third parties and dominant advertising platforms like Google and Facebook. We present an innovative theoretical framework which we call a data monadology to foreground this interrelationship, predicated on an economic model that exchanges personal data for the infrastructural services used to build applications. Our main contribution is an SDK taxonomy, which renders them more transparent and observable. We categorise SDK services into three main categories: (i) Programmatic AdTech for monetisation; (ii) App Development, for building, maintaining and offering additional artificial intelligence features and (iii) App Extensions which more visibly embed third parties into apps like maps, wallets or other payment services. A major finding of our analysis is the special category of the Super SDK, reserved for platforms like Google and Facebook. Not only do they offer a vast array of services across all three categories, making them indispensable to developers, they are super conduits for personal data and the primary technical means for the expansion of platform monopolisation across the mobile ecosystem. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241231270",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Jennifer Pybus",
        "Mark Coté"
      ],
      "url": "https://doi.org/10.1177/20539517241231270",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 64,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fb019461-9529-477c-8733-3d365815c13a",
    "title": "Friction, snake oil, and weird countries: Cybersecurity systems could deepen global inequality through regional blocking",
    "abstract": "<jats:p> In this moment of rising nationalism worldwide, governments, civil society groups, transnational companies, and web users all complain of increasing regional fragmentation online. While prior work in this area has primarily focused on issues of government censorship and regulatory compliance, we use an inductive and qualitative approach to examine targeted blocking by corporate entities of entire regions motivated by concerns about fraud, abuse, and theft. Through participant-observation at relevant events and intensive interviews with experts, we document the quest by professionals tasked with preserving online security to use new machine-learning based techniques to develop a “fairer” system to determine patterns of “good” and “bad” usage. However, we argue that without understanding the systematic social and political conditions that produce differential behaviors online, these systems may continue to embed unequal treatments, and troublingly may further disguise such discrimination behind more complex and less transparent automated assessment. In order to support this claim, we analyze how current forms of regional blocking incentivize users in blocked regions to behave in ways that are commonly flagged as problematic by dominant security and identification systems. To realize truly global, non-Eurocentric cybersecurity techniques would mean incorporating the ecosystems of service utilization developed by marginalized users rather than reasserting norms of an imagined (Western) user that casts aberrations as suspect. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719835238",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Anne Jonas",
        "Jenna Burrell"
      ],
      "url": "https://doi.org/10.1177/2053951719835238",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 27,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8d010c4f-c577-4ef8-98b6-2364eb1e0247",
    "title": "Reading datasets: Strategies for interpreting the politics of data signification",
    "abstract": "<jats:p> All datasets emerge from and are enmeshed in power-laden semiotic systems. While emerging data ethics curriculum is supporting data science students in identifying data biases and their consequences, critical attention to the cultural histories and vested interests animating data semantics is needed to elucidate the assumptions and political commitments on which data rest, along with the externalities they produce. In this article, I introduce three modes of reading that can be engaged when studying datasets—a denotative reading (extrapolating the literal meaning of values in a dataset), a connotative reading (tracing the socio-political provenance of data semantics), and a deconstructive reading (seeking what gets Othered through data semantics and structure). I then outline how I have taught students to engage these methods when analyzing three datasets in Data and Society—a course designed to cultivate student competency in politically aware data analysis and interpretation. I show how combined, the reading strategies prompt students to grapple with the double binds of perceiving contemporary problems through systems of representation that are always situated, incomplete, and inflected with diverse politics. While I introduce these methods in the context of teaching, I argue that the methods are integral to any data practice in the conclusion. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211029322",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Lindsay Poirier"
      ],
      "url": "https://doi.org/10.1177/20539517211029322",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 54,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8dcef865-82d8-4612-91be-34323c47161a",
    "title": "Algorithmic governance: Developing a research agenda through the power of collective intelligence",
    "abstract": "We are living in an algorithmic age where mathematics and computer science are coming together in powerful new ways to influence, shape and guide our behaviour and the governance of our societies. As these algorithmic governance structures proliferate, it is vital that we ensure their effectiveness and legitimacy. That is, we need to ensure that they are an effective means for achieving a legitimate policy goal that are also procedurally fair, open and unbiased. But how can we ensure that algorithmic governance structures are both? This article shares the results of a collective intelligence workshop that addressed exactly this question. The workshop brought together a multidisciplinary group of scholars to consider (a) barriers to legitimate and effective algorithmic governance and (b) the research methods needed to address the nature and impact of specific barriers. An interactive management workshop technique was used to harness the collective intelligence of this multidisciplinary group. This method enabled participants to produce a framework and research agenda for those who are concerned about algorithmic governance. We outline this research agenda below, providing a detailed map of key research themes, questions and methods that our workshop felt ought to be pursued. This builds upon existing work on research agendas for critical algorithm studies in a unique way through the method of collective intelligence.",
    "metadata": {
      "doi": "10.1177/2053951717726554",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "John Danaher",
        "Michael J Hogan",
        "Chris Noone",
        "Rónán Kennedy",
        "Anthony Behan",
        "Aisling De Paor",
        "Heike Felzmann",
        "Muki Haklay",
        "Su-Ming Khoo",
        "John Morison",
        "Maria Helen Murphy",
        "Niall O'Brolchain",
        "Burkhard Schafer",
        "Kalpana Shankar"
      ],
      "url": "https://doi.org/10.1177/2053951717726554",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171772655",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 36,
      "is_referenced_by_count": 129,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d80dafca-3b95-4046-a0a0-612d1ecff22a",
    "title": "The literary uses of high-dimensional space",
    "abstract": "<jats:p> Debates over “Big Data” shed more heat than light in the humanities, because the term ascribes new importance to statistical methods without explaining how those methods have changed. What we badly need instead is a conversation about the substantive innovations that have made statistical modeling useful for disciplines where, in the past, it truly wasn’t. These innovations are partly technical, but more fundamentally expressed in what Leo Breiman calls a new “culture” of statistical modeling. Where 20th-century methods often required humanists to squeeze our unstructured texts, sounds, or images into some special-purpose data model, new methods can handle unstructured evidence more directly by modeling it in a high-dimensional space. This opens a range of research opportunities that humanists have barely begun to discuss. To date, topic modeling has received most attention, but in the long run, supervised predictive models may be even more important. I sketch their potential by describing how Jordan Sellers and I have begun to model poetic distinction in the long 19th century—revealing an arc of gradual change much longer than received literary histories would lead us to expect. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715602494",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Ted Underwood"
      ],
      "url": "https://doi.org/10.1177/2053951715602494",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 18,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "40813616-b03a-43e6-ae2f-b9e0df18c1c0",
    "title": "Racial formations as data formations",
    "abstract": "<jats:p> This commentary uses Paul Gilroy’s controversial claim that new technoscientific processes are instituting an ‘end to race’ as a provocation to discuss the epistemological transformation of race in algorithmic culture. We situate Gilroy’s provocation within the context of an abolitionist agenda against racial-thinking, underscoring the relationship between his post-race polemic and a post-visual discourse. We then discuss the challenges of studying race within regimes of computation, which rely on structures that are, for the most part, opaque; in particular, modes of classification that operate through proxies and abstractions and that figure racialized bodies not as single, coherent subjects, but as shifting clusters of data. We argue that in this new regime, race emerges as an epiphenomenon of processes of classifying and sorting – what we call ‘racial formations as data formations’. This discussion is significant because it raises new theoretical, methodological and political questions for scholars of media and critical algorithmic studies. It asks: how are we supposed to think, to identify and to confront race and racialisation when they vanish into algorithmic systems that are beyond our perception? What becomes of racial formations in post-visual regimes? </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211046377",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Thao Phan",
        "Scott Wark"
      ],
      "url": "https://doi.org/10.1177/20539517211046377",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 33,
      "is_referenced_by_count": 25,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a6d14071-56c9-40ad-89d5-5ba9dd254345",
    "title": "Interpretation as luxury: Heart patients living with data doubt, hope, and anxiety",
    "abstract": "<jats:p> Personal health technologies such as apps and wearables that generate health and behavior data close to the individual patient are envisioned to enable personalized healthcare - and self-care. And yet, they are consumer devices. Proponents of these devices presuppose that measuring will be helpful, and that data will be meaningful. However, a growing body of research suggests that self-tracking data does not necessarily make sense to users. Drawing together data studies and digital health research, we aim to further research on data ambivalence, a term we use to refer to the ambiguities and uncertainties people experience when interpreting their own data, as well as the critical obligation towards cultivating ethically sound uses and responses to such data in context. We develop the relationship between data, interpretation, and context as a central theoretical and practical problem in the datafication of healthcare. We then show how interpretation and context matter for data ambivalence through an empirical study of heart patients with an implanted advanced pacemaker who were offered a Fitbit wristband for self-tracking as part of a research project. We argue that the hope, anxiety, and doubt connected to the promise and accuracy of data are tempered by the context and purpose of self-tracking, and by individual circumstances. Finally, we link the findings on context-sensitivity in data interpretation to questions about response-ability in cloud-based care infrastructures. We discuss the ethical dilemmas associated with the use of commercial wellness-technologies in healthcare, and with researching such emerging practices. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720924436",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Stine Lomborg",
        "Henriette Langstrup",
        "Tariq Osman Andersen"
      ],
      "url": "https://doi.org/10.1177/2053951720924436",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172092443",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 50,
      "is_referenced_by_count": 37,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "cfc5e92b-bd5d-4111-ade6-e9242d2e03c7",
    "title": "Diversity and neocolonialism in Big Data research: Avoiding extractivism while struggling with paternalism",
    "abstract": "<jats:p> The extractive logic of Big Data-driven technology and knowledge production has raised serious concerns. While most criticism initially focused on the impacts on Western societies, attention is now increasingly turning to the consequences for communities in the Global South. To date, debates have focused on private-sector activities. In this article, we start from the conviction that publicly funded knowledge and technology production must also be scrutinized for their potential neocolonial entanglements. To this end, we analyze the dynamics of collaboration in an European Union-funded research project that collects data for developing a social platform focused on diversity. The project includes pilot sites in China, Denmark, the United Kingdom, India, Italy, Mexico, Mongolia, and Paraguay. We present the experience at four field sites and reflect on the project’s initial conception, our collaboration, challenges, progress, and results. We then analyze the different experiences in comparison. We conclude that while we have succeeded in finding viable strategies to avoid contributing to the dynamics of unilateral data extraction as one side of the neocolonial circle, it has been infinitely more difficult to break through the much more subtle but no less powerful mechanisms of paternalism that we find to be prevalent in data-driven North–South relations. These mechanisms, however, can be identified as the other side of the neocolonial circle. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231206802",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Paula Helm",
        "Amalia de Götzen",
        "Luca Cernuzzi",
        "Alethia Hume",
        "Shyam Diwakar",
        "Salvador Ruiz Correa",
        "Daniel Gatica-Perez"
      ],
      "url": "https://doi.org/10.1177/20539517231206802",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e9302f6c-59ac-47e8-889e-0f7503d8ac54",
    "title": "Erratum",
    "abstract": "",
    "metadata": {
      "doi": "10.1177/20539517211027766",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [],
      "url": "https://doi.org/10.1177/20539517211027766",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "not available"
    }
  },
  {
    "id": "e58bebef-27cc-48d6-ab2e-f2c0625b20a7",
    "title": "The after party: Cynical resignation in Adtech's pivot to privacy",
    "abstract": "<jats:p> Digital advertising and technology companies are resigned to a new privacy imperative. They are bracing for a world where third-party tracking will be restricted by design or by law. Digital resignation typically refers to how companies cultivate a sense of powerlessness about privacy among internet users. Our paper looks through this optic from the other end of the lens: How is the digital advertising industry coping with the increasing salience of privacy? Recent developments have forced companies to implement “privacy-preserving” designs—or at least promise some semblance of privacy. Yet, the industry remains dependent on flows of data and means of identification to enable still-desired targeting, measurement, and optimization. Our paper analyzes this contradiction by looking at systems that aim to replicate existing functionalities while protecting user “privacy.” We call this a form of “cynical resignation” and characterize its key maneuvers as follows: (a) sanitizing surveillance; (b) party-hopping; and (c) sabotage. We argue that this “cynical resignation” to a privacy imperative represents a policy failure. In the absence of decisive interventions into the underlying business models of data capitalism, companies offer techno-solutionism and self-regulations that seem to conform to new laws and norms while reinforcing commitments to data-driven personalization. This may benefit the largest tech companies, since their privileged access to first-party data will make more companies reliant on them, and their computational power will be even more valuable in a world where modeling is used to compensate for the loss of third-party data and traditional methods of personal identification. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231203665",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Lee McGuigan",
        "Sarah Myers West",
        "Ido Sivan-Sevilla",
        "Patrick Parham"
      ],
      "url": "https://doi.org/10.1177/20539517231203665",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 98,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3e0785c4-4135-4847-81dd-418dafdf3233",
    "title": "What do we see when we look at networks: Visual network analysis, relational ambiguity, and force-directed layouts",
    "abstract": "<jats:p> It is increasingly common in natural and social sciences to rely on network visualizations to explore relational datasets and illustrate findings. Such practices have been around long enough to prove that scholars find it useful to project networks in a two-dimensional space and to use their visual qualities as proxies for their topological features. Yet these practices remain based on intuition, and the foundations and limits of this type of exploration are still implicit. To fill this lack of formalization, this paper offers explicit documentation for the kind of visual network analysis encouraged by force-directed layouts. Using the example of a network of Jazz performers, band and record labels extracted from Wikipedia, the paper provides guidelines on how to make networks readable and how to interpret their visual features. It discusses how the inherent ambiguity of network visualizations can be exploited for exploratory data analysis. Acknowledging that vagueness is a feature of many relational datasets in the humanities and social sciences, the paper contends that visual ambiguity, if properly interpreted, can be an asset for the analysis. Finally, we propose two attempts to distinguish the ambiguity inherited from the represented phenomenon from the distortions coming from fitting a multidimensional object in a two-dimensional space. We discuss why these attempts are only partially successful, and we propose further steps towards a metric of spatialization quality. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211018488",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Tommaso Venturini",
        "Mathieu Jacomy",
        "Pablo Jensen"
      ],
      "url": "https://doi.org/10.1177/20539517211018488",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 68,
      "is_referenced_by_count": 28,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "66b84408-2afc-4d57-a49b-92c5d2faa1bf",
    "title": "The ethical dimensions of Google autocomplete",
    "abstract": "What questions should we ask of Google’s Autocomplete suggestions? This article highlights some of the key ethical issues raised by Google’s automated suggestion tool that provides potential queries below a user’s search box. Much of the discourse surrounding Google’s suggestions has been framed through legal cases in which complex issues can become distilled into black-and-white questions of the law. For example, do Google have to remove a particular suggestion and do they have to pay a settlement for damages? This commentary argues that shaping this discourse along primarily legal lines obscures many of these other moral dimensions raised by Google Autocomplete. Building from existing typologies, this commentary first outlines the legal discourse before exploring five additional ethical challenges, each framed around a particular moral question in which all users have a stake. Written in the form of a commentary, the purpose of this article is not to conclusively answer the ethical questions raised, but rather to give an account of why these particular questions are worth debating. Autocomplete’s suggestions are not simply a mirror of what users are typing into Google’s search bar. Google’s official statement is that “Autocomplete is a time-saving but complex feature. It doesn’t simply display the most common queries on a given topic” but “also predict[s] individual words and phrases that are based on both real searches as well as word patterns found across the web” (Google, 2022). Both its underlying methods and associated terminology have changed throughout time, shifting between providing completions, suggestions, and predictions. In doing so, the grounds for potential critique are ever-changing, which means that Google’s approach to Autocomplete deserves significant scrutiny.",
    "metadata": {
      "doi": "10.1177/20539517231156518",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Rosie Graham"
      ],
      "url": "https://doi.org/10.1177/20539517231156518",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 25,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "519430cc-009e-4911-a7d5-730b3a6cab7b",
    "title": "Machine Anthropology: A View from International Relations",
    "abstract": "<jats:p> International relations are made up of thick layers of meaning and big streams of data. How can we capture the nuances and scales of increasingly digitalised world politics, taking advantage of the possibilities that come with ‘big data’ and ‘digital methods’ in our discipline of International Relations (IR)? What is needed, we argue, is a methodological twin-move of making big data thick and thick data big. Taking diplomacy, one of IR's core practices as our case, we illustrate how anthropological and computational approaches can be merged in IR research. We report from our experiences with the project DIPLOFACE: Diplomatic Face-Work between Confidential Negotiations and Public Display, investigating how digital communication technologies influence both the study and conduct of age-old and traditionally analogue practices of inter-state diplomacy. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211063690",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Rebecca Adler-Nissen",
        "Kristin Anabel Eggeling",
        "Patrice Wangen"
      ],
      "url": "https://doi.org/10.1177/20539517211063690",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 31,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "dea091e5-85a5-4b90-b084-3a794f7a0ec9",
    "title": "The visible body and the invisible organization: Information asymmetry and college athletics data",
    "abstract": "<jats:p> Elite athletes are constantly tracked, measured, scored, and sorted to improve their performance. Privacy is sacrificed in the name of improvement. Athletes frequently do not know why particular personal data are collected or to what end. Our interview study of 23 elite US college athletes and 26 staff members reveals that their sports play is governed through information asymmetries. These asymmetries look different for different sports with different levels of investment, different racial and gender makeups, and different performance metrics. As large, data-intensive organizations with highly differentiated subgroups, university athletics are an excellent site for theory building in critical data studies, especially given the most consequential data collected from us, with the greatest effect on our lives, is frequently a product of collective engagement with specific organizational contexts like workplaces and schools. Empirical analysis reveals two key tensions in this data regime: Athletes in high-status sports, more likely to be Black men, have relatively less freedom to see or dispute their personal data, while athletes in general are more comfortable sharing personal data with people further away from them. We build from these findings to develop a theory of collective informational harm in bounded institutional settings such as the workplace. The quantified organization, as we term it, is concerned not with monitoring individuals but building data collectives through processes of category creation and managerial data relations of coercion and consent. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231179197",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Daniel Greene",
        "Nathan Beard",
        "Tamara Clegg",
        "Erianne Weight"
      ],
      "url": "https://doi.org/10.1177/20539517231179197",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 40,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c51d752d-25ff-4387-8119-1b149c49d85d",
    "title": "Toxicity and verbal aggression on social media: Polarized discourse on wearing face masks during the COVID-19 pandemic",
    "abstract": "<jats:p> Medical and public health professionals recommend wearing face masks to combat the spread of the coronavirus disease of 2019 (COVID-19). While the majority of people in the United States support wearing face masks as an effective tool to combat COVID-19, a smaller percentage declared the recommendation by public health agencies as a government imposition and an infringement on personal liberty. Social media play a significant role in amplifying public health issues, whereby a minority against the imposition can speak loudly, perhaps using tactics of verbal aggression taking the form of toxic language. We investigated the role that toxicity plays in the online discourse around wearing face masks. Overall, we found tweets including anti-mask hashtags were significantly more likely to use toxic language, while tweets with pro-mask hashtags were somewhat less toxic with the exception of #WearADamnMask. We conclude that the tensions between these two positions raise doubt and uncertainty around the issue, which make it difficult for health communicators to break through the clutter in order to combat the infodemic. Public health agencies and other governmental institutions should monitor toxicity trends on social media in order to better ascertain prevailing sentiment toward their recommendations and then apply these data-driven insights to refine and adapt their risk communication messaging toward mask wearing, vaccine uptake, and other interventions. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211023533",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Paola Pascual-Ferrá",
        "Neil Alperstein",
        "Daniel J Barnett",
        "Rajiv N Rimal"
      ],
      "url": "https://doi.org/10.1177/20539517211023533",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 68,
      "is_referenced_by_count": 48,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fbb98341-3186-4d72-bd9e-949cf720cafd",
    "title": "Black boxes, not green: Mythologizing artificial intelligence and omitting the environment",
    "abstract": "<jats:p> We are repeatedly told that AI will help us to solve some of the world's biggest challenges, from treating chronic diseases and reducing fatality rates in traffic accidents to fighting climate change and anticipating cybersecurity threats. However, the article contends that public discourse on AI systematically avoids considering AI’s environmental costs. </jats:p><jats:p> Artificial Intelligence- Brevini argues- runs on technology, machines, and infrastructures that deplete scarce resources in their production, consumption, and disposal, thus increasing the amounts of energy in their use, and exacerbate problems of waste and pollution. It also relies on data centers, that demands impressive amounts of energy to compute, analyse, categorize. If we want to stand a chance at tackling the Climate Emergency, then we have to stop avoiding addressing the environmental problems generated by AI. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720935141",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Benedetta Brevini"
      ],
      "url": "https://doi.org/10.1177/2053951720935141",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 38,
      "is_referenced_by_count": 65,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9108af44-4a01-4fd4-97a8-2b4b12f61f42",
    "title": "Data citizenship: Quantifying structural racism in COVID-19 and beyond",
    "abstract": "<jats:p>Data-driven public health policies were widely implemented to mitigate the uneven impact of COVID-19. In the United States, evidence-based interventions are often employed in “racial equity” initiatives to provide calculable representations of racial disparities. However, disparities in working or living conditions, germane to public health but outside the conventional scope of epidemiology, are seldom measured or addressed. What is the effect of defining racial equity with quantitative health outcomes? Drawing on qualitative analysis of 175 interviews with experts and residents in Chicago during the emergence of COVID-19, we find that these policies link the distribution of public resources to effective participation in state projects of data generation. Bringing together theories of quantification and biosocial citizenship, we argue that a form of data citizenship has emerged where public resources are allocated based on quantitative metrics and the variations they depict. Data citizenship is characterized by at least two mechanisms for governing with statistics. Data fixes produce better numbers through technical adjustments in data collection or analysis based on expert assumptions or expectations. Data drag delays distribution of public relief until numbers are compiled to demonstrate and specify needs or deservingness. This paper challenges the use of racial statistics as a salve for structural racism and illustrates how statistical data can exacerbate racial disparities by promising equity.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231213821",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Cal Lee Garrett",
        "Claire Laurier Decoteau"
      ],
      "url": "https://doi.org/10.1177/20539517231213821",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 61,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a7a93e2c-df22-402d-ae2d-aa06c7e0551f",
    "title": "Digital companion species and eating data: Implications for theorising digital data–human assemblages",
    "abstract": "<jats:p> This commentary is an attempt to begin to identify and think through some of the ways in which sociocultural theory may contribute to understandings of the relationship between humans and digital data. I develop an argument that rests largely on the work of two scholars in the field of science and technology studies: Donna Haraway and Annemarie Mol. Both authors emphasised materiality and multiple ontologies in their writing. I argue that these concepts have much to offer critical data studies. I employ the tropes of companion species, drawn from Haraway, and eating data, from Mol, and demonstrate how these may be employed to theorise digital data–human assemblages. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715619947",
      "type": "journal-article",
      "published": [
        2016,
        6,
        1
      ],
      "authors": [
        "Deborah Lupton"
      ],
      "url": "https://doi.org/10.1177/2053951715619947",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 25,
      "is_referenced_by_count": 63,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7f2c418c-2f1f-47df-85a8-6384b00f5567",
    "title": "Data extraction in dockless bikeshare: An analysis from users’ perspective",
    "abstract": "<jats:p> With the popularisation of dockless bicycle sharing in cities around the planet in the recent years, studies have increasingly focused on its intrusion to privacy through the extraction and monetisation of users’ personal data and travel trajectories. This raises the concern of surveillance capitalism that is often embedded within urban mobility platforms. While some research has analysed the business models of dockless bikeshare and identified data extraction as their core value proposition, how bikeshare users themselves perceive and interact with data extraction has so far remained unexplored. Using survey data and interview data with dockless bike users in Shenzhen, China, this study explores users’ perspectives on data extraction in dockless bikeshare with both quantitative and qualitative methods. The result indicate that socio-demographic backgrounds, mobility patterns and location of residence have significant impacts on users’ attitudes to sharing data with dockless bike operators. In addition, a considerable portion of bikeshare users in Shenzhen on the one hand normalise data extraction while on the other problematise receiving financial compensation for their data. Users’ acquiescence to data extraction is likely to sustain and reinforce the extractive model of surveillance capitalism in dockless bikeshare. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241299724",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Zhaoqi Zhou"
      ],
      "url": "https://doi.org/10.1177/20539517241299724",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 89,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e0d1b974-c2ec-4f26-a920-6e465a6b900d",
    "title": "Developing data capability with non-profit organisations using participatory methods",
    "abstract": "<jats:p> In this paper, we explore the methodologies underpinning two participatory research collaborations with Australian non-profit organisations that aimed to build data capability and social benefit in data use. We suggest that studying and intervening in data practices in situ, that is, in organisational data settings expands opportunities for improving the social value of data. These situated and collaborative approaches not only address the ‘expertise lag’ for non-profits but also help to realign the potential social value of organisational data use. We explore the relationship between data literacy, data expertise and data capability to test the idea that collaborative work with non-profit organisations can be a practical step towards addressing data equity and generating data-driven social outcomes. Rather than adopting approaches to data literacy that focus on individuals – or ideal ‘data citizens’ – we target the organisation-wide data settings, goals and practices of the non-profit sector. We conclude that participatory methods can embed social value-generating data capability where it can be sustained at an organisational level, aligning with community needs to promote collaborative data action. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221099882",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Anthony McCosker",
        "Xiaofang Yao",
        "Kath Albury",
        "Alexia Maddox",
        "Jane Farmer",
        "Julia Stoyanovich"
      ],
      "url": "https://doi.org/10.1177/20539517221099882",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 59,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "69188aba-44de-460b-bb58-b1aa77f64d81",
    "title": "Emotional artificial intelligence in children’s toys and devices: Ethics, governance and practical remedies",
    "abstract": "<jats:p> This article examines the social acceptability and governance of emotional artificial intelligence (emotional AI) in children’s toys and other child-oriented devices. To explore this, it conducts interviews with stakeholders with a professional interest in emotional AI, toys, children and policy to consider implications of the usage of emotional AI in children’s toys and services. It also conducts a demographically representative UK national survey to ascertain parental perspectives on networked toys that utilise data about emotions. The article highlights disquiet about the evolution of generational unfairness, that encompasses injustices regarding the datafication of childhood, manipulation, parental vulnerability, synthetic personalities, child and parental media literacy, and need for improved governance. It concludes with practical recommendations for regulators and the toy industry. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951721994877",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Andrew McStay",
        "Gilad Rosner"
      ],
      "url": "https://doi.org/10.1177/2053951721994877",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 35,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "52148fd4-9b48-497a-b423-02ab6b5b3a1d",
    "title": "Just good enough data: Figuring data citizenships through air pollution sensing and data stories",
    "abstract": "<jats:p> Citizen sensing, or the use of low-cost and accessible digital technologies to monitor environments, has contributed to new types of environmental data and data practices. Through a discussion of participatory research into air pollution sensing with residents of northeastern Pennsylvania concerned about the effects of hydraulic fracturing, we examine how new technologies for generating environmental data also give rise to new problems for analysing and making sense of citizen-gathered data. After first outlining the citizen data practices we collaboratively developed with residents for monitoring air quality, we then describe the data stories that we created along with citizens as a method and technique for composing data. We further mobilise the concept of ‘just good enough data’ to discuss the ways in which citizen data gives rise to alternative ways of creating, valuing and interpreting datasets. We specifically consider how environmental data raises different concerns and possibilities in relation to Big Data, which can be distinct from security or social media studies. We then suggest ways in which citizen datasets could generate different practices and interpretive insights that go beyond the usual uses of environmental data for regulation, compliance and modelling to generate expanded data citizenships. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716679677",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Jennifer Gabrys",
        "Helen Pritchard",
        "Benjamin Barratt"
      ],
      "url": "https://doi.org/10.1177/2053951716679677",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 47,
      "is_referenced_by_count": 132,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c9ece9a5-7a44-4878-93b0-6e770b961bf1",
    "title": "The great Transformer: Examining the role of large language models in the political economy of AI",
    "abstract": "<jats:p> In recent years, AI research has become more and more computationally demanding. In natural language processing (NLP), this tendency is reflected in the emergence of large language models (LLMs) like GPT-3. These powerful neural network-based models can be used for a range of NLP tasks and their language generation capacities have become so sophisticated that it can be very difficult to distinguish their outputs from human language. LLMs have raised concerns over their demonstrable biases, heavy environmental footprints, and future social ramifications. In December 2020, critical research on LLMs led Google to fire Timnit Gebru, co-lead of the company’s AI Ethics team, which sparked a major public controversy around LLMs and the growing corporate influence over AI research. This article explores the role LLMs play in the political economy of AI as infrastructural components for AI research and development. Retracing the technical developments that have led to the emergence of LLMs, we point out how they are intertwined with the business model of big tech companies and further shift power relations in their favour. This becomes visible through the Transformer, which is the underlying architecture of most LLMs today and started the race for ever bigger models when it was introduced by Google in 2017. Using the example of GPT-3, we shed light on recent corporate efforts to commodify LLMs through paid API access and exclusive licensing, raising questions around monopolization and dependency in a field that is increasingly divided by access to large-scale computing power. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211047734",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Dieuwertje Luitse",
        "Wiebke Denkena"
      ],
      "url": "https://doi.org/10.1177/20539517211047734",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 78,
      "is_referenced_by_count": 84,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f76855d2-4229-4662-96f3-6529ae92d0bd",
    "title": "Computational grounded theory revisited: From computer-led to computer-assisted text analysis",
    "abstract": "<jats:p> The size and variation in both meaning-making and populations that characterize much contemporary text data demand research processes that support both discovery, interpretation and measurement. We assess one dominant strategy within the social sciences that takes a computer-led approach to text analysis. The approach is coined computational grounded theory. This strategy, we argue, relies on a set of unwarranted assumptions, namely, that unsupervised models return natural clusters of meaning, that the researcher can understand text with limited immersion and that indirect validation is sufficient for ensuring unbiased and precise measurement. In response to this criticism, we develop a framework that is computer assisted. We argue that our reformulation of computational grounded theory better aligns with the principles within grounded theory, anthropological theory generation and ethnography. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221080146",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Hjalmar Bang Carlsen",
        "Snorre Ralund"
      ],
      "url": "https://doi.org/10.1177/20539517221080146",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 32,
      "is_referenced_by_count": 20,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "cb5bd758-c62a-40c9-9428-674d005d9696",
    "title": "Smart forests and data practices: From the Internet of Trees to planetary governance",
    "abstract": "Environments are increasingly becoming technologized sites of data production. From smart cities to smart forests, digital networks are analyzing and joining up environmental processes. This commentary focuses on one such understudied smart environment, smart forests, as emerging digital infrastructures that are materializing to manage and mitigate environmental change. How does the digitalization of forests not only change understandings of these environments but also generate different practices and ontologies for addressing environmental change? I first analyze smart forests within the expanding area of smart environments, and then discuss five digital practices that characterize smart forests. Based on this analysis, I suggest that forests are not only becoming highly digital environments but also that forests are transforming into technologies for managing environmental change. Smart forest interventions therefore expand the scope of what could count as a technology, especially in the context of data-oriented planetary governance.",
    "metadata": {
      "doi": "10.1177/2053951720904871",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Jennifer Gabrys"
      ],
      "url": "https://doi.org/10.1177/2053951720904871",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172090487",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 74,
      "is_referenced_by_count": 134,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e9893c1d-1083-40bf-a3f8-9631de2f28aa",
    "title": "Manipulate to empower: Hyper-relevance and the contradictions of marketing in the age of surveillance capitalism",
    "abstract": "In this article, we explore how digital marketers think about marketing in the age of Big Data surveillance, automatic computational analyses, and algorithmic shaping of choice contexts. Our starting point is a contradiction at the heart of digital marketing namely that digital marketing brings about unprecedented levels of consumer empowerment and autonomy and total control over and manipulation of consumer decision-making. We argue that this contradiction of digital marketing is resolved via the notion of relevance, which represents what Fredric Jameson calls a symbolic act. The notion of the symbolic act lets us see the centering of relevance as a creative act of digital marketers who undertake to symbolically resolve a contradiction that cannot otherwise be resolved. Specifically, we suggest that relevance allows marketers to believe that in the age of surveillance capitalism, the manipulation of choice contexts and decision-making is the same as consumer empowerment. Put differently, relevance is the moment when marketing manipulation disappears and all that is left is the empowered consumer. To create relevant manipulations that are experienced as empowering by the consumer requires always-on surveillance, massive analyses of consumer data and hyper-targeted responses, in short, a persistent marketing presence. The vision of digital marketing is therefore a fascinating one: marketing disappears at precisely the moment when it extends throughout the life without limit.",
    "metadata": {
      "doi": "10.1177/2053951720904112",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Aron Darmody",
        "Detlev Zwick"
      ],
      "url": "https://doi.org/10.1177/2053951720904112",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172090411",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 67,
      "is_referenced_by_count": 74,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9d9aed2d-b8f8-4c26-bf87-701cdaa1725b",
    "title": "The trainer, the verifier, the imitator: Three ways in which human platform workers support artificial intelligence",
    "abstract": "<jats:p>This paper sheds light on the role of digital platform labour in the development of today’s artificial intelligence, predicated on data-intensive machine learning algorithms. Focus is on the specific ways in which outsourcing of data tasks to myriad ‘micro-workers’, recruited and managed through specialized platforms, powers virtual assistants, self-driving vehicles and connected objects. Using qualitative data from multiple sources, we show that micro-work performs a variety of functions, between three poles that we label, respectively, ‘artificial intelligence preparation’, ‘artificial intelligence verification’ and ‘artificial intelligence impersonation’. Because of the wide scope of application of micro-work, it is a structural component of contemporary artificial intelligence production processes – not an ephemeral form of support that may vanish once the technology reaches maturity stage. Through the lens of micro-work, we prefigure the policy implications of a future in which data technologies do not replace human workforce but imply its marginalization and precariousness.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720919776",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Paola Tubaro",
        "Antonio A Casilli",
        "Marion Coville"
      ],
      "url": "https://doi.org/10.1177/2053951720919776",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172091977",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 29,
      "is_referenced_by_count": 103,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0ddee319-4a7f-469b-b930-ad44516aeabe",
    "title": "What is data justice? The case for connecting digital rights and freedoms globally",
    "abstract": "The increasing availability of digital data reflecting economic and human development, and in particular the availability of data emitted as a by-product of people’s use of technological devices and services, has both political and practical implications for the way people are seen and treated by the state and by the private sector. Yet the data revolution is so far primarily a technical one: the power of data to sort, categorise and intervene has not yet been explicitly connected to a social justice agenda by the agencies and authorities involved. Meanwhile, although data-driven discrimination is advancing at a similar pace to data processing technologies, awareness and mechanisms for combating it are not. This paper posits that just as an idea of justice is needed in order to establish the rule of law, an idea of data justice – fairness in the way people are made visible, represented and treated as a result of their production of digital data – is necessary to determine ethical paths through a datafying world. Bringing together the emerging scholarly perspectives on this topic, I propose three pillars as the basis of a notion of international data justice: (in)visibility, (dis)engagement with technology and antidiscrimination. These pillars integrate positive with negative rights and freedoms, and by doing so challenge both the basis of current data protection regulations and the growing assumption that being visible through the data we emit is part of the contemporary social contract.",
    "metadata": {
      "doi": "10.1177/2053951717736335",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Linnet Taylor"
      ],
      "url": "https://doi.org/10.1177/2053951717736335",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171773633",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 38,
      "is_referenced_by_count": 346,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "472e3170-ad9d-48ae-92f5-2253d6d737f5",
    "title": "Platform affordances and data practices: The value of dispute on Wikipedia",
    "abstract": "<jats:p> In this paper we introduce the device perspective as a methodological contribution to platform studies. Through an engagement with debates about the notion of affordances, which focus on the relation between the technical and the social, we put forward an approach to study the production of data within platforms by engaging with the material properties of platforms as well as their interpretation and deployment by various types of users. As a case in point, we study how the affordances of Wikipedia are deployed in the production of encyclopedic knowledge and how this can be used to study controversies. The analysis shows how Wikipedia affords unstable encyclopedic knowledge by having mechanisms in place that suggest the continuous (re)negotiation of existing knowledge. We furthermore showcase the use of our open-source software, Contropedia, which can be utilized to study knowledge production on Wikipedia. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716653418",
      "type": "journal-article",
      "published": [
        2016,
        6
      ],
      "authors": [
        "Esther Weltevrede",
        "Erik Borra"
      ],
      "url": "https://doi.org/10.1177/2053951716653418",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 69,
      "is_referenced_by_count": 40,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "af1c5337-ec3e-444b-a69d-8c881bf77f71",
    "title": "Where are human subjects in Big Data research? The emerging ethics divide",
    "abstract": "<jats:p> There are growing discontinuities between the research practices of data science and established tools of research ethics regulation. Some of the core commitments of existing research ethics regulations, such as the distinction between research and practice, cannot be cleanly exported from biomedical research to data science research. Such discontinuities have led some data science practitioners and researchers to move toward rejecting ethics regulations outright. These shifts occur at the same time as a proposal for major revisions to the Common Rule—the primary regulation governing human-subjects research in the USA—is under consideration for the first time in decades. We contextualize these revisions in long-running complaints about regulation of social science research and argue data science should be understood as continuous with social sciences in this regard. The proposed regulations are more flexible and scalable to the methods of non-biomedical research, yet problematically largely exclude data science methods from human-subjects regulation, particularly uses of public datasets. The ethical frameworks for Big Data research are highly contested and in flux, and the potential harms of data science research are unpredictable. We examine several contentious cases of research harms in data science, including the 2014 Facebook emotional contagion study and the 2016 use of geographical data techniques to identify the pseudonymous artist Banksy. To address disputes about application of human-subjects research ethics in data science, critical data studies should offer a historically nuanced theory of “data subjectivity” responsive to the epistemic methods, harms and benefits of data science and commerce. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716650211",
      "type": "journal-article",
      "published": [
        2016,
        6
      ],
      "authors": [
        "Jacob Metcalf",
        "Kate Crawford"
      ],
      "url": "https://doi.org/10.1177/2053951716650211",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 80,
      "is_referenced_by_count": 253,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f8012579-6959-478a-9718-7e8962c660f3",
    "title": "Critical data studies: An introduction",
    "abstract": "<jats:p> Critical Data Studies (CDS) explore the unique cultural, ethical, and critical challenges posed by Big Data. Rather than treat Big Data as only scientifically empirical and therefore largely neutral phenomena, CDS advocates the view that Big Data should be seen as always-already constituted within wider data assemblages. Assemblages is a concept that helps capture the multitude of ways that already-composed data structures inflect and interact with society, its organization and functioning, and the resulting impact on individuals’ daily lives. CDS questions the many assumptions about Big Data that permeate contemporary literature on information and society by locating instances where Big Data may be naively taken to denote objective and transparent informational entities. In this introduction to the Big Data &amp; Society CDS special theme, we briefly describe CDS work, its orientations, and principles. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716674238",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Andrew Iliadis",
        "Federica Russo"
      ],
      "url": "https://doi.org/10.1177/2053951716674238",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 51,
      "is_referenced_by_count": 245,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5edac19d-4bbe-4a45-8fd8-70848e8dfd86",
    "title": "Official statistics and Big Data",
    "abstract": "<jats:p> The rise of Big Data changes the context in which organisations producing official statistics operate. Big Data provides opportunities, but in order to make optimal use of Big Data, a number of challenges have to be addressed. This stimulates increased collaboration between National Statistical Institutes, Big Data holders, businesses and universities. In time, this may lead to a shift in the role of statistical institutes in the provision of high-quality and impartial statistical information to society. In this paper, the changes in context, the opportunities, the challenges and the way to collaborate are addressed. The collaboration between the various stakeholders will involve each partner building on and contributing different strengths. For national statistical offices, traditional strengths include, on the one hand, the ability to collect data and combine data sources with statistical products and, on the other hand, their focus on quality, transparency and sound methodology. In the Big Data era of competing and multiplying data sources, they continue to have a unique knowledge of official statistical production methods. And their impartiality and respect for privacy as enshrined in law uniquely position them as a trusted third party. Based on this, they may advise on the quality and validity of information of various sources. By thus positioning themselves, they will be able to play their role as key information providers in a changing society. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714538417",
      "type": "journal-article",
      "published": [
        2014,
        4,
        1
      ],
      "authors": [
        "Peter Struijs",
        "Barteld Braaksma",
        "Piet JH Daas"
      ],
      "url": "https://doi.org/10.1177/2053951714538417",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 13,
      "is_referenced_by_count": 68,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f334b74c-a50b-4dac-b41f-1ebcc107842c",
    "title": "How the machine ‘thinks’: Understanding opacity in machine learning algorithms",
    "abstract": "<jats:p> This article considers the issue of opacity as a problem for socially consequential mechanisms of classification and ranking, such as spam filters, credit card fraud detection, search engines, news trends, market segmentation and advertising, insurance or loan qualification, and credit scoring. These mechanisms of classification all frequently rely on computational algorithms, and in many cases on machine learning algorithms to do this work. In this article, I draw a distinction between three forms of opacity: (1) opacity as intentional corporate or state secrecy, (2) opacity as technical illiteracy, and (3) an opacity that arises from the characteristics of machine learning algorithms and the scale required to apply them usefully. The analysis in this article gets inside the algorithms themselves. I cite existing literatures in computer science, known industry practices (as they are publicly presented), and do some testing and manipulation of code as a form of lightweight code audit. I argue that recognizing the distinct forms of opacity that may be coming into play in a given application is a key to determining which of a variety of technical and non-technical solutions could help to prevent harm. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715622512",
      "type": "journal-article",
      "published": [
        2016,
        6,
        1
      ],
      "authors": [
        "Jenna Burrell"
      ],
      "url": "https://doi.org/10.1177/2053951715622512",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 31,
      "is_referenced_by_count": 1330,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2bd79123-66eb-4f93-b694-49f6448a4bcb",
    "title": "Known or knowing publics? Social media data mining and the question of public agency",
    "abstract": "<jats:p> New methods to analyse social media data provide a powerful way to know publics and capture what they say and do. At the same time, access to these methods is uneven, with corporations and governments tending to have best access to relevant data and analytics tools. Critics raise a number of concerns about the implications dominant uses of data mining and analytics may have for the public: they result in less privacy, more surveillance and social discrimination, and they provide new ways of controlling how publics come to be represented and so understood. In this paper, we consider if a different relationship between the public and data mining might be established, one in which publics might be said to have greater agency and reflexivity vis-à-vis data power. Drawing on growing calls for alternative data regimes and practices, we argue that to enable this different relationship, data mining and analytics need to be democratised in three ways: they should be subject to greater public supervision and regulation, available and accessible to all, and used to create not simply known but reflexive, active and knowing publics. We therefore imagine conditions in which data mining is not just used as a way to know publics, but can become a means for publics to know themselves. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715611145",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Helen Kennedy",
        "Giles Moss"
      ],
      "url": "https://doi.org/10.1177/2053951715611145",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 57,
      "is_referenced_by_count": 89,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "eb6c8453-59a2-4f5b-b16d-a6103442d27e",
    "title": "Blockchain imperialism in the Pacific",
    "abstract": "<jats:p> The rise of blockchain as a techno-solution in the development sector underscores the critical imbalances of data power under ‘computational capitalism’ ( Beller, 2018 ). This article will consider the political economy of techno-solutionist and blockchain discourses in the developing world, using as its object of study blockchain projects in Pacific Island nations. Backed by US State Department soft power initiatives such as Tech Camp, these projects inculcate tech-driven notions of economic and political development, or ICT4D, while opening up new terrains for data accumulation and platform control. Blockchain developers in search of proof of concept have found the development sector a fecund space for tech experimentation as they leverage a desire for tech-development and exploit regulatory weakness. The material implications of blockchain projects and discourse have been to create governance solutions which bypass the developing world state as a largely corrupting intermediary. In the Pacific, this has meant blockchain supply-chain management systems, proprietary financial innovation in humanitarian relief and an Asian Development Bank project to manage indigenous Fijian lands exclusively on the blockchain. In all these instances, discourses of solutionism, innovation and data empowerment have been deployed in aid of blockchain cartographies of control. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720985249",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Olivier Jutel"
      ],
      "url": "https://doi.org/10.1177/2053951720985249",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 85,
      "is_referenced_by_count": 32,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ce9d9545-6542-4843-a7ef-1ff9a6741f1a",
    "title": "Challenging algorithmic profiling: The limits of data protection and anti-discrimination in responding to emergent discrimination",
    "abstract": "<jats:p> The potential for biases being built into algorithms has been known for some time (e.g., Friedman and Nissenbaum, 1996), yet literature has only recently demonstrated the ways algorithmic profiling can result in social sorting and harm marginalised groups (e.g., Browne, 2015; Eubanks, 2018; Noble, 2018). We contend that with increased algorithmic complexity, biases will become more sophisticated and difficult to identify, control for, or contest. Our argument has four steps: first, we show how harnessing algorithms means that data gathered at a particular place and time relating to specific persons, can be used to build group models applied in different contexts to different persons. Thus, privacy and data protection rights, with their focus on individuals (Coll, 2014; Parsons, 2015), do not protect from the discriminatory potential of algorithmic profiling. Second, we explore the idea that anti-discrimination regulation may be more promising, but acknowledge limitations. Third, we argue that in order to harness anti-discrimination regulation, it needs to confront emergent forms of discrimination or risk creating new invisibilities, including invisibility from existing safeguards. Finally, we outline suggestions to address emergent forms of discrimination and exclusionary invisibilities via intersectional and post-colonial analysis. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719895805",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Monique Mann",
        "Tobias Matzner"
      ],
      "url": "https://doi.org/10.1177/2053951719895805",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171989580",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 48,
      "is_referenced_by_count": 62,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "df5ee39c-bb00-4fc7-872e-5b71523ccbf3",
    "title": "Democratic governance in an age of datafication: Lessons from mapping government discourses and practices",
    "abstract": "<jats:p> There is an abundance of enthusiasm and optimism about how governments at all levels can make use of big data, algorithms and artificial intelligence. There is also growing concern about the risks that come with these new systems. This article makes the case for greater government transparency and accountability about uses of big data through a Government of Canada qualitative research case study. Adapting a method from critical cartographers, I employ counter-mapping to map government big data practices and internal discussions of risk and challenge. I do so by drawing on interviews and freedom of information requests. The analysis reveals that there are more concerns and risks than often publicly discussed and that there are significant areas of silence that need greater attention. The article underlines the need for our democratic systems to respond to our new datafied contexts by ensuring that our institutions make changes to better protect citizen rights, uphold democratic principles and ensure means for citizen intervention. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718809145",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Joanna Redden"
      ],
      "url": "https://doi.org/10.1177/2053951718809145",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 81,
      "is_referenced_by_count": 44,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4a8f2ac0-30d1-4b62-a89a-d810f242e5b3",
    "title": "The perils of ‘tech for good’ lie in its politics of helping",
    "abstract": "<jats:p>Vexing political questions of power, inequality and coloniality permeate the tech sector and its growing use of global ‘virtual’ assembly lines that see them penetrate even refugee camps in efforts to extract value. As a response, tech companies have been expanding non-commercial activities within a presumed framework of humanitarianism, in part, trying to outweigh the negative implications of unjust business practices often characterised by third-party avoidance of responsibility. This commentary focuses on tech companies’ engagement with people in the Global South – not as recipients of tech beneficence – but as labourers who make tech possible. First, we document why companies are brought into humanitarian crises, and then we briefly chart examples of the practices of tech companies in the Global South. Then, we argue that ‘tech for good’, often presumed as altruistic, instead reproduces an expansive history of questionable corporate social responsibility efforts that sustain inequalities more than assuaging them. We conclude by reflecting on the impact of commodifying compassion for humanitarian helping and argue that tech companies should stop trying to ‘help’ through self-perceived altruistic activities. Instead, corporations should focus on remaking their core business practices in an image of justice, protection, and equal value creation, particularly in contexts characterised by vulnerability.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241267718",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Lisa Ann Richey",
        "Adam Moe Fejerskov"
      ],
      "url": "https://doi.org/10.1177/20539517241267718",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 45,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "446bd170-1a6a-49e4-a9a4-e3e03b183050",
    "title": "Lost in a random forest: Using Big Data to study rare events",
    "abstract": "<jats:p> Sudden, broad-scale shifts in public opinion about social problems are relatively rare. Until recently, social scientists were forced to conduct post-hoc case studies of such unusual events that ignore the broader universe of possible shifts in public opinion that do not materialize. The vast amount of data that has recently become available via social media sites such as Facebook and Twitter—as well as the mass-digitization of qualitative archives provide an unprecedented opportunity for scholars to avoid such selection on the dependent variable. Yet the sheer scale of these new data creates a new set of methodological challenges. Conventional linear models, for example, minimize the influence of rare events as “outliers”—especially within analyses of large samples. While more advanced regression models exist to analyze outliers, they suffer from an even more daunting challenge: equifinality, or the likelihood that rare events may occur via different causal pathways. I discuss a variety of possible solutions to these problems—including recent advances in fuzzy set theory and machine learning—but ultimately advocate an ecumenical approach that combines multiple techniques in iterative fashion. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715604333",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Christopher A Bail"
      ],
      "url": "https://doi.org/10.1177/2053951715604333",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 19,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7baed0a5-4577-4f7f-aa8c-2c28908b7e9c",
    "title": "Big Data and the danger of being precisely inaccurate",
    "abstract": "<jats:p> Social scientists and data analysts are increasingly making use of Big Data in their analyses. These data sets are often “found data” arising from purely observational sources rather than data derived under strict rules of a statistically designed experiment. However, since these large data sets easily meet the sample size requirements of most statistical procedures, they give analysts a false sense of security as they proceed to focus on employing traditional statistical methods. We explain how most analyses performed on Big Data today lead to “precisely inaccurate” results that hide biases in the data but are easily overlooked due to the enhanced significance of the results created by the data size. Before any analyses are performed on large data sets, we recommend employing a simple data segmentation technique to control for some major components of observational data biases. These segments will help to improve the accuracy of the results. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715602495",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Daniel A McFarland",
        "H Richard McFarland"
      ],
      "url": "https://doi.org/10.1177/2053951715602495",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 13,
      "is_referenced_by_count": 45,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a6d4077b-3d73-43cf-a491-e970aa7cbc8a",
    "title": "Que(e)rying artificial intelligence use for infectious disease surveillance: The need for a reparative algorithmic praxis",
    "abstract": "<jats:p>The increasing likelihood of pandemics highlights the need for superior tools at our disposal. By robustly and efficiently analyzing vast datasets, artificial intelligence (AI) has the potential to help decision-makers better respond to, manage, and even avert infectious disease outbreaks. However, these systems could also stigmatize, discriminate, exclude, exploit, and/or otherwise oppress vulnerable populations. In doing so, they could amplify allocative and representational harms. Given the possible far-reaching consequences, critical ethical reflection and oversight are essential. Such reflection would be incomplete without considering the impacts on queer people. From HIV/AIDS to COVID-19, outbreaks have disproportionately affected sexual and gender minorities (SGMs), reflecting a long history of structural oppression and injustices. AI could further exacerbate inequalities—like anti-queer bias—particularly amid the omission of marginalized and minoritized perspectives from algorithmic fairness efforts. Adopting an Intersectional, reparative approach, this paper que(e)ries the use of AI for infectious disease surveillance purposes. Placing this technology within patterns of power, privilege, marginalization, and disadvantage, it interrogates how to achieve algorithmic justice for SGMs. It proposes concrete steps towards a reparative algorithmic praxis, including: (1) exploring how these systems reproduce inequalities, (2) centering sexual and gender diversity to disrupt problematic epistemic positions, and (3) combating opacity through participatory governance mechanisms. This work is necessary to understand how AI systems reproduce major health disparities and hold them accountable. By contemplating how to begin redressing harms, it offers a starting point for further deliberation and action towards inclusive, justice-oriented algorithmic systems in practice. I anticipate these lessons being deeply transferrable across contexts.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241289440",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Elise E. Racine"
      ],
      "url": "https://doi.org/10.1177/20539517241289440",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 28,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0a47d35f-00ae-454a-af59-276fd276d70e",
    "title": "Click here to consent forever: Expiry dates for informed consent",
    "abstract": "<jats:p> The legal basis for processing personal data and some other types of Big Data is often the informed consent of the data subject involved. Many data controllers, such as social network sites, offer terms and conditions, privacy policies or similar documents to which a user can consent when registering as a user. There are many issues with such informed consent: people get too many consent requests to read everything, policy documents are often very long and difficult to understand and users feel they do not have a real choice anyway. Furthermore, in the context of Big Data refusing consent may not prevent predicting missing data. Finally, consent is usually asked for when registering, but rarely is consent renewed. As a result, consenting once often implies consent forever. At the same time, given the rapid changes in Big Data and data analysis, consent may easily get outdated (when earlier consent no longer reflects a user’s preferences). This paper suggests expiry dates for consent, not to settle questions, but to put them on the table as a start for further discussion on this topic. Although such expiry dates may not solve all the issues of informed consent, they may be a useful tool in some situations. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715624935",
      "type": "journal-article",
      "published": [
        2016,
        6,
        1
      ],
      "authors": [
        "Bart Custers"
      ],
      "url": "https://doi.org/10.1177/2053951715624935",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 35,
      "is_referenced_by_count": 39,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6589490a-a6ce-4a8c-905b-65f724482b20",
    "title": "Artificial intelligence, human intelligence and hybrid intelligence based on mutual augmentation",
    "abstract": "<jats:p> There is little consensus on what artificial intelligence (AI) systems may or may not embrace. Although this may point to multiplicity of interpretations and backgrounds, a lack of conceptual clarity could thwart the development of common ground around the concept among researchers, practitioners and users of AI and pave the way for misinterpretation and abuse of the concept. This article argues that one of the effective ways to delineate the concept of AI is to compare and contrast it with human intelligence. In doing so, the article broaches the unique capabilities of humans and AI in relation to one another (human and machine tacit knowledge), as well as two types of AI systems: one that goes beyond human intelligence and one that is necessarily and inherently tied to it. It finally highlights how humans and AI can augment their capabilities and intelligence through synergistic human–AI interactions (i.e., human-augmented AI and augmented human intelligence), resulting in hybrid intelligence, and concludes with a future-looking research agenda. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221142824",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Mohammad Hossein Jarrahi",
        "Christoph Lutz",
        "Gemma Newlands"
      ],
      "url": "https://doi.org/10.1177/20539517221142824",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 47,
      "is_referenced_by_count": 47,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7036681d-634c-44af-a292-05cd93c972ec",
    "title": "The algorithm audit: Scoring the algorithms that score us",
    "abstract": "<jats:p> In recent years, the ethical impact of AI has been increasingly scrutinized, with public scandals emerging over biased outcomes, lack of transparency, and the misuse of data. This has led to a growing mistrust of AI and increased calls for mandated ethical audits of algorithms. Current proposals for ethical assessment of algorithms are either too high level to be put into practice without further guidance, or they focus on very specific and technical notions of fairness or transparency that do not consider multiple stakeholders or the broader social context. In this article, we present an auditing framework to guide the ethical assessment of an algorithm. The audit instrument itself is comprised of three elements: a list of possible interests of stakeholders affected by the algorithm, an assessment of metrics that describe key ethically salient features of the algorithm, and a relevancy matrix that connects the assessed metrics to stakeholder interests. The proposed audit instrument yields an ethical evaluation of an algorithm that could be used by regulators and others interested in doing due diligence, while paying careful attention to the complex societal context within which the algorithm is deployed. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720983865",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Shea Brown",
        "Jovana Davidovic",
        "Ali Hasan"
      ],
      "url": "https://doi.org/10.1177/2053951720983865",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 26,
      "is_referenced_by_count": 104,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bb0c2123-26a8-4380-b61f-c3c6279846be",
    "title": "Algorithmic management in a work context",
    "abstract": "<jats:p> The rapid development of machine-learning algorithms, which underpin contemporary artificial intelligence systems, has created new opportunities for the automation of work processes and management functions. While algorithmic management has been observed primarily within the platform-mediated gig economy, its transformative reach and consequences are also spreading to more standard work settings. Exploring algorithmic management as a sociotechnical concept, which reflects both technological infrastructures and organizational choices, we discuss how algorithmic management may influence existing power and social structures within organizations. We identify three key issues. First, we explore how algorithmic management shapes pre-existing power dynamics between workers and managers. Second, we discuss how algorithmic management demands new roles and competencies while also fostering oppositional attitudes toward algorithms. Third, we explain how algorithmic management impacts knowledge and information exchange within an organization, unpacking the concept of opacity on both a technical and organizational level. We conclude by situating this piece in broader discussions on the future of work, accountability, and identifying future research steps. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211020332",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Mohammad Hossein Jarrahi",
        "Gemma Newlands",
        "Min Kyung Lee",
        "Christine T. Wolf",
        "Eliscia Kinder",
        "Will Sutherland"
      ],
      "url": "https://doi.org/10.1177/20539517211020332",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 104,
      "is_referenced_by_count": 151,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e8aa2702-f137-4f3b-95df-04621c5d6e82",
    "title": "Addressing ethical gaps in ‘Technology for Good’: Foregrounding care and capabilities",
    "abstract": "<jats:p> This paper identifies and addresses persistent gaps in the consideration of ethical practice in ‘technology for good’ development contexts. Its main contribution is to model an integrative approach using multiple ethical frameworks to analyse and understand the everyday nature of ethical practice, including in professional practice among ‘technology for good’ start-ups. The paper identifies inherent paradoxes in the ‘technology for good’ sector as well as ethical gaps related to (1) the sometimes-misplaced assignment of virtuousness to an individual; (2) difficulties in understanding social constraints on ethical action; and (3) the often unaccounted for mismatch between ethical intentions and outcomes in everyday practice, including in professional work associated with an ‘ethical turn’ in technology. These gaps persist even in contexts where ethics are foregrounded as matters of concern. To address the gaps, the paper suggests systemic, rather than individualized, considerations of care and capability applied to innovation settings, in combination with considerations of virtue and consequence. This paper advocates for addressing these challenges holistically in order to generate renewed capacity for change at a systemic level. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221113774",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Alison B Powell",
        "Funda Ustek-Spilda",
        "Sebastián Lehuedé",
        "Irina Shklovski"
      ],
      "url": "https://doi.org/10.1177/20539517221113774",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 54,
      "is_referenced_by_count": 18,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "764c23bd-7f10-4f7c-8255-bfb0e5ba96f3",
    "title": "The problem with annotation. Human labour and outsourcing between France and Madagascar",
    "abstract": "<jats:p>Artificial intelligence advancements have reignited job displacement debates that focus on how the use of artificial intelligence affects labour, without considering how the production of this technology influences labour division. The generalisation of machine learning has created an increased demand for outsourced data workers. Outsourcing companies and crowdwork platforms are both used to generate, annotate, and enrich data. This data tasks are performed by workers from low-income countries, who often earn poverty wages. As with traditional outsourcing, workers must integrate complex multinational subcontracting networks. In this article, we examine how France outsources artificial intelligence-related tasks to workers in the African island nation of Madagascar. For our study, we interviewed 26 data workers, eight employees of French start-ups, and conducted secondary research on two artificial intelligence systems – a canteen checkout terminal and an algorithm to detect shoplifters in stores. The data collected allowed us to reconstruct an end-to-end artificial intelligence production value chain, revealing the need for data classification and artificial intelligence problematisation. Commercial artificial intelligence, therefore, does not displace employment by automating service jobs. Rather, by delocalising labour into the Global South, it lengthens the externalisation chain.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231188723",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Clément Le Ludec",
        "Maxime Cornet",
        "Antonio A Casilli"
      ],
      "url": "https://doi.org/10.1177/20539517231188723",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 42,
      "is_referenced_by_count": 25,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "435b04a8-8461-4b7f-a55c-b4587c3c8616",
    "title": "Algorithmic governmentality in Latin America: Sociotechnical imaginaries, neocolonial soft power, and authoritarianism",
    "abstract": "<jats:p> Latin America stands as one of the most unequal regions globally, where economic and social crises persist regardless of the ideological leanings of the ruling governments. Many countries in the region grapple with pervasive issues such as corruption, impunity, and a lack of adherence to the rule of law. In this context of generalized crisis, governments have turned to discourses of innovation and technological progress to justify their actions, advocating for the incorporation of automated systems into public administration. Algorithmic governmentality, the government of the social world through the algorithmic processing of data, emerges as a political rationality. Drawing from recent contributions in the theory of governmentality and critical data studies, our commentary centers on three critical dimensions: algorithmic governmentality as political rationality manifested in sociotechnical imaginaries; as an expression of soft power wielded by the U.S. government over the region; and the means by which regional governments automate social asymmetries and social control. This commentary delves into the intricate dynamics of algorithmic governmentality in Latin America, shedding light on its multifaceted implications for governance, democracy, and social structures in the region. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241229697",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Paola Ricaurte",
        "Edgar Gómez-Cruz",
        "Ignacio Siles"
      ],
      "url": "https://doi.org/10.1177/20539517241229697",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 35,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "60bd4882-1135-4b93-8adc-b37e2375d10a",
    "title": "The uncontroversial ‘thingness’ of AI",
    "abstract": "<jats:p> This commentary starts with the question ‘How is it that AI has come to be figured uncontroversially as a thing, however many controversies “it” may engender?’ Addressing this question takes us to knowledge practices that philosopher of science Helen Verran has named a ‘hardening of the categories’, processes that not only characterise the onto-epistemology of AI but also are central to its constituent techniques and technologies. In a context where the stabilization of AI as a figure enables further investments in associated techniques and technologies, AI's status as controversial works to reiterate both its ontological status and its agency. It follows that interventions into the field of AI controversies that fail to trouble and destabilise the figure of AI risk contributing to its uncontroversial reproduction. This is not to deny the proliferating data and compute-intensive techniques and technologies that travel under the sign of AI but rather to call for a keener focus on their locations, politics, material-semiotic specificity, and effects, including their ongoing enactment as a singular and controversial object. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231206794",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Lucy Suchman"
      ],
      "url": "https://doi.org/10.1177/20539517231206794",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 24,
      "is_referenced_by_count": 47,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0fbfafb9-e712-466f-9c8d-775196d05ba6",
    "title": "Health in data space: Formative and experiential dimensions of cross-border health data sharing",
    "abstract": "<jats:p>Healthcare is increasingly datafied, and a wide range of actors—patients, clinicians, administrators, policymakers, and industry lobbyists—want to be able to exchange and access health data internationally and use them for an increasing number of purposes. Therefore, competing initiatives aimed at fostering international data integration proliferate, with the proposed European Health Data Space as one of the most prominent examples. But how do legislators conceptualize a health data space? And what could they gain from rethinking the governmental object of this legislation? To explore these questions, we suggest taking the term “data space,” present in the European Health Data Space initiative, and develop it theoretically to establish a vocabulary fit for understanding international data-intensive health environments. Space is a concept with appealing affordances. It is a way of naming a mode of being which is simultaneously symbolic and material, abstract and concrete, social and physical. We show how these affordances of the concept of space can be helpful when exploring new ways of living in cross-border data-intensive healthcare settings. Whereas policy reports often describe data sharing as a matter of providing technical means and legal provisions to “wire together” existing data resources, we argue that data spaces should be understood as sociotechnical constructs enacted through three formative and four experiential dimensions.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231224258",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Klaus Hoeyer",
        "Sara Green",
        "Andrea Martani",
        "Alexandra Middleton",
        "Clémence Pinel"
      ],
      "url": "https://doi.org/10.1177/20539517231224258",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 97,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "02b1b1ef-586e-4677-9135-7d3c4009f739",
    "title": "Machine learning in tutorials – Universal applicability, underinformed application, and other misconceptions",
    "abstract": "<jats:p> Machine learning has become a key component of contemporary information systems. Unlike prior information systems explicitly programmed in formal languages, ML systems infer rules from data. This paper shows what this difference means for the critical analysis of socio-technical systems based on machine learning. To provide a foundation for future critical analysis of machine learning-based systems, we engage with how the term is framed and constructed in self-education resources. For this, we analyze machine learning tutorials, an important information source for self-learners and a key tool for the formation of the practices of the machine learning community. Our analysis identifies canonical examples of machine learning as well as important misconceptions and problematic framings. Our results show that machine learning is presented as being universally applicable and that the application of machine learning without special expertise is actively encouraged. Explanations of machine learning algorithms are missing or strongly limited. Meanwhile, the importance of data is vastly understated. This has implications for the manifestation of (new) social inequalities through machine learning-based systems. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211017593",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Hendrik Heuer",
        "Juliane Jarke",
        "Andreas Breiter"
      ],
      "url": "https://doi.org/10.1177/20539517211017593",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 42,
      "is_referenced_by_count": 20,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "573d74a2-584f-4f77-8b07-1d72657b09af",
    "title": "In Palantir we trust? Regulation of data analysis platforms in public security",
    "abstract": "<jats:p> Organizations increasingly rely on digital technologies to perform tasks. To do so, they have to integrate data banks to make the data usable. We argue that there is a growing, academically underexplored market consisting of data integration and analysis platforms. We explain that, especially in the public sector, the regulatory implications of data integration and analysis must be studied because they affect vulnerable citizens and because it is not just a matter of state agencies overseeing technology companies but also of the state overseeing itself. We propose a platform-theory-based conceptual approach that directs our attention towards the specific characteristics of platforms—such as datafication, modularity, and multilaterality and the associated regulatory challenges. Due to a scarcity of empirical analyses about how public sector platforms are regulated, we undertake an in-depth case study of a data integration and analysis platform operated by Palantir Technologies in the German federal state of Hesse. Our analysis of the regulatory activities and conflicts uncovers many obstacles to effective platform regulation. Drawing on recent initiatives to improve intermediary liability, we ultimately point to additional paths for regulating public sector platforms. Our findings also highlight the importance of political factors in platform regulation-as-a-practice. We conclude that platform regulation in the public sector is not only about technology-specific regulation but also about general mechanisms of democratic control, such as the separation of power, public transparency, and civil rights. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241255108",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Lena Ulbricht",
        "Simon Egbert"
      ],
      "url": "https://doi.org/10.1177/20539517241255108",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 75,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9641b441-7128-4f21-a34b-d16ecf8ff5ae",
    "title": "The interplay of rational evaluation and motivated reasoning in privacy helplessness: An integrative approach",
    "abstract": "<jats:p> This study investigated the factors that influence individuals’ privacy helplessness in the context of social media and mobile application use. An integrative research model was proposed, simultaneously examining both rational evaluation processes and directional motivated reasoning. The integrative research model was tested using national survey data collected from Facebook users (Study 1, n = 660) and mobile application users (Study 2, n = 385) in the US. The findings demonstrated significant associations between privacy helplessness and factors related to directional motivated reasoning (e.g. perceived rewards, costs, and benefits) as well as the rational evaluation model (e.g. perceived privacy control, trust in the provider, and response efficacy). Moreover, the interaction effects observed in the studies suggest that the two mechanisms either reinforced or attenuated each other's influence. In conclusion, the results emphasize that privacy research should explore both theoretical mechanisms concurrently, as opposed to independently, since they not only operate in conjunction but also interact to define boundary conditions for one another. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241237485",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Hichang Cho"
      ],
      "url": "https://doi.org/10.1177/20539517241237485",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 33,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "cc92001a-f0e0-4f0d-a116-28698afc2b25",
    "title": "AI as super-controversy: Eliciting AI and society controversies with an extended expert community in the UK",
    "abstract": "<jats:p> Following the release of large language models in the late 2010s, the backers of this new type of artificial intelligence (AI) publicly affirmed that the technology is controversial and harmful to society. This situation sets contemporary AI apart from 20th-century controversies about technnoscience, such as nuclear power and genetically modified (GM) foods, and disrupts established assumptions concerning public controversies as occasions for technological democracy. In particular, it challenges the idea that such controversies enable inclusion and collective processes of problem definition (‘problematisation’) across societal domains. In this paper, we show how social research can contribute to addressing this challenge of AI controversies by adopting a distinctive methodology of controversy analysis: controversy elicitation. This approach actively selects, qualifies and evaluates controversies in terms of their capacity to problematise AI across the science and non-science binary. We describe our implementation of this approach in a participatory study of recent AI controversies, conducted through consultation with UK experts in AI and society. Combining an online questionnaire, social media analysis and a participatory workshop, our study suggests that civil society actors have developed distinctive strategies of problematisation that counter the strategic affirmation of AI’s controversiality by its proponents and which centre on the public mobilisation of AI-related incidents: demonstrations of bias, accidents and walkouts. Crucially, this emphasis on ‘AI frictions’ does not result in the fragmentation of AI controversies, but rather enables the articulation of AI as a ‘super-controversy’: the explication of connections between technical propositions, situated troubles and structural problems in society (discrimination, inequalities and corporate power). </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241255103",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Noortje Marres",
        "Michael Castelle",
        "Beatrice Gobbo",
        "Chiara Poletti",
        "James Tripp"
      ],
      "url": "https://doi.org/10.1177/20539517241255103",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 43,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "97e63f44-2634-45b8-8175-a1bcd9cbdabf",
    "title": "Digital subjectivation and financial markets: Criticizing Social Studies of Finance with Lazzarato",
    "abstract": "<jats:p> The recently rising field of Critical Data Studies is still facing fundamental questions. Among these is the enigma of digital subjectivation. Who are the subjects of Big Data? A field where this question is particularly pressing is finance. Since the 1990s traders have been steadily integrated into computerized data assemblages, which calls for an ontology that eliminates the distinction between human sovereign subjects and non-human instrumental objects. The latter subjectivize traders in pre-conscious ways, because human consciousness runs too slow to follow the volatility of the market. In response to this conundrum Social Studies of Finance has drawn on Actor-Network Theory to interpret financial markets as technically constructed networks of human and non-human actors. I argue that in order to develop an explicitly critical data study it might be advantageous to refer to Maurizio Lazzarato’s theory of machinic subjugation instead. Although both accounts describe financial digital subjectivation similarly, Lazzarato has the advantage of coupling his description to a clear critique of and resistance to finance. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716662897",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Tim Christiaens"
      ],
      "url": "https://doi.org/10.1177/2053951716662897",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 76,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3819fbae-46ce-469e-9044-c20a3080dfab",
    "title": "Algorithmic memory and the right to be forgotten on the web",
    "abstract": "<jats:p> The debate on the right to be forgotten on Google involves the relationship between human information processing and digital processing by algorithms. The specificity of digital memory is not so much its often discussed inability to forget. What distinguishes digital memory is, instead, its ability to process information without understanding. Algorithms only work with data (i.e. with differences) without remembering or forgetting. Merely calculating, algorithms manage to produce significant results not because they operate in an intelligent way, but because they “parasitically” exploit the intelligence, the memory, and the attribution of meaning by human actors. The specificity of algorithmic processing makes it possible to bypass the paradox of remembering to forget, which up to now blocked any human-based forgetting technique. If you decide to forget some memory, the most immediate effect is drawing attention to it, thereby activating remembering. Working differently from human intelligence, however, algorithms can implement, for the first time, the classical insight that it might be possible to reinforce forgetting not by erasing memories but by multiplying them. After discussing several projects on the web which implicitly adopt this approach, the article concludes by raising some deeper problems posed when algorithms use data and metadata to produce information that cannot be attributed to any human being. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717703996",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Elena Esposito"
      ],
      "url": "https://doi.org/10.1177/2053951717703996",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 74,
      "is_referenced_by_count": 25,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3553a7c3-de3e-446e-9e09-add4a9ca5a67",
    "title": "Editorial: The personalisation of insurance: Data, behaviour and innovation",
    "abstract": "<jats:p> The adoption of Big Data analytics (BDA) in insurance has proved controversial but there has been little analysis specifying how insurance practices are changing. Is insurance passively subject to the forces of disruptive innovation, moving away from the pooling of risk towards its personalisation or individualisation, and what might that mean in practice? This special theme situates disruptive innovations, particularly the experimental practices of behaviour-based personalisation, in the context of the practice and regulation of contemporary insurance. Our contributors argue that behaviour-based personalisation in insurance has different and broader implications than have yet been appreciated. BDAs are changing how insurance governs risk; how it knows, classifies, manages, prices and sells it, in ways that are more opaque and more extensive than the black boxes of in-car telematics. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720973707",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Liz McFall",
        "Gert Meyers",
        "Ine Van Hoyweghen"
      ],
      "url": "https://doi.org/10.1177/2053951720973707",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 76,
      "is_referenced_by_count": 27,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3a7f4ab0-0e30-4a14-ad74-08d80e35e3f2",
    "title": "A qualitative analysis of sarcasm, irony and related #hashtags on Twitter",
    "abstract": "<jats:p> As the use of automated social media analysis tools surges, concerns over accuracy of analytics have increased. Some tentative evidence suggests that sarcasm alone could account for as much as a 50% drop in accuracy when automatically detecting sentiment. This paper assesses and outlines the prevalence of sarcastic and ironic language within social media posts. Several past studies proposed models for automatic sarcasm and irony detection for sentiment analysis; however, these approaches result in models trained on training data of highly questionable quality, with little qualitative appreciation of the underlying data. To understand the issues and scale of the problem, we are the first to conduct and present results of a focused manual semantic annotation analysis of two datasets of Twitter messages (in total 4334 tweets), associated with; (i) hashtags commonly employed in automated sarcasm and irony detection approaches, and (ii) tweets relating to 25 distinct events, including, scandals, product releases, cultural events, accidents, terror incidents, etc. We also highlight the contextualised use of multi-word hashtags in the communication of humour, sarcasm and irony, pointing out that many sentiment analysis tools simply fail to recognise such hashtag-based expressions. Our findings also offer indicative evidence regarding the quality of training data used for automated machine learning models in sarcasm, irony and sentiment detection. Worryingly only 15% of tweets labelled as sarcastic were truly sarcastic. We highlight the need for future research studies to rethink their approach to data preparation and a more careful interpretation of sentiment analysis. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720972735",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Martin Sykora",
        "Suzanne Elayan",
        "Thomas W Jackson"
      ],
      "url": "https://doi.org/10.1177/2053951720972735",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 70,
      "is_referenced_by_count": 38,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6749f7c4-596e-4c0a-948b-50678898a88f",
    "title": "Producing “one vast index”: Google Book Search as an algorithmic system",
    "abstract": "In 2004, Google embarked on a massive book digitization project. Forty library partners and billions of scanned pages later, Google Book Search has provided searchable text access to millions of books. While many details of Google’s conversion processes remain proprietary secret, here we piece together their general outlines by closely examining Google Book Search products, Google patents, and the entanglement of libraries and computer scientists in the longer history of digitization work. We argue that far from simply “scanning” books, Google’s efforts may be characterized as algorithmic digitization, strongly shaped by an equation of digital access with full-text searchability. We explore the consequences of Google’s algorithmic digitization system for what end users ultimately do and do not see, placing these effects in the context of the multiple technical, material, and legal challenges surrounding Google Book Search. By approaching digitization primarily as a text extraction and indexing challenge—an effort to convert print books into electronically searchable data—GBS enacts one possible future for books, in which they are defined largely by their textual content.",
    "metadata": {
      "doi": "10.1177/2053951717716950",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Melissa K Chalmers",
        "Paul N Edwards"
      ],
      "url": "https://doi.org/10.1177/2053951717716950",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171771695",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 34,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0b1a0c36-a281-49f4-90e7-ffab084df26a",
    "title": "Leveraging blockchain for energy transition in urban contexts",
    "abstract": "<jats:p> This article explores the potential of leveraging blockchain technology to facilitate energy transition within urban settings. It explores three innovative market models—peer-to-peer, community self-consumption, and transactive energy—which hold promise for a shift in (local) electricity trading due to decentralized and digital transactional characteristics. Utilizing a scenario building framework, this research scrutinizes these market models, their corresponding trading mechanisms, and the advantages and disadvantages of implementing blockchain technology. The results provide valuable insights into investment necessities, market democratization, service quality and reliability, urban governance, civic engagement and citizenry welfare. Consequently, this study offers a novel conceptualization of market models, laying the groundwork for a systematic understanding of blockchain’s potentiality in ecosystem governance in the context of energy transition. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231205503",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Mehdi Montakhabi",
        "Akash Madhusudan",
        "Mustafa A Mustafa",
        "Wim Vanhaverbeke",
        "Esteve Almirall",
        "Shenja van der Graaf"
      ],
      "url": "https://doi.org/10.1177/20539517231205503",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 62,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9990b6e7-597e-4d99-b605-f9b8a76012c5",
    "title": "AI and discriminative decisions in recruitment: Challenging the core assumptions",
    "abstract": "<jats:p>In this article, we engage critically with the idea of promoting artificial intelligence (AI) technologies in recruitment as tools to eliminate discrimination in decision-making. We show that the arguments for using AI technologies to eliminate discrimination in personnel selection depend on presuming specific meanings of the concepts of rationality, bias, fairness, objectivity and AI, which the AI industry and other proponents of AI-based recruitment accept as self-evident. Our critical analysis of the arguments for relying on AI to decrease discrimination in recruitment is informed by insights gleaned from philosophy and methodology of science, legal and political philosophy, and critical discussions on AI, discrimination and recruitment. We scrutinize the role of the research on cognitive biases and implicit bias in justifying these arguments – a topic overlooked thus far in the debates about practical applications of AI. Furthermore, we argue that the recent use of AI in personnel selection can be understood as the latest trend in the long history of psychometric-based recruitment. This historical continuum has not been fully recognized in current debates either, as they focus mainly on the seemingly novel and disruptive character of AI technologies.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241235872",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Päivi Seppälä",
        "Magdalena Małecka"
      ],
      "url": "https://doi.org/10.1177/20539517241235872",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 93,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "646456d0-226a-4c7f-b6c8-8b401ae46309",
    "title": "Big Data solutions on a small scale: Evaluating accessible high-performance computing for social research",
    "abstract": "<jats:p> Though full of promise, Big Data research success is often contingent on access to the newest, most advanced, and often expensive hardware systems and the expertise needed to build and implement such systems. As a result, the accessibility of the growing number of Big Data-capable technology solutions has often been the preserve of business analytics. Pay as you store/process services like Amazon Web Services have opened up possibilities for smaller scale Big Data projects. There is high demand for this type of research in the digital humanities and digital sociology, for example. However, scholars are increasingly finding themselves at a disadvantage as available data sets of interest continue to grow in size and complexity. Without a large amount of funding or the ability to form interdisciplinary partnerships, only a select few find themselves in the position to successfully engage Big Data. This article identifies several notable and popular Big Data technologies typically implemented using large and extremely powerful cloud-based systems and investigates the feasibility and utility of development of Big Data analytics systems implemented using low-cost commodity hardware in basic and easily maintainable configurations for use within academic social research. Through our investigation and experimental case study (in the growing field of social Twitter analytics), we found that not only are solutions like Cloudera’s Hadoop feasible, but that they can also enable robust, deep, and fruitful research outcomes in a variety of use-case scenarios across the disciplines. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714559105",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "Dhiraj Murthy",
        "Sawyer A Bowman"
      ],
      "url": "https://doi.org/10.1177/2053951714559105",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 43,
      "is_referenced_by_count": 17,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d7da1f5e-d738-464e-8bef-0ad8bd38c410",
    "title": "‘What about the dads?’ Linking fathers and children in administrative data: A systematic scoping review",
    "abstract": "<jats:p> Research has shown that paternal involvement positively impacts on child health and development. We aimed to develop a conceptual model of dimensions of fatherhood, identify and categorise methods used for linking fathers with their children in administrative data, and map these methods onto the dimensions of fatherhood. We carried out a systematic scoping review to create a conceptual framework of paternal involvement and identify studies exploring the impact of paternal exposures on child health and development outcomes using administrative data. We identified four methods that have been used globally to link fathers and children in administrative data based on family or household identifiers using address data, identifiable information about the father on the child's birth registration, health claims data, and Personal Identification Numbers. We did not identify direct measures of paternal involvement but mapping linkage methods to the framework highlighted possible proxies. The addition of paternal National Health Service numbers to birth notifications presents a way forward in the advancement of fatherhood research using administrative data sources. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211069299",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Irina Lut",
        "Katie Harron",
        "Pia Hardelid",
        "Margaret O’Brien",
        "Jenny Woodman"
      ],
      "url": "https://doi.org/10.1177/20539517211069299",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 77,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "98a596b8-7846-4bf6-b00f-0634741c6e2f",
    "title": "Archival strategies for contemporary collecting in a world of big data: Challenges and opportunities with curating the UK web archive",
    "abstract": "<jats:p> In this contribution, we will discuss the opportunities and challenges arising from memory institutions' need to redefine their archival strategies for contemporary collecting in a world of big data. We will reflect on this topic by critically examining the case study of the UK Web Archive, which is made up of the six UK Legal Deposit Libraries: the British Library, National Library of Scotland, National Library of Wales, Bodleian Libraries Oxford, Cambridge University Library and Trinity College Dublin. The UK Web Archive aims to archive, preserve and give access to the UK web space. This is achieved through an annual domain crawl, first undertaken in 2013, in addition to more frequent crawls of key websites and specially curated collections which date back as far as 2005. These collections reflect important aspects of British culture and events that shape society. This commentary will explore a number of questions including: what heritage is captured and what heritage is instead neglected by the UK Web archive? What heritage is created in the form of new data and what are its properties? What are the ethical issues that memory institutions face when developing these web archiving practices? What transformations are required to overcome such challenges and what institutional futures can we envisage? </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951721990409",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Nicola Jayne Bingham",
        "Helena Byrne"
      ],
      "url": "https://doi.org/10.1177/2053951721990409",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 36,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fbf2b278-cd8d-40b9-a7ba-15448747c90e",
    "title": "European Search? How to counter-imagine and counteract hegemonic search with European search engine projects",
    "abstract": "<jats:p> This article investigates how developers of alternative search engines challenge increasingly corporate imaginaries of digital futures by building out counter-imaginaries of search engines devoted to social values instead of mere profit maximization. Drawing on three in-depth case studies of European search engines, it analyzes how search engine developers counter-imagine hegemonic search, what social values support their imaginaries, and how they are intertwined with their sociotechnical practices. This analysis shows that notions like privacy, independence, and openness appear to be fluid, context-dependent, and changing over time, leading to a certain “value pragmatics” that allows the projects to scale beyond their own communities of practice. It further shows how European values, and broader notions of Europe as “unified or pluralistic,” are constructed and co-produced with developers’ attempts to counter-imagine and counteract hegemonic search. To conclude, I suggest three points of intervention that may help alternative search engine projects, and digital technologies more generally, to not only make their counter-imaginaries more powerful, but also acquire the necessary resources to build their technologies and infrastructures accordingly. I finally discuss how “European values,” in all their richness and diversity, can contribute to this undertaking. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231163173",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Astrid Mager"
      ],
      "url": "https://doi.org/10.1177/20539517231163173",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 62,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a5c686e5-efcb-4b6b-a665-f6077e6447f7",
    "title": "Interoperable and standardized algorithmic images: The domestic war on drugs and mugshots within facial recognition technologies",
    "abstract": "<jats:p> Beginning in the 1990s, the National Institute of Standards and Technology (NIST) leveraged the 1980s’ American War on Drugs to improve and expand facial recognition technology (FRT) infrastructure, including the domestic building of FRTs reliant on mugshots. When examining mugshot databases gathered by the NIST, such as the Multiple Encounters Dataset (MEDS) I and II (2010) and Special Database 18 Mugshot Identification Database (SD-18) (2016), it is clear that the same gendered and racialized dynamics present in policing practices related to the War on Drugs is reflected in the mugshot databases that continue to use for FRT research and evaluation into the contemporary moment. This paper details the SD-18 and MEDS databases, as well as the MORPH database, showcasing how their representational, technical and political protocols operate. The desires for frictionless interoperability built into the images’ technical protocols supersede concerns for eugenic political and representational protocols, resulting in a current moment where the deployment of mugshot datasets cannot be contained to their original intended use with FRTs, but leak into other forms of algorithmic governance as well as into algorithmic image-making and visual culture, including generative artificial intelligence systems such as DALL-E. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241274593",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Aaron Tucker"
      ],
      "url": "https://doi.org/10.1177/20539517241274593",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 62,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "536d2f86-3e47-4f82-979b-5741311eec80",
    "title": "Formally comparing topic models and human-generated qualitative coding  of physician mothers’ experiences  of workplace discrimination",
    "abstract": "<jats:p> Differences between computationally generated and human-generated themes in unstructured text are important to understand yet difficult to assess formally. In this study, we bridge these approaches through two contributions. First, we formally compare a primarily computational approach, topic modeling, to a primarily human-driven approach, qualitative thematic coding, in an impactful context: physician mothers’ experience of workplace discrimination. Second, we compare our chosen topic model to a principled alternative topic model to make explicit study design decisions meriting consideration in future research. By formally contrasting computationally generated (i.e. topic modeling) and human-generated (i.e. thematic coding) knowledge, we shed light on issues of interest to several audiences, notably computational social scientists who wish to understand study design tradeoffs, and qualitative researchers who may wish to leverage computational methods to improve the speed and reproducibility of labor-intensive coding. Although useful in other domains, we highlight the value of fast, reproducible methods to better understand experiences of workplace discrimination. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221149106",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Adam S Miner",
        "Sheridan A Stewart",
        "Meghan C Halley",
        "Laura K Nelson",
        "Eleni Linos"
      ],
      "url": "https://doi.org/10.1177/20539517221149106",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 66,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "34103769-3ec2-4072-9c3e-d4eb6159a92e",
    "title": "Folk theories of algorithmic recommendations on Spotify: Enacting data assemblages in the global South",
    "abstract": "<jats:p>This paper examines folk theories of algorithmic recommendations on Spotify in order to make visible the cultural specificities of data assemblages in the global South. The study was conducted in Costa Rica and draws on triangulated data from 30 interviews, 4 focus groups with 22 users, and the study of “rich pictures” made by individuals to graphically represent their understanding of algorithmic recommendations. We found two main folk theories: one that personifies Spotify (and conceives of it as a social being that provides recommendations thanks to surveillance) and another one that envisions it as a system full of resources (and a computational machine that offers an individualized musical experience through the appropriate kind of “training”). Whereas the first theory emphasizes local conceptions of social relations to make sense of algorithms, the second one stresses the role of algorithms in providing a global experience of music and technology. We analyze why people espouse either one of these theories (or both) and how these theories provide users with resources to enact different modalities of power and resistance in relation to recommendation algorithms. We argue that folk theories thus offer a productive way to broaden understanding of what agency means in relation to algorithms.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720923377",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Ignacio Siles",
        "Andrés Segura-Castillo",
        "Ricardo Solís",
        "Mónica Sancho"
      ],
      "url": "https://doi.org/10.1177/2053951720923377",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172092337",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 35,
      "is_referenced_by_count": 105,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9e9eab54-14f4-4890-ba6e-c03c30ffa396",
    "title": "The end of ‘small biology’? Some thoughts about biomedicine and big science",
    "abstract": "<jats:p> In biology—as in other scientific fields—there is a lively opposition between big and small science projects. In this commentary, I try to contextualize this opposition in the field of biomedicine, and I argue that, at least in this context, big science projects should come first. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716678430",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Emanuele Ratti"
      ],
      "url": "https://doi.org/10.1177/2053951716678430",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 16,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "584e3d7f-2ca8-4285-94f3-ca836dbb043f",
    "title": "Sunlight alone is not a disinfectant: Consent and the futility of opening Big Data black boxes (without assistance)",
    "abstract": "<jats:p> In our attempts to achieve privacy and reputation deliverables, advocating for service providers and other data managers to open Big Data black boxes and be more transparent about consent processes, algorithmic details, and data practice is easy. Moving from this call to meaningful forms of transparency, where the Big Data details are available, useful, and manageable is more difficult. Most challenging is moving from that difficult task of meaningful transparency to the seemingly impossible scenario of achieving, consistently and ubiquitously, meaningful forms of consent, where individuals are aware of data practices and implications, understand these realities, and agree to them as well. This commentary unpacks these concerns in the online consent context. It emphasizes that self-governance fallacy pervades current approaches to achieving digital forms of privacy, exemplified by the assertion that transparency and information access alone are enough to help individuals achieve privacy and reputation protections. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720935615",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Jonathan A. Obar"
      ],
      "url": "https://doi.org/10.1177/2053951720935615",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172093561",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 12,
      "is_referenced_by_count": 15,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "61df6c96-3ea2-421a-861c-b55fce68a4d5",
    "title": "The needle and the damage done: Of haystacks and anxious panopticons",
    "abstract": "How should we understand the surveillance state post Snowden? This paper is concerned with the relationship between increased surveillance capacity and state power. The paper begins by analysing two metaphors used in public post Snowden discourse to describe state surveillance practices: the haystack and the panopticon. It argues that these metaphors share a flawed common entailment regarding surveillance, knowledge and power which cannot accurately capture important aspects of state anxiety generated by mass surveillance in an age of big data. The paper shows that the nature of big data itself complicates the power attributed to mass surveillance states by these metaphors and those who use them. Relying heavily on Ezrahi’s distinction between information and knowledge, the paper situates this argument concerning the state and anxiety borne of information overload in the context of literature that concerns the state and information management. Drawing primarily on James Scott’s work on legibility, it argues that the big data born of mass surveillance problematises the concept of information as empowering the state. Instead, understanding mass surveillance in an age of big data requires understanding the relationship between the surveillance state and information in terms of anxiety as well as power.",
    "metadata": {
      "doi": "10.1177/2053951717734574",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Sarah Logan"
      ],
      "url": "https://doi.org/10.1177/2053951717734574",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171773457",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 38,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c830b8d8-ccc3-4e9e-ae2c-647742c34bd1",
    "title": "Introduction: Spatial Big Data and everyday life",
    "abstract": "<jats:p> Spatial Big Data—be this natively geocoded content, geographical metadata, or data that itself refers to spaces and places—has become a pervasive presence in the spaces and practices of everyday life. Beyond preoccupations with “the geotag” and with mapping geocoded social media content, this special theme explores what it means to encounter and experience spatial Big Data as a quotidian phenomenon that is both spatial, characterized by and enacting of material spatialities, and spatializing, configuring relations between subjects, objects, and spaces in new and unprecedented ways. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716661366",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Agnieszka Leszczynski",
        "Jeremy Crampton"
      ],
      "url": "https://doi.org/10.1177/2053951716661366",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 30,
      "is_referenced_by_count": 40,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3422abf3-aa37-4ef0-b521-514523418596",
    "title": "Algorithmic probing: Prompting offensive Google results and their moderation",
    "abstract": "<jats:p> Google results have been scrutinized over the years for what they privilege, be it the surface web, the powerful, optimized webpages, the personalized and/or their own properties. For some time now, another type of Google returns also has been the source of attention: the offensive result. The following revisits a selection of offensive and other problematic results found by journalists and researchers alike. In a technique termed ‘algorithmic probing’, the prompting queries are re-run to study what has come of these results in Google Web and Image Search but mainly in Google Autocompletion. The question concerns a different kind of privileging – Google's hierarchy of concerns – or the extent to which certain categories as well as languages are moderated and others less so. In all, it was found that Google heavily moderates religion, ethnicities and sexualities (albeit with gaps) but leaves alone stereotypes of gendered professions as well as ageism. It also moderates to a greater degree in English compared to southern European and Balkan languages. The article concludes with a discussion of the stakes of Google's moderation, including its uneven coverage. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231176228",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Richard Rogers"
      ],
      "url": "https://doi.org/10.1177/20539517231176228",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 66,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "18495064-8ea3-47e5-8fd8-d2caafe52992",
    "title": "COVID-19 is spatial: Ensuring that mobile Big Data is used for social good",
    "abstract": "<jats:p> The mobility restrictions related to COVID-19 pandemic have resulted in the biggest disruption to individual mobilities in modern times. The crisis is clearly spatial in nature, and examining the geographical aspect is important in understanding the broad implications of the pandemic. The avalanche of mobile Big Data makes it possible to study the spatial effects of the crisis with spatiotemporal detail at the national and global scales. However, the current crisis also highlights serious limitations in the readiness to take the advantage of mobile Big Data for social good, both within and beyond the interests of health sector. We propose two strategical pathways for the future use of mobile Big Data for societal impact assessment, addressing access to both raw mobile Big Data as well as aggregated data products. Both pathways require careful considerations of privacy issues, harmonized and transparent methodologies, and attention to the representativeness, reliability and continuity of data. The goal is to be better prepared to use mobile Big Data in future crises. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720952088",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Age Poom",
        "Olle Järv",
        "Matthew Zook",
        "Tuuli Toivonen"
      ],
      "url": "https://doi.org/10.1177/2053951720952088",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 47,
      "is_referenced_by_count": 59,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ee3e5638-e2c6-4fee-9589-6e8ec6faca6a",
    "title": "Cognitive assemblages: The entangled nature of algorithmic content moderation",
    "abstract": "<jats:p> This article examines algorithmic content moderation, using the moderation of violent extremist content as a specific case. In recent years, algorithms have increasingly been mobilized to perform essential moderation functions for online social media platforms such as Facebook, YouTube, and Twitter, including limiting the proliferation of extremist speech. Drawing on Katherine Hayles’ concept of “cognitive assemblages” and the Critical Security Studies literature, we show how algorithmic regulation operates within larger assemblages of humans and non-humans to influence the surveillance and regulation of information flows. We argue that the dynamics of algorithmic regulation are more liquid, cobbled together and distributed than it appears. It is characterized by a set of shifting human and machine entities, which mix traditional surveillance methods with more sophisticated tools, and whose linkages and interactions are transient. The processes that enable the consolidation of knowledge about risky profiles and contents are, therefore, collective and distributed among humans and machines. This allows us to argue that the cognitive assemblages involved in content moderation become a cobbled space of preemptive calculation. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221143361",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Valentine Crosset",
        "Benoît Dupont"
      ],
      "url": "https://doi.org/10.1177/20539517221143361",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 103,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4ce8615e-e4db-49de-8c8b-665513b81dc9",
    "title": "Cross-cultural narratives of weaponised artificial intelligence: Comparing France, India, Japan and the United States",
    "abstract": "<jats:p> Stories about ‘intelligent machines’ have long featured in popular culture. Existing research has mapped these artificial intelligence (AI) narratives but lacks an in-depth understanding of (a) narratives related specifically to weaponised AI and autonomous weapon systems and (b) whether and how these narratives resonate across different states and associated cultural contexts. We speak to these gaps by examining narratives about weaponised AI across publics in France, India, Japan and the US. Based on a public opinion survey conducted in these states in 2022–2023, we find that narratives found in English-language popular culture are shared cross-culturally, although with some variations. However, we also find culturally distinct narratives, particularly in India and Japan. Further, we assess whether these narratives shape the publics’ attitudes towards regulating weaponised AI. Although respondents demonstrate overall uncertainty and lack of knowledge regarding developments in the sphere of weaponised AI, they assess these technologies in a negative-leaning way and mostly support regulation. With these findings, our study offers a first step towards further investigating the extent to which weaponised AI narratives circulate globally and how salient perceptions of these technologies are across different publics. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241303151",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Ingvild Bode",
        "Hendrik Huelss",
        "Anna Nadibaidze",
        "Tom FA Watts"
      ],
      "url": "https://doi.org/10.1177/20539517241303151",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 63,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5f454d4c-de6f-4c12-8a15-f7374efd0cd1",
    "title": "The limits of computation: A philosophical critique of contemporary Big Data research",
    "abstract": "<jats:p> This paper reviews the contemporary discussion on the epistemological and ontological effects of Big Data within social science, observing an increased focus on relationality and complexity, and a tendency to naturalize social phenomena. The epistemic limits of this emerging computational paradigm are outlined through a comparison with the discussions in the early days of digitalization, when digital technology was primarily seen through the lens of dematerialization, and as part of the larger processes of “postmodernity”. Since then, the online landscape has become increasingly centralized, and the “liquidity” of dematerialized technology has come to empower online platforms in shaping the conditions for human behavior. This contrast between the contemporary epistemological currents and the previous philosophical discussions brings to the fore contradictions within the study of digital social life: While qualitative change has become increasingly dominant, the focus has gone towards quantitative methods; while the platforms have become empowered to shape social behavior, the focus has gone from social context to naturalizing social patterns; while meaning is increasingly contested and fragmented, the role of hermeneutics has diminished; while platforms have become power hubs pursuing their interests through sophisticated data manipulation, the data they provide is increasingly trusted to hold the keys to understanding social life. These contradictions, we argue, are partially the result of a lack of philosophical discussion on the nature of social reality in the digital era; only from a firm metatheoretical perspective can we avoid forgetting the reality of the system under study as we are affected by the powerful social life of Big Data. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718811843",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Petter Törnberg",
        "Anton Törnberg"
      ],
      "url": "https://doi.org/10.1177/2053951718811843",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 86,
      "is_referenced_by_count": 35,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "44353913-cfb1-4aff-8fb8-0a03b22aa467",
    "title": "Big Data, social physics, and spatial analysis: The early years",
    "abstract": "<jats:p> This paper examines one of the historical antecedents of Big Data, the social physics movement. Its origins are in the scientific revolution of the 17th century in Western Europe. But it is not named as such until the middle of the 19th century, and not formally institutionalized until another hundred years later when it is associated with work by George Zipf and John Stewart. Social physics is marked by the belief that large-scale statistical measurement of social variables reveals underlying relational patterns that can be explained by theories and laws found in natural science, and physics in particular. This larger epistemological position is known as monism, the idea that there is only one set of principles that applies to the explanation of both natural and social worlds. Social physics entered geography through the work of the mid-20th-century geographer William Warntz, who developed his own spatial version called “macrogeography.” It involved the computation of large data sets, made ever easier with the contemporaneous development of the computer, joined with the gravitational potential model. Our argument is that Warntz's concerns with numeracy, large data sets, machine-based computing power, relatively simple mathematical formulas drawn from natural science, and an isomorphism between natural and social worlds became grounds on which Big Data later staked its claim to knowledge; it is a past that has not yet passed. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714535365",
      "type": "journal-article",
      "published": [
        2014,
        4,
        1
      ],
      "authors": [
        "Trevor J Barnes",
        "Matthew W Wilson"
      ],
      "url": "https://doi.org/10.1177/2053951714535365",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 52,
      "is_referenced_by_count": 79,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6285802d-d69b-47fa-ae89-25a601f5c599",
    "title": "The curious case of blockchain in rural China: Unravelling power,  profit, and surveillance",
    "abstract": "<jats:p> Blockchain originated from the aspiration for decentralization, and in Western countries, its association with freedom from governmental and corporate dominance remains unwavering. However, in China–where blockchain has taken an intriguing foothold–the socio-technical imaginaries of blockchain diverge significantly. As China rises in blockchain development, critical literature examining its ventures is notably lacking. This article analyses state-led initiatives and corporate endeavours related to blockchain deployment in rural China. While blockchain's roots lie in libertarian ideals, within China, it serves as a ‘state techno-solutionist’ tool, empowering authoritarian capitalism for enhanced state control and corporate profit through data exploitation. Although the application of blockchain in agricultural tracing and finance is heralded as a blessing to elevate smallholder farmers from poverty and enhance agricultural practices, the reality contrasts sharply. Instead of empowering farmers, the technology exacerbates power imbalances, embedding them in a system marked by extensive data harvesting and surveillance. Such integration entangles these farmers subsisting on China's economic fringes within broader national and global capitalist financial frameworks, rendering them more susceptible to exploitation and manipulation. Moreover, blockchain in rural China epitomizes authoritarian capitalism, where capitalists aligning closely with state agendas. Blockchain's transparency, traceability, and tamper-resistant features, instead of diminishing government interference, are harnessed by capitalists to amplify the social credit system, strengthening the data dominance of platform companies and supporting state surveillance. Therefore, blockchain emerges as a threat to rural China's ways of life–all driven by the pursuit of corporate profit and the government's quest to reclaim national greatness. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241259674",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Alvin Hoi-Chun Hung"
      ],
      "url": "https://doi.org/10.1177/20539517241259674",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 103,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e9c85327-7c41-45ea-9472-ce5eba390b98",
    "title": "Choreographing for public value in digital health?",
    "abstract": "<jats:p>Entanglements between public and private entities in digital health are not new, yet we do not have full insight into how these public-private dances are choreographed or what notions of public value drive governments’ appetite for investing into or collaborating with private digital health firms around health data. We examine key events, actors, public discussions, policy deliberations and regulations for over 30 years to find that European Union policy has paved an innovation-friendly path for technology companies entering healthcare. The recent pandemic has normalized these collaborations even further. The paper also finds that conceptualizations of public value in digital health mostly relate to economic aspects – markets, jobs and money. Other interpretations, such as public health, long-term sustainability or the common good, tend to be sidelined. The paper closes by considering whether the advent of the European Health Data Space will change this trajectory before giving suggestions on how a focus on public health value can be re-established.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231220622",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Nicole Gross",
        "Susi Geiger"
      ],
      "url": "https://doi.org/10.1177/20539517231220622",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 85,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e6bed6fd-7020-4e46-acb2-19aa7f17f80f",
    "title": "Chromium as a tool of logistical power: A material political economy of open-source",
    "abstract": "<jats:p> Open-source software is used by almost all technology companies and has become an integral part of the technical infrastructure of digital capitalism. Generally, developers of open-source software have been viewed as a social movement at odds with the capitalist profit motive. This idealized view has been challenged as companies have made significant investments in open-source since the early 2000s. Current research frames corporate participation in open-source as fundamentally extractive in nature, failing to account for these sizable investments. Through a historical analysis of Google's Chromium browser project, we provide another way to understand corporate participation in open-source. This article takes a material political economic approach to argue that control of open-source projects can grant companies logistical power that enables them to influence standards and shape the Internet as an infrastructure for digital capitalism. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231182399",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Bolun Zhang",
        "Davide Carpano"
      ],
      "url": "https://doi.org/10.1177/20539517231182399",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 84,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b97a3832-f6cb-46b6-a872-2185fa1c01d0",
    "title": "Prediction as extraction of discretion",
    "abstract": "<jats:p> I argue that prediction is not primarily a technological means for knowing future outcomes, but a social model for extracting and concentrating discretionary power. Prediction is a ‘relational grammar’ that governs this allocation of discretion: the everyday ability to define one's situation. This extractive dynamic extends a long historical pattern, in which new methods for producing knowledge entail a redistribution of decision-making power. I focus on two contemporary domains: (1) crime and policing are emblematic of how predictive systems are extractive by design, with pre-existing interests governing what is measured and what persistently goes unmeasured. (2) The prediction of productivity demonstrates the long tradition of extracting discretion as a means to extract labour power. Time after time, making human behaviour more predictable for the client of prediction (the manager, the police officer) often means making life and work more unpredictable for the target of prediction (the employee, the urban citizen). </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231171053",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Sun-ha Hong"
      ],
      "url": "https://doi.org/10.1177/20539517231171053",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 97,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ef371043-ef0e-465d-a5fd-b931c9fe13ec",
    "title": "Stepping back from Data and AI for Good – current trends and ways forward",
    "abstract": "<jats:p> Various ‘Data for Good’ and ‘AI for Good’ initiatives have emerged in recent years to promote and organise efforts to use new computational techniques to solve societal problems. The initiatives exercise ongoing influence on how the capabilities of computational techniques are understood as vehicles of social and political change. This paper analyses the development of the initiatives from a rhetorical slogan into a research program that understands itself as a ‘field’ of applications. It discusses recent academic literature on the topic to show a problematic entanglement between the promotion of initiatives and prescriptions of what ‘good’ ought to be. In contrast, we call researchers to take a practical and analytical step back. The paper provides a framework for future research by calling for descriptive research on the composition of the initiatives and critical research that draws from broader social science debates on computational techniques. The empirical part of the paper provides first steps towards this direction by positioning Data and AI for Good initiatives as part of a single continuum and situating it within a historical trajectory that has its immediate precursor in ICT for Development initiatives. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231173901",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Ville Aula",
        "James Bowles"
      ],
      "url": "https://doi.org/10.1177/20539517231173901",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 55,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "41d412d8-e798-4030-b950-12d91505a3cf",
    "title": "Synthetic ethnography: Field devices for the qualitative study of generative models",
    "abstract": "<jats:p> Advancements in generative artificial intelligence have led to a rapid proliferation of machine learning models capable of synthesizing text, images, sounds, and other kinds of content. While the increasing realism of synthetic content stokes fears about misinformation and triggers debates around intellectual property, generative models are adopted across creative industries and synthetic media seep into cultural production. Qualitative research in the social and human sciences has dedicated comparatively little attention to this category of machine learning, particularly in terms of what types of novel research methodology they both demand and facilitate. In this article, we propose a methodological approach for the qualitative study of generative models grounded on the experimentation with field devices which we call synthetic ethnography. Synthetic ethnography is not simply a qualitative research methodology applied to the study of the social and cultural contexts developing around generative artificial intelligence, but also strives to envision practical and experimental ways to repurpose these models as research tools in their own right. After briefly introducing generative models and revisiting the trajectory of digital ethnographic research, we discuss three case studies for which the authors have developed experimental field devices to study different aspects of generative artificial intelligence ethnographically. In the conclusion, we derive a broader methodological proposal from these case studies, arguing that synthetic ethnography facilitates insights into how the algorithmic processes, training datasets and latent spaces behind these systems modulate bias, reconfigure agency, and challenge epistemological categories. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241303126",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Gabriele de Seta",
        "Matti Pohjonen",
        "Aleksi Knuutila"
      ],
      "url": "https://doi.org/10.1177/20539517241303126",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 82,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "19c68624-423c-41fb-986c-245304ab9cde",
    "title": "Undermining competition, undermining markets? Implications of Big Tech and digital personal data for competition policy",
    "abstract": "<jats:p> Many countries and jurisdictions are reforming their competition policies in response to growing political and public concerns about market concentration, especially when it comes to the market power of Big Tech firms. A particular concern is the new dynamics in market competition resulting from the rise of digital personal data as the key resource or asset underpinning our economies. Our aim in this paper is to examine the competition policy investigations, proposals, and reforms emerging around the world in order to analyse the policy implications of digital personal data to market competition regimes. Our methodological approach entailed an analysis of policy materials (written in English) produced in various jurisdictions or by international institutions dealing with competition policy. We identified the underlying policy themes, concerns, and processes across these different jurisdictions and institutions in order to understand their concerns about how Big Tech and personal data affect competition and competition policy. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241311584",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Kean Birch",
        "‘Damola Adediji"
      ],
      "url": "https://doi.org/10.1177/20539517241311584",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 71,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c69293bb-68a8-4ede-bdfb-1f5347833302",
    "title": "Mapping the discursive landscape of data activism: Articulations and actors in an emerging movement",
    "abstract": "<jats:p> Growing awareness of the societal consequences of datafication in recent years has given rise to a new form of civil society engagement called data activism. This article examines the discourse surrounding data activism on the social media platform Twitter. Through a mixed-methods approach combining computational analysis of Twitter content and close readings of Twitter profiles, we explore how new forms of civil society action related to data justice are articulated and linked to other forms of activism, conflicts and problems, and the actors involved in these articulations. Our analysis reveals a distinction between two articulatory patterns in the data activism discourse. The first involves grassroots actors, such as community organisations and individual citizens, who challenge existing power structures and advocate for social change. The second, on the other hand, is associated with academics, capitalists and policymakers who already hold positions of power and influence. This asymmetry is consistent with previous findings in data activism research. We encourage future research to extend these patterns, using additional methods and case studies, to further refine and contextualise the understanding of data activism within the civil society realm. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241266416",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Agnes Liminga",
        "Simon Lindgren"
      ],
      "url": "https://doi.org/10.1177/20539517241266416",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 77,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a8fce201-c5ca-4a09-89f4-6a427ff0b624",
    "title": "Profile characteristics of fake Twitter accounts",
    "abstract": "<jats:p> In online social networks, the audience size commanded by an organization or an individual is a critical measure of that entity’s popularity and this measure has important economic and/or political implications. Such efforts to measure popularity of users or exploit knowledge about their audience are complicated by the presence of fake profiles on these networks. In this study, analysis of 62 million publicly available Twitter user profiles was conducted and a strategy to identify automatically generated fake profiles was established. Using a combination of a pattern-matching algorithm on screen-names and an analysis of update times, a reasonable number (∼0.1% of total users) of highly reliable fake user accounts were identified. Analysis of profile creation times and URLs of these fake accounts revealed their distinct behavior relative to a ground truth data set. The characteristics of friends and followers of users in the two data sets further revealed the very different nature of the two groups. The ratio of number of followers-to-friends for ground truth users was ∼1, consistent with past observations, while the fake profiles had a median ratio ∼30, indicating that the fake users we identified were primarily focused on gathering friends. An analysis of the temporal evolution of accounts over 2 years showed that the friends-to-followers ratio increased over time for fake profiles while they decreased for ground truth users. Our results, thus, suggest that a profile-based approach can be used for identifying a core set of fake online social network users in a time-efficient manner. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716674236",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Supraja Gurajala",
        "Joshua S White",
        "Brian Hudson",
        "Brian R Voter",
        "Jeanna N Matthews"
      ],
      "url": "https://doi.org/10.1177/2053951716674236",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 24,
      "is_referenced_by_count": 51,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "97717428-6362-4320-bc48-9f01e1495135",
    "title": "The revolution that did not happen: Telematics and car insurance in the 2010s",
    "abstract": "<jats:p> Attempts to use Big Data to transform car insurance pricing in France have failed. Why? Three possible explanations are discussed: organisational and cognitive inertia, normative preventions, and deliberate strategy. This article finds that moral or political reluctance has played only a secondary role in the failure of telematics devices. More important has been the deployment of an experimental strategy that has resulted in the conclusion that in the short and medium term at least, the use of big data to rate car insurance is not profitable. There are too many organisational and cognitive barriers to the smooth adoption of innovation. All insurers note they all arrived at this conclusion. An implicit consensus therefore remains to retain the old business model. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221142033",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Pierre Francois",
        "Théo Voldoire"
      ],
      "url": "https://doi.org/10.1177/20539517221142033",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 42,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d7301f65-2a06-4796-a445-dd609b4c269b",
    "title": "Commercial genetic information and criminal investigations: The case for social privacy",
    "abstract": "<jats:p> Taking a DNA test with a commercial company is an increasingly popular enterprise, with tens of millions of consumers worldwide. In recent years, these genetic databases have also been used for so-called investigative genetic genealogy (IGG): uploading a crime scene DNA sample in these databases to find a distant relative of the unknown suspect. This forensic use of genetic consumer information has already helped solve many crimes. The debate on IGG tends to focus on individual rights and values, such as individual consent, individual control over information, and – perhaps most prominently – individual privacy. In this paper, I propose to approach IGG through the lens of privacy's social value, in contrast to merely its individual value. First, I discuss the conceptualization of privacy as a social value. Next, I explore several issues of IGG that privacy's social value allows consideration for: the informational and decisional interconnectedness, the risk of a tyranny of the minority, the involvement of multiple contexts, and the relationship between citizens and state. I conclude that this approach offers a fruitful perspective to evaluate the ethical and social desirability of IGG, evading the simplified dichotomy between individual privacy versus the security of society, in which the former will almost automatically lose. A focus on privacy's social value recognizes the effects for society on both sides of the balance. It brings into the light fundamental ethical, social, and political concerns of IGG, that extend beyond individual data control or consent. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231216957",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Nina F. de Groot"
      ],
      "url": "https://doi.org/10.1177/20539517231216957",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 77,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b5818fdb-07b7-4b9e-8421-d0534df86c7f",
    "title": "Chinese sociotechnical imaginaries of Earth observation: From sight to foresight",
    "abstract": "<jats:p>Although Earth observation (EO) is considered a universal scientific technique with a hegemonic gaze, national sociotechnical imaginaries shape its practice. Historically established and organized by national governments, EO, which is commonly pursued via satellite remote sensing, depends on domestic perceptions of the technique's scope and applications. EO is also a political technology with the capacity to mediate and potentially regulate life on Earth at a range of scales. In China, the state and scientists endeavor to transform EO into a data-driven, inductive, and predictive method with a focus on social coordination, especially in cities—a key scale for scientific study and the organization and reproduction of state power. Contributing to China's reimagining of EO as a governance and governmentality tool are advances in social sensing, which leverages big data continuously generated by individuals’ devices. By analyzing big EO and social data, rather than only observe past and present changes to the Earth's surface, the Chinese state and scientists seek to predict future social events. While these changes are narrated as a popularization of remote sensing enabling more responsive, human-centric governance, they may augur the rise of antipolitical technologies that attempt to prevent dissent by determining and even guiding future behavior. As China, a satellite power, aims to export its services for observing and predicting Earth and upscale them through global governance, critique of their associated sociotechnical imaginaries is crucial. Such research reveals the heterogeneity of the satellite gaze and may identify where and how people hold power within EO systems.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231191527",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Mia M Bennett"
      ],
      "url": "https://doi.org/10.1177/20539517231191527",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 122,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b648fd97-bc4e-477f-a16a-8d8e3c9c5d40",
    "title": "Diversity in sociotechnical machine learning systems",
    "abstract": "<jats:p> There has been a surge of recent interest in sociocultural diversity in machine learning research. Currently, however, there is a gap between discussions of measures and benefits of diversity in machine learning, on the one hand, and the broader research on the underlying concepts of diversity and the precise mechanisms of its functional benefits, on the other. This gap is problematic because diversity is not a monolithic concept. Rather, different concepts of diversity are based on distinct rationales that should inform how we measure diversity in a given context. Similarly, the lack of specificity about the precise mechanisms underpinning diversity’s potential benefits can result in uninformative generalities, invalid experimental designs, and illicit interpretations of findings. In this work, we draw on research in philosophy, psychology, and social and organizational sciences to make three contributions: First, we introduce a taxonomy of different diversity concepts from philosophy of science, and explicate the distinct epistemic and political rationales underlying these concepts. Second, we provide an overview of mechanisms by which diversity can benefit group performance. Third, we situate these taxonomies of concepts and mechanisms in the lifecycle of sociotechnical machine learning systems and make a case for their usefulness in fair and accountable machine learning. We do so by illustrating how they clarify the discourse around diversity in the context of machine learning systems, promote the formulation of more precise research questions about diversity’s impact, and provide conceptual tools to further advance research and practice. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221082027",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Sina Fazelpour",
        "Maria De-Arteaga"
      ],
      "url": "https://doi.org/10.1177/20539517221082027",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 74,
      "is_referenced_by_count": 21,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ea79cece-c912-499e-a791-5eda7e5152b7",
    "title": "Algorithmic rationality: Epistemology and efficiency in the data sciences",
    "abstract": "<jats:p> Recently, philosophers and social scientists have turned their attention to the epistemological shifts provoked in established sciences by their incorporation of big data techniques. There has been less focus on the forms of epistemology proper to the investigation of algorithms themselves, understood as scientific objects in their own right. This article, based upon 12 months of ethnographic fieldwork with Russian data scientists, addresses this lack through an investigation of the specific forms of epistemic attention paid to algorithms by data scientists. On the one hand, algorithms are unlike other mathematical objects in that they are not subject to disputation through deductive proof. On the other hand, unlike concrete things in the world such as particles or organisms, algorithms cannot be installed as the objects of experimental systems directly. They can only be evaluated in their functioning as components of extended computational assemblages; on their own, they are inert. As a consequence, the epistemological coding proper to this evaluation does not turn on truth and falsehood but rather on the efficiency of a given algorithmic assemblage. This article suggests that understanding the forms of algorithmic rationality employed in such inquiry is crucial for charting the place of data science within the contemporary academy and knowledge economy more generally. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717700925",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Ian Lowrie"
      ],
      "url": "https://doi.org/10.1177/2053951717700925",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 52,
      "is_referenced_by_count": 39,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f4b1d713-92a3-43fb-8106-fbf301af20f4",
    "title": "Crowd-sourcing the smart city: Using big geosocial media metrics in urban governance",
    "abstract": "<jats:p> Using Big Data to better understand urban questions is an exciting field with challenging methodological and theoretical problems. It is also, however, potentially troubling when Big Data (particularly derived from social media) is applied uncritically to urban governance via the ideas and practices of “smart cities”. This essay reviews both the historical depth of central ideas within smart city governance —particular the idea that enough data/information/knowledge can solve society problems—but also the ways that the most recent version differs. Namely, that the motivations and ideological underpinning behind the goal of urban betterment is largely driven by technology advocates and neoliberalism rather than the strong social justice themes associated with earlier applications of data to cities. Geosocial media data and metrics derived from them can provide useful insight and policy direction. But one must be ever mindful that metrics don’t simply measure; in the process of deciding what is important and possible to measure, these data are simultaneously defining what cities are. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717694384",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Matthew Zook"
      ],
      "url": "https://doi.org/10.1177/2053951717694384",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 84,
      "is_referenced_by_count": 60,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "77121978-6d12-4091-a652-6010ec17d1ed",
    "title": "Opening the black box of data-based school monitoring: Data infrastructures, flows and practices in state education agencies",
    "abstract": "<jats:p> Contributing to a rising number of Critical Data Studies which seek to understand and critically reflect on the increasing datafication and digitalisation of governance, this paper focuses on the field of school monitoring, in particular on digital data infrastructures, flows and practices in state education agencies. Our goal is to examine selected features of the enactment of datafication and, hence, to open up what has widely remained a black box for most education researchers. Our findings are based on interviews conducted in three state education agencies in two different national contexts (the US and Germany), thus addressing the question of how the datafication and digitalisation of school governance has not only manifested within but also across educational contexts and systems. As our findings illustrate, the implementation of data-based school monitoring and leadership in state education agencies appears as a complex entanglement of very different logics, practices and problems, producing both new capabilities and powers. Nonetheless, by identifying different types of ‘doing data discrepancies’ reported by our interviewees, we suggest an analytical heuristic to better understand at least some features of the multifaceted enactment of data-based, increasingly digitalised governance, within and beyond the field of education. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719853311",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Sigrid Hartong",
        "Annina Förschler"
      ],
      "url": "https://doi.org/10.1177/2053951719853311",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 38,
      "is_referenced_by_count": 50,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "dc3a9d90-6813-432e-927b-770dbb0327b6",
    "title": "What is responsible and sustainable data science?",
    "abstract": "<jats:p> In the expansion of health ecosystems, issues of responsibility and sustainability of the data science involved are central. The idea that these values should be central to the practice of data science is increasingly gaining traction, yet there is no agreement on what exactly makes data science responsible or sustainable because these concepts prove slippery when applied to a global field involving commercial, academic and governmental actors. This lack of clarity is causing problems in setting goals and boundaries for data scientific practice, and risks fundamental disagreement on governance principles for this emerging field. We will argue in this commentary for a commons analytical framework as one approach to this problem, since it offers useful signposts for how to establish governance principles for shared resources. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719858114",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Linnet Taylor",
        "Nadezhda Purtova"
      ],
      "url": "https://doi.org/10.1177/2053951719858114",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171985811",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 16,
      "is_referenced_by_count": 22,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "897725b6-5b12-4f8e-ab86-fc481d39037d",
    "title": "Virtual, visible, and actionable: Data assemblages and the sightlines of justice",
    "abstract": "This paper explores the politics of representing events in the world in the form of data points, data sets, or data associations. Data collection involves an act of seeing and recording something that was previously hidden and possibly unnamed. The incidences included in a data set are not random or unrelated but stand for coherent, classifiable phenomena in the world. Moreover, for data to have an impact on law and policy, such information must be seen as actionable, that is, the aggregated data must show people both something they can perceive and something that demands interrogation, explanation, or resolution. Actionable data problematize the taken-for-granted order of society by pointing to questions or imbalances that can be corrected or rectified, or simply better understood, through systematic compilations of occurrences, frequencies, distributions, or correlations. The paper describes and analyzes three different modes of authorized seeing that render data on global environmental phenomena such as climate change both visible and actionable. It argues that the political force of environmental data compilations derives from the divergent epistemological standpoints and expert practices associated with producing views from nowhere, everywhere, and somewhere.",
    "metadata": {
      "doi": "10.1177/2053951717724477",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Sheila Jasanoff"
      ],
      "url": "https://doi.org/10.1177/2053951717724477",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171772447",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 51,
      "is_referenced_by_count": 93,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bb050a2b-4b1e-430c-beb2-af4c815b95c9",
    "title": "When digital health meets digital capitalism, how many common goods are at stake?",
    "abstract": "<jats:p> In recent years, all major consumer technology corporations have moved into the domain of health research. This ‘Googlization of health research’ (‘GHR’) begs the question of how the common good will be served in this research. As critical data scholars contend, such phenomena must be situated within the political economy of digital capitalism in order to foreground the question of public interest and the common good. Here, trends like GHR are framed within a double, incommensurable logic, where private gain and economic value are pitted against public good and societal value. While helpful for highlighting the exploitative potential of digital capitalism, this framing is limiting, insofar as it acknowledges only one conception of the common good. This article uses the analytical framework of modes of justification developed by Boltanksi and Thévenot to identify a plurality of orders of worth and conceptualizations of the common good at work in GHR. Not just the ‘civic’ (doing good for society) and ‘market’ (enhancing wealth creation) orders, but also an ‘industrial’ (increasing efficiency), a ‘project’ (innovation and experimentation), and what I call a ‘vitalist’ (proliferating life) order. Using promotional material of GHR initiatives and preliminary interviews with participants in GHR projects, I ask what moral orientations guide different actors in GHR. Engaging seriously with these different conceptions of the common good is paramount. First, in order to critically evaluate them and explicate what is at stake in the move towards GHR, and ultimately, in order to develop viable governance solutions that ensure strong ‘civic’ components. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718819032",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Tamar Sharon"
      ],
      "url": "https://doi.org/10.1177/2053951718819032",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 64,
      "is_referenced_by_count": 95,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b0e48680-32b7-4d45-b294-b3a55f1357be",
    "title": "Challenges in administrative data linkage for research",
    "abstract": "Linkage of population-based administrative data is a valuable tool for combining detailed individual-level information from different sources for research. While not a substitute for classical studies based on primary data collection, analyses of linked administrative data can answer questions that require large sample sizes or detailed data on hard-to-reach populations, and generate evidence with a high level of external validity and applicability for policy making. There are unique challenges in the appropriate research use of linked administrative data, for example with respect to bias from linkage errors where records cannot be linked or are linked together incorrectly. For confidentiality and other reasons, the separation of data linkage processes and analysis of linked data is generally regarded as best practice. However, the ‘black box’ of data linkage can make it difficult for researchers to judge the reliability of the resulting linked data for their required purposes. This article aims to provide an overview of challenges in linking administrative data for research. We aim to increase understanding of the implications of (i) the data linkage environment and privacy preservation; (ii) the linkage process itself (including data preparation, and deterministic and probabilistic linkage methods) and (iii) linkage quality and potential bias in linked data. We draw on examples from a number of countries to illustrate a range of approaches for data linkage in different contexts.",
    "metadata": {
      "doi": "10.1177/2053951717745678",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Katie Harron",
        "Chris Dibben",
        "James Boyd",
        "Anders Hjern",
        "Mahmoud Azimaee",
        "Mauricio L Barreto",
        "Harvey Goldstein"
      ],
      "url": "https://doi.org/10.1177/2053951717745678",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171774567",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 207,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "95f18647-7afd-47ce-819b-2426aee2e321",
    "title": "Prospecting (in) the data sciences",
    "abstract": "Data science is characterized by engaging heterogeneous data to tackle real world questions and problems. But data science has no data of its own and must seek it within real world domains. We call this search for data “prospecting” and argue that the dynamics of prospecting are pervasive in, even characteristic of, data science. Prospecting aims to render the data, knowledge, expertise, and practices of worldly domains available and tractable to data science method and epistemology. Prospecting precedes data synthesis, analysis, or visualization, and is constituted by the upstream work of discovering disordered or inaccessible data resources, thereafter to be ordered and rendered available for computation. Through this work, data science positions itself in the middle of all things—capable of engaging this, that, or any domain—and thus prospecting is a key driver of data science’s ongoing formation as a universal(izing) science.",
    "metadata": {
      "doi": "10.1177/2053951720906849",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Stephen C Slota",
        "Andrew S Hoffman",
        "David Ribes",
        "Geoffrey C Bowker"
      ],
      "url": "https://doi.org/10.1177/2053951720906849",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172090684",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 33,
      "is_referenced_by_count": 31,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b6853861-df60-4fa5-958c-faa9b92da61b",
    "title": "The virtue of simplicity: On machine learning models in algorithmic trading",
    "abstract": "<jats:p>Machine learning models are becoming increasingly prevalent in algorithmic trading and investment management. The spread of machine learning in finance challenges existing practices of modelling and model use and creates a demand for practical solutions for how to manage the complexity pertaining to these techniques. Drawing on interviews with quants applying machine learning techniques to financial problems, the article examines how these people manage model complexity in the process of devising machine learning-powered trading algorithms. The analysis shows that machine learning quants use Ockham’s razor – things should not be multiplied without necessity – as a heuristic tool to prevent excess model complexity and secure a certain level of human control and interpretability in the modelling process. I argue that understanding the way quants handle the complexity of learning models is a key to grasping the transformation of the human’s role in contemporary data and model-driven finance. The study contributes to social studies of finance research on the human–model interplay by exploring it in the context of machine learning model use.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720926558",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Kristian Bondo Hansen"
      ],
      "url": "https://doi.org/10.1177/2053951720926558",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172092655",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 64,
      "is_referenced_by_count": 48,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3d626594-32c0-4420-9ed7-34bfff7f4179",
    "title": "Surface and Sublevel Hate",
    "abstract": "<jats:p> On the face of it, contemporary “alt-tech” platforms appear more moderate than legacy hate havens. Yet it's also clear that virulent hate in the form of misogyny, white supremacy, and xenophobia has not disappeared. Probing this tension, this article conceptualizes two forms of hate: Surface “Hate” (moderate content that is highly visible and easily accessible) and Sublevel Hate (explicit content that is more marginal and less discernible). These terms are illustrated by examining several viral videos on Rumble. This twinned mechanism explains how alt-tech platforms can be both accessible and extreme at the same time. Stratified hate is strategic, heightening the appeal and durability of online communities. Recognizing this dangerous dynamic is key for interventions seeking to counter it. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221148136",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Luke Munn"
      ],
      "url": "https://doi.org/10.1177/20539517221148136",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 30,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "385dc79c-793d-43c4-a614-b1edd1632fc8",
    "title": "Big data surveillance across fields: Algorithmic governance for policing &amp; regulation",
    "abstract": "<jats:p> While the academic separation of policing and regulation is still largely operative, points of convergence are more significant than ever in the digital age, starting with concomitant debates about algorithms as a new figure of power. From the policing of illegal activities to the regulation of legal ones, the algorithmization of such critical social ordering practices has been the subject of growing attention. These burgeoning discussions are focused on one common element: big data surveillance. In accordance with such similarities and paralleled developments in policing and regulation, the article aims to further bridge the gap between literatures to respond to the calls for studying big data surveillance across institutional domains and social fields. To do so, it is focused on one case study that articulates algorithmic policing and regulation domains, in-between security and economic fields. This is the fight against illicit finance, i.e. ‘the global action against the financial flows that fuel crime and terrorism’. To what extent does big data surveillance make a difference in the main global policy of crime-fighting and financial regulation? Drawing on a fieldwork in a large North American bank, the present article takes stock of the algorithmic overlap between policing and regulation. It argues that the final result is policing and regulation of neither too much nor too little, which gives rise to automated and everyday mass surveillance while remaining as far removed from regulatory and crime-fighting ambitions as it is from dystopian visions of big data and algorithmic drama. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221112431",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Anthony Amicelle"
      ],
      "url": "https://doi.org/10.1177/20539517221112431",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "23eb6fa3-f8aa-4006-879d-bd4894efcdfa",
    "title": "Local government cultural economy data practices and futures: Capacity,  decision-making and partnerships",
    "abstract": "<jats:p> This article investigates local government cultural economy data practices in England (UK). Engaging with academic literature and policy reports, it highlights the following issues relating to these data practices: types of data; the context and drivers for using data; the possibilities and challenges of data volume; and training and expertise required to position data in relation to strategic decision-making. Engaging with the authors’ research project with local government councillors and data officers working in local authorities in England, this article provides insights into situated experiences and working contexts. The analysis reveals specific challenges and opportunities around resources and capacity, decision-making and partnerships. These data practices and challenges are critically examined through perspectives from critical data studies and the data feminism principles of context and visibility. Insights and issues are raised around decision-making, intuition and capacity, expertise and gatekeeping and more encompassing concerns around data characteristics and social power. In response, approaches from data literacy, namely data biographies, are explored to inform interventions into local government cultural economy data practices. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241285378",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Daniel Ashton",
        "Makanani Bell"
      ],
      "url": "https://doi.org/10.1177/20539517241285378",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7d0fd8ef-e7b8-485e-a7e8-ae5066395ec7",
    "title": "“Big data see through you”: Sexual identifications in an age of algorithmic recommendation",
    "abstract": "<jats:p> On Douyin, China's domestic version of TikTok, straight users are being recommended queer content, and videos created by straight men are being recommended to queer viewers. As Douyin recommends videos based on users’ online activities (e.g., liking, sharing, or spending time watching a video) and networks (e.g., connections made on the platform), sexuality comes to be algorithmically interpreted and defined. This process differs from an understanding of gender and sexuality as more or less fixed classifications that are the result of what people register when entering a platform concerning their gender and sexual identifications. This article analyzes viewers’ and creators’ experiences and reflections on the algorithmic grouping of sexual orientation and erotic curiosity through the relational lens of configurations. Using two years of online observational data and in-depth interviews with 18 Douyin users, both straight and same-sex orientated, we found that a language-centered, semiotic approach alone cannot assist in capturing the reconfiguration of sexual identifications presently occurring in China, and most likely elsewhere. Sexual identifications are the result of a relational process in which desires (regardless of sexual orientation) and intimacy, content creation and consumption, platform vernaculars and affordances, and data and algorithms converge and clash. This process allows for an erotic curiosity that has not yet been named or normalized in language systems and therefore reconfigures how sexual identity or orientation come to be understood in relation to the ever-increasing presence of computational power. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231215358",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Shuaishuai Wang",
        "Rachel Spronk"
      ],
      "url": "https://doi.org/10.1177/20539517231215358",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 46,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e5f48e0e-7c30-472b-9ee5-a44c3610f093",
    "title": "The sale of heritage on eBay: Market trends and cultural value",
    "abstract": "<jats:p> The marketisation of heritage has been a major topic of interest among heritage specialists studying how the online marketplace shapes sales. Missing from that debate is a large-scale analysis seeking to understand market trends on popular selling platforms such as eBay. Sites such as eBay can inform what heritage items are of interest to the wider public, and thus what is potentially of greater cultural value, while also demonstrating monetary value trends. To better understand the sale of heritage on eBay’s international site, this work applies named entity recognition using conditional random fields, a method within natural language processing, and word dictionaries that inform on market trends. The methods demonstrate how Western markets, particularly the US and UK, have dominated sales for different cultures. Roman, Egyptian, Viking (Norse/Dane) and Near East objects are sold the most. Surprisingly, Cyprus and Egypt, two countries with relatively strict prohibition against the sale of heritage items, make the top 10 selling countries on eBay. Objects such as jewellery, statues and figurines, and religious items sell in relatively greater numbers, while masks and vessels (e.g. vases) sell at generally higher prices. Metal, stone and terracotta are commonly sold materials. More rare materials, such as those made of ivory, papyrus or wood, have relatively higher prices. Few sellers dominate the market, where in some months 40% of sales are controlled by the top 10 sellers. The tool used for the study is freely provided, demonstrating benefits in an automated approach to understanding sale trends. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720968865",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Mark Altaweel",
        "Tasoula Georgiou Hadjitofi"
      ],
      "url": "https://doi.org/10.1177/2053951720968865",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 55,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5466bc22-a2cf-474a-8e94-19fa7eb29e70",
    "title": "Beyond mystery: Putting algorithmic accountability in context",
    "abstract": "<jats:p> Critical algorithm scholarship has demonstrated the difficulties of attributing accountability for the actions and effects of algorithmic systems. In this commentary, we argue that we cannot stop at denouncing the lack of accountability for algorithms and their effects but must engage the broader systems and distributed agencies that algorithmic systems exist within; including standards, regulations, technologies, and social relations. To this end, we explore accountability in “the Generated Detective,” an algorithmically generated comic. Taking up the mantle of detectives ourselves, we investigate accountability in relation to this piece of experimental fiction. We problematize efforts to effect accountability through transparency by undertaking a simple operation: asking for permission to re-publish a set of the algorithmically selected and modified words and images which make the frames of the comic. Recounting this process, we demonstrate slippage between the “complication” of the algorithm and the obscurity of the legal and institutional structures in which it exists. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719826856",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Elizabeth Reddy",
        "Baki Cakici",
        "Andrea Ballestero"
      ],
      "url": "https://doi.org/10.1177/2053951719826856",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 28,
      "is_referenced_by_count": 22,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b4868c04-807c-43eb-bd88-f4ec0e690aad",
    "title": "Cleaning up data work: Negotiating meaning, morality, and inequality in  a tech startup",
    "abstract": "<jats:p> Data work—the routinized, information-processing operations that support artificial intelligence systems—has been portrayed as a source of both economic opportunity and exploitation. Existing research on the moral economy of data work focuses on platforms where individuals anonymously complete one-off projects for as little as one cent per task. However, data work is increasingly performed inside organizational settings to promote more consistent and accurate output. How do technologists and data workers construct and morally justify these arrangements? This article is based on 19 months of participant-observation research inside a San Francisco-based startup. Drawing on theories of relational work, I show how managers in San Francisco and contractors in the Philippines collaborated to “clean up” the morally questionable status of data work. Managers attempted to engineer interactions with data workers to emphasize fun and friendship while obscuring vast inequalities. Filipino data workers framed American managers as benevolent patrons and themselves as grateful clients to reinforce managers’ sense of responsibility for their well-being. By shifting attention from the structure of roles to the structure of relationships in organization-based data work, this article demonstrates the function of culture and meaning-making in both generating reliable and accurate data and reproducing status hierarchies in the tech industry. Additionally, this article's examination of the complex and often contradictory dynamics of organizational attachment and marginalization has implications for debates about how the conditions of data work can be improved. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241285372",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Benjamin Shestakofsky"
      ],
      "url": "https://doi.org/10.1177/20539517241285372",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 44,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7438ef7d-9e44-4938-9866-0d97a272fe13",
    "title": "The locus of legitimate interpretation in Big Data sciences: Lessons for computational social science from -omic biology and high-energy physics",
    "abstract": "<jats:p> This paper argues that analyses of the ways in which Big Data has been enacted in other academic disciplines can provide us with concepts that will help understand the application of Big Data to social questions. We use examples drawn from our Science and Technology Studies (STS) analyses of -omic biology and high energy physics to demonstrate the utility of three theoretical concepts: (i) primary and secondary inscriptions, (ii) crafted and found data, and (iii) the locus of legitimate interpretation. These help us to show how the histories, organisational forms, and power dynamics of a field lead to different enactments of big data. The paper suggests that these concepts can be used to help us to understand the ways in which Big Data is being enacted in the domain of the social sciences, and to outline in general terms the ways in which this enactment might be different to that which we have observed in the ‘hard’ sciences. We contend that the locus of legitimate interpretation of Big Data biology and physics is tightly delineated, found within the disciplinary institutions and cultures of these disciplines. We suggest that when using Big Data to make knowledge claims about ‘the social’ the locus of legitimate interpretation is more diffuse, with knowledge claims that are treated as being credible made from other disciplines, or even by those outside academia entirely. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718768831",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Andrew Bartlett",
        "Jamie Lewis",
        "Luis Reyes-Galindo",
        "Neil Stephens"
      ],
      "url": "https://doi.org/10.1177/2053951718768831",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 104,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2313bb75-7f8b-458c-a998-ecd2c73cb70a",
    "title": "Big Data and the brave new world of social media research",
    "abstract": "<jats:p> The recent Facebook study about emotional contagion has generated a high-profile debate about the ethical and social issues in Big Data research. These issues are not unprecedented, but the debate highlighted that, in focusing on research ethics and the legal issues about this type of research, an important larger picture is overlooked about the extent to which free will is compatible with the growth of deterministic scientific knowledge, and how Big Data research has become central to this growth of knowledge. After discussing the ‘emotional contagion study’ as an illustration, these larger issues about Big Data and scientific knowledge are addressed by providing definitions of data, Big Data and of how scientific knowledge changes the human-made environment. Against this background, it will be possible to examine why the uses of data-driven analyses of human behaviour in particular have recently experienced rapid growth. The essay then goes on to discuss the distinction between basic scientific research as against applied research, a distinction which, it is argued, is necessary to understand the quite different implications in the context of scientific as opposed to applied research. Further, it is important to recognize that Big Data analyses are both enabled and constrained by the nature of data sources available. Big Data research is bound to become more widespread, and this will require more awareness on the part of data scientists, policymakers and a wider public about its contexts and often unintended consequences. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714563194",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "Ralph Schroeder"
      ],
      "url": "https://doi.org/10.1177/2053951714563194",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 48,
      "is_referenced_by_count": 88,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1ebb72dd-a138-49fd-b5c2-700913dffeb1",
    "title": "Big data for official migration statistics: Evidence from 29 national statistical institutions",
    "abstract": "<jats:p> International migration statistics suffer from extensive gaps and shortcomings. Recently, national statistical institutions (NSIs) have started using big data to complement traditional statistics, including on migration. Although these are promising developments, we still lack answers on the extent to which NSIs are currently using big data for migration and to what extent it complements the gaps in traditional data. We gathered data by interviewing experts from 29 NSIs to investigate how big data is used for official migration statistics. We show that 15 out of 29 NSIs either used big data for migration, had a pilot project or have been involved in joint initiatives. We reveal the specific implications of big data in human migration (e.g. internal mobility, stocks, flows and mobility patterns, among others and the most common sources used to extract official statistics). Moreover, we discuss the challenges and barriers preventing NSIs from using such data. Factors deterring countries from utilising big data include limited data accessibility, an absence of legal frameworks for big data usage, ethical concerns, the possession of already high-quality data, a deficit in expertise and methodologies and a lack of perceived necessity for supplementary data or approaches. Moreover, many countries did not know which data to use and were concerned about the quality and accuracy of such data. Legal barriers were more of an issue than the ethical aspects, and overall, participating countries believe that there is a high potential for big data in the future. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231210244",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Ahmad Wali Ahmad Yar",
        "Tuba Bircan"
      ],
      "url": "https://doi.org/10.1177/20539517231210244",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 38,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "15bb8c03-6487-489e-a31d-856acb0f3b81",
    "title": "Studying the COVID-19 infodemic at scale",
    "abstract": "<jats:p> This special theme issue of Big Data &amp; Society presents leading-edge, interdisciplinary research that focuses on examining how health-related (mis-)information is circulating on social media. In particular, we are focusing on how computational and Big Data approaches can help to provide a better understanding of the ongoing COVID-19 infodemic (overexposure to both accurate and misleading information on a health topic) and to develop effective strategies to combat it. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211021115",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Anatoliy Gruzd",
        "Manlio De Domenico",
        "Pier Luigi Sacco",
        "Sylvie Briand"
      ],
      "url": "https://doi.org/10.1177/20539517211021115",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 32,
      "is_referenced_by_count": 29,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "838f47f0-40f3-41ae-826f-6c4e5c556a49",
    "title": "Visual Geolocations. Repurposing online data to design alternative views",
    "abstract": "<jats:p> Data produced by humans and machines is more and more heterogeneous, visual, and location based. This availability inspired in the last years a number of reactions from researchers, designers, and artists that, using different visual manipulations techniques, have attempted at repurposing this material to add meaning and design new perspectives with specific intentions. Three different approaches are described here: the design of interfaces for exploring satellite footage in novel ways, the analysis of urban esthetics through the visual manipulation of collections of user-generated contents, and the enrichment of geo-based datasets with the selection and rearrangement of web imagery. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717702409",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Gabriele Colombo",
        "Paolo Ciuccarelli",
        "Michele Mauri"
      ],
      "url": "https://doi.org/10.1177/2053951717702409",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 21,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d5f10d60-caa8-4b6f-97a1-20d958ceb0a6",
    "title": "The data will not save us: Afropessimism and racial antimatter in the COVID-19 pandemic",
    "abstract": "<jats:p> The Trump Administration's governance of COVID-19 racial health disparities data has become a key front in the viral war against the pandemic and racial health injustice. In this paper, I analyze how the COVID-19 pandemic joins an already ongoing racial spectacle and system of structural gaslighting organized around “racial health disparities” in the United States and globally. The field of racial health disparities has yet to question the domain assumptions that uphold its field of investigation; as a result, the entire reform program called for by racial health disparities science is already featured on the menu of the white supremacist power structure. The societal infrastructure that produces scientific knowledge about patterns of health and disease in the human population needs to confront its structural position as part of the racial spectacle organized around racial health disparities in the United States. This paper offers an interpretation of racial antimatter to explain why the data will not save us in the COVID-19 pandemic, drawing on articulations of racial spectacle and structural gaslighting within critical race theory and Afropessimist thought. By positioning events in the COVID-19 pandemic together within the same racially speculative frame, I show how the collection of racial health disparities data came up against white supremacists’ political ambitions in a time-space where the demand for human life to matter and the iterative regeneration of racial antimatter collided. This paper highlights the need for ongoing analysis of the unfolding and future spectacles organized around racial health disparities. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211067948",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Anthony Ryan Hatch"
      ],
      "url": "https://doi.org/10.1177/20539517211067948",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 106,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a57d2179-f5db-4d80-8d8b-d971ee04322a",
    "title": "Algorithmic empowerment: A comparative ethnography  of two open-source algorithmic  platforms – Decide Madrid and vTaiwan",
    "abstract": "<jats:p> Scholars of critical algorithmic studies, including those from geography, anthropology, Science and Technology Studies and communication studies, have begun to consider how algorithmic devices and platforms facilitate democratic practices. In this article, I draw on a comparative ethnography of two alternative open-source algorithmic platforms – Decide Madrid and vTaiwan – to consider how they are dynamically constituted by differing algorithmic–human relationships. I compare how different algorithmic–human relationships empower citizens to influence political decision-making through proposing, commenting, and voting on the urban issues that should receive political resources in Taipei and Madrid. I argue that algorithmic empowerment is an emerging process in which algorithmic–human relationships orient away from limitations and towards conditions of plurality, actionality, and power decentralisation. This argument frames algorithmic empowerment as bringing about empowering conditions that allow (underrepresented) individuals to shape policy-making and consider plural perspectives for political change and action, not as an outcome-driven, binary assessment (i.e. yes/no). This article contributes a novel, situated, and comparative conceptualisation of algorithmic empowerment that moves beyond technological determinism and universalism. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221123505",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Yu-Shan Tseng"
      ],
      "url": "https://doi.org/10.1177/20539517221123505",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 69,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f85706d5-5c67-4dcc-a8f9-f8cfc714a09c",
    "title": "A science that knows no country: Pandemic preparedness, global risk, sovereign science",
    "abstract": "This paper examines political norms and relationships associated with governance of pandemic risk. Through a pair of linked controversies over scientific access to H5N1 flu virus and genomic data, it examining the duties, obligations, and allocations of authority articulated around the imperative for globally free-flowing information and around the corollary imperative for a science that is set free to produce such information. It argues that scientific regimes are laying claim to a kind of sovereignty, particularly in moments where scientific experts call into question the legitimacy of claims grounded in national sovereignty, by positioning the norms of scientific practice, including a commitment to unfettered access to scientific information and to the authority of science to declare what needs to be known, as essential to global governance. Scientific authority occupies a constitutional position insofar as it figures centrally in the repertoire of imaginaries that shape how a global community is imagined: what binds that community together and what shared political commitments, norms, and subjection to delegated authority are seen as necessary for it to be rightly governed.",
    "metadata": {
      "doi": "10.1177/2053951717742417",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "J Benjamin Hurlbut"
      ],
      "url": "https://doi.org/10.1177/2053951717742417",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171774241",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 36,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0444a3a0-844d-47d8-84fb-fa451ae935af",
    "title": "Freezing out: Legacy media's shaping of AI as a cold controversy",
    "abstract": "<jats:p>Mainstream coverage of artificial intelligence often appears to emphasise the technologies’ benefit and economic potential over its growing downsides. How does a technology poised to be so disruptive become so uncritically embraced? Why is it, simply put, that artificial intelligence's representations in legacy media do not normally convey the controversialities otherwise found in research or policy debates? We introduce the concept of ‘freezing out’ to describe processes of translation that cool down debates over the merits of technology. Freezing out looks at the other side of controversy studies to study the production of uncontroversies or cold controversies rather than hot topics and debates. We use the coverage of artificial intelligence in Canadian national news outlets to analyse how controversiality becomes ‘frozen out’. Since Canadian academics won the prestigious ImageNet prize in 2012 introducing the modern turn toward machine learning approaches, Canada has promoted itself as a global leader. Using in-depth interviews with Francophone and Anglophone journalists as well as topic modelling on data collected from five major newspapers, we find that routine news making processes between journalists, experts, entrepreneurs, and governments build, maintain, and promote Canada's artificial intelligence ecosystem. Freezing out contributes to a broader interest in how heterogeneous actors traverse their domain of expertise across policy, media, and research circles to cool down artificial intelligence controversies.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231219242",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Guillaume Dandurand",
        "Fenwick McKelvey",
        "Jonathan Roberge"
      ],
      "url": "https://doi.org/10.1177/20539517231219242",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 74,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d53e8afe-f221-4969-b7fb-9200299f8974",
    "title": "Re-integrating scholarly infrastructure: The ambiguous role of data sharing platforms",
    "abstract": "<jats:p> Web-based platforms play an increasingly important role in managing and sharing research data of all types and sizes. This article presents a case study of the data storage, sharing, and management platform Figshare. We argue that such platforms are displacing and reconfiguring the infrastructure of norms, technologies, and institutions that underlies traditional scholarly communication. Using a theoretical framework that combines infrastructure studies with platform studies, we show that Figshare leverages the platform logic of core and complementary components to re-integrate a presently splintered scholarly infrastructure. By means of this logic, platforms may provide the path to bring data inside a scholarly communication system still optimized mainly for text publications. Yet the platform strategy also risks turning over critical scientific functions to private firms whose longevity, openness, and corporate goals remain uncertain. It may amplify the existing trend of splintering infrastructures, with attendant effects on equity of service. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718756683",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Jean-Christophe Plantin",
        "Carl Lagoze",
        "Paul N Edwards"
      ],
      "url": "https://doi.org/10.1177/2053951718756683",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 73,
      "is_referenced_by_count": 35,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f58255c7-dbe9-42df-8e09-e00c1aed7ac3",
    "title": "The urban geographical imagination in the age of Big Data",
    "abstract": "<jats:p> This paper explores the variety of ways that emerging sources of (big) data are being used to re-conceptualize the city, and how these understandings of what the urban is shapes the design of interventions into it. Drawing on work on the performativity of economics, this paper uses two vignettes of the ‘new urban science’ and municipal vacant property mapping in order to argue that the mobilization of Big Data in the urban context doesn’t necessarily produce a single, greater understanding of the city as it actually is, but rather a highly variegated series of essentialized understandings of the city that render it knowable, governable and intervene-able. Through the construction of new, data-driven urban geographical imaginaries, these projects have opened up the space for urban interventions that work to depoliticize urban injustices and valorize new kinds of technical expertise as the means of going about solving these problems, opening up new possibilities for a remaking of urban space in the image of these sociotechnical paradigms. Ultimately, this paper argues that despite the importance of Big Data, as both a discourse and practice, to emerging forms of urban research and management, there is no singular or universal understanding of the urban that is promoted or developed through the application of these new sources of data, which in turn opens up meaningful possibilities for developing alternative uses of Big Data for understanding and intervening in the city in more emancipatory ways. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716665129",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Taylor Shelton"
      ],
      "url": "https://doi.org/10.1177/2053951716665129",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 87,
      "is_referenced_by_count": 32,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5a7fffe1-07b5-4b58-81af-5fbacf1200b3",
    "title": "The city as a license: Design, rights and civics in a blockchain society",
    "abstract": "",
    "metadata": {
      "doi": "10.1177/20539517241227902",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Martijn de Waal",
        "Gabriele Ferri",
        "Inte Gloerich",
        "John Vines",
        "Chris Elsden"
      ],
      "url": "https://doi.org/10.1177/20539517241227902",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 48,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "not available"
    }
  },
  {
    "id": "250e5403-4698-4fa3-ada6-e5b5585c421d",
    "title": "Digital epidemiology, deep phenotyping and the enduring fantasy of pathological omniscience",
    "abstract": "<jats:p> Epidemiology is a field torn between practices of surveillance and methods of analysis. Since the onset of COVID-19, epidemiological expertise has been mostly identified with the first, as dashboards of case and mortality rates took centre stage. However, since its establishment as an academic field in the early 20th century, epidemiology’s methods have always impacted on how diseases are classified, how knowledge is collected, and what kind of knowledge was considered worth keeping and analysing. Recent advances in digital epidemiology, this article argues, are not just a quantitative expansion of epidemiology’s scope, but a qualitative extension of its analytical traditions. Digital epidemiology is enabled by deep and digital phenotyping, the large-scale re-purposing of any data scraped from the digital exhaust of human behaviour and social interaction. This technological innovation is in need of critical examination, as it poses a significant epistemic shift to the production of pathological knowledge. This article offers a critical revision of the key literature in this budding field to underline the extent to which digital epidemiology is envisioned to redefine the classification and understanding of disease from the ground up. Utilising analytical tools from science and technology studies, the article demonstrates the disruptive expectations built into this expansion of epidemiological surveillance. Given the sweeping claims and the radical visions articulated in the field, the article develops a tentative critique of what I call a fantasy of pathological omniscience; a vision of how data-driven engineering seeks to capture and resolve illness in the world, past, present and future. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211066451",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Lukas Engelmann"
      ],
      "url": "https://doi.org/10.1177/20539517211066451",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 71,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "297cc56d-23a5-45fc-9b40-d583db6addd4",
    "title": "The digital life of the #migrantcaravan: Contextualizing Twitter as a spatial technology",
    "abstract": "<jats:p> The Central American migrant caravans of 2018 are best understood as having been precipitated by entangled multi-scalar geopolitical histories among the United States, Mexico, Guatemala, Honduras, and El Salvador. Unsurprisingly, the migrants traveling north to the United States garnered widespread attention on social media. So much so that the reaction to the caravan accelerated plans to deploy troops to the US southern border and deny Central Americans the opportunity to seek asylum. This example showcases how the digital world can have exponential material effects. While coverage on border security and migration has been extensive, within political geography, such concerns have rarely been paired with social media. In this article, we take as our object of analysis the digitality or “digital life” of the migrant caravan. Mapping the patterns of migrant caravan-related tweeting paired with the exploration of Twitter’s networked dimensions reveals the platform to be a fundamentally spatial technology. Rather than reflect, refract or distort, Twitter produces and (its power) is in turn produced through spatial mechanisms. We present multiple cartographic visualizations in support of this claim and highlight the ways in which a contextual knowledge of the subject under study—the migrant caravan—can further inform analyses of Big Data. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720978485",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Margath A Walker",
        "Emmanuel Frimpong Boamah"
      ],
      "url": "https://doi.org/10.1177/2053951720978485",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 82,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4cad824f-0e51-40ee-9d9d-51d8126cbee5",
    "title": "Ethical scaling for content moderation: Extreme speech and the (in)significance  of artificial intelligence",
    "abstract": "<jats:p> In this article, we present new empirical evidence to demonstrate the severe limitations of existing machine learning content moderation methods to keep pace with, let alone stay ahead of, hateful language online. Building on the collaborative coding project “AI4Dignity” we outline the ambiguities and complexities of annotating problematic text in AI-assisted moderation systems. We diagnose the shortcomings of the content moderation and natural language processing approach as emerging from a broader epistemological trapping wrapped in the liberal-modern idea of “the human”. Presenting a decolonial critique of the “human vs machine” conundrum and drawing attention to the structuring effects of coloniality on extreme speech, we propose “ethical scaling” to highlight moderation process as political praxis. As a normative framework for platform governance, ethical scaling calls for a transparent, reflexive, and replicable process of iteration for content moderation with community participation and global parity, which should evolve in conjunction with addressing algorithmic amplification of divisive content and resource allocation for content moderation. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231172424",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Sahana Udupa",
        "Antonis Maronikolakis",
        "Axel Wisiorek"
      ],
      "url": "https://doi.org/10.1177/20539517231172424",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 52,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bc6e3ad1-b1d4-4ea6-a40f-26c0b795f159",
    "title": "Three fallacies of digital footprints",
    "abstract": "<jats:p> “Digital footprints” is an attractive, useful, and increasingly popular metaphor for thinking about Big Data. In this essay, I elaborate on this metaphor to highlight three relatively basic fallacies in the way we tend to think about Big Data: first, that they contain information on complete populations, or “ N = all”; second, that they contain recordings of naturalistic behavior; and third, that they can be understood devoid of context. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715602496",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Kevin Lewis"
      ],
      "url": "https://doi.org/10.1177/2053951715602496",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 17,
      "is_referenced_by_count": 24,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8d29ebc9-840a-41a0-821d-8a62762050b6",
    "title": "Linguistically guided community discovery",
    "abstract": "<jats:p> Within some online communities, discussion often centers on issues on which writers take sides, and within some subset of those debate-prone communities, we find over time that particular sets of writers almost always end up on the same side of an issue. These sets we call factions. In this paper, we describe a tool to perform what we call faction discovery on online communities. Generalizing methods developed in the bibliometrics and information retrieval literature, we define a network determined by similarities of content in a community of users and add in direct evidence of online ties between users (e.g., link information such as mention-links). We then perform community detection on the network to find factions. Using a set of data collected from science and fantasy blogs, we show that the discovered factions accurately reflect an active conflict in the community leading to significant, politically related social fracture. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719846634",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Jean M Gawron",
        "Alex Dodge",
        "Ming-Hsiang Tsou",
        "Brian Spitzberg",
        "Li An"
      ],
      "url": "https://doi.org/10.1177/2053951719846634",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 69,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c659188a-0739-428b-b257-b650dfe86c40",
    "title": "Is it about “them”? leveraging big data research to understand  anti-immigrant discourse",
    "abstract": "<jats:p> The paper explores the potential of big data analytics for researching anti-immigrant discourse. We emphasize contextualization as an essential element of research and follow a hybrid approach inspired by best practices of computational content analysis, combining human hermeneutic expertise with supervised machine learning to classify a corpus of comments in online news communities in Singapore over 6 months ( N = 399,225). The paper highlights how big data analytics can provide a nuanced and critical apprehension of immigrant-related discourse in large social media datasets. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241249432",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Claire Stravato Emes"
      ],
      "url": "https://doi.org/10.1177/20539517241249432",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 132,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4235c5c3-5259-4d62-9f65-c66f75a1b596",
    "title": "European artificial intelligence policy as digital single market making",
    "abstract": "<jats:p> Rapid innovation in digital services relying on artificial intelligence (AI) challenges existing regulations across a wide array of policy fields. The European Union (EU) has pursued a position as global leader on ethical AI regulation in explicit contrast to US laissez-faire and Chinese state surveillance approaches. This article asks how the seemingly heterogeneous approaches of market making and ethical AI are woven together at a deeper level in EU regulation. Combining quantitative analysis of all official EU documents on AI with in-depth reading of key reports, communications, and legislative corpora, we demonstrate that single market integration constitutes a fundamental but overlooked engine and structuring principle of new AI regulation. Under the influence of this principle, removing barriers to competition and the free flow of data, on the one hand, and securing ethical and responsible AI, on the other hand, are seen as compatible and even mutually reinforcing. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231153811",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Troels Krarup",
        "Maja Horst"
      ],
      "url": "https://doi.org/10.1177/20539517231153811",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 19,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4fb3e7bb-feda-43c8-a0bb-f2a5fb0af395",
    "title": "Platforms and hyper-choice on the World Wide Web",
    "abstract": "<jats:p> Choice is a sine qua non of contemporary life. From childhood until death, we are faced with an unending series of choices through which we cultivate a sense of self, govern conduct, and shape the future. Nowadays, individuals increasingly experience and enact consumer choice online through web-based platforms such as Yelp.com , TripAdvisor.com and Amazon.com . These platforms not only provide a sprawling array of goods and services to choose from, but also reviews, ratings and ranking devices and systems of classification to navigate this landscape of choice. This paper suggests a radical reconsideration of platform architectures and design features to consider how they reconfigure and respecify choice, ‘choosers’, and choice-making practices. Platforms are not simply cameras that present choice and enable comparisons between different options, but are more akin to engines that govern, drive and expand choice, configuring users within particular discourses, practices and subjectivities. In making sense of the entangled trajectories of consumer choice, platform architectures and Big Data, I suggest that ‘hyper-choice’ emerges as a condition of the contemporary platform-driven web. I examine hyper-choice not only in terms of the relationship between platforms and a growing abundance of choice, but more importantly how platforms reconfigure choice in ways that go beyond and fundamentally challenge existing understandings of what choice is, who and what is involved in producing knowledge about choice, and what it means to be a ‘chooser’. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718765878",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Timothy Graham"
      ],
      "url": "https://doi.org/10.1177/2053951718765878",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 50,
      "is_referenced_by_count": 19,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1196ac94-854b-45a0-bb6a-a1ca6c46bea8",
    "title": "Gender and the invisibility of care on Wikipedia",
    "abstract": "<jats:p> Digital platforms produce bias and inequality that have a significant impact on peoples’ sense of self, agency and life chances. Wikipedia has largely evaded the criticism of other algorithmic systems like Google search and training databases like ImageNet, but Wikipedia is a critical source of representation in our current era – not only because it is one of the world's most popular websites, but because its data are being used as training data for the AI systems that are increasingly used for decision-making. We conducted an analysis of Wikipedia biographies in a national context, comparing the temporality and subjects of notability between English Wikipedia and the Australian Honours system in order to understand Wikipedia's unique role in the production of notability over the site's 20-year history. Framing Wikipedia as an active producer (rather than a reflection) of notability, we demonstrate that women are more likely to be awarded a Wikipedia page after the award announcements or not at all if their contribution is for labour relating to the caring professions than if their service is for sports, arts and films, politics or the judiciary. We argue that Wikipedia's inability to recognise gendered care work as noteworthy is mirrored in its own practices. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231210276",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Heather Ford",
        "Tamson Pietsch",
        "Kelly Tall"
      ],
      "url": "https://doi.org/10.1177/20539517231210276",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 62,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2bd7cf4b-60ab-4ba8-8293-2790d88edb03",
    "title": "Data for queer lives: How LGBTQ gender and sexuality identities challenge norms of demographics",
    "abstract": "<jats:p> In this article, we argue that dominant norms of demographic data are insufficient for accounting for the complexities that characterize many lesbian, gay, bisexual, transgender, and queer (LGBTQ, or broadly “queer”) lives. Here, we draw from the responses of 178 people who identified as non-heterosexual or non-cisgender to demographic questions we developed regarding gender and sexual orientation. Demographic data commonly imagines identity as fixed, singular, and discrete. However, our findings suggest that, for LGBTQ people, gender and sexual identities are often multiple and in flux. An overwhelming majority of our respondents reported shifting in their understandings of their sexual identities over time. In addition, for many of our respondents, gender identity was made up of overlapping factors, including the relationship between gender and transgender identities. These findings challenge researchers to reconsider how identity is understood as and through data. Drawing from critical data studies, feminist and queer digital media studies, and social justice initiatives like Data for Black Lives, we call for a reimagining of identity-based data as “queer data” or “data for queer lives.” We offer also recommendations for researchers to develop more inclusive survey questions. At the same time, we address the ways that queer perspectives destabilize the underlying logics of data by resisting classification and “capture.” For marginalized people, the stakes of this work extend beyond academia, especially in the era of algorithms and big data when the issue of who is or is not “counted” profoundly affects visibility, access, and power in the digital realm. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720933286",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Bonnie Ruberg",
        "Spencer Ruelos"
      ],
      "url": "https://doi.org/10.1177/2053951720933286",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172093328",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 29,
      "is_referenced_by_count": 54,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "68ff71f8-cd1f-4be7-890b-ba71d4414bef",
    "title": "Recording the ethical provenance of data and automating data stewardship",
    "abstract": "<jats:p> Health organisations use numerous different mechanisms to collect biomedical data, to determine the applicable ethical, legal and institutional conditions of use, and to reutilise the data in accordance with the relevant rules. These methods and mechanisms differ from one organisation to another, and involve considerable specialised human labour, including record-keeping functions and decision-making committees. In reutilising data at scale, however, organisations struggle to meet demands for data interoperability and for rapid inter-organisational data exchange due to reliance on legacy paper-based records and on the human-initiated administration of accompanying permissions in data. The adoption of permissions-recording, and permissions-administration tools that can be implemented at scale across numerous organisations is imperative. Further, these must be implemented in a manner that does not compromise the nuanced and contextual adjudicative processes of research ethics committees, data access committees, and biomedical research organisations. The tools required to implement a streamlined system of biomedical data exchange have in great part been developed. Indeed, there remains but a small core of functions that must further be standardised and automated to enable the recording and administration of permissions in biomedical research data with minimal human effort. Recording ethical provenance in this manner would enable biomedical data exchange to be performed at scale, in full respect of the ethical, legal, and institutional rules applicable to different datasets. This despite foundational differences between the distinct legal and normative frameworks is applicable to distinct communities and organisations that share data between one another. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231163174",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Alexander Bernier",
        "Maili Raven-Adams",
        "Davide Zaccagnini",
        "Bartha M. Knoppers"
      ],
      "url": "https://doi.org/10.1177/20539517231163174",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 31,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3a9b807e-f5b4-4c90-8ebd-032df396792c",
    "title": "“Governing the urban commons”: DLT, institutions, and citizens in perspective",
    "abstract": "<jats:p> Borrowing from insights produced in urban planning, media and governance studies thereby leveraging the Ostrom-nian ideas of institutions and polycentricity, this paper examines how to govern commons in the smart city. It offers a reflection upon whether Distributed Ledger Technologies (DLTs) could be a key notion for the commons discourse which centers around stakeholders, self-organization, and a rights-based framework. By decentralizing ledgers and enabling the interoperability of the various interfaces, DLTs make records more accessible, exchanges more transparent, and reduce costs while increasing efficiency, and permit automation, therefore commoning interactions both offline and online are facilitated. We argue that the use of DLTs to preserve the spatiotemporal integrity of key urban spaces is a common value question that needs to be elucidated or renegotiated in order to provide any useful guidance to DLTs integrity-preserving potential. In doing so, we draw attention to DLT-based urban commons and urban governance, and point to inherent incompatibilities that may lead to radical and not-so-smooth changes in urban institutions, while providing a way of thinking which can move the smart city closer towards a values-centered process and away from a preoccupation with technology and efficiency. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231182391",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Le Anh Nguyen Long",
        "Shenja van der Graaf",
        "Athanasios Votsis"
      ],
      "url": "https://doi.org/10.1177/20539517231182391",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 124,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "22d1b069-d54c-4d8c-94d3-2e58fba716b8",
    "title": "Disability data and its situational and contextual irrationalities in the Global South",
    "abstract": "<jats:p> The inconsistent implementation of disability rights in crisis responses such as the recent COVID-19 pandemic has illuminated the double difficulty that persons with disabilities (PwD) must face. Ableism remains the basis for pandemic responses, leading to a range of irrationalities in collecting and using disability data during critical times. This commentary identifies situational and contextual rationalities in disability data collection and use in Global South. Through vignettes from Indonesia and Vietnam, this commentary illuminates the socio-technical and cultural infrastructure that perpetuates the obscurity of disability rights in the pandemic responses in, respectively, the largest democratic and socialist-communist countries in Southeast Asia. In addition to better listening to the voice of PwD, stronger engagement of organizations of PwD in policy making and programming is advocated for enabling more equitable pandemic preparedness, response, and recovery plans to manifest in future. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231160523",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Abdul Rohman",
        "Dyah Pitaloka",
        "Erlina Erlina",
        "Duy Dang",
        "Ade Prastyani"
      ],
      "url": "https://doi.org/10.1177/20539517231160523",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 15,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "67a7f943-0306-4ed6-ba27-0ad891e8caa3",
    "title": "Nothing new under the sun: Medical professional maintenance in the face of artificial intelligence's disruption",
    "abstract": "<jats:p> This paper follows the reaction of the radiology profession to artificial intelligence (AI). We examine the effort of radiology as a powerful medical specialty to maintain its professional jurisdiction while allowing AI's disruption. We study the discursive work of radiologists as evident in their academic publications. Our results suggest that radiologists hold simultaneously multiple perspectives in regard to AI, which allow them to be both conservative and innovative in their relations to it: accept it, subordinate it, reject it and surrender to it, all the same time. These perspectives are: (a) to integrate AI tools and skills into the radiology profession by cooperating and coproducing with AI experts while preserving the core values and structures of the radiology profession; (b) to absorb AI into radiology as (yet another) technology, subordinating it to radiologists’ authority; (c) to fight-off the threat made by AI by undermining the legitimacy and capabilities of AI in radiology and strengthening professional boundaries and (d) to assimilate the radiology profession into the field of AI. These perspectives enable radiologists as a powerful medical specialty to engage in a rhetorical dance with the equally powerful AI specialty and challenge techno-optimistic approaches to innovation. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231210269",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Netta Avnoon",
        "Amalya L Oliver"
      ],
      "url": "https://doi.org/10.1177/20539517231210269",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 93,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ee464bd6-0ecd-4617-a728-03d1da9f9bbb",
    "title": "Performative innovation: Data governance in China's fintech industries",
    "abstract": "<jats:p> The financial applications of data technology have enabled the rise of Chinese fintech industries. As part of people's everyday lives, fintech apps have helped companies collect vast amounts of user data for business profit and social good. This paper takes an open-systems approach to study the constructs of this emerging idea of data governance, particularly its operational logic, involved stakeholders, and socio-cultural consequences in the context of fintech industries in China. It asserts that data governance at the company level has been realized through three types of tasks: standardization, configuration, and monetization of big data. These tasks are oriented by the imperative of business innovation which is considered pivotal for the company to survive the competition. An ensemble of internal and external actors joined the governing process, but internal actors hold the stake. The goal of innovation drives the companies to speedily collect data from a wider variety of sources, thus having to establish more sophisticated systems to manage and utilize those data. These complicated systems, however, have urged the government to strengthen regulatory controls alongside the general support of business innovation. This study unveils the performative aspects of big-data-based innovation at fintech firms. It also helps to understand the pathology of the innovation-governance paradox shared in the data economy in the global context. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221123312",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Jing Wang"
      ],
      "url": "https://doi.org/10.1177/20539517221123312",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 54,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "89921c96-1799-4efd-be59-5c3ab6fd2acc",
    "title": "Datafied ageing futures: Regimes of anticipation and participatory futuring",
    "abstract": "<jats:p> With this paper we join others in their call to resist and challenge regimes of anticipations that suggest our futures are inevitably linked to certain imaginaries about data-driven systems. The future is not simply happening but is made now – through regimes of anticipation that shape our expectations, imaginaries, visions and hypes, and define what is thinkable and desirable. Who or what is able to claim the future is an exercise of power and a matter of social justice. However, current anticipations circulating about datafied futures are often determined by powerful social actors such as states or technology companies. In this paper, we explore how we might open up futures-making to different people in relation to futures of ageing. Central is the question of whether and how we can actually think (and imagine) outside of powerful anticipation regimes around the increasing spread and relevance of data-driven systems and/or ageist assumptions about how to ‘fix’ the problem of demographic ageing. We draw on data from a series of design fiction workshops with older adults, civil society organisations and civil servants in Germany, Austria and the UK. Our analysis explores how participatory futuring might allow participants to question their own assumptions and anticipations about the futures of data-driven technologies in ageing societies but that, due to ‘discursive closure’, this may not lead to radically different futures imaginaries. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241306363",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Juliane Jarke",
        "Helen Manchester"
      ],
      "url": "https://doi.org/10.1177/20539517241306363",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 66,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fb0c0505-b842-48a1-9b4c-66cd9a433407",
    "title": "Predicting ethnicity with first names in online social media networks",
    "abstract": "<jats:p> Social scientists increasingly use (big) social media data to illuminate long-standing substantive questions in social science research. However, a key challenge of analyzing such data is their lower level of individual detail compared to highly detailed survey data. This limits the scope of substantive questions that can be addressed with these data. In this study, we provide a method to upgrade individual detail in terms of ethnicity in data gathered from social media via the use of register data. Our research aim is twofold: first, we predict the most likely value of ethnicity, given one's first name, and second, we show how one can test hypotheses with the predicted values for ethnicity as an independent variable while simultaneously accounting for the uncertainty in these predictions. We apply our method to social network data collected from Facebook. We illustrate our approach and provide an example of hypothesis testing using our procedure, i.e., estimating the relation between predicted network ethnic homogeneity on Facebook and trust in institutions. In a comparison of our method with two other methods, we find that our method provides the most conservative tests of hypotheses. We discuss the promise of our approach and pinpoint future research directions. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718761141",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Bas Hofstra",
        "Niek C de Schipper"
      ],
      "url": "https://doi.org/10.1177/2053951718761141",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 68,
      "is_referenced_by_count": 18,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fc95f0ca-5b41-4215-8563-8ccd5057db14",
    "title": "Accounting for “the social” in contact tracing applications: The paradox  between public health governance and mistrust of government's data use",
    "abstract": "<jats:p> This essay adopts three accounts (sociological, neoliberal, and cybernetic) of “the social” to get a clearer picture of why there is a barrier faced by the government when implementing contact tracing mobile applications. In Hong Kong's context, the paradox involves declining trust of the government's protection of data privacy and growing concern about data surveillance since the 2019 social unrest I argue that exploring the idea of sociality is valuable in that it re-reconfigures the datafication of pandemic control by revealing different sets of social relations, particularly the asymmetrical power relation between the government and its people. The refusal to download or use the mobile app also shows that the public has a faith in human agency and human resistance in data-saturated cities. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211054277",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Yao-Tai Li"
      ],
      "url": "https://doi.org/10.1177/20539517211054277",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 22,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "889abd66-fcc6-49bd-97a8-d13f5d86fc2c",
    "title": "Based and confused: Tracing the political connotations of a memetic phrase across the web",
    "abstract": "<jats:p> Current research on the weaponisation of far-right discourse online has mostly focused on the dangers of normalising hate speech. However, this often operates on questionable assumptions about how far-right terms retain problematic meanings over time and across different platforms. Yet contextual meaning-change, we argue, is key to assessing the normalisation of problematic but fuzzy terms as they spread across the Web. To redress this, our article traces the changing meaning of the term based, a word that was appropriated from Black Twitter to become a staple of online far-right slang in the mid-2010s. Through a quali-quantitative cross-platform approach, we analyse the evolution of the term between 2010 and 2021 on Twitter, Reddit and 4chan. We find that while the far right meaning of based partially survived, its meaning changed and was rendered diffuse as it was adopted by other communities, afforded by a repurposable kernel of meaning to based as ‘not caring about what other people think’ and ‘being true to yourself’ to which different (political) connotations were attached. This challenges the understanding of far-right memes and hate speech as carrying a single and persistent problematic message, and instead emphasises their varied meanings and subcultural functions within specific online communities. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231163175",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Sal Hagen",
        "Daniël de Zeeuw"
      ],
      "url": "https://doi.org/10.1177/20539517231163175",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 69,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b609a1a6-64f7-47bb-9606-85564de27847",
    "title": "Knowledge co-creation in participatory policy and practice: Building community through data-driven direct democracy",
    "abstract": "<jats:p> Engaging citizens with digital technology to co-create data, information and knowledge has widely become an important strategy for informing the policy response to COVID-19 and the ‘infodemic’ of misinformation in cyberspace. This move towards digital citizen participation aligns well with the United Nations’ agenda to encourage the use of digital tools to enable data-driven, direct democracy. From data capture to information generation, and knowledge co-creation, every stage of the data lifecycle bears important considerations to inform policy and practice. Drawing on evidence of participatory policy and practice during COVID-19, we outline a framework for citizen ‘e-participation’ in knowledge co-creation across every stage of the policy cycle. We explore how coupling the generation of information with that of social capital can provide opportunities to collectively build trust in institutions, accelerate recovery and facilitate the ‘e-society’. We outline the key aspects of realising this vision of data-driven direct democracy by discussing several examples. Sustaining participatory knowledge co-creation beyond COVID-19 requires that local organisations and institutions (e.g. academia, health and welfare, government, business) incorporate adaptive learning mechanisms into their operational and governance structures, their integrated service models, as well as employing emerging social innovations. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211019430",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Myron A Godinho",
        "Ann Borda",
        "Timothy Kariotis",
        "Andreea Molnar",
        "Patty Kostkova",
        "Siaw-Teng Liaw"
      ],
      "url": "https://doi.org/10.1177/20539517211019430",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 20,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fefe4fa7-726f-4ed2-ba51-1a8b3d5d514e",
    "title": "Corrigendum to Racial formation, coloniality, and climate finance organizations: Implications for emergent data projects in the Pacific",
    "abstract": "",
    "metadata": {
      "doi": "10.1177/20539517211034695",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [],
      "url": "https://doi.org/10.1177/20539517211034695",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "not available"
    }
  },
  {
    "id": "0ff60c1e-8a9d-428a-be85-11ead92e5809",
    "title": "Datafication and the practice  of intelligence production",
    "abstract": "<jats:p> Datafication of social life affects what society regards as knowledge. Jasanoff’s regimes of sight framework provides three ideal-type models of authorised knowing in environmental data practice. This paper applies Jasanoff's framework for analysing intelligence practice through an exploratory empirical study of crime and intelligence practitioners in a selection of police services in Australia, New Zealand, Canada and the United States. The paper argues that the ‘view from somewhere’ (VFS) captures the essence of existing police intelligence practices in the four countries but the ‘view from nowhere’ (VFN) is emerging as a possible future for police intelligence – an approach promoted by technology companies and supported mainly by police leaders and managers. The paper investigates the challenges and limits of a shift by police from VFS to VFN in the production of intelligence; the challenges are primarily political, which threaten the dominance of police contextual knowledge over ‘scientific’ knowledge. These political challenges also have symbolic and material implications. The paper concludes that, because of these challenges, a complete shift from VFS to VFN is not likely to happen. At best the two models might co-exist with the latter subordinate to the imperatives of the former, resulting in further tension between sworn officers and civilians, organisational inertia, as well as technologies that may be under-utilised or abandoned. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221089310",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Janet Chan",
        "Carrie Sanders",
        "Lyria Bennett Moses",
        "Holly Blackmore"
      ],
      "url": "https://doi.org/10.1177/20539517221089310",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 53,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c1443063-daac-4f08-a1fd-47c9a600ebef",
    "title": "Tradeoffs all the way down: Ethical abduction as a decision-making process for data-intensive technology development",
    "abstract": "<jats:p> Ample scholarship demonstrates that data-intensive technologies have the capacity to cause serious harm and that their developers are obliged to address ethics in their work. This ethnographic paper tells the story of data scientists attempting to instantiate a carefully considered ethical vision into a data infrastructure while balancing competing priorities, negotiating divergent interests, and wrestling with contrasting values. I use their story to develop the concept of “ethical abduction,” which I characterize as an exemplary process by which actors can intentionally and systematically address ethical issues that arise during their day-to-day actions by making decisions with consideration for a foundational ethical worldview. It entails tacking back and forth between divergent but complementary ways of thinking: between establishing ideals and making decisions given practical constraints; between understanding historical context and anticipating future consequences; between acknowledging structural dependencies and accepting responsibility for moral agency. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221101351",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Anissa Tanweer"
      ],
      "url": "https://doi.org/10.1177/20539517221101351",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "47e68843-baaa-42e6-ab26-096f186d0c39",
    "title": "Doctors for the truth: Latin American antivaccine oppositional cultures on Telegram",
    "abstract": "<jats:p> The antivaccine hesitancy movement represents a challenge to public policy and platform regulations. During COVID-19, various Latin American antivaccine groups clashed with official sanitary initiatives. Despite many responses, little progress has been made in reaching these groups to transform their perceptions about the benefits of the COVID-19 vaccine. During the pandemic in Latin America, the antivaccine network Médicos por la Verdad (Doctors for the Truth) gained prominence in various countries. Finding itself limited by legal and technical restrictions, this network used alternative media such as Telegram to disseminate messages. This study argues that such groups may be considered an antivaccination culture that opposes government measures. This focus emphasizes narrative construction and allows us to understand the phenomenon from the collective meaning-making perspective. This study analyzed 232,638 Telegram messages from 14 public channels associated with the Médicos por la Verdad network. Our findings indicate that this antivaccine network builds an oppositional culture expressed and reinforced through multimodal, trans-media, fragmented narratives and suspends disbelief that constructs a world where the community enacts a truth pact. These narrative methods foster building a resilient network of oppositional cultures, decreasing the effectiveness of policies. We conclude that research beyond the framework of misinformation and the analysis of conventional platforms is needed to understand the antivaccine oppositional cultures. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241306359",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Eduardo Paz Díaz",
        "Paola Ricaurte"
      ],
      "url": "https://doi.org/10.1177/20539517241306359",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 130,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "899c4063-e62c-43f0-bf1b-d1bfb5a9ee9a",
    "title": "Disrupting the library: Digital scholarship and Big Data at the National Library of Scotland",
    "abstract": "<jats:p> With a mass digitisation programme underway and the addition of non-print legal deposit and web archive collections, the National Library of Scotland is now both producing and collecting data at an unprecedented rate, with over 5PB of storage in the Library’s data centres. As well as the opportunities to support large scale analysis of the collections, this also presents new challenges around data management, storage, rights, formats, skills and access. Furthermore, by assuming the role of both creators and collectors, libraries face broader questions about the concepts of ‘collections' and ‘heritage', and the ethical implications of collecting practices. While the ‘collections as data’ movement has encouraged cultural heritage organisations to present collections in machine-readable formats, new services, processes and tools also need to be established to enable these emerging forms of research, and new modes of working need to be established to take into account an increasing need for transparency around the creation and presentation of digital collections. This commentary explores the National Library of Scotland's new digital scholarship service, the implications of this new activity and the obstacles that libraries encounter when navigating a world of Big Data. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720970576",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Sarah Ames",
        "Stuart Lewis"
      ],
      "url": "https://doi.org/10.1177/2053951720970576",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 33,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f3a7fe39-1fa0-4cdd-acf9-6c6918af1fe0",
    "title": "Algorithmic failure as a humanities methodology: Machine learning's mispredictions identify rich cases for qualitative analysis",
    "abstract": "<jats:p> This commentary tests a methodology proposed by Munk et al. (2022) for using failed predictions in machine learning as a method to identify ambiguous and rich cases for qualitative analysis. Using a dataset describing actions performed by fictional characters interacting with machine vision technologies in 500 artworks, movies, novels and videogames, I trained a simple machine learning algorithm (using the kNN algorithm in R) to predict whether or not an action was active or passive using only information about the fictional characters. Predictable actions were generally unemotional and unambiguous activities where machine vision technologies were treated as simple tools. Unpredictable actions, that is, actions that the algorithm could not correctly predict, were more ambivalent and emotionally loaded, with more complex power relationships between characters and technologies. The results thus support Munk et al.'s theory that failed predictions can be productively used to identify rich cases for qualitative analysis. This test goes beyond simply replicating Munk et al.'s results by demonstrating that the method can be applied to a broader humanities domain, and that it does not require complex neural networks but can also work with a simpler machine learning algorithm. Further research is needed to develop an understanding of what kinds of data the method is useful for and which kinds of machine learning are most generative. To support this, the R code required to produce the results is included so the test can be replicated. The code can also be reused or adapted to test the method on other datasets. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221131290",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Jill Walker Rettberg"
      ],
      "url": "https://doi.org/10.1177/20539517221131290",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 22,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d1edc193-8782-40b7-b061-a8ee65ff1448",
    "title": "The unbearable (technical) unreliability of automated facial emotion recognition",
    "abstract": "<jats:p> Emotion recognition, and in particular acial emotion recognition (FER), is among the most controversial applications of machine learning, not least because of its ethical implications for human subjects. In this article, we address the controversial conjecture that machines can read emotions from our facial expressions by asking whether this task can be performed reliably. This means, rather than considering the potential harms or scientific soundness of facial emotion recognition systems, focusing on the reliability of the ground truths used to develop emotion recognition systems, assessing how well different human observers agree on the emotions they detect in subjects’ faces. Additionally, we discuss the extent to which sharing context can help observers agree on the emotions they perceive on subjects’ faces. Briefly, we demonstrate that when large and heterogeneous samples of observers are involved, the task of emotion detection from static images crumbles into inconsistency. We thus reveal that any endeavour to understand human behaviour from large sets of labelled patterns is over-ambitious, even if it were technically feasible. We conclude that we cannot speak of actual accuracy for facial emotion recognition systems for any practical purposes. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221129549",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Federico Cabitza",
        "Andrea Campagner",
        "Martina Mattioli"
      ],
      "url": "https://doi.org/10.1177/20539517221129549",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 92,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2d58497c-ce8f-402f-82ec-71f51e558b1f",
    "title": "Stacked spaces: Mapping digital infrastructures",
    "abstract": "<jats:p> This article turns towards the spatial life of ‘digital infrastructures’, i.e. code, protocols, standards, and data formats that are hidden from view in everyday applications of computational technologies. It does so by drawing on the version control system Git as a case study, and telling the story of its initial development in order to reconstruct the circumstances and technical considerations surrounding its conception. This account engages with computational infrastructures on their own terms by adopting the figure of the ‘stack’ to frame a technically informed analysis, and exploring its implications for a different kind of geographic inquiry. Drawing on topology as employed by Law and Mol, attention is given to the multiplicity of spatialities and temporalities enrolled in digital infrastructures in general, and Git specifically. Along the lines of the case study and by reading it against other literatures, this notion of topology is expanded to include the material performation of fundamentally arbitrary, more-than-human topologies, as well as their nested articulation, translation and negotiation within digital infrastructures. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716642456",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Till Straube"
      ],
      "url": "https://doi.org/10.1177/2053951716642456",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 74,
      "is_referenced_by_count": 16,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6e2a3eea-ce0b-4c8a-9858-8a0eb5da6c81",
    "title": "Data/infrastructure in the smart city: Understanding the infrastructural power of Citymapper app through technicity of data",
    "abstract": "<jats:p> Over the last few years, smart cities have been a focus of scholarly attention. Most of these critical studies concentrated on the multinational corporations’ discourses and their implications on urban policies. Besides these factors, however, the data-driven city develops within a complex web of entanglements whereby data-driven technologies modulate the urban infrastructure in a multitude of ways contingent upon the social, political, material and technical aspects. As such, this article attends to the infrastructural implications of a smart city product, Citymapper, which is a transport app built on open data available as part of London’s smart city planning. In order to establish the relationship between data and infrastructure, I use Gilbert Simondon’s notions of ‘transduction’, ‘individuation’ and ‘technicity’ to explore this relationship in a processual and relational way. In constructing this relationship as co-generative, whereby infrastructure and data transindividuate, I subsequently posit the term data/infrastructure. Against this theoretical background, I study the ways in which Citymapper individuates and thereby gains infrastructural power through technicity of data by studying the ways in which the users’ contribute to data generation that feed back into the app. Specifically, by following the transformation of the app from initially mediating the bus timetable to transducing users into environmental sensing nodes through which the app collects behavioural data, I foreground the epistemological, infrastructural and social consequences of Citymapper’s infrastructural power for the data-driven city. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720965618",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Güneş Tavmen"
      ],
      "url": "https://doi.org/10.1177/2053951720965618",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 75,
      "is_referenced_by_count": 18,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c05ad75e-f496-4ccc-9356-9496520fc539",
    "title": "Foundation models are platform models: Prompting and the political economy of AI",
    "abstract": "<jats:p> A recent innovation in the field of machine learning has been the creation of very large pre-trained models, also referred to as ‘foundation models’, that draw on much larger and broader sets of data than typical deep learning systems and can be applied to a wide variety of tasks. Underpinning text-based systems such as OpenAI's ChatGPT and image generators such as Midjourney, these models have received extraordinary amounts of public attention, in part due to their reliance on prompting as the main technique to direct and apply them. This paper thus uses prompting as an entry point into the critical study of foundation models and their implications. The paper proceeds as follows: In the first section, we introduce foundation models in more detail, outline some of the main critiques, and present our general approach. We then discuss prompting as an algorithmic technique, show how it makes foundation models programmable, and explain how it enables different audiences to use these models as (computational) platforms. In the third section, we link the material properties of the technologies under scrutiny to questions of political economy, discussing, in turn, deep user interactions, reordered cost structures, and centralization and lock-in. We conclude by arguing that foundation models and prompting further strengthen Big Tech's dominance over the field of computing and, through their broad applicability, many other economic sectors, challenging our capacities for critical appraisal and regulatory response. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241247839",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Sarah Burkhardt",
        "Bernhard Rieder"
      ],
      "url": "https://doi.org/10.1177/20539517241247839",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 74,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1565feb0-4e53-41e8-b710-0ba414688bfc",
    "title": "Review bombing the platformed city: Contested political speech in online  local reviews",
    "abstract": "<jats:p> Local review platforms like Yelp and Google Maps use systems combining automated and human judgment to delineate the limits of acceptable speech, allowing some reviews to remain public and removing or obscuring others. This article examines the phenomenon of “review bombing,” in which controversial businesses receive an influx of reviews, using spatiotemporal analysis of review activity to analyze their shifting catchment areas, measuring what sociologist Richard Ocejo calls the “extraterritoriality” of their “taste communities”. Specifically, this article examines businesses in the United States that are caught up in political controversies using the locations of their consumer-reviewers on Yelp. The author compiles a test dataset of affected businesses encompassing national and local politics, including the 2016 and 2020 U.S. elections, the #BlackLivesMatter and #MeToo movements, and the COVID-19 pandemic, and selects two for in-depth case studies and spatial analysis: Washington, D.C.-based pizzeria Comet Ping Pong (subject of the #Pizzagate conspiracy theory) and St. Louis-based Pi Pizzeria (caught up in debates about policing and the Black Lives Matter movement). In Comet Ping Pong's case, review bombing resulted in a wider spatial distribution of primarily negative reviewers, while Pi has a much more local pattern, with a fairly even split of supporters and detractors, showing how different political controversies resonate across different scales. The article contrasts Yelp's interventionist approach to content moderation to the relatively laissez-faire attitude of competitors like Google, and considers the consequences of this form of \"algorithmic censorship\" for small businesses, communities, and online speech. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241275879",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Will B Payne"
      ],
      "url": "https://doi.org/10.1177/20539517241275879",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 94,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3a337148-64df-49d8-9da0-187491f194e8",
    "title": "An unexpected journey: A few lessons from sciences Po médialab's experience",
    "abstract": "In this article, we present a few lessons we learnt in the establishment of the Sciences Po médialab. As an interdisciplinary laboratory associating social scientists, code developers and information designers, the médialab is not one of a kind. In the last years, several of such initiatives have been established around the world to harness the potential of digital technologies for the study of collective life. If we narrate this particular story, it is because, having lived it from the inside, we can provide an intimate account of the surprises and displacements of digital research. Founding the médialab in 2009, we knew that we were leaving the reassuring traditions of social sciences to venture in the unexplored territory of digital inscriptions. What we couldn't foresee was how much such encounter would change our research. Buying into gospel of Big Data, we imagined that the main novelty of digital research came from handling larger amounts of data. We soon realized that the interest of digital inscriptions comes instead from their proliferating diversity. Such diversity encouraged us to reshape our professional alliances, research practices and theoretical perspectives. It also led us to overcome several of the oppositions that used to characterize social sciences (qualitative/quantitative, situation/aggregation, micro/macro, local/global) and to move in the direction of a more continuous sociology.",
    "metadata": {
      "doi": "10.1177/2053951717720949",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Tommaso Venturini",
        "Mathieu Jacomy",
        "Axel Meunier",
        "Bruno Latour"
      ],
      "url": "https://doi.org/10.1177/2053951717720949",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171772094",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 47,
      "is_referenced_by_count": 30,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4c722424-3b49-4ede-a8e9-b7f341f675bf",
    "title": "Identifying how COVID-19-related misinformation reacts to the announcement of the UK national lockdown: An interrupted time-series study",
    "abstract": "<jats:p> COVID-19 is unique in that it is the first global pandemic occurring amidst a crowded information environment that has facilitated the proliferation of misinformation on social media. Dangerous misleading narratives have the potential to disrupt ‘official’ information sharing at major government announcements. Using an interrupted time-series design, we test the impact of the announcement of the first UK lockdown (8–8.30 p.m. 23 March 2020) on short-term trends of misinformation on Twitter. We utilise a novel dataset of all COVID-19-related social media posts on Twitter from the UK 48 hours before and 48 hours after the announcement (n = 2,531,888). We find that while the number of tweets increased immediately post announcement, there was no evidence of an increase in misinformation-related tweets. We found an increase in COVID-19-related bot activity post-announcement. Topic modelling of misinformation tweets revealed four distinct clusters: ‘government and policy’, ‘symptoms’, ‘pushing back against misinformation’ and ‘cures and treatments’. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211013869",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Mark Green",
        "Elena Musi",
        "Francisco Rowe",
        "Darren Charles",
        "Frances Darlington Pollock",
        "Chris Kypridemos",
        "Andrew Morse",
        "Patricia Rossini",
        "John Tulloch",
        "Andrew Davies",
        "Emily Dearden",
        "Henrdramoorthy Maheswaran",
        "Alex Singleton",
        "Roberto Vivancos",
        "Sally Sheard"
      ],
      "url": "https://doi.org/10.1177/20539517211013869",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 40,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e09870ab-70d8-4585-af88-09e71c1fc363",
    "title": "Deepening the data divide: Marginalised perspectives and non-profit priorities in Australian data sharing reforms",
    "abstract": "<jats:p> This paper investigates open public data and data sharing reforms in Australia (2018–2022) and their potential role in deepening the ‘data divide’. In the contemporary datafied welfare state, open public data and data sharing are increasingly vexed issues in times of data-driven artificial intelligence (AI). We scrutinise public consultation surrounding the establishment of the Australian Data Availability and Transparency Act 2022 (DAT Act). Through topic modelling and critical discourse analysis, the study examines the representation and concerns of marginalised groups in the reform process. We highlight the overlooked role of non-profits and civil society in the public data ecosystem. The analysis emphasises the significant yet unacknowledged contributions of these organisations in advocating for data equity and justice. We argue that responsible and equitable public data practices do not just depend on administrative and technical procedures for data sharing but are fundamentally entwined with the social and institutional hierarchies in which public data is produced and used. The study calls for greater inclusion and support for civil society organisations to bridge the data divide, contributing to broader debates on the merits and challenges of open data and data sharing practices within a data justice framework. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241311585",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Xiaofang Yao",
        "Anthony McCosker",
        "Yong-Bin Kang"
      ],
      "url": "https://doi.org/10.1177/20539517241311585",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 76,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d66203a5-5d45-4393-9db3-18675eae3d22",
    "title": "‘It depends on your threat model’: the anticipatory dimensions of resistance to data-driven surveillance",
    "abstract": "<jats:p> While many forms of data-driven surveillance are now a ‘fact’ of contemporary life amidst datafication, obtaining concrete knowledge of how different institutions exploit data presents an ongoing challenge, requiring the expertise and power to untangle increasingly complex and opaque technological and institutional arrangements. The how and why of potential surveillance are thus wrapped in a form of continuously produced uncertainty. How then, do affected groups and individuals determine how to counter the threats and harms of surveillance? Responding to an interdisciplinary concern with agency amidst datafication, this article explores what I term ‘anticipatory data practices’ – future-oriented practices which provide a concrete anchor and a heuristic for action amidst the persistent uncertainties of life with data. This article traces how anticipatory data practices have emerged within civil society practices concerned with countering the harms of surveillance and data exploitation. The mixed-method empirical analysis of this article draws from 50 interviews with digital security educators and technology developers; participant observation at 12 civil society events between 2016 and 2019 and the textual analysis of 100 security manuals produced by NGOs and grassroots groups. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720985557",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Becky Kazansky"
      ],
      "url": "https://doi.org/10.1177/2053951720985557",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 80,
      "is_referenced_by_count": 19,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c3beb4f7-3a97-4b37-8dd3-3d743d4be786",
    "title": "Recalibration in counting and accounting practices: Dealing with algorithmic output in public and private",
    "abstract": "<jats:p>Algorithms are increasingly affecting us in our daily lives. They seem to be everywhere, yet they are seldom seen by the humans dealing with the consequences that result from them. Yet, in recent theorisations, there is a risk that the algorithm is being given too much prominence. This article addresses the interaction between algorithmic outputs and the humans engaging with them by drawing on studies of two distinct empirical fields – self-quantification and audit controls of taxpayers. We explore recalibration as a way to understand the practices and processes involved when, on the one hand, decisions are made based on results from algorithmic calculations in counting and accounting software, and on the other hand, when decisions are made based on human experience/knowledge. In particular, we are concerned with moments when an algorithmic output differs from expectations of ‘normalcy’ and ‘normativity’ in any given situation. This could be a ‘normal’ relation between sales and VAT deductions for a business, or a ‘normal’ number of steps one takes in a day, or ‘normative’ as it is according to the book, following guidelines and recommendations from other sources. In these moments, we argue that a process of recalibration occurs – an effortful moment where, rather than treat the algorithmic output as given, individuals’ tacit knowledge, experiences and intuition are brought into play to address the deviation from the normal and normative.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719858751",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Farzana Dudhwala",
        "Lotta Björklund Larsen"
      ],
      "url": "https://doi.org/10.1177/2053951719858751",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171985875",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 22,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "36cb39a2-1bf7-430c-a43b-58def8ad5e85",
    "title": "Beyond algorithmic reformism: Forward engineering the designs of algorithmic systems",
    "abstract": "<jats:p> This article develops a method for investigating the consequences of algorithmic systems according to the documents that specify their design constrains. As opposed to reverse engineering algorithms to identify how their logic operates, the article proposes to design or \"forward engineer\" algorithmic systems in order to theorize how their consequences are informed by design constraints: the specific problems, use cases, and presuppositions that they respond to. This demands a departure from algorithmic reformism, which responds to concerns about the consequences of algorithmic systems by proposing to make algorithms more transparent or less biased. Instead, by investigating algorithmic systems according to documents that specify their design constraints, we identify how the consequences of algorithms are presupposed by the problems that they propose to solve, the types of solutions that they enlist to solve these problems, and the systems of authority that these solutions depend on. To accomplish this, this article develops a methodological framework for researching the process of designing algorithmic systems. In doing so, it proposes to move beyond reforming the technical implementation details of algorithms in order to address the design problems and constraints that underlie them. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720913064",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Peter Polack"
      ],
      "url": "https://doi.org/10.1177/2053951720913064",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172091306",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 27,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "022b5e4a-4590-4d1c-82fe-2c6acce65d77",
    "title": "Trust and privacy in the context of user-generated health data",
    "abstract": "<jats:p> This study identifies and explores evolving concepts of trust and privacy in the context of user-generated health data. We define “user-generated health data” as data captured through devices or software (whether purpose built or commercially available) and used outside of traditional clinical settings for tracking personal health data. The investigators conducted qualitative research through semistructured interviews (n = 32) with researchers, health technology start-up companies, and members of the general public to inquire why and how they interact with and understand the value of user-generated health data. We found significant results concerning new attitudes toward trust, privacy, and sharing of health data outside of clinical settings that conflict with regulations governing health data within clinical settings. Members of the general public expressed little concern about sharing health data with the companies that sold the devices or apps they used, and indicated that they rarely read the “terms and conditions” detailing how their data may be exploited by the company or third-party affiliates before consenting to them. In contrast, interviews with researchers revealed significant resistance among potential research participants to sharing their user-generated health data for purposes of scientific study. The widespread rhetoric of personalization and social sharing in “user-generated culture” appears to facilitate an understanding of user-generated health data that deemphasizes the risk of exploitation in favor of loosely defined benefits to individual and social well-being. We recommend clarification and greater transparency of regulations governing data sharing related to health. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717704673",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Kirsten Ostherr",
        "Svetlana Borodina",
        "Rachel Conrad Bracken",
        "Charles Lotterman",
        "Eliot Storer",
        "Brandon Williams"
      ],
      "url": "https://doi.org/10.1177/2053951717704673",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 64,
      "is_referenced_by_count": 50,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4125ba9b-1450-4230-b922-d020721f8398",
    "title": "Phenotyping as disciplinary practice: Data infrastructure and the interprofessional conflict over drug use in California",
    "abstract": "<jats:p> The narrative of the digital phenotype as a transformative vector in healthcare is nearly identical to the concept of “data drivenness” in other fields such as law enforcement. We examine the role of a prescription drug monitoring program in California—a computerized law enforcement surveillance program enabled by a landmark Supreme Court case that upheld “broad police powers”—in the interprofessional conflict between physicians and law enforcement over the jurisdiction of drug use. We bring together interview passages, clinical artifacts, and academic and gray literature to investigate the power relations between police, physicians, and patients to show that prescribing data appear to the physician as evidence of problematic patient behavior by the patients, and to law enforcement as evidence of physician misconduct. In turn, physicians have adopted a disciplinary approach to patients, using quasi-legalistic documents to litigate patient behavior. We conclude that police powers have been used to pave data infrastructure through a contested jurisdiction, and law enforcement have used that infrastructure to enroll physicians into the work of disciplining patients. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211031258",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Mustafa I Hussain",
        "Geoffrey C Bowker"
      ],
      "url": "https://doi.org/10.1177/20539517211031258",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 33,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "778f185a-008b-479a-92aa-394b47c8959f",
    "title": "‘Blockchain for good’: Exploring the notion of social good inside the blockchain scene",
    "abstract": "<jats:p> One of the most intriguing discussions concerning blockchain technology revolves around its potential to ‘do good’. Consequently, numerous projects and institutions are showing interest in the capacity of blockchain to impact the social sphere positively. However, so far, very little literature has addressed the fundamental notion of ‘good’ that underlies its implementation or explores its connection to social justice theories. This article aims to analyse the narratives that surround the use of blockchain for social good and to compare them with traditional concepts that are significant in social justice theories, such as distribution and recognition. Results show that the selected informants involved in the blockchain scene tend to frame social good in rational, mathematical, and often competitive terms. This tendency contributes to the reinforcement of a neoliberal imaginary that neglects to address structural inequalities as relevant issues. Instead, it envisions social justice as an avenue for generating value, enhancing meritocracy, and ensuring technical accountability, echoing Silicon Valley's aspirations to ‘change the world’. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231205479",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Silvia Semenzin"
      ],
      "url": "https://doi.org/10.1177/20539517231205479",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 75,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d20265ad-9e2f-481c-a55b-bd511dd5d882",
    "title": "Exploring the impact of national culture on the development of open government data: A cross-cultural analysis",
    "abstract": "<jats:p> The development of open government data has attracted interest from academics and practitioners. However, only a few studies have examined a culture-based account of open government data development. This study empirically investigates the impact of national culture on open government data. Through the data investigation and analysis of 55 countries, this research finds that the development of open government data is positively linked with national culture with respect to individualism, indulgence and long-term orientation and is negatively related to power distance. Furthermore, this study shows that economic development moderates the relationship between national culture and open government data development, especially with respect to individualism and long-term orientation. Practically, the findings of this research can help policymakers better understand the multifaceted impacts of national culture on the development of open government data, including the promotion of cultural values (i.e. high individualism, high indulgence, and high long-term orientation) and the change in the passive and conservative attitude of citizens toward the openness of government data in countries where power distance culture is high. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231206809",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Xiaojuan Zhang",
        "Farhan Khan",
        "Xiaoguang Wang",
        "Changle Tang"
      ],
      "url": "https://doi.org/10.1177/20539517231206809",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 66,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1e2d2460-ffba-4462-b0ea-3aecd91ba6eb",
    "title": "What are neural networks <i>not</i> good at? On artificial creativity",
    "abstract": "<jats:p> This article discusses three dimensions of creativity: metaphorical thinking; social interaction; and going beyond extrapolation in predictions. An overview of applications of neural networks in these three areas is offered. It is argued that the current reliance on the apparatus of statistical regression limits the scope of possibilities for neural networks in general, and in moving towards artificial creativity in particular. Artificial creativity may require revising some foundational principles on which neural networks are currently built. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719839433",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Anton Oleinik"
      ],
      "url": "https://doi.org/10.1177/2053951719839433",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 87,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7b356871-8428-42e5-8a35-e1a32ab0103c",
    "title": "Imaginaries of democratization and the value of open environmental data: Analysis of Microsoft's planetary computer",
    "abstract": "<jats:p>The proliferation of environmentally oriented programs within the tech industry, and the industry's coinciding efforts toward data and technology democratization, generate concerns about the status of environmental data within digital economy. While the accumulation of digital personal data has been a cornerstone of domination of the data analytics industry, many believe environmental data to be a source of “untapped potential.” The potential of environmental data, the argument goes, would benefit equally the digital economy, environmental sciences, and academic data and artificial intelligence experts. This article analyzes the proliferation of the rhetoric about open environmental data by focusing on Microsoft's Planetary Computer cloud computing program and computer vision experts who curate and use biodiversity data stored on Microsoft's servers. Through an analytical framework of sociotechnical imaginaries, the article draws connections between visions of future for environmental knowledge production and governance promoted by Microsoft and the work of computer vision experts intending to benefit from the potential of environmental data as machine learning training sets while at the same time helping environmental sciences. Although environmental data on the Planetary Computer is democratized, it nonetheless becomes a valued asset to data economy, but often with unintended consequences, such as enabling citizen science biodiversity data to be used by state surveillance apparatus. The article challenges the view that data's democratization is unproblematically serving environmental sciences by examining the consequences of imaginaries of democratization emerging from the data industry leaders and processes of nonmonetary valuation of environmental data by experts who curate these datasets.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241242448",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Przemyslaw Matt Lukacz"
      ],
      "url": "https://doi.org/10.1177/20539517241242448",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 86,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9dac831d-8bbd-47fe-8cd5-40bf96f889a0",
    "title": "Deeply embedded wages: Navigating digital payments in data work",
    "abstract": "<jats:p> Many workers worldwide rely on digital platforms for their income. In Venezuela, a nation grappling with extreme inflation and where most of the workforce is self-employed, data production platforms for machine learning have emerged as a viable opportunity for many to earn an income in US dollars. Data workers are deeply interconnected within a vast network of entities that act as intermediaries for wage payments in digital currencies. Past research on embeddedness has noted that being intertwined in multi-tiered socioeconomic networks of companies and individuals can offer significant rewards to social participants, while also connoting a particular set of limitations. This paper provides qualitative evidence regarding how this “deep embeddedness” impacts data workers in Venezuela. Given the backdrop of a national crisis and rampant hyperinflation, the perks of receiving wages through financial platforms include accessing more stable currencies and investment outside the national financial system. However, relying on numerous intermediaries often diminishes income due to transaction fees. Moreover, this introduces heightened financial risks, particularly due to the unpredictable nature of cryptocurrencies as an investment. This paper evaluates the effects of the platformization of wages and its effect on working conditions. The over-reliance on external financial platforms erodes worker autonomy through power dynamics that lean in favor of the platforms that set the transaction rules and prices. These findings present a multifaceted perspective on deep embeddedness in platform labor, highlighting how the rewards of financial intermediation often come at a substantial cost for the workers in precarious situations. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241242446",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Julian Posada"
      ],
      "url": "https://doi.org/10.1177/20539517241242446",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "228d5cba-c1a3-46b6-8b33-2571f59e798c",
    "title": "Listening without ears: Artificial intelligence in audio mastering",
    "abstract": "<jats:p> Since the inception of recorded music there has been a need for standards and reliability across sound formats and listening environments. The role of the audio mastering engineer is prestigious and akin to a craft expert combining scientific knowledge, musical learning, manual precision and skill, and an awareness of cultural fashions and creative labour. With the advent of algorithms, big data and machine learning, loosely termed artificial intelligence in this creative sector, there is now the possibility of automating human audio mastering processes and radically disrupting mastering careers. The emergence of dedicated products and services in artificial intelligence-driven audio mastering poses profound questions for the future of the music industry, already having faced significant challenges due to the digitalization of music over the past decades. The research reports on qualitative and ethnographic inquiry with audio mastering engineers on the automation of their expertise and the potential for artificial intelligence to augment or replace aspects of their workflows. Investigating audio mastering engineers' awareness of artificial intelligence, the research probes the importance of criticality in their labour. The research identifies intuitive performance and critical listening as areas where human ingenuity and communication pose problems for simulation. Affective labour disrupts speculation of algorithmic domination by highlighting the pragmatic strategies available for humans to adapt and augment digital technologies. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718808553",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Thomas Birtchnell"
      ],
      "url": "https://doi.org/10.1177/2053951718808553",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 17,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d3a2ce08-1746-40af-a6c8-9a3e457858ab",
    "title": "Algorithmic configurations in caring arrangements",
    "abstract": "<jats:p> This article examines heterogeneous forms of human relationalities with algorithms envisioned in the development of a public algorithmic system and their anticipated effects. To do that, we focus on the distinct shapes given to both technologies and people by discourses and practices, together with their underlying logics and associated values. Analysing the blog posts documenting the emergence of Omaolo, a digital platform for healthcare and social welfare in Finland, we identify two algorithmic configurations: the ‘service engine’, which aligns with the public administration goals of standardising social and healthcare services in order to provide financial benefits; and the ‘treatment facilitator’, which advances the prevalent goals of social and healthcare professionals preoccupied with the fulfilment of situated care needs. We demonstrate that each of the configurations has different implications for social and healthcare organisations in which algorithmic technologies are deployed, for the professionals working there and for the people seeking public support. While the service engine might seem to undermine the collective bases of public service delivery, the treatment facilitator evidently supports them. Our findings remind us of the importance of research endeavours that acknowledge the complex and creative nature of development work, and consider the various parties and interests involved, in an attempt to attain more caring arrangements for the uses of data and algorithmic techniques in the public sector and beyond. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241299726",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Sonja Trifuljesko",
        "Minna Ruckenstein"
      ],
      "url": "https://doi.org/10.1177/20539517241299726",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 75,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f3cf6947-4731-4765-8300-5072d339dc8a",
    "title": "Dangers of the digital fit: Rethinking seamlessness and social sustainability in data-intensive healthcare",
    "abstract": "<jats:p> For years, attempts at ensuring the social sustainability of digital solutions have focused on ensuring that they are perceived as helpful and easy to use. A smooth and seamless work experience has been the goal to strive for. Based on document analysis and interviews with 15 stakeholders, we trace the setting up of a data infrastructure in Danish General Practice that had achieved just this goal – only to end in a scandal and subsequent loss of public support. The ease of data access made it possible for data to be extracted, exchanged and used by new actors and for new purposes – without those producing the data fully realizing the expansion of the infrastructure. We suggest that the case has wider relevance for a still more data-intensive healthcare sector and a growing data economy: when those who produce the data are not made aware of new uses of data, it makes it more difficult to resolve potential conflicts along the way. In the Danish case, conflicting views on legitimate data use led to the collapse of the infrastructure. Therefore, while seamlessness may be a solution to the old problem of a poor fit between user and technology, this celebrated virtue may also involve new problems relating to social instability. As digital solutions tend to be integrated still more seamlessly in still more of our activities, we need to develop political mechanisms to define and protect the rights and obligations of both data suppliers and users in order to ensure the long-term sustainability of digital infrastructures. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717752964",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Sarah Wadmann",
        "Klaus Hoeyer"
      ],
      "url": "https://doi.org/10.1177/2053951717752964",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 55,
      "is_referenced_by_count": 38,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bc9da469-f917-4ec9-bfbb-8d918311a62f",
    "title": "Navigating Big Data dilemmas: Feminist holistic reflexivity in social media research",
    "abstract": "<jats:p> Social media offers an attractive site for Big Data research. Access to big social media data, however, is controlled by companies that privilege corporate, governmental, and private research firms. Additionally, Institutional Review Boards’ regulative practices and slow adaptation to emerging ethical dilemmas in online contexts creates challenges for Big Data researchers. We examine these challenges in the context of a feminist qualitative Big Data analysis of the hashtag event #WhyIStayed. We argue power, context, and subjugated knowledges must each be central considerations in conducting Big Data social media research. In doing so, this paper offers a feminist practice of holistic reflexivity in order to help social media researchers navigate and negotiate this terrain. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718807731",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Cheryl Cooky",
        "Jasmine R Linabary",
        "Danielle J Corple"
      ],
      "url": "https://doi.org/10.1177/2053951718807731",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 58,
      "is_referenced_by_count": 23,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d39fad47-32d3-490c-b9d4-859d737c01f4",
    "title": "‘Happy failures’: Experimentation with behaviour-based personalisation in car insurance",
    "abstract": "Insurance markets have always relied on large amounts of data to assess risks and price their products. New data-driven technologies, including wearable health trackers, smartphone sensors, predictive modelling and Big Data analytics, are challenging these established practices. In tracking insurance clients’ behaviour, these innovations promise the reduction of insurance costs and more accurate pricing through the personalisation of premiums and products. Building on insights from the sociology of markets and Science and Technology Studies (STS), this article investigates the role of economic experimentation in the making of data-driven personalisation markets in insurance. We document a case study of a car insurance experiment, launched by a Belgian direct insurance company in 2016 to set up an experiment of tracking driving style behavioural data of over 5000 participants over a one-year period. Based on interviews and document analysis, we outline how this in vivo experiment was set-up, which interventions and manipulations were imposed to make the experiment successful, and how the study was evaluated by the actors. Using JL Austin’s distinction between happy and unhappy statements, we argue how the experiment, despite its failure not to provide the desired evidence (on the link between driving style behaviour and accident losses), could be considered a ‘happy’ event. We conclude by highlighting the role of economic experiments ‘in the wild’ for the making of future markets of data-driven personalisation.",
    "metadata": {
      "doi": "10.1177/2053951720914650",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Gert Meyers",
        "Ine Van Hoyweghen"
      ],
      "url": "https://doi.org/10.1177/2053951720914650",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172091465",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 29,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "269eb77f-8b2b-4111-9a5d-93c2e60af8b7",
    "title": "How to translate artificial intelligence? Myths and justifications in public discourse",
    "abstract": "<jats:p>Automated technologies populating today’s online world rely on social expectations about how “smart” they appear to be. Algorithmic processing, as well as bias and missteps in the course of their development, all come to shape a cultural realm that in turn determines what they come to be about. It is our contention that a robust analytical frame could be derived from culturally driven Science and Technology Studies while focusing on Callon’s concept of translation. Excitement and apprehensions must find a specific language to move past a state of latency. Translations are thus contextual and highly performative, transforming justifications into legitimate claims, translators into discursive entrepreneurs, and power relations into new forms of governance and governmentality. In this piece, we discuss three cases in which artificial intelligence was deciphered to the public: (i) the Montreal Declaration for a Responsible Development of Artificial Intelligence, held as a prime example of how stakeholders manage to establish the terms of the debate on ethical artificial intelligence while avoiding substantive commitment; (ii) Mark Zuckerberg’s 2018 congressional hearing, where he construed machine learning as the solution to the many problems the platform might encounter; and (iii) the normative renegotiations surrounding the gradual introduction of “killer robots” in military engagements. Of interest are not only the rational arguments put forward, but also the rhetorical maneuvers deployed. Through the examination of the ramifications of these translations, we intend to show how they are constructed in face of and in relation to forms of criticisms, thus revealing the highly cybernetic deployment of artificial intelligence technologies.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720919968",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Jonathan Roberge",
        "Marius Senneville",
        "Kevin Morin"
      ],
      "url": "https://doi.org/10.1177/2053951720919968",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172091996",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 34,
      "is_referenced_by_count": 26,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "84fb03df-c722-4ba6-baed-1a804ca69554",
    "title": "The emerging role of Big Data in key development issues: Opportunities, challenges, and concerns",
    "abstract": "<jats:p> This paper presents a review of academic literature, policy documents from government organizations and international agencies, and reports from industries and popular media on the trends in Big Data utilization in key development issues and its worthwhileness, usefulness, and relevance. By looking at Big Data deployment in a number of key economic sectors, it seeks to provide a better understanding of the opportunities and challenges of using it for addressing key issues facing the developing world. It reviews the uses of Big Data in agriculture and farming activities in developing countries to assess the capabilities required at various levels to benefit from Big Data. It also provides insights into how the current digital divide is associated with and facilitated by the pattern of Big Data diffusion and its effective use in key development areas. It also discusses the lessons that developing countries can learn from the utilization of Big Data in big corporations as well as in other activities in industrialized countries. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714564227",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "Nir Kshetri"
      ],
      "url": "https://doi.org/10.1177/2053951714564227",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 102,
      "is_referenced_by_count": 107,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6a8da7df-3571-4dee-9451-fab555ca28a8",
    "title": "Design choices: Mechanism design and platform capitalism",
    "abstract": "<jats:p> Mechanism design is a form of optimization developed in economic theory. It casts economists as institutional engineers, choosing an outcome and then arranging a set of market rules and conditions to achieve it. The toolkit from mechanism design is widely used in economics, policymaking, and now in building and managing online environments. Mechanism design has become one of the most pervasive yet inconspicuous influences on the digital mediation of social life. Its optimizing schemes structure online advertising markets and other multi-sided platform businesses. Whatever normative rationales mechanism design might draw on in its economic origins, as its influence has grown and its applications have become more computational, we suggest those justifications for using mechanism design to orchestrate and optimize human interaction are losing traction. In this article, we ask what ideological work mechanism design is doing in economics, computer science, and its applications to the governance of digital platforms. Observing mechanism design in action in algorithmic environments, we argue it has become a tool for producing information domination, distributing social costs in ways that benefit designers, and controlling and coordinating participants in multi-sided platforms. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211034312",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Salomé Viljoen",
        "Jake Goldenfein",
        "Lee McGuigan"
      ],
      "url": "https://doi.org/10.1177/20539517211034312",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 68,
      "is_referenced_by_count": 36,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0dadd60c-1818-415f-a3a4-4b9babb55b4c",
    "title": "Biometric identity systems in law enforcement and the politics of (voice) recognition: The case of SiiP",
    "abstract": "<jats:p> Biometric identity systems are now a prominent feature of contemporary law enforcement, including in Europe. Often advanced on the premise of efficiency and accuracy, they have also been the subject of significant controversy. Much attention has focussed on longer-standing biometric data collection, such as finger-printing and facial recognition, foregrounding concerns with the impact such technologies can have on the nature of policing and fundamental human rights. Less researched is the growing use of voice recognition in law enforcement. This paper examines the case of the recent Speaker Identification Integrated Project, a European wide initiative to create the first international and interoperable database of voice biometrics, now the third largest biometric database at Interpol. Drawing on Freedom of Information requests, interviews and public documentation, we outline the emergence and features of SiiP and explore how voice is recognised and attributed meaning. We understand Speaker Identification Integrated Project as constituting a particular ‘regime of recognition’ premised on the use of soft biometrics (age, language, accent and gender) to disembed voice in order to optimise for difference. This, in turn, has implications for the nature and scope of law enforcement, people's position in society, and justice concerns more broadly. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211063604",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Fieke Jansen",
        "Javier Sánchez-Monedero",
        "Lina Dencik"
      ],
      "url": "https://doi.org/10.1177/20539517211063604",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "15447f40-d9df-419f-ae11-cb4844e586bb",
    "title": "Shapes and frictions of synthetic data",
    "abstract": "<jats:p>Synthetic data are computer-generated data that mimic and substitute empirical observations without directly corresponding to real-world phenomena. Widely used in privacy protection, machine learning, and simulation, synthetic data is an emerging field only just beginning to be explored in the social sciences and critical data studies. However, recent developments, such as the use of synthetic data in the US Census and American Community Survey, make a reflection on the nature and implications of synthetic data urgent. While earlier work focused mostly on training data for machine-learning models, this paper presents a broad typology of synthetic data and discusses its frictions. The main argument presented is that the traditional representational model of data as symbolic references to corresponding physical or conceptual objects is insufficient for understanding and critically engaging with issues and implications of synthetic data. The paper discusses an alternative relational model, which defines data not through an object of reference but based on “who uses them, how and for which purposes”. The relational model is more productive for capturing the fact that synthetic data are defined through their purpose; their performance in a particular situation (such as training a machine learning model); and a context-dependent operationalization of evidence. The post-representational anything-goes epistemology of synthetic data can be productively challenged through a forensic approach that foregrounds the outliers, artifacts, and gaps in datasets as meaningful information.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241249390",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Dietmar Offenhuber"
      ],
      "url": "https://doi.org/10.1177/20539517241249390",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 72,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d2941839-dc3f-4ef4-917b-d20be0923fb6",
    "title": "How platforms govern: Social regulation in digital capitalism",
    "abstract": "<jats:p> The rise of digital platforms has in recent years redefined contemporary capitalism—provoking discussions on whether platformization should be understood as bringing an altogether new form of capitalism, or as merely a continuation and intensification of existing neoliberal trends. This paper draws on regulation theory to examine social regulation in digital capitalism, arguing for understanding digital capitalism as continuities of existing capitalist trends coming to produce discontinuities. The paper makes three main arguments. First, it situates digital capitalism as a continuation of longer running post-Fordist trends of financialization, digitalization, and privatization—converging in the emergence of digital proprietary markets, owned and regulated by transnational platform companies. Second, as the platform model is founded on monopolizing regulation, platforms come into direct competition with states and public institutions, which they pursue through a set of distinct technopolitical strategies to claim power to govern—resulting in a geographically variegated process of institutional transformation. Third, while the digital proprietary markets are continuities of existing trends, they bring new pressures and affordances, thus producing discontinuities in social regulation. We examine such discontinuities in relation to three aspects of social regulation: (a) from neoliberalism to techno-feudalism; (b) from Taylorist hierarchies toward algorithmic herds and technoliberal subjectivity; and (c) from postmodernity toward an automated consumer culture. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231153808",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Petter Törnberg"
      ],
      "url": "https://doi.org/10.1177/20539517231153808",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 99,
      "is_referenced_by_count": 35,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9e2d6de4-55bd-48b6-8e4e-4a8123a8cd57",
    "title": "Good organizational reasons for better medical records: The data work of clinical documentation integrity specialists",
    "abstract": "<jats:p> Healthcare organizations and workers are under pressure to produce increasingly complete and accurate data for multiple data-intensive endeavors. However, little research has examined the emerging occupations arising to carry out the data work necessary to produce “improved” data sets, or the specific work activities of these emerging data occupations. We describe the work of Clinical Documentation Integrity Specialists (CDIS), an emerging occupation that focuses on improving clinical documentation to produce more detailed and accurate administrative datasets crucial for evolving data-intensive forms of healthcare accountability, management, and research. Using ethnographic methods, we describe the core of CDIS’ work as a translation practice in which the language, interests, and concerns of clinicians and clinical documentation are translated via real-time “nudging” and ongoing education of clinicians into the language, interests, and concerns of medical coders, structured administrative datasets, and the various stakeholders of these datasets. Further, we show how the institutional context of CDIS’ work shapes the occupational virtues that guide CDIS’ translation practice, including financial reimbursement, quality measures, clinical accuracy, and protecting clinician’s time. Despite the existence of these multiple virtues, financial reimbursement is the most prominent virtue guiding CDIS’ limited attention. Thus, overall clinical documentation is “improved” in specific, partial ways. This research provides one of the first studies of the emergent data work occupations arising in the wake of digitization and big data opportunities, and shows how local data settings shape large scale data in specific ways and thus may influence outcomes of analyses based on such data. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720965616",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Kathleen H Pine",
        "Claus Bossen"
      ],
      "url": "https://doi.org/10.1177/2053951720965616",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 51,
      "is_referenced_by_count": 22,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6d4e8b4d-4a67-4fd5-b63d-9426b77e9dfe",
    "title": "Public views of the smart city: Towards the construction of a social problem",
    "abstract": "<jats:p> Digitization and datafication of public space have a significant impact on how cities are developed, governed, perceived and used. As technological developments are based upon political decisions, which impact people’s everyday lives, and from which not everyone benefits or suffers equally, we argue that ‘the smart city’ should be part of continuous public debate; that it should be considered and treated as a social problem. Through nine focus groups, we invited respondents to explore and discuss instances and dilemmas of the smart city. We investigated which interpretative repertoires they used to frame the smart city as a social and actionable problem. Following Blumer's and Gamson's theories on the social construction of problems and on collective action frames, we assessed respondents’ discursive interpretations and their subjective construction of their senses of injustice, agency and identity regarding this subject. We find that – in the context of the city of Rotterdam in The Netherlands – citizens do not experience and consider the smart city as a social and actionable problem. Although they do associate the technological development of smart cities with potential threats, this does not change or constrain their sense of ‘actionability’, nor their behaviour, as they consider themselves to be powerless individuals regarding what, in their eyes, is a complex, elusive and inevitable situation they are confronted with. Strikingly, rather than specifically and contextually reflecting on smart city issues, respondents tended to express their concerns in the more general context of digital and data technologies invading everyday life. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211072190",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Emiel A. Rijshouwer",
        "Els M. Leclercq",
        "Liesbet van Zoonen"
      ],
      "url": "https://doi.org/10.1177/20539517211072190",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 55,
      "is_referenced_by_count": 18,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3f159353-13bf-447c-80f4-570ceffada99",
    "title": "Excavating awareness and power in data science: A manifesto for trustworthy pervasive data research",
    "abstract": "<jats:p> Frequent public uproar over forms of data science that rely on information about people demonstrates the challenges of defining and demonstrating trustworthy digital data research practices. This paper reviews problems of trustworthiness in what we term pervasive data research: scholarship that relies on the rich information generated about people through digital interaction. We highlight the entwined problems of participant unawareness of such research and the relationship of pervasive data research to corporate datafication and surveillance. We suggest a way forward by drawing from the history of a different methodological approach in which researchers have struggled with trustworthy practice: ethnography. To grapple with the colonial legacy of their methods, ethnographers have developed analytic lenses and researcher practices that foreground relations of awareness and power. These lenses are inspiring but also challenging for pervasive data research, given the flattening of contexts inherent in digital data collection. We propose ways that pervasive data researchers can incorporate reflection on awareness and power within their research to support the development of trustworthy data science. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211040759",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Katie Shilton",
        "Emanuel Moss",
        "Sarah A. Gilbert",
        "Matthew J. Bietz",
        "Casey Fiesler",
        "Jacob Metcalf",
        "Jessica Vitak",
        "Michael Zimmer"
      ],
      "url": "https://doi.org/10.1177/20539517211040759",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 90,
      "is_referenced_by_count": 20,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bdc1ca1e-a92d-4d40-99ae-d9dbf91be216",
    "title": "Justice, injustice, and artificial  intelligence: Lessons from political  theory and philosophy",
    "abstract": "<jats:p> Some recent uses of artificial intelligence for (for example) facial recognition, evaluating resumes, and sorting photographs by subject matter have revealed troubling disparities in performance or impact based on the demographic traits (like race and gender) of subject populations. These disparities raise pressing questions about how using artificial intelligence can work to promote justice or entrench injustice. Political theorists and philosophers have developed nuanced vocabularies and theoretical frameworks for understanding and adjudicating disputes about what justice requires and what constitutes injustice. The interdisciplinary community committed to understanding and conscientiously using big data could benefit from this work. Thus, in the spirit of encouraging cross-disciplinary dialogue and collaboration, this piece examines contemporary scholarship in political theory and philosophy to illustrate some of the vocabularies and frameworks political theorists and philosophers have developed for thinking about justice and injustice. It then draws on these frameworks to illuminate how the use of artificial intelligence can implicate questions of justice, with a focus on institutional discrimination, structural injustice, and epistemic injustice. Ultimately, the piece argues that the use of artificial intelligence—far from representing a decision to take power out of human hands—represents a novel way of harnessing human power, making questions of justice central to its conscientious undertaking. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221080676",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Lucia M. Rafanelli"
      ],
      "url": "https://doi.org/10.1177/20539517221080676",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 27,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c1168223-e57c-40dc-9720-502f25fa0e25",
    "title": "The Datafication of #MeToo: Whiteness, Racial Capitalism, and Anti-Violence Technologies",
    "abstract": "<jats:p> This article illustrates how racial capitalism can enhance understandings of data, capital, and inequality through an in-depth study of digital platforms used for intervening in gender-based violence. Specifically, we examine an emergent sociotechnical strategy that uses software platforms and artificial intelligence (AI) chatbots to offer users emergency assistance, education, and a means to report and build evidence against perpetrators. Our analysis details how two reporting apps construct data to support institutionally legible narratives of violence, highlighting overlooked racialised dimensions of the data capital generated through their use. We draw attention to how they reinforce property relations built on extraction and ownership, capital accumulation that reinforces benefits derived through data property relations and ownership, and the commodification of diversity and inclusion. Recognising these patterns are not unique to anti-violence apps, we reflect on how this example aids in understanding how racial capitalism becomes a constitutive element of digital platforms, which more generally extract information from users, rely on complex financial partnerships, and often sustain problematic relationships with the criminal legal system. We conclude with a discussion of how racial capitalism can advance scholarship at the intersections of data and power. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211055898",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Kathryn Henne",
        "Renee Shelby",
        "Jenna Harb"
      ],
      "url": "https://doi.org/10.1177/20539517211055898",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 90,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "21745792-33c9-4f45-aa9a-d20e22716ab7",
    "title": "From FAIR data to fair data use: Methodological data fairness in health-related social media research",
    "abstract": "<jats:p> The paper problematises the reliability and ethics of using social media data, such as sourced from Twitter or Instagram, to carry out health-related research. As in many other domains, the opportunity to mine social media for information has been hailed as transformative for research on well-being and disease. Considerations around the fairness, responsibilities and accountabilities relating to using such data have often been set aside, on the understanding that as long as data were anonymised, no real ethical or scientific issue would arise. We first counter this perception by emphasising that the use of social media data in health research can yield problematic and unethical results. We then provide a conceptualisation of methodological data fairness that can complement data management principles such as FAIR by enhancing the actionability of social media data for future research. We highlight the forms that methodological data fairness can take at different stages of the research process and identify practical steps through which researchers can ensure that their practices and outcomes are scientifically sound as well as fair to society at large. We conclude that making research data fair as well as FAIR is inextricably linked to concerns around the adequacy of data practices. The failure to act on those concerns raises serious ethical, methodological and epistemic issues with the knowledge and evidence that are being produced. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211010310",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Sabina Leonelli",
        "Rebecca Lovell",
        "Benedict W Wheeler",
        "Lora Fleming",
        "Hywel Williams"
      ],
      "url": "https://doi.org/10.1177/20539517211010310",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 84,
      "is_referenced_by_count": 27,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e133c698-1ddd-4254-b9a4-74643dbe1ff1",
    "title": "Emotional AI, soft biometrics and the surveillance of emotional life: An unusual consensus on privacy",
    "abstract": "By the early 2020s, emotional artificial intelligence (emotional AI) will become increasingly present in everyday objects and practices such as assistants, cars, games, mobile phones, wearables, toys, marketing, insurance, policing, education and border controls. There is also keen interest in using these technologies to regulate and optimize the emotional experiences of spaces, such as workplaces, hospitals, prisons, classrooms, travel infrastructures, restaurants, retail and chain stores. Developers frequently claim that their applications do not identify people. Taking the claim at face value, this paper asks, what are the privacy implications of emotional AI practices that do not identify individuals? To investigate privacy perspectives on soft non-identifying emotional AI, the paper draws upon the following: over 100 interviews with the emotion detection industry, legal community, policy-makers, regulators and NGOs interested in privacy; a workshop with stakeholders to design ethical codes for using data about emotions; a UK survey of 2068 citizens on feelings about emotion capture technologies. It finds a weak consensus among social stakeholders on the need for privacy, this driven by different interests and motivations. Given this weak consensus, it concludes that there exists a limited window of opportunity to societally agree principles of practice regarding privacy and the use of data about emotions.",
    "metadata": {
      "doi": "10.1177/2053951720904386",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Andrew McStay"
      ],
      "url": "https://doi.org/10.1177/2053951720904386",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172090438",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 28,
      "is_referenced_by_count": 97,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "faae624b-8603-4f8c-a6ba-3222f625cd8b",
    "title": "Expectations of artificial intelligence and the performativity of ethics: Implications for communication governance",
    "abstract": "<jats:p> This article draws on the sociology of expectations to examine the construction of expectations of ‘ethical AI’ and considers the implications of these expectations for communication governance. We first analyse a range of public documents to identify the key actors, mechanisms and issues which structure societal expectations around artificial intelligence (AI) and an emerging discourse on ethics. We then explore expectations of AI and ethics through a survey of members of the public. Finally, we discuss the implications of our findings for the role of AI in communication governance. We find that, despite societal expectations that we can design ethical AI, and public expectations that developers and governments should share responsibility for the outcomes of AI use, there is a significant divergence between these expectations and the ways in which AI technologies are currently used and governed in large scale communication systems. We conclude that discourses of ‘ethical AI’ are generically performative, but to become more effective we need to acknowledge the limitations of contemporary AI and the requirement for extensive human labour to meet the challenges of communication governance. An effective ethics of AI requires domain appropriate AI tools, updated professional practices, dignified places of work and robust regulatory and accountability frameworks. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720915939",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Aphra Kerr",
        "Marguerite Barry",
        "John D Kelleher"
      ],
      "url": "https://doi.org/10.1177/2053951720915939",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172091593",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 33,
      "is_referenced_by_count": 80,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e7abfd79-bd6c-47c9-b81c-114b0b04e804",
    "title": "Ideological variation in preferred content and source credibility on Reddit during  the COVID-19 pandemic",
    "abstract": "<jats:p> In this exploratory study, we examine political polarization regarding the online discussion of the COVID-19 pandemic. We use data from Reddit to explore the differences in the topics emphasized by different subreddits according to political ideology. We also examine whether there are systematic differences in the credibility of sources shared by the subscribers of subreddits that vary by ideology, and in the tendency to share information from sources implicated in spreading COVID-19 misinformation. Our results show polarization in topics of discussion: the Trump, White House, and economic relief topics are statistically more prominent in liberal subreddits, and China and deaths topics are more prominent in conservative subreddits. There are also significant differences between liberal and conservative subreddits in their preferences for news sources. Liberal subreddits share and discuss articles from more credible news sources than conservative subreddits, and conservative subreddits are more likely than liberal subreddits to share articles from sites flagged for publishing COVID-19 misinformation. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221076486",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Wallace Chipidza",
        "Christopher Krewson",
        "Nicole Gatto",
        "Elmira Akbaripourdibazar",
        "Tendai Gwanzura"
      ],
      "url": "https://doi.org/10.1177/20539517221076486",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 31,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f9ada611-8134-47e6-a67e-767ab0c9f9f8",
    "title": "The data archive as factory: Alienation and resistance of data processors",
    "abstract": "<jats:p> Archival data processing consists of cleaning and formatting data between the moment a dataset is deposited and its publication on the archive’s website. In this article, I approach data processing by combining scholarship on invisible labor in knowledge infrastructures with a Marxian framework and show the relevance of considering data processing as factory labor. Using this perspective to analyze ethnographic data collected during a six-month participatory observation at a U.S. data archive, I generate a taxonomy of the forms of alienation that data processing generates, but also the types of resistance that processors develop, across four categories: routine, speed, skill, and meaning. This synthetic approach demonstrates, first, that data processing reproduces typical forms of factory worker’s alienation: processors are asked to work along a strict standardized pipeline, at a fast pace, without acquiring substantive skills or having a meaningful involvement in their work. It reveals, second, how data processors resist the alienating nature of this workflow by developing multiple tactics along the same four categories. Seen through this dual lens, data processors are therefore not only invisible workers, but also factory workers who follow and subvert a workflow organized as an assembly line. I conclude by proposing a four-step framework to better value the social contribution of data workers beyond the archive. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211007510",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Jean-Christophe Plantin"
      ],
      "url": "https://doi.org/10.1177/20539517211007510",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9b974c28-29de-4939-a63a-04af74697a81",
    "title": "Everyday digital traces",
    "abstract": "<jats:p> Our research responds to calls for more engagement with everyday personal data. We used a co-designed, fictional persona called Alex Smith to concretise and represent people's online information to help participants (through role-playing) reflect on data and digital traces. Drawing together four fields of scholarly research concerning personal data: digital traces and the digital self, datafication and dataveillance, mundane, everyday data and the data journey – our aim was to advance understandings of personal data by exploring ordinary people's seemingly innocuous digital traces generated through everyday online interactions. Our paper presents three key findings from our analysis: (1) how ordinary people cope with and manage everyday data; (2) the haunting effects and affects of peer-to-peer surveillance and (3) postdigital identities. We argue that greater attention needs to be paid to everyday digital traces – how they are understood, managed and revealed because this has implications for ordinary people, corporate entities and governments. We contribute to a gap in critical data studies literature that calls for further investigations into ordinary people's engagement with data. We also offer a method that can be adapted for and used with different participant groups, which also supports their awareness of cumulative functions of personal data and potential use by un/known actors. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231213827",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Andrea Armstrong",
        "Jo Briggs",
        "Wendy Moncur",
        "Daniel Paul Carey",
        "Emma Nicol",
        "Burkhard Schafer"
      ],
      "url": "https://doi.org/10.1177/20539517231213827",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 80,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "73c5684d-1b70-4b60-a4dd-d96181131a50",
    "title": "Predictive privacy: Collective data protection in the context of artificial intelligence and big data",
    "abstract": "<jats:p> Big data and artificial intelligence pose a new challenge for data protection as these techniques allow predictions to be made about third parties based on the anonymous data of many people. Examples of predicted information include purchasing power, gender, age, health, sexual orientation, ethnicity, etc. The basis for such applications of “predictive analytics” is the comparison between behavioral data (e.g. usage, tracking, or activity data) of the individual in question and the potentially anonymously processed data of many others using machine learning models or simpler statistical methods. The article starts by noting that predictive analytics has a significant potential to be abused, which manifests itself in the form of social inequality, discrimination, and exclusion. These potentials are not regulated by current data protection law in the EU; indeed, the use of anonymized mass data takes place in a largely unregulated space. Under the term “predictive privacy,” a data protection approach is presented that counters the risks of abuse of predictive analytics. A person's predictive privacy is violated when personal information about them is predicted without their knowledge and against their will based on the data of many other people. Predictive privacy is then formulated as a protected good and improvements to data protection with regard to the regulation of predictive analytics are proposed. Finally, the article points out that the goal of data protection in the context of predictive analytics is the regulation of “prediction power,” which is a new manifestation of informational power asymmetry between platform companies and society. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231166886",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Rainer Mühlhoff"
      ],
      "url": "https://doi.org/10.1177/20539517231166886",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 24,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c3580a36-85af-410e-bb74-ecf91f6b8173",
    "title": "Open data: Accountability and transparency",
    "abstract": "The movements by national governments, funding agencies, universities, and research communities toward “open data” face many difficult challenges. In high-level visions of open data, researchers’ data and metadata practices are expected to be robust and structured. The integration of the internet into scientific institutions amplifies these expectations. When examined critically, however, the data and metadata practices of scholarly researchers often appear incomplete or deficient. The concepts of “accountability” and “transparency” provide insight in understanding these perceived gaps. Researchers’ primary accountabilities are related to meeting the expectations of research competency, not to external standards of data deposition or metadata creation. Likewise, making data open in a transparent way can involve a significant investment of time and resources with no obvious benefits. This paper uses differing notions of accountability and transparency to conceptualize “open data” as the result of ongoing achievements, not one-time acts.",
    "metadata": {
      "doi": "10.1177/2053951717718853",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Matthew S Mayernik"
      ],
      "url": "https://doi.org/10.1177/2053951717718853",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171771885",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 24,
      "is_referenced_by_count": 43,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "22f7a054-ecab-4598-b01e-07ff5ca53216",
    "title": "Computational reparations as generative justice: Decolonial transitions to unalienated circular value flow",
    "abstract": "<jats:p> The Latin roots of the word reparations are “re” (again) plus “parere” which means “to give birth to, bring into being, produce”. Together they mean “to make generative once again”. In this sense, the extraction processes that cause labor injustice, ecological devastation, and social degradation cannot be repaired by simply transferring money. Reparations need to take on the full sense of “restorative”: the transition to a decolonial system that can support value generators in the control of their own systems of production, protect the value they create from extraction, and circulate value in unalienated forms that benefit the human and non-human communities that produced that value. With funding from the National Science Foundation, we have developed a research framework for this process that starts with “artisanal labor”: employee-owned business and worker collectives that have people doing what they love, despite low incomes. Focusing primarily on Detroit's Black-owned urban farms, artisanal textile businesses, Black hair salons, worker collectives, and other community-based production, with additional connections to Indigenous and other communities, we have introduced digital fabrication technologies, sensors, artificial intelligence, server-side apps and other computational support for a transition to unalienated circular value flow. We will report on our investigations with the challenges at multiple scales. At each level, we show how computational supports can act as restorative mechanisms for lost circular value flows, and thus address both past and ongoing disenfranchisement. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231221732",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Ron Eglash",
        "Kwame P Robinson",
        "Audrey Bennett",
        "Lionel Robert",
        "Mathew Garvin"
      ],
      "url": "https://doi.org/10.1177/20539517231221732",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 75,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ea09dfe8-ccf7-4c58-8e7a-05f94544a3b9",
    "title": "Making sense of algorithms: Relational perception of contact tracing and risk assessment during COVID-19",
    "abstract": "<jats:p> Governments and citizens of nearly every nation have been compelled to respond to COVID-19. Many measures have been adopted, including contact tracing and risk assessment algorithms, whereby citizen whereabouts are monitored to trace contact with other infectious individuals in order to generate a risk status via algorithmic evaluation. Based on 38 in-depth interviews, we investigate how people make sense of Health Code ( jiankangma), the Chinese contact tracing and risk assessment algorithmic sociotechnical assemblage. We probe how people accept or resist Health Code by examining their ongoing, dynamic, and relational interactions with it. Participants display a rich variety of attitudes toward privacy and surveillance, ranging from fatalism to the possibility of privacy to trade-offs for surveillance in exchange for public health, which is mediated by the perceived effectiveness of Health Code and changing views on the intentions of institutions who deploy it. We show how perceived competency varies not just on how well the technology works, but on the social and cultural enforcement of various non-technical aspects like quarantine, citizen data inputs, and cell reception. Furthermore, we illustrate how perceptions of Health Code are nested in people’s broader interpretations of disease control at the national and global level, and unexpectedly strengthen the Chinese authority’s legitimacy. None of the Chinese public, Health Code, or people’s perceptions toward Health Code are predetermined, fixed, or categorically consistent, but are co-constitutive and dynamic over time. We conclude with a theorization of a relational perception and methodological reflections to study algorithmic sociotechnical assemblages beyond COVID-19. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951721995218",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Chuncheng Liu",
        "Ross Graham"
      ],
      "url": "https://doi.org/10.1177/2053951721995218",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 47,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0ff9b5b1-dc56-4473-9b6b-c42094f17dd0",
    "title": "In search of ‘extra data’: Making tissues flow from personal to personalised medicine",
    "abstract": "<jats:p> One of the key features of the contemporary data economy is the widespread circulation of data and its interoperability. Critical data scholars have analysed data repurposing practices and other factors facilitating the travelling of data. While this approach focused on flows provides great potential, in this article we argue that it tends to overlook questions of attachment and belonging. Drawing upon ethnographic fieldwork within a Danish data-linkage infrastructure, and building upon insights from archival science, we discuss the work of data practitioners enabling the repurposing of pathology samples extracted from patients for the conduct of ‘personal medicine’ – our term to discuss the so-called old-fashioned treatment of patients – towards personalised medicine. This first involves ‘getting to know’ the tissues and unpacking their previous uses and meanings, then detaching them from their original source to extract data from such tissues and making them flow towards a new container where they can be worked on and connected with other data. As data practitioners make these tissues travel, transforming them into research data, they organise the attachments of data to new agendas, persons and places. Crucially, in our case, we observe the prominence of national attachments, whereby managing tissues and data in and out of containers involves tying them to the nation to serve its interests. We thus expose how the building of data linkage infrastructures entails more than the accumulation and curation of data, but also involves crafting meanings, futures and belonging to specific communities and territories. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211035664",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Clémence Pinel",
        "Mette N Svendsen"
      ],
      "url": "https://doi.org/10.1177/20539517211035664",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 42,
      "is_referenced_by_count": 16,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b52a8b8c-a15c-433c-831d-a01531f75551",
    "title": "Neither opaque nor transparent: A transdisciplinary methodology to investigate datafication at the EU borders",
    "abstract": "<jats:p> In 2020, the European Union announced the award of the contract for the biometric part of the new database for border control, the Entry Exit System, to two companies: IDEMIA and Sopra Steria. Both companies had been previously involved in the development of databases for border and migration management. While there has been a growing amount of publicly available documents that show what kind of technologies are being implemented, for how much money, and by whom, there has been limited engagement with digital methods in this field. Moreover, critical border and security scholarship has largely focused on qualitative and ethnographic methods. Building on a data feminist approach, we propose a transdisciplinary methodology that goes beyond binaries of qualitative/quantitative and opacity/transparency, examines power asymmetries and makes the labour of coding visible. Empirically, we build and analyse a dataset of the contracts awarded by two European Union agencies key to its border management policies – the European Agency for Large-Scale Information Systems (eu-LISA) and the European Border and Coast Guard Agency (Frontex). We supplement the digital analysis and visualisation of networks of companies with close reading of tender documents. In so doing, we show how a transdisciplinary methodology can be a device for making datafication ‘intelligible’ at the European Union borders. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221124586",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Ana Valdivia",
        "Claudia Aradau",
        "Tobias Blanke",
        "Sarah Perret"
      ],
      "url": "https://doi.org/10.1177/20539517221124586",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 77,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "131c3428-7638-4c88-9489-82ae664c1a0d",
    "title": "Data arenas: The relational dynamics of data activism",
    "abstract": "<jats:p> The article proposes the theoretical category of data arenas as a relational field for strategic actors in diverse areas of the contentious politics of data (Beraldo and Milan, 2019). The paper argues that the conceptualization of data activism needs to be related to the immediate data arena in which the action takes place, in order to select the interactive opportunities and threats for emerging data-driven repertoires of action. To fully work through the relational dynamics of data activism, it is necessary to move from a conceptualization of data infrastructure to the notion of data arenas as an ‘open-ended bundle of rules and resources that allows certain kinds of interaction to proceed’ (Jasper, 2006: 141). Using the case of environmental data activism, I highlight four key dimensions to study: (a) strategic use of data as capital that differentiates and positions actors, as well as influences their further choices; (b) practices of defining the boundaries of the problem on which the arena focuses and outlining the pool of actors who participate in the process of solving it; (3) sets of relationships among the outlined pool of actors which represent opportunities and threats for the actors, related to the position they occupy within an arena; and (4) power as the ability to control and shape an arena. Data arena approach shed new light on data activism as a relational practice, combining the latest developments in research on data contexts and the political situatedness of data with the emerging field of research on data activism. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231177617",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Bartosz Ślosarski"
      ],
      "url": "https://doi.org/10.1177/20539517231177617",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 74,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "92fbb8c5-e1d5-49f7-be8e-34c294759d6b",
    "title": "Going viral: How a single tweet spawned a COVID-19 conspiracy theory on Twitter",
    "abstract": "<jats:p> In late March of 2020, a new hashtag, #FilmYourHospital, made its first appearance on social media. The hashtag encouraged people to visit local hospitals to take pictures and videos of empty hospitals to help “prove” that the COVID-19 pandemic is an elaborate hoax. Using techniques from Social Network Analysis, this case study examines how this conspiracy theory propagated on Twitter and whether the hashtag virality was aided by the use of automation or coordination among Twitter users. We found that while much of the content came from users with limited reach, the oxygen that fueled this conspiracy in its early days came from a handful of prominent conservative politicians and far right political activists on Twitter. These power users used this hashtag to build awareness about the campaign and to encourage their followers to break quarantine and film what is happening at their local hospitals. After the initial boost by a few prominent accounts, the campaign was mostly sustained by pro-Trump accounts, followed by a secondary wave of propagation outside the U.S. The rise of the #FilmYourHospital conspiracy from a single tweet demonstrates the ongoing challenge of addressing false, viral information during the COVID-19 pandemic. While the spread of misinformation can be potentially mitigated by fact-checking and directing people to credible sources of information from public health agencies, false and misleading claims that are driven by politics and supported by strong convictions and not science are much harder to root out. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720938405",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Anatoliy Gruzd",
        "Philip Mai"
      ],
      "url": "https://doi.org/10.1177/2053951720938405",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 36,
      "is_referenced_by_count": 140,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f7f388de-6766-46fe-b99e-8fa1fd86ef9d",
    "title": "“Reach the right people”: The politics of “interests” in Facebook’s classification system for ad targeting",
    "abstract": "<jats:p> Political campaigns increasingly rely on Facebook for reaching their constituents, particularly through ad targeting. Facebook’s business model is premised on a promise to connect advertisers with the “right” users: those likely to click, download, engage, purchase. The company pursues this promise (in part) by algorithmically inferring users’ interests from their data and providing advertisers with a means of targeting users by their inferred interests. In this study, we explore for whom this interest classification system works in order to build on conversations in critical data studies about the ways such systems produce knowledge about the world rooted in power structures. We critically analyze the classification system from a variety of empirical vantage points—via user data; Facebook documentation, training, and patents; and Facebook’s tools for advertisers—and through theoretical concepts from a variety of domains. In this, we focus on the ways the classification system shapes possibilities for political representation and voice, particularly for people of color, women, and LGBTQ+ people. We argue that this “big data-driven” classification system should be read as political: it articulates a stance not only on what issues are or are not important in the U.S. public sphere, but also on who is considered a significant enough public to be adequately accounted for. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951721996046",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Kelley Cotter",
        "Mel Medeiros",
        "Chankyung Pak",
        "Kjerstin Thorson"
      ],
      "url": "https://doi.org/10.1177/2053951721996046",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 83,
      "is_referenced_by_count": 32,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f973f54b-65d9-4f2f-995f-a30e01c30b75",
    "title": "The effectiveness of embedded values analysis modules in Computer Science education: An empirical study",
    "abstract": "<jats:p> Embedding ethics modules within computer science courses has become a popular response to the growing recognition that computer science programs need to better equip their students to navigate the ethical dimensions of computing technologies such as artificial intelligence, machine learning, and big data analytics. However, the popularity of this approach has outpaced the evidence of its positive outcomes. To help close that gap, this empirical study reports positive results from Northeastern University's program that embeds values analysis modules into computer science courses. The resulting data suggest that such modules have a positive effect on students’ moral attitudes and that students leave the modules believing they are more prepared to navigate the ethical dimensions they will likely face in their eventual careers. Importantly, these gains were accomplished at an institution without a philosophy doctoral program, suggesting this strategy can be effectively employed by a wider range of institutions than many have thought. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231176230",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Matthew Kopec",
        "Meica Magnani",
        "Vance Ricks",
        "Roben Torosyan",
        "John Basl",
        "Nicholas Miklaucic",
        "Felix Muzny",
        "Ronald Sandler",
        "Christo Wilson",
        "Adam Wisniewski-Jensen",
        "Cora Lundgren",
        "Ryan Baylon",
        "Kevin Mills",
        "Mark Wells"
      ],
      "url": "https://doi.org/10.1177/20539517231176230",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 85,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0162e0ea-09f2-434d-afec-45f2a308c8ec",
    "title": "On samples, data, and their mobility in biobanking: How imagined travels help to relate samples and data",
    "abstract": "<jats:p> Biobanking involves the assembling, curating, and distributing of samples and data. While relations between samples and data are often taken as defining properties of biobanking, several studies have pointed to the challenges in relating them in practice. This article investigates how samples and data are curated, connected, and made mobile in practice. Building on an analysis of data collected at five hospital-based biobanks in Austria, the article describes and compares biobanking in three types of biobank collections: ‘departmental collections’, ‘project-specific collections’ and ‘hospital-wide collections’. It draws attention to the invisible work going into this infrastructure and highlights the central role of visions to make samples and data travel to a different location and thus support biomedical research. It shows that while visions of future travels are often epistemologically uncertain, they are informed by social ties and relationships between the collectives involved in the curation of samples and data on the one hand and the imagined users on the other. Finally, we point to the importance that policy actors in this domain consider the aspects we identified—and, in particular, reflect the temporalities inherent in such a research infrastructure. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231158635",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Ingrid Metzler",
        "Lisa-Maria Ferent",
        "Ulrike Felt"
      ],
      "url": "https://doi.org/10.1177/20539517231158635",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 37,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fb5d79c9-356f-4b41-82b8-578f09290702",
    "title": "Big Data and quality data for fake news and misinformation detection",
    "abstract": "<jats:p> Fake news has become an important topic of research in a variety of disciplines including linguistics and computer science. In this paper, we explain how the problem is approached from the perspective of natural language processing, with the goal of building a system to automatically detect misinformation in news. The main challenge in this line of research is collecting quality data, i.e., instances of fake and real news articles on a balanced distribution of topics. We review available datasets and introduce the MisInfoText repository as a contribution of our lab to the community. We make available the full text of the news articles, together with veracity labels previously assigned based on manual assessment of the articles’ truth content. We also perform a topic modelling experiment to elaborate on the gaps and sources of imbalance in currently available datasets to guide future efforts. We appeal to the community to collect more data and to make it available for research purposes. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719843310",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Fatemeh Torabi Asr",
        "Maite Taboada"
      ],
      "url": "https://doi.org/10.1177/2053951719843310",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 64,
      "is_referenced_by_count": 80,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5820bf44-6180-4bac-92eb-b68c65f0b806",
    "title": "Practicing, materialising and contesting environmental data",
    "abstract": "<jats:p> While there are now an increasing number of studies that critically and rigorously engage with Big Data discourses and practices, these analyses often focus on social media and other forms of online data typically generated about users. This introduction discusses how environmental Big Data is emerging as a parallel area of investigation within studies of Big Data. New practices, technologies, actors and issues are concretising that are distinct and specific to the operations of environmental data. Situating these developments in relation to the seven contributions to this special collection, the introduction outlines significant characteristics of environmental data practices, data materialisations and data contestations. In these contributions, it becomes evident that processes for validating, distributing and acting on environmental data become key sites of materialisation and contestation, where new engagements with environmental politics and citizenship are worked through and realised. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716673391",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Jennifer Gabrys"
      ],
      "url": "https://doi.org/10.1177/2053951716673391",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 53,
      "is_referenced_by_count": 41,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8513fd94-9d6a-4ce3-a4cc-7b338821cf6d",
    "title": "Adapting computational text analysis to social science (and vice versa)",
    "abstract": "<jats:p> Social scientists and computer scientist are divided by small differences in perspective and not by any significant disciplinary divide. In the field of text analysis, several such differences are noted: social scientists often use unsupervised models to explore corpora, whereas many computer scientists employ supervised models to train data; social scientists hold to more conventional causal notions than do most computer scientists, and often favor intense exploitation of existing algorithms, whereas computer scientists focus more on developing new models; and computer scientists tend to trust human judgment more than social scientists do. These differences have implications that potentially can improve the practice of social science. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715602908",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Paul DiMaggio"
      ],
      "url": "https://doi.org/10.1177/2053951715602908",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 33,
      "is_referenced_by_count": 118,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "043f2190-0b6b-46c4-ad29-6a0ad15a1ccd",
    "title": "Big–Thick Blending: A method for mixing analytical insights from big and thick data sources",
    "abstract": "<jats:p> Recent works have suggested an analytical complementarity in mixing big and thick data sources. These works have, however, remained as programmatic suggestions, leaving us with limited methodological inputs on how to archive such complementary integration. This article responds to this limitation by proposing a method for ‘blending’ big and thick analytical insights. The paper first develops a methodological framework based on the cognitivist linguistics terminology of ‘blending’. Two cases are then explored in which blended spaces are crafted from engaging big and thick analytical insights with each other. Through these examples, we learn how blending processes should be conducted as a rapid, iterative and collaborative effort with respect for individual expertise. Further, we demonstrate how the unique, but often overlooked, granularity of big data plays a key role in affording the blending with thick data. We conclude by suggesting four commonly appearing blending strategies that can be applied when relying upon big and thick data sources. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718765026",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Tobias Bornakke",
        "Brian L Due"
      ],
      "url": "https://doi.org/10.1177/2053951718765026",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 58,
      "is_referenced_by_count": 43,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b4ba3c31-24d5-477f-ad03-7c52e1b8c9ab",
    "title": "Framing Big Data: The discursive construction of a radio cell query in Germany",
    "abstract": "The article examines the construction of “Big Data” in media discourse. Rather than asking what Big Data really is or is not, it deals with the discursive work that goes into making Big Data a socially relevant phenomenon and problem in the first place. It starts from the idea that in modern societies the public understanding of technology is largely driven by a media-based discourse, which is a key arena for circulating collectively shared meanings. This largely ignored dimension invites us to appreciate what matters to journalists and the wider public when discussing the collection and use of data. To this end, our study looks at how Big Data is framed in terms of the governmental use of large datasets as a contentious area of data application. It reconstructs the perspectives surrounding the so-called “Handygate” affair in Germany based on broadcast news and social media conversations. In this incident, state authorities collected and analyzed mobile phone data through a radio cell query during events to commemorate the Dresden bombing in February 2011. We employ a qualitative discourse analysis that allows us to reconstruct the conceptualizations of Big Data as a proper instrument for criminal prosecution or an unjustified infringement of constitutional rights.",
    "metadata": {
      "doi": "10.1177/2053951717745897",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Christian Pentzold",
        "Charlotte Fischer"
      ],
      "url": "https://doi.org/10.1177/2053951717745897",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171774589",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 43,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "893c2b3d-8447-40cc-b7a8-354aafaa94b9",
    "title": "Institutions, infrastructures, and data friction – Reforming secondary use of health data in Finland",
    "abstract": "<jats:p>New data-driven ideas of healthcare have increased pressures to reform existing data infrastructures. This article explores the role of data governing institutions during a reform of both secondary health data infrastructure and related legislation in Finland. The analysis elaborates on recent conceptual work on data journeys and data frictions, connecting them to institutional and regulatory issues. The study employs an interpretative approach, using interview and document data. The results show the stark contrast between the goals of open and Big Data inspired reforms and the existing institutional realities. The multiple tensions that emerged during the process indicate how data frictions emanate to the institutional level, and how mundane data practices and institutional dynamics are intertwined. The article argues that in the Finnish case, public institutions acted as sage-guards of public interest, preventing more controversial parts from passing. Finally, it argues that initiating regulatory and infrastructural reforms simultaneously was beneficial for solving the tensions of the initiative and analysing either side separately would have produced misleading accounts of the overall initiative. The results highlight the benefits of analysing institutional dynamics and data practices as connected issues.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719875980",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Ville Aula"
      ],
      "url": "https://doi.org/10.1177/2053951719875980",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171987598",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 48,
      "is_referenced_by_count": 18,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d253d9ee-12aa-4d59-87ce-7b7ca80c29a7",
    "title": "After automation: Homelessness prioritization algorithms and the future of care labor",
    "abstract": "<jats:p> People experiencing homelessness seek support from homeless services systems that increasingly rely on prioritization algorithms to determine who is the most deserving of scarce resources. In this paper, we argue that algorithmic harms in homeless services require a reparative approach that takes the data work of care workers seriously. Building on Davis, Williams, and Yang's concept of algorithmic reparation, we present a qualitative study that examines the intertwining of data work and care labor of 15 care workers. We show how they wrestle with the ethics of algorithmic prioritization and develop workarounds that allow them to advocate for their clients. We contribute an empirical understanding of how care workers provide care under homeless services systems that equate data work with care labor to justify work intensification. Our findings have implications for understanding the future of care labor in datafied conditions and the social and political ramifications of algorithmically mediated care. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241239043",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Pelle Tracey",
        "Patricia Garcia"
      ],
      "url": "https://doi.org/10.1177/20539517241239043",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 36,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9c6089e1-b533-4f18-9ca3-067b637512c5",
    "title": "Digital identity: Contemporary challenges for data protection, privacy and non-discrimination rights",
    "abstract": "<jats:p> The World Bank estimates that over one billion people currently lack official identity documents. To tackle this crucial issue, the United Nations included the aim to provide legal identity for all by 2030 among the Sustainable Development Goals. Technology can be a powerful tool to reach this target. In the digital age, new technologies increasingly mediate identity verification and identification of individuals. Currently, State-led and public–private initiatives use technology to provide official identification, to control and secure external borders, and to distribute humanitarian aid to populations in need. All of these initiatives have profound implications for the protection of human rights of those affected by them. Digital identity technologies may render individuals without legal documentation more visible and therefore less vulnerable to abuse and exploitation. However, they also present risks for the protection of individuals' human rights. As they build on personal data for identification and identity verification, data protection and privacy rights are most clearly affected. The prohibition of discrimination in the digital space is also of concern as these technological advances' societal impact is not yet fully understood. Accordingly, the article argues that emerging digital identity platforms will only contribute to the protection of human rights if the providers adequately mitigate any risks of potential discrimination and promote high standards of privacy and data protection. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719855091",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Ana Beduschi"
      ],
      "url": "https://doi.org/10.1177/2053951719855091",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171985509",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 16,
      "is_referenced_by_count": 30,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a78ff087-360f-4179-8e8f-2bcd03ebc18a",
    "title": "Situating AI policy: Controversies covered and the normalisation of AI",
    "abstract": "<jats:p> Artificial intelligence has become an issue in public policy. Multiple documents issued by public sector actors link artificial intelligence to a wide range of issues, problems or goals and propose corresponding measures and interventions. While there has been substantial research on national and supranational artificial intelligence strategies and regulations, this article is interested in unpacking the processes and priorities of artificial intelligence policy in the making. Conceptually, this article takes a controversy studies lens onto artificial intelligence policy, and complements this with concepts and insights from policy studies. Empirically, we investigate the emergence of German artificial intelligence policy based on content analyses of policy documents and expert interviews. The findings reveal a late, but then powerful institutionalisation of artificial intelligence policy in German federal politics. Artificial intelligence policy in Germany focuses on funding research and supporting industry actors in networked configurations, much more than addressing societal concerns on inequality, discrimination or political economy. With regard to controversies, we observe that German policy is evading controversies by normalising artificial intelligence both with regard to taking artificial intelligence integration in all sectors of society for granted, as well as by accommodating artificial intelligence issues into the routines and institutions of German policy. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241299725",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Laura Liebig",
        "Anna Jobin",
        "Licinia Güttel",
        "Christian Katzenbach"
      ],
      "url": "https://doi.org/10.1177/20539517241299725",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 74,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "45f7c620-6fcd-4bc1-8fc7-dafc31a80e91",
    "title": "Trade-offs in AI assistant choice: Do consumers prioritize transparency and sustainability over AI assistant performance?",
    "abstract": "<jats:p> As artificial intelligence (AI) becomes more integrated into society, concerns have arisen about unintended biases in AI-driven decision-making and the environmental impact of AI technology development. AI assistants such as Siri and Alexa, while helpful, can obscure decision-making and contribute to increased energy use and CO2 emissions. The present study explores whether consumers prioritize transparency and environmental sustainability over performance when choosing AI assistants with conjoint designs. Japanese participants were presented with different AI assistant profiles, varying in performance quality, transparency, cost, and environmental efficiency. The results revealed that Japanese participants prioritized transparency over performance when choosing AI assistants, but they prioritized performance over environmental sustainability. Moreover, future-oriented participants placed more importance on sustainability than those with a present orientation, while participants with an internal locus of control valued transparency more than those with an external locus of control. The findings of this study enhance our understanding of how consumers choose AI options and offer valuable guidance for creating AI systems and communication strategies that work effectively. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241290217",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Tomohiro Ioku",
        "Jaehyun Song",
        "Eiichiro Watamura"
      ],
      "url": "https://doi.org/10.1177/20539517241290217",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 108,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "79c73ef8-8754-4575-a7bf-d3bbe466d78e",
    "title": "Strong or thin digital democracy? The democratic implications of Taiwan's open government data policy in the 2010s",
    "abstract": "<jats:p> What kind of “democracy” do new government-led digital initiatives facilitate? This paper discusses the issue by investigating the open government data policy in Taiwan in the 2010s, asking whether the policy encouraged “strong democracy.” Using interviews, written records, and an analysis of platform design, I argue that the implementation of Taiwan's open data policy has not institutionalized the engagement of civil society groups or ordinary citizens in government decision-making processes, which is at odds with the claims that open government data encourages “strong democracy.” Instead, open government data in Taiwan has facilitated monitorial democracy, which presupposes watchful but not active citizens, and neoliberal democracy, which presupposes profit-pursuing citizens. Both are more in line with “thin democracy,” which focuses more on individual rights and private interests than on participation and political community. The finding sheds light on why conservative governments around the world often embrace open government initiatives. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241296038",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Terrence Ting-Yen Chen"
      ],
      "url": "https://doi.org/10.1177/20539517241296038",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 69,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5a5a2bd2-c4d6-4b2a-b4d1-0affc8ca45c1",
    "title": "Big Data and surveillance: Hype, commercial logics and new intimate spheres",
    "abstract": "<jats:p> Big Data Analytics promises to help companies and public sector service providers anticipate consumer and service user behaviours so that they can be targeted in greater depth. The attempts made by these organisations to connect analytically with users raise questions about whether surveillance, and its associated ethical and rights-based concerns, are intensified. The articles in this special themed issue explore this question from both organisational and user perspectives. They highlight the hype which firms use to drive consumer, employee and service user engagement with analytics within both private and public spaces. Further, they explore extent to which, through Big Data, there is an attempt to expand surveillance into the emotional registers of domestic, embodied experience. Collectively, the papers reveal a fascinating nexus between the much-vaunted potential of analytics, the data practices themselves and the newly configured intimate spheres which have been drawn into the commercial value chain. Together, they highlight the need for conceptual and regulatory innovation so that analytics in practice may be better understood and critiqued. Whilst there is now a rich variety of scholarship on Big Data Analytics, critical perspectives on the organising practices of Big Data Analytics and its surveillance implications are thin on the ground. Combined, the articles published in this special theme begin to address this shortcoming. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720925853",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Kirstie Ball",
        "William Webster"
      ],
      "url": "https://doi.org/10.1177/2053951720925853",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172092585",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 17,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4bd2c877-bff6-493f-9afc-599321a3fa8b",
    "title": "The social media image",
    "abstract": "<jats:p> How do the organization and presentation of large-scale social media images recondition the process by which visual knowledge, value, and meaning are made in contemporary conditions? Analyzing fundamental elements in the changing syntax of existing visual software ontology—the ways current social media platforms and aggregators organize and categorize social media images—this article relates how visual materials created within social media platforms manifest distinct modes of knowledge production and acquisition. First, I analyze the structure of social media images within data streams as opposed to previous information organization in a structured database. While the database has no pre-defined notions of time and thus challenges traditional linear forms, the data stream re-emphasizes the linearity of a particular data sequence and activates a set of new relations to contemporary temporalities. Next, I show how these visual arrangements and temporal principles are manifested and discussed in three artworks: “Untitled” (Perfect Lovers) by Felix Gonzalez-Torres (1991), The Clock by Christian Marclay (2011), and Last Clock by Jussi Ängeslevä and Ross Cooper (2002). By emphasizing the technical and poetic ways in which social media situate the present as a “thick” historical unit that embodies multiple and synchronous temporalities, this article illuminates some of the conditions, challenges, and tensions between former visual structures and current ones, and unfolds the cultural significations of contemporary big visual data. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714546645",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "Nadav Hochman"
      ],
      "url": "https://doi.org/10.1177/2053951714546645",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 65,
      "is_referenced_by_count": 20,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "72e388df-d976-4315-a2de-ee83e98da486",
    "title": "Social media analytics and research testbed (SMART): Exploring spatiotemporal           patterns of human dynamics with geo-targeted social media messages",
    "abstract": "<jats:p> The multilevel model of meme diffusion conceptualizes how mediated messages diffuse over time and space. As a pilot application of implementing the meme diffusion, we developed the social media analytics and research testbed to monitor Twitter messages and track the diffusion of information in and across different cities and geographic regions. Social media analytics and research testbed is an online geo-targeted search and analytics tool, including an automatic data processing procedure at the backend and an interactive frontend user interface. Social media analytics and research testbed is initially designed to facilitate (1) searching and geo-locating tweet topics and terms in different cities and geographic regions; (2) filtering noise from raw data (such as removing redundant retweets and using machine learning methods to improve precision); (3) analyzing social media data from a spatiotemporal perspective; and (4) visualizing social media data in diagnostic ways (such as weekly and monthly trends, trend maps, top media, top retweets, top mentions, or top hashtags). Social media analytics and research testbed provides researchers and domain experts with a tool that can efficiently facilitate the refinement, formalization, and testing of research hypotheses or questions. Three case studies (flu outbreaks, Ebola epidemic, and marijuana legalization) are introduced to illustrate how the predictions of meme diffusion can be examined and to demonstrate the potentials and key functions of social media analytics and research testbed. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716652914",
      "type": "journal-article",
      "published": [
        2016,
        6
      ],
      "authors": [
        "Jiue-An Yang",
        "Ming-Hsiang Tsou",
        "Chin-Te Jung",
        "Christopher Allen",
        "Brian H Spitzberg",
        "Jean Mark Gawron",
        "Su-Yeon Han"
      ],
      "url": "https://doi.org/10.1177/2053951716652914",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 23,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e43bd07c-01e0-4f9a-9f95-c27797f70854",
    "title": "Experiments with a data-public: Moving digital methods into critical proximity with political practice",
    "abstract": "<jats:p> Making publics visible through digital traces has recently generated interest by practitioners of public engagement and scholars within the field of digital methods. This paper presents an experiment in moving such methods into critical proximity with political practice and discusses how digital visualizations of topical debates become appropriated by actors and hardwired into existing ecologies of publics and politics. Through an experiment in rendering a specific data-public visible, it shows how the interplay between diverse conceptions of the public as well as the specific platforms and data invoked, resulted in a situated affordance-space that allowed specific renderings take shape, while disadvantaging others. Furthermore, it argues that several accepted tropes in the literatures of digital methods ended up being problematic guidelines in this space. Among these is the prescription to shown heterogeneity by pushing back at established media logics. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718825357",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Anders Koed Madsen",
        "Anders Kristian Munk"
      ],
      "url": "https://doi.org/10.1177/2053951718825357",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 51,
      "is_referenced_by_count": 15,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b85c162e-afd9-4423-9b76-ad2509c4e539",
    "title": "The politics of the NPC meme: Reactionary subcultural practice and vernacular theory",
    "abstract": "<jats:p> The acronym ‘NPC’ originates from videogame culture, where it refers to computer-controlled drones whose behaviour is dictated by their programming. By 2018 the term had gained traction within right-wing subcultural spaces as shorthand for individuals apparently incapable of thinking for themselves. By the autumn of 2018, these spaces were awash with NPC memes accusing liberals and leftists of uncritically accepting progressive doxa and parroting left-wing catchphrases. In mid-October, with midterm elections looming in the US, Twitter banned over 1000 NPC roleplay accounts created by supporters of Donald Trump, citing concerns over disinformation. This event was much discussed both within right-wing subcultural spaces and by mainstream media outlets, serving as an occasion to reassess the political effects of digital media in general and reactionary memes in particular. Here we use a combination of computational analysis and theoretically informed close reading to trace the NPC meme's trajectory and explore its role in entrenching affectively charged political and (sub)cultural faultlines. We show how mainstream attention at once amplified the meme and attenuated its affective resonance in the subcultural spaces where it originated. We also contend that while the NPC meme has served as a vehicle for antidemocratic bigotry, it may yet harbour critical potential, providing a vocabulary for theorising the cultural and political impacts of communicative capitalism. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231172422",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Rob Gallagher",
        "Robert Topinka"
      ],
      "url": "https://doi.org/10.1177/20539517231172422",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 51,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "82ab8e75-b2a4-4ce5-906a-1ded4cf4f954",
    "title": "Data-bodies and data activism: Presencing women in digital heritage research",
    "abstract": "<jats:p> As heritage-as-the-already-occurred folds into heritage-in-the-making practices, temporal and spatial fluidity is made more complex by digital mediation and particularly by Big Data. Such liveliness evokes ontological, epistemological and methodological challenges. Drawing on more-than-human theorizing, this article reframes the notion of data-bodies to advance data activist-oriented research in heritage. Focused primarily on women, it examines how their distributed agency and voice with respect to data practices and the (re)makings of (digital) heritage could be amplified. I describe three methodological directions, influenced by feminist work in critical data studies, which could be employed by researchers: attuning to and becoming with data, making data physical and changing narratives. From data-bodies to haunted data, performative data curation and mapping data-bodies, and attuning to data streams and re-voicing narratives, this article contributes to discussions of how to engage critically and creatively with the datafication of digital heritage practices, knowings and ontologies. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720965613",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Terrie Lynn Thompson"
      ],
      "url": "https://doi.org/10.1177/2053951720965613",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 45,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "807e1f26-193f-41b6-ad15-95f73c0c5874",
    "title": "Locative media and data-driven computing experiments",
    "abstract": "<jats:p> Over the past two decades urban social life has undergone a rapid and pervasive geocoding, becoming mediated, augmented and anticipated by location-sensitive technologies and services that generate and utilise big, personal, locative data. The production of these data has prompted the development of exploratory data-driven computing experiments that seek to find ways to extract value and insight from them. These projects often start from the data, rather than from a question or theory, and try to imagine and identify their potential utility. In this paper, we explore the desires and mechanics of data-driven computing experiments. We demonstrate how both locative media data and computing experiments are ‘staged’ to create new values and computing techniques, which in turn are used to try and derive possible futures that are ridden with unintended consequences. We argue that using computing experiments to imagine potential urban futures produces effects that often have little to do with creating new urban practices. Instead, these experiments promote Big Data science and the prospect that data produced for one purpose can be recast for another and act as alternative mechanisms of envisioning urban futures. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716652161",
      "type": "journal-article",
      "published": [
        2016,
        6
      ],
      "authors": [
        "Sung-Yueh Perng",
        "Rob Kitchin",
        "Leighton Evans"
      ],
      "url": "https://doi.org/10.1177/2053951716652161",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 61,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2fea65ba-e7af-4d6e-9ca6-72b89183bcb6",
    "title": "Data and life on the street",
    "abstract": "<jats:p> What does the abundance of data and proliferation of data-making methods mean for the ordinary person, the person on the street? And, what could they come to mean? In this paper, we present an overview of a year-long project to examine just such questions and complicate, in some ways, what it is to ask them. The project is a collective exercise in which we – a mixture of social scientists, designers and makers – and those living and working on one street in Cambridge (UK), Tenison Road, are working to think through how data might be materialised and come to matter. The project aims to better understand the specificities and contingencies that arise when data is produced and used in place. Mid-way through the project, we use this commentary to give some background to the work and detail one or two of the troubles we have encountered in putting locally relevant data to work. We also touch on a methodological standpoint we are working our way into and through, one that we hope complicates the separations between subject and object in data-making and opens up possibilities for a generative refiguring of the manifold relations. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714539278",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "Alex S Taylor",
        "Siân Lindley",
        "Tim Regan",
        "David Sweeney"
      ],
      "url": "https://doi.org/10.1177/2053951714539278",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 8,
      "is_referenced_by_count": 18,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fb97421d-ce18-4069-8a58-ea0d230545cd",
    "title": "Occluded algorithms",
    "abstract": "<jats:p> Two definitions of algorithm, their uses, and their implied models of computing in society, are reviewed. The first, termed the structural programming definition, aligns more with usage in computer science, and as the name suggests, the intellectual project of structured programming. The second, termed the systemic definition, is more informal and emerges from ethnographic observations of discussions of software in both professional and everyday settings. Specific examples of locating algorithms within modern codebases are shared, as well as code directly impacting social and ethical concerns. The structural distinction between algorithms and social concerns is explained as mirroring the engineering construct of algorithms and data structures. It is proposed that, rather than this separation being an attempt to enforce a professional boundary and evade social responsibility, it is a crucial technical distinction within code which makes it clearer and more transparent. The power structures reinforced by the broader, cultural interpretations of algorithm are reconsidered, along with what it would mean for software to have an inclusive design culture. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719858743",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Adam Burke"
      ],
      "url": "https://doi.org/10.1177/2053951719858743",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171985874",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 17,
      "is_referenced_by_count": 19,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9e033b4a-d873-40c2-b4bd-7366512f1604",
    "title": "Google, data voids, and the dynamics of the politics of exclusion",
    "abstract": "<jats:p> This study deploys a critical approach to big data analytics to gauge the tentative contours of data voids in Google searches that reflect extreme-right dynamics of exclusion in the aftermath of the 2015 humanitarian crisis in Europe. The study adds complexity to the analysis of data voids, expanding the framework of investigation outside the USA context by concentrating on Germany and Sweden. Building on previous big data analytics addressing the politics of exclusion, the study proposes a catalogue of queries concerning the issue of migration in both Germany and Sweden on a continuum from mainstream to extreme-right vocabularies. This catalogue of queries enables specific and localized queries to identify data voids. The results show that a search engine's reliance on source popularity may lead to extreme-right sources appearing in top positions. Furthermore, using platforms for user-generated content provides a way for localized queries to gain top positions. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221149099",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Ov Cristian Norocel",
        "Dirk Lewandowski"
      ],
      "url": "https://doi.org/10.1177/20539517221149099",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 65,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9febccae-7ceb-45ea-8f19-b4bf0d904cbf",
    "title": "Digital phenotyping and the (data) shadow of Alzheimer's disease",
    "abstract": "<jats:p> In this paper, we examine the practice and promises of digital phenotyping. We build on work on the ‘data self’ to focus on a medical domain in which the value and nature of knowledge and relations with data have been played out with particular persistence, that of Alzheimer's disease research. Drawing on research with researchers and developers, we consider the intersection of hopes and concerns related to both digital tools and Alzheimer's disease using the metaphor of the ‘data shadow’. We suggest that as a tool for engaging with the nature of the data self, the shadow is usefully able to capture both the dynamic and distorted nature of data representations, and the unease and concern associated with encounters between individuals or groups and data about them. We then consider what the data shadow ‘is’ in relation to ageing data subjects, and the nature of the representation of the individual's cognitive state and dementia risk that is produced by digital tools. Second, we consider what the data shadow ‘does’, through researchers and practitioners’ discussions of digital phenotyping practices in the dementia field as alternately empowering, enabling and threatening. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211070748",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Richard Milne",
        "Alessia Costa",
        "Natassia Brenman"
      ],
      "url": "https://doi.org/10.1177/20539517211070748",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 53,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c4a180fa-da6e-4e36-976e-c3b00f94322d",
    "title": "Corrigendum to Spotify as a technology for integrating health, exercise and wellness practices into financialised capitalism",
    "abstract": "",
    "metadata": {
      "doi": "10.1177/20539517231216843",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [],
      "url": "https://doi.org/10.1177/20539517231216843",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "not available"
    }
  },
  {
    "id": "6c40acb8-918d-4687-95fe-cbcab25422f0",
    "title": "The ‘sentient’ city and what it may portend",
    "abstract": "<jats:p> The claim is frequently made that, as cities become loaded up with information and communications technology and a resultant profusion of data, so they are becoming sentient. But what might this mean? This paper offers some insights into this claim by, first of all, reworking the notion of the social as a spatial complex of ‘outstincts’. That makes it possible, secondly, to reconsider what a city which is aware of itself might look like, both by examining what kinds of technological practices are becoming commonplace and by considering the particular case of spatial awareness. In turn, this leads to a third rumination on how cities might become aware as different kinds of sprite, channelling outstincts in spatially variable ways. Whatever the case, it is clear that new technical-artistic interventions are required if these sprites are not to become simply servants of the security–entertainment complex. Some of these interventions are examined in the fourth part of the paper. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714532241",
      "type": "journal-article",
      "published": [
        2014,
        4,
        1
      ],
      "authors": [
        "Nigel Thrift"
      ],
      "url": "https://doi.org/10.1177/2053951714532241",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 126,
      "is_referenced_by_count": 88,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "02f2a255-2071-421b-b6a4-a9b435ed4311",
    "title": "Médialab stories: How to align actor network theory and digital methods",
    "abstract": "<jats:p> The history of laboratories may become controversial in social sciences. In this paper, the story of Sciences Po Médialab told by Venturini et al. is discussed and completed by demonstrating the incoherence in the choice of digital methods at the Médialab from the actor network theory perspective. As the Médialab mostly used web topologies as structural analysis of social positions, they were not able to account for the propagation of ideas, considered in actor network theory as non-humans that have their own agency. The main arguments in favour of the ‘more continuous social’ developed at the Médialab (quali-quanti, following the actors, zooming) proved to be as misleading as the network metaphor. The distribution of agency that actor network theory so successfully expands was paradoxicallty reduced to structures and individual preferences, to the detriment of the agency of replications that circulate entities in the form of messages, content or memes, and that should now become the next step for actor network theory-style digital methods. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718816722",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Dominique Boullier"
      ],
      "url": "https://doi.org/10.1177/2053951718816722",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 64,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "07b2e5c5-3d81-4948-ac88-4430ee066588",
    "title": "Deleterious consequences: How Google's original sociotechnical affordances ultimately shaped ‘trusted users’ in surveillance capitalism",
    "abstract": "<jats:p> Google dominates around 92% of the search market worldwide (as of November 2022), with most of its revenue derived from search advertising. However, Google's hegemony over search and the resulting implications are not necessarily accidental, arbitrary or (un)intentional. This article revisits Brin and Page's original paper, drawing on six of their key innovations, concerns and design choices ( counting citations or backlinks, trusted user, advertising, personalization, usage data, smart algorithms) to explain the evolution of Google's hypertext search engine technologies through ‘moments of contingency’, which led to corporate lock-ins. Underpinned by analyses of patents, statements and secondary sources, it elucidates how early Google considerations and certain affordances not only came to shape the web ( backlinks, trusted user, advertising) but subsequently facilitated contemporary surveillance capitalism. Building upon Zuboff's ‘Big Other’, it describes the ways in which Google as an infrastructure is intertwined with Big Data's platformization and the ad infinitum collection of usage data, beyond just personalization. This extraction and refinement of usage data as ‘behavioural surplus’ results in ‘deleterious consequences’: a ‘habit of automaticity,’ which shapes the trusted user through ‘ubiquitous googling’ and smart algorithms, whilst simultaneously generating prediction products for surveillance capitalism. Advancing Latour's ‘predicting the path’ of technological innovation, this cause-and-effect story contributes a new taxonomy of Google sociotechnical affordances to critical STS, media history and web search literature. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231171058",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Renée Ridgway"
      ],
      "url": "https://doi.org/10.1177/20539517231171058",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 70,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "72a3f80e-f14a-4c73-a1fe-09763bfd59ba",
    "title": "Mapping Persian Twitter: Networks and mechanism of political communication in Iranian 2017 presidential election",
    "abstract": "<jats:p> This paper investigates the structure of networked publics and their sharing practices in Persian Twitter during a period surrounding Iran’s 2017 presidential election. Building on networked gatekeeping and framing theories, we used a mixed methodological approach to analyze a dataset of 2,596,284 Persian tweets. Results revealed that Twitter provided a space for Iranians to discuss public topics. However, this space is not necessarily used by voiceless and marginalized groups; and the uses are not limited to discussing controversial issues. The growing body of conservative crowdsourced elites emerged to defend the regime’s ideology. Moreover, the dominant networked frames were shaped around normal and routine subjects in an election time. Thus, Twitter was not a platform for only seeking liberal demands. It was to some extent used to serve the regime’s political interests. Furthermore, while many ordinary users rose to prominence, mainstream media continued to act as powerful players. This study contributes to the existing literature into networked practices, digital democracy, and citizen journalism; particularly in restrictive contexts. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211025568",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Hossein Kermani",
        "Marzieh Adham"
      ],
      "url": "https://doi.org/10.1177/20539517211025568",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 63,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e8824d10-515a-49f5-b634-f0c93ef09b39",
    "title": "Editorial introduction: Towards a machinic anthropology",
    "abstract": "<jats:p> Bringing together a motley crew of social scientists and data scientists, the aim of this special theme issue is to explore what an integration or even fusion between anthropology and data science might look like. Going beyond existing work on the complementarity between ‘thick’ qualitative and ‘big’ quantitative data, the ambition is to unsettle and push established disciplinary, methodological and epistemological boundaries by creatively and critically probing various computational methods for augmenting and automatizing the collection, processing and analysis of ethnographic data, and vice versa. Can ethnographic and other qualitative data and methods be integrated with natural language processing tools and other machine-learning techniques, and if so, to what effect? Does the rise of data science allow for the realization of Levi-Strauss’ old dream of a computational structuralism, and even if so, should it? Might one even go as far as saying that computers are now becoming agents of social scientific analysis or even thinking: are we about to witness the birth of distinctly anthropological forms of artificial intelligence? By exploring these questions, the hope is not only to introduce scholars and students to computational anthropological methods, but also to disrupt predominant norms and assumptions among computational social scientists and data science writ large. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231153803",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Morten Axel Pedersen"
      ],
      "url": "https://doi.org/10.1177/20539517231153803",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 110,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c85a01d5-9321-47c7-954b-fb05b36d7bd3",
    "title": "Productive myopia: Racialized organizations and edtech",
    "abstract": "<jats:p> This paper reports on a two-year, field-based study set in a charter management organization (CMO-LAX), a not-for-profit educational organization that operates 18 public schools exclusively in the Black and Latinx communities of South and East Los Angeles. At CMO-LAX, the nine-member Data Team pursues the organization's avowed mission of making public schools data-driven, primarily through the aggregation, analysis, and visualization of digital data derived from quotidian educational activities. This paper draws on the theory of racialized organizations to characterize aspects of data-driven management of public education as practiced by CMO-LAX. I explore two examples of how CMO-LAX shapes data to support racial projects: the reconstruction of the figure of chronic truants and the incorporation of this figure in a calculative regime of student accomplishment. Organizational uses of data support a strategy I call productive myopia, a way of pursuing racial projects via seemingly independent, objective quantifications. This strategy allows the organization to claim to mitigate racial projects and, simultaneously, to accommodate them. This paper concludes by arguing for approaches to research and practice that center racial projects, particularly when data-intensive tools and platforms are incorporated into the provision of public goods and services such as education. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211050499",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Roderic Crooks"
      ],
      "url": "https://doi.org/10.1177/20539517211050499",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 98,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "705232c5-ac40-4a6f-9a52-b7213b6fac56",
    "title": "Social data governance: From reflective practices to comparative synthesis",
    "abstract": "<jats:p> This special theme brings together reflections and deliberations regarding the design, implementation, and development of data governance. By addressing “social data governance” as the keyword of the special theme, we aim to further the discussion on a contextual understanding of both the governing foundations and effects of data, dataism, and datafication in different societies. Such a discussion reminds us to pay particular attention to—and thus account for—the social dynamics that underpin and contextualize the design, operation, and promotion of quantified governing mechanisms in which information on social behaviors is collected, datafied, manipulated, and represented. Essentially, the social dynamics of data governance have existed for a long time and in many forms, ranging from credit bureaus’ scrutiny, evaluation, and labeling of their customers to internet-enabled massive data collection and scoring systems used by governments, and to automated contact tracing techniques as a centerpiece of dataveillance and infection control amid the COVID-19 pandemic. Nevertheless, scholarly work from a wide range of disciplines like law, mathematics, and business and with diverse geographical foci has not yet been comparatively and reflectively articulated. Being rich and diverse, the special theme advances such a requisite understanding of the status and relevance of social dynamics of data governance mechanisms based on a wide range of empirical cases around the globe. To scrutinize the social dynamics helps illuminate and contrast divergent manifestations of data governance and their underlying mechanisms. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221139786",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Jun Liu",
        "Jing Wang"
      ],
      "url": "https://doi.org/10.1177/20539517221139786",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 44,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "79c0e541-6692-448e-84dc-c3507a20f83d",
    "title": "For what it's worth. Unearthing the values embedded in digital phenotyping for mental health",
    "abstract": "<jats:p> Digital phenotyping for mental health is an emerging trend which uses digital data, derived from mobile applications, wearable technologies and digital sensors, to measure, track and predict the mental health of an individual. Digital phenotyping for mental health is a growing, but as yet underexamined, field. As we will show, the rapid growth of digital phenotyping for mental health raises crucial questions about the values that underpin and are reinforced by this technology, as well as regarding to whom it may become valuable. In this commentary, we explore these questions by focusing on the construction of value across two interrelated domains: user experience and epistemologies on the one hand, and issues of data and ownership on the other. In doing so, we demonstrate the need for a deeper ethical and epistemological engagement with the value assumptions that underpin the promise of digital phenotyping for mental health. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211047319",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Rasmus Birk",
        "Anna Lavis",
        "Federica Lucivero",
        "Gabrielle Samuel"
      ],
      "url": "https://doi.org/10.1177/20539517211047319",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 25,
      "is_referenced_by_count": 15,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "14524947-516b-4dce-8a83-950ee425cb40",
    "title": "Engaging citizens in experiments with computational analysis of patient stories: From unwarranted reductions to meaningful insights",
    "abstract": "<jats:p> In recent years, citizen engagement in policy and research has gained considerable momentum. In the healthcare domain, patient narratives, through various mediums, have emerged as a valuable source of insight into the experiences of patients and the healthcare system. Recognizing the value of such textual data, diverse analytical methods have been developed, spanning from text mining to narrative analysis. This article presents experiments that combine computational methods, qualitative methods and citizen science for analyzing patients’ stories. In this article, we reflect on two experiments in which we combined these approaches, which we analyze through a generative lens. We distinguish three main effects of the experiments: they provide a platform for discussions as a 'site of controversy'; they act as 'mediator', fostering new connections and mutual understanding among participants; and they serve as 'tin opener', stimulating substantive discussions about methodological development and substantive healthcare matters. Narrative reduction, which occurs when rich narrative data is simplified into structured quantifiable forms, is not inherently problematic; instead, it can be meaningful when combined with qualitative methods and citizen science, emphasizing the importance of utilizing diverse methods to balance authenticity and gaining broader insights. The study highlights the significance of collaborative sense-making and meaning-making in interdisciplinary research. Engaging patients, their relatives, and professionals in the analytical process, facilitated by tools like word clouds, promotes engaged discussions that yield actionable insights. Further development of such interdisciplinary approaches holds promise for a more nuanced understanding of patient experiences, fostering epistemological pluralism, and refining healthcare practices. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241290218",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Nada Akrouh",
        "Rik Wehrens",
        "Hester van de Bovenkamp"
      ],
      "url": "https://doi.org/10.1177/20539517241290218",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 73,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "75b59a3a-19c9-45cb-a303-8ffaabad914d",
    "title": "Ethnographic data in the age of big data: How to compare and combine",
    "abstract": "<jats:p> Big data enables researchers to closely follow the behavior of large groups of individuals by using high-frequency digital traces. However, these digital traces often lack context, and it is not always clear what is measured. In contrast, data from ethnographic fieldwork follows a limited number of individuals but can provide the context often lacking from big data. Yet, there is an under-explored potential in combining ethnographic data with big data and other digital data sources. This paper presents ways that quantitative research designs can combine big data and ethnographic data and account for the synergies that such combinations can provide. We highlight the differences and similarities between ethnographic data and big data, focusing on the three dimensions: individuals, depth of information, and time. We outline how ethnographic data can validate big data by providing a “ground truth” and complement it by giving a “thick description.” Further, we lay out ways that analysis carried out using big data could benefit from collaboration with ethnographers, and we discuss the potential within the fields of machine learning and causal inference. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211069893",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Andreas Bjerre-Nielsen",
        "Kristoffer Lind Glavind"
      ],
      "url": "https://doi.org/10.1177/20539517211069893",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 34,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "24d0a22c-0739-41a7-8e19-711cb1c2157e",
    "title": "Responsible AI literacy: A stakeholder-first approach",
    "abstract": "<jats:p>The need for citizens to better understand the ethical and social challenges of algorithmic systems has led to a rapid proliferation of AI literacy initiatives. After reviewing the literature on AI literacy projects, we found that most educational practices in this area are based on teaching programming fundamentals, primarily to K-12 students. This leaves out citizens and those who are primarily interested in understanding the implications of automated decision- making systems, rather than in learning to code. To address these gaps, this article explores the methodological contributions of responsible AI education practices that focus first on stakeholders when designing learning experiences for different audiences and contexts. The article examines the weaknesses identified in current AI literacy projects, explains the stakeholder-first approach, and analyzes several responsible AI education case studies, to illustrate how such an approach can help overcome the aforementioned limitations. The results suggest that the stakeholder-first approach allows to address audiences beyond the usual ones in the field of AI literacy, and to incorporate new content and methodologies depending on the needs of the respective audiences, thus opening new avenues for teaching and research in the field.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231219958",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Daniel Domínguez Figaredo",
        "Julia Stoyanovich"
      ],
      "url": "https://doi.org/10.1177/20539517231219958",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 99,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "72b19492-e523-4e26-9c4b-6ec41b5393d2",
    "title": "Hackathons, data and discourse: Convolutions of the data (logical)",
    "abstract": "<jats:p> This paper draws together empirical findings from our study of hackathons in the UK with literature on big data through three interconnected frameworks: data as discourse, data as datalogical and data as materiality. We suggest not only that hackathons resonate the wider socio-technical and political constructions of (big) data that are currently enacted in policy, education and the corporate sector (to name a few), but also that an investigation of hackathons reveals the extent to which ‘data’ operates as a powerful discursive tool; how the discourses (and politics) of data mask and reveal a series of tropes pertaining to data; that the politics of data are routinely and simultaneously obscured and claimed with serious implications for expertise and knowledge; and that ultimately, and for the vast majority of hackathons we have attended, the discursive and material constructions of data serve to underpin rather than challenge existing power relations and politics. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716679675",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Helen Thornham",
        "Edgar Gómez Cruz"
      ],
      "url": "https://doi.org/10.1177/2053951716679675",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 51,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e3a1049b-a9e9-41b9-a05b-eef6d6a0fdf8",
    "title": "Cyborg finance mirrors cyborg social media",
    "abstract": "<jats:p> This article aims at showing the similarities between the financial and the tech sectors in their use and reliance on information and algorithms and how such dependency affects their attitude towards regulation. Drawing on Pasquale’s recommendations for reform, it sets out a proposal for a constant and independent scrutiny of internet service providers. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720935139",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Kamel Ajji"
      ],
      "url": "https://doi.org/10.1177/2053951720935139",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172093513",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 1,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1d1ba3f2-5094-436c-81ea-2ee3efef5c32",
    "title": "Controversing the datafied smart city: Conceptualising a ‘making-controversial’ approach to civic engagement",
    "abstract": "<jats:p> In this paper, we propose the concept of controversing as an approach for engaging citizens in debates around the datafied city and in shaping responsible smart cities that incorporate diverse public values. Controversing addresses the engagement of citizens in discussions about the datafication of urban life by productively deploying controversies around data. Attempts to engage citizens in the smart city frequently involve ‘neutral’ data visualisations aimed at making abstract sociotechnical issues more tangible. In addition, citizens are meant to gather around issues already defined externally by others. Instead, we focus on how people might become engaged and develop the capacity to shape alternative urban futures. We suggest that making controversial apparently less contentious issues in the smart city allows people to identify their own issues, come together temporarily as a public, imagine alternative possibilities and thus develop capacities for action. In this context, controversies can act as agents of change and open up new spaces for participation and action. We develop the notion of controversing as a deliberate strategy of making datafication controversial, and operationalise the term along the dimensions of recontextualisation, meaning-making and agency. We then look at two cases from the mid-sized city of Amersfoort in the Netherlands, first to test the conceptual potential of controversing to expose how frictions shape citizen engagement, and second to analyse how controversing may frame design-oriented methods aimed at involving diverse participants in discussing datafication and defining public values in the datafied smart city. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211025557",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Corelia Baibarac-Duignan",
        "Michiel de Lange"
      ],
      "url": "https://doi.org/10.1177/20539517211025557",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 17,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9a259f86-ca1c-49cf-a0a4-b5b5fe97191a",
    "title": "From attention economy to  cognitive lock-ins",
    "abstract": "<jats:p> The economic logic of the attention economy is frequently used to critique and respond to the dangers of unfettered technological expansion, including nascent platforms and products powered by generative artificial intelligence. This commentary warns that while large parts of the internet have been financed through such business models, there is no guarantee that emerging generative artificial intelligence products will be commercialized in this way too. Instead, I argue, we must look beyond the attention economy to predict the future of monetization of an industry already mired in anti-competitive practices. Using popular large language models such as OpenAI’s ChatGPT as a case, I discuss how some platforms are developing computational dependencies between technology and their users. I propose the term ‘cognitive lock-in’ to help us unpack the implications of such technological dependencies, and redirect the study of this nascent business model. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241275878",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Morten Hansen"
      ],
      "url": "https://doi.org/10.1177/20539517241275878",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 48,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ae225ab4-3898-4313-a3cd-e6f171c862bf",
    "title": "Capitalizing on transparency: Commercial surveillance and pharmaceutical marketing after the Physician Sunshine Act",
    "abstract": "<jats:p> How corporations surveil and influence consumers using big data tools is a major area of research and public debate. However, few studies explore it in relation to physicians in the USA, even though they have been surveilled and targeted by the pharmaceutical industry since at least the 1950s. Indeed, in 2010, concerns about the pharmaceutical industry's undue influence led to the passing of the Physician Sunshine Act, a unique piece of transparency legislation that requires companies to report their financial ties to physicians and teaching hospitals in a public database. This article argues that while the Sunshine Act has clearly helped expose important commercial influences on both prescribing and the scale of industry involvement with physicians, it has also, paradoxically, fuelled further commercial surveillance and marketing. The article casts new light on innovative pharmaceutical marketing approaches and the key role of data brokers and analytics companies in the identification, targeting, managing, and surveillance of physicians. We place this analysis within the political economies of the pharmaceutical industry, surveillance-based marketing, and transparency, and argue that policies to promote increased transparency must be tightly tied to policies that impede the commodification and use of transparency data for surveillance and marketing purposes. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211069631",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Shai Mulinari",
        "Piotr Ozieranski"
      ],
      "url": "https://doi.org/10.1177/20539517211069631",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 87,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5b69bcdc-1692-4b91-a6aa-2ac2d3f3be1d",
    "title": "How should we do the history of Big Data?",
    "abstract": "<jats:p> Taking its lead from Ian Hacking’s article ‘How should we do the history of statistics?’, this article reflects on how we might develop a sociologically informed history of Big Data. It argues that within the history of social statistics we have a relatively well developed history of the material phenomenon of Big Data. Yet this article argues that we now need to take the concept of ‘Big Data’ seriously, there is a pressing need to explore the type of work that is being done by that concept. The article suggests a programme for work that explores the emergence of the concept of Big Data so as to track the institutional, organisational, political and everyday adoption of this term. It argues that the term Big Data has the effect of making-up data and, as such, is powerful in framing our understanding of those data and the possibilities that they afford. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716646135",
      "type": "journal-article",
      "published": [
        2016,
        6,
        1
      ],
      "authors": [
        "David Beer"
      ],
      "url": "https://doi.org/10.1177/2053951716646135",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 30,
      "is_referenced_by_count": 39,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0bdf0f51-6842-4663-bbed-81757295b7d7",
    "title": "Weaving seams with data: Conceptualizing City APIs as elements of infrastructures",
    "abstract": "<jats:p> This article addresses the role of application programming interfaces (APIs) for integrating data sources in the context of smart cities and communities. On top of the built infrastructures in cities, application programming interfaces allow to weave new kinds of seams from static and dynamic data sources into the urban fabric. Contributing to debates about “urban informatics” and the governance of urban information infrastructures, this article provides a technically informed and critically grounded approach to evaluating APIs as crucial but often overlooked elements within these infrastructures. The conceptualization of what we term City APIs is informed by three perspectives: In the first part, we review established criticisms of proprietary social media APIs and their crucial function in current web architectures. In the second part, we discuss how the design process of APIs defines conventions of data exchanges that also reflect negotiations between API producers and API consumers about affordances and mental models of the underlying computer systems involved. In the third part, we present recent urban data innovation initiatives, especially CitySDK and OrganiCity, to underline the centrality of API design and governance for new kinds of civic and commercial services developed within and for cities. By bridging the fields of criticism, design, and implementation, we argue that City APIs as elements of infrastructures reveal how urban renewal processes become crucial sites of socio-political contestation between data science, technological development, urban management, and civic participation. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719827619",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Christoph Raetzsch",
        "Gabriel Pereira",
        "Lasse S Vestergaard",
        "Martin Brynskov"
      ],
      "url": "https://doi.org/10.1177/2053951719827619",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 92,
      "is_referenced_by_count": 24,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f4957011-17b1-4d11-9c63-256e7a9cbaf0",
    "title": "The fabrication of synthetic data promises: Tracing emerging arenas of expectations and boundary work<sup>1</sup>",
    "abstract": "<jats:p> Synthetic data, denoting artificially produced data that are used for data science tasks, are increasingly held as a promising solution to digital societies’ predicaments. While burgeoning research has investigated the implications of synthetic data, the fabrication of synthetic data promises remains understudied. This article draws on the sociology of expectations and the concept of boundary work to interrogate emerging arenas of expectations and attendant boundary work practices through which synthetic data promises are fabricated. To this end, it draws from a wide range of empirical materials, including scientific literatures, promissory reports, industry webinars, and interviews. First, it shows that scientific literatures reveal a strong increase in interest and three transformations in the framing of synthetic data in recent decades: from vernacular term to scientific concept, from possibility to inevitability, and from research technique to social promise. Second, it demonstrates that promissory organizations’ reports on synthetic data are generically performative as they circulate widely and constitute a source of authority for various stakeholders. Finally, it highlights three types of boundary work in relation to synthetic data: stipulations of its epistemic superiority, negotiations concerning most apt methodologies, and contestations regarding whether synthetic data are “fake.” I conclude by arguing that a sociology of expectations approach can productively question the hyperbolic promises attributed to synthetic data. Overall, this article contributes to germinal social studies of synthetic data by highlighting the constitutive role of expectations and boundary work in the fabrication of synthetic data promises. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241307915",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Louis Ravn"
      ],
      "url": "https://doi.org/10.1177/20539517241307915",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 93,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "28e5dd80-5ac1-4f08-be2a-5c07d8bf0333",
    "title": "‘I’ve left enough data’: Relations between people and data and the production of surveillance",
    "abstract": "<jats:p> Exploring emergent relations between data-producing individuals and their data products, this study aims to contribute to the ongoing scholarly discussion on agencies in data practices. It focuses on shifts in surveillance structure in the era of Big Data, in which the individual becomes both a subject and an object in the production of data surveillance. Drawing on the concept of the ‘dividual’, the study analyses data practices for a tracing system invented by the South Korean government during the COVID-19 pandemic, with findings from field research conducted with 11 research participants in various urban sites in Seoul. Highlighting how the tracing system positioned surveillance ‘in the hands of citizens’, the study exposes the complexities of the relations that the participants formed with the data they produced, and how they reflexively reappropriated their practices through alterations and deflections on the basis of their tacit knowledge and imaginaries concerning digital data and their constituent positions in the knowledge production system. The resultant expression of surveillance was directly shaped by the evolving relationship between the producers (participants) and products (digital data). The study proposes that an intersectional focus on surveillance and critical data studies, with close attention to ordinary people's relations with data, has the capacity to inquire into the politics of data more fully. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231173904",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Hwankyung Janet Lee"
      ],
      "url": "https://doi.org/10.1177/20539517231173904",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 53,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "25c80347-041a-41f9-b462-81c14b7a86e9",
    "title": "‘Data saves lives’: Ideational-material drivers of health data journeys in the UK",
    "abstract": "<jats:p> In this paper, we bring together the concepts of data valences and data journeys to examine how ideational and material factors work together to shape the movement of health data from the UK healthcare sector to universities for reuse in research. Specifically, we focus on the interaction of university-based researchers’ constructs about data with the material conditions of health data circulation in the UK and how these dynamics drive greater circulation of health data through the data sharing infrastructure. Building on our empirical research, we identify four data valences or expectations about data present in the discourses of university-based researchers – vanguard, discovery, truthiness and actionability – and three material factors – investment in data, infrastructure and labour. We argue that the interaction of these factors has created a favourable environment for making data flow from the healthcare sector into the hands of university-based researchers. This work contributes to a better understanding of why health data reuse practices are expanding and being sustained, and it challenges previous health data reuse research that treats the drivers shaping data flows as self-evident or already determined. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241296056",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Itzelle Medina-Perea",
        "Jo Bates",
        "Andrew Cox"
      ],
      "url": "https://doi.org/10.1177/20539517241296056",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 51,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "488aa2d2-1556-4bd5-933b-c7b7049dd251",
    "title": "“Too Soon” to count? How gender and race cloud notability considerations on Wikipedia",
    "abstract": "<jats:p> While research has explored the extent of gender bias and the barriers to women's inclusion on English-language Wikipedia, very little research has focused on the problem of racial bias within the encyclopedia. Despite advocacy groups' efforts to incrementally improve representation on Wikipedia, much is unknown regarding how biographies are assessed after creation. Applying a combination of web-scraping, deep learning, natural language processing, and qualitative analysis to pages of academics nominated for deletion on Wikipedia, we demonstrate how Wikipedia's notability guidelines are unequally applied across race and gender. We find that online presence predicts whether a Wikipedia page is kept or deleted for white male academics but that this metric is idiosyncratically applied for female and BIPOC academics. Further, women's pages, regardless of race, were more likely to be deemed “too soon” for Wikipedia. A deeper analysis of the deletion archives reveals that when the tag is used on a woman's biography it is done so outside of the community guidelines, referring to one's career stage rather than media/online coverage. We argue that awareness of hidden biases on Wikipedia is critical to the objective and equitable application of the notability criteria across race and gender both on the encyclopedia and beyond. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231165490",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Mackenzie Emily Lemieux",
        "Rebecca Zhang",
        "Francesca Tripodi"
      ],
      "url": "https://doi.org/10.1177/20539517231165490",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 94,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d870518c-257e-4a12-a331-7c47024c3360",
    "title": "Against carceral data collection in response to anti-Asian violences",
    "abstract": "<jats:p> This commentary reflects on recent instances of anti-Asian violence and state responses to redress violence through data-driven strategies. Data collection often presents itself as an appealing strategy, due to impacted communities’ desires for evidence and metrics to substantiate political claims. Yet, data collection can bolster the carceral state. This commentary takes an antagonistic approach to policing, including the ongoing creation of data infrastructures by—and for—law enforcement through hate crimes legislation. We critically discuss the challenges and possibilities in building towards anti-carceral responses amidst ongoing racial violence and crisis. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211028252",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Rachel Kuo",
        "Matthew Bui"
      ],
      "url": "https://doi.org/10.1177/20539517211028252",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e2147a7a-2723-4dc0-8711-9573620ec6ed",
    "title": "Negotiating the reuse of health-data: Research, Big Data, and the European General Data Protection Regulation",
    "abstract": "<jats:p>Before the EU General Data Protection Regulation entered into force in May 2018, we witnessed an intense struggle of actors associated with data-dependent fields of science, in particular health-related academia and biobanks striving for legal derogations for data reuse in research. These actors engaged in a similar line of argument and formed issue alliances to pool their collective power. Using descriptive coding followed by an interpretive analysis, this article investigates the argumentative repertoire of these actors and embeds the analysis in ethical debates on data sharing and biobank-related data governance. We observe efforts to perform a paradigmatic shift of the discourse around the General Data Protection Regulation-implementation away from ‘protecting data’ as key concern to ‘protecting health’ of individuals and societies at large. Instead of data protection, the key risks stressed by health researchers became potential obstacles to research. In line, exchange of information with data subjects is not a key concern in the arguments of biobank-related actors and it is assumed that patients want ‘their’ data to be used. We interpret these narratives as a ‘reaction’ to potential restrictions for data reuse and in line with a broader trend towards Big Data science, as the very idea of biobanking is conceptualized around long-term use of readily prepared data. We conclude that a sustainable implementation of biobanks needs not only to comply with the General Data Protection Regulation, but must proactively re-imagine its relation to citizens and data subjects in order to account for the various ways that science gets entangled with society.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719862594",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Johannes Starkbaum",
        "Ulrike Felt"
      ],
      "url": "https://doi.org/10.1177/2053951719862594",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171986259",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 35,
      "is_referenced_by_count": 26,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f733b9ba-a749-4ec0-880b-dbe31c99ae1b",
    "title": "Yellow Techno-Peril: The ‘Clash of Civilizations’ and anti-Chinese racial rhetoric in the US–China AI arms race",
    "abstract": "<jats:p> The rhetoric of an ‘AI arms race’ between the United States and China has become increasingly prominent over the past 5 years, despite warnings that it is unnecessarily polarising and undermines safe and ethical artificial intelligence (AI) development. However, existing critiques of the AI arms race narrative engage only sparingly with the racialised dimensions of this discourse. In this article, I draw on the rich theoretical insights of Asian American and Asian diaspora studies to show how the AI arms race narrative is deeply racialised in two key ways. First, I show how the rhetoric of an AI arms race builds upon the myth of a ‘Clash of Civilizations’ between the West and the East. This civilisational rhetoric constitutes China and the United States as distinct and mutually opposed cultural entities, thus foreclosing the possibility of more peaceful and cooperative alternatives to the AI arms race. Second, I demonstrate how the US–China AI arms race specifically draws on previous racialised configurations of anti-Asian sentiment, such as techno-Orientalism and the Yellow Peril. I coin the term Yellow Techno-Peril to connote how older European and Americans fears of being overrun or controlled by China are reproduced in the AI arms race. I close by offering recommendations to key stakeholders such as policymakers, decisionmakers, journalists and media organisations as to how they can mitigate and avoid the racialised rhetoric of an AI arms race between the United States and China. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241227873",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Kerry McInerney"
      ],
      "url": "https://doi.org/10.1177/20539517241227873",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 86,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "30ceff7d-506b-4b10-b41b-55cc8b44935a",
    "title": "Playing with machines: Using machine learning to understand automated copyright enforcement at scale",
    "abstract": "<jats:p>This article presents the results of methodological experimentation that utilises machine learning to investigate automated copyright enforcement on YouTube. Using a dataset of 76.7 million YouTube videos, we explore how digital and computational methods can be leveraged to better understand content moderation and copyright enforcement at a large scale.We used the BERT language model to train a machine learning classifier to identify videos in categories that reflect ongoing controversies in copyright takedowns. We use this to explore, in a granular way, how copyright is enforced on YouTube, using both statistical methods and qualitative analysis of our categorised dataset. We provide a large-scale systematic analysis of removals rates from Content ID’s automated detection system and the largely automated, text search based, Digital Millennium Copyright Act notice and takedown system. These are complex systems that are often difficult to analyse, and YouTube only makes available data at high levels of abstraction. Our analysis provides a comparison of different types of automation in content moderation, and we show how these different systems play out across different categories of content. We hope that this work provides a methodological base for continued experimentation with the use of digital and computational methods to enable large-scale analysis of the operation of automated systems.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720919963",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Joanne E Gray",
        "Nicolas P Suzor"
      ],
      "url": "https://doi.org/10.1177/2053951720919963",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172091996",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 39,
      "is_referenced_by_count": 18,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "08893c97-8f40-4c44-9d79-a3a3dc368c56",
    "title": "The role of sensors in the production  of smart city spaces",
    "abstract": "<jats:p> Smart cities build on the idea of collecting data about the city in order for city administration to be operated more efficiently. Within a research project gathering an interdisciplinary team of researchers – engineers, designers, gender scholars and human geographers – we have been working together using participatory design approaches to explore how paying attention to the diversity of human needs may contribute to making urban spaces comfortable and safe for more people. The project team has deployed sensors collecting data on air quality, sound and mobility in a smart city testbed in Norrköping, Sweden. While these sensors are meant to capture an accurate ‘map’ of the street and what is going on along it, our interdisciplinary conversations around the sensors have revealed the heterogeneity both of smart city planning and spatial formulations of the city. The discussions have given rise to questions regarding the work that goes into constructing the sensor box itself, as well as the work of deploying it, and how these influence the ‘map’ that the sensors produce. In this paper, we draw on Lefebvre to explore how the sensors themselves produce smart spaces. We analyze how the box depends on perceived space to function (e.g. requiring electricity), and simultaneously it produces conceptualizations of space that are influenced by the materiality of the box itself (e.g. sensors being affected by heat and noise). Further, we explore how the (in)visibility of sensor technology influences lived space. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221110218",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Desirée Enlund",
        "Katherine Harrison",
        "Rasmus Ringdahl",
        "Ahmet Börütecene",
        "Jonas Löwgren",
        "Vangelis Angelakis"
      ],
      "url": "https://doi.org/10.1177/20539517221110218",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 61,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8f298bc2-8e25-411a-bbbf-43d25bf83e2a",
    "title": "Contesting algorithms: Restoring the public interest in content filtering by artificial intelligence",
    "abstract": "<jats:p> In recent years, artificial intelligence has been deployed by online platforms to prevent the upload of allegedly illegal content or to remove unwarranted expressions. These systems are trained to spot objectionable content and to remove it, block it, or filter it out before it is even uploaded. Artificial intelligence filters offer a robust approach to content moderation which is shaping the public sphere. This dramatic shift in norm setting and law enforcement is potentially game-changing for democracy. Artificial intelligence filters carry censorial power, which could bypass traditional checks and balances secured by law. Their opaque and dynamic nature creates barriers to oversight, and conceals critical value choices and tradeoffs. Currently, we lack adequate tools to hold them accountable. This paper seeks to address this gap by introducing an adversarial procedure— – Contesting Algorithms. It proposes to deliberately introduce friction into the dominant removal systems governed by artificial intelligence. Algorithmic content moderation often seeks to optimize a single goal, such as removing copyright-infringing materials or blocking hate speech, while other values in the public interest, such as fair use or free speech, are often neglected. Contesting algorithms introduce an adversarial design which reflects conflicting values, and thereby may offer a check on dominant removal systems. Facilitating an adversarial intervention may promote democratic principles by keeping society in the loop. An adversarial public artificial intelligence system could enhance dynamic transparency, facilitate an alternative public articulation of social values using machine learning systems, and restore societal power to deliberate and determine social tradeoffs. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720932296",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Niva Elkin-Koren"
      ],
      "url": "https://doi.org/10.1177/2053951720932296",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 76,
      "is_referenced_by_count": 31,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8b57ac29-d4e4-469d-9561-e0df19573d05",
    "title": "COVID-19, digital health technology and the politics of the unprecedented",
    "abstract": "<jats:p> The COVID-19 global pandemic has stretched the capacities of public health institutions and health systems around the world, opening the door to a range of technologically-driven solutions. In this article, we seek to historicize the expanding role of digital health technologies and examine the political-economic context from which they have emerged. Drawing on critical insights from science and technology studies, we maintain that the rise of digital health technologies has been catalyzed by broad shifts in global health governance that have expanded the role of market forces in public health and a unique set of political and economic crises that have accelerated the adoption of digital technologies—often under the guise of appeals to technological innovation to address “unprecedented” crises. These interrelated historical trends, we contend, are critical for understanding current state responses to the pandemic and possibilities for more equitable and democratic applications of technology in public health. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211019441",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Dillon Wamsley",
        "Benjamin Chin-Yee"
      ],
      "url": "https://doi.org/10.1177/20539517211019441",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 35,
      "is_referenced_by_count": 19,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8ab89742-9883-45fd-9368-3d14e2755d07",
    "title": "Digital phenotyping – Editorial",
    "abstract": "There is an astonishing posthuman promise in digital phenotyping, as Beth Semel recently argued (Semel, 2022). The goal of digital phenotyping enthusiasts is no less than to bypass the human observer as a deeply flawed threshold of medical knowledge production. The second goal is then – ultimately – to rid the human body and mind of its frailty and to utilise technology for a ‘world without disease’ (Topol and Corr, 2019). This promissory rhetoric is not only geared towards the disruption of dated medical conventions but comes equipped with bold, revolutionary concepts. Objective knowledge, based on aggregated, automated, and sweeping data collection to deliver granular, minute, and personalised healthcare; digital phenotyping is a collection of ideas, technologies, and practices to realise a powerful and futuristic vision of a medicine far beyond human capacities. This posthuman promise might be naive and driven by an abundant positivism, but as a small movement, made up of medical researchers and digital disruptors alike, it has continuously gathered steam over the last decade. The purpose of this collection is foremost to take stock and to collect a range of critical questions for a first revision of what digital phenotyping might be and what it could potentially become. The meaning of digital phenotyping is not as well defined as the many publications in this growing body of scholarship might suggest. Some of that vagueness has been captured in the critical literature. Birk and Samuel, in their sociological analysis, have described the term recently in more general terms as an analytical concept that presumes simply that diseases and illness are by and large ‘measurable by digital devices’ (Birk and Samuel, 2020). This assumes that a person’s experience of any kind of suffering is always in one way or another expressed in the digital traces of their behaviour. The leg injury that might result in a different mobility pattern; measurable tremors in the thumb control of smartphones as a sign of Parkinson’s; sudden lack of social interaction as a sign of depression: digital phenotypes can in theory be defined for any illness and disease and captured by any of the sensors, devices, and technologies, through which humans leave digital traces. Loi, in his ethical and philosophical exploration of the digital phenotype, assumes it in more general terms to be ‘an assemblage of information in digital form, that humans produce intentionally or as a by-product of other activities, and which affects human behaviour’ (Loi, 2018). Many questions remain, not least why and how this concept seeks association with genetic terminology. What does the wholesale capturing of a human’s digital traces as phenotype imply? What does it mean to group a sheer endless range of symptoms within the paradigm of inheritable traits and how does this framing structure research on and with digital phenotypes? The phrase itself was coined by the physician Sachin Jain and colleagues at Harvard in 2015 in a letter to Nature Biotechnology. Conceptually, they conceived of digital phenotyping with reference to Richard Dawkins’ elaborations on the ‘extended phenotype’ (Jain et al., 2015; Dawkins, 1982). Not only did they see digital technologies equipped to deliver a never-before-seen mass of potentially valuable data for diagnostics and prognostics but importantly these data were produced beyond the brief and cursory encounters between patients and physicians. The full-scale exploitation of these data would enable new insight into disease expressions over a lifetime. This was not only an expansion of surveillance but would open a new paradigm of medical knowledge production: rather than just recording symptoms in a medical consultation, ‘digital phenotypes redefine disease expression in terms of the lived experience of individuals, which expands our ability to classify and understand disease’ (Jain et al., 2015). In a 2017 JAMA article, the American neuroscientist Thomas R. Insel conceptualized digital phenotyping into nothing less but a ‘New Science of Behaviour’ (Insel, 2017). Since then, the phrase has given",
    "metadata": {
      "doi": "10.1177/20539517221113775",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Lukas Engelmann",
        "Ger Wackers"
      ],
      "url": "https://doi.org/10.1177/20539517221113775",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 19,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2721928b-afcd-45d4-8e9c-fc55015803f8",
    "title": "Tracing You: How transparent surveillance reveals a desire for visibility",
    "abstract": "<jats:p> Tracing You is an artwork that presents a website's best attempt to see the world from its visitors’ viewpoints. By cross referencing visitor IP addresses with available online data sources, the work traces each visitor back through the network to its possible origin. The end of that trace is the closest available image that potentially shows the visitor’s physical environment. Sometimes what this image shows is eerily accurate; other times it is wildly dislocated. This computational surveillance system thus makes transparent the potential visibility of one’s present location on the Earth, while also giving each site visitor the ability to watch other visitor “traces” in real time. By making its surveillance capacity and intention overt, Tracing You provokes questions about the architecture of networks and how that architecture affects our own visibility both within and outside of the network. Further, reactions to the work reveal attitudes towards surveillance post-Snowden, including, in some cases, an angry desire for more visibility than Tracing You currently provides. This commentary describes how the artwork functions, presents and discusses visitor reactions, and briefly theorizes origins for these reactions within the contexts of surveillance, sousveillance, and transparency in the age of ubiquitous online social networks. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717694053",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Benjamin Grosser"
      ],
      "url": "https://doi.org/10.1177/2053951717694053",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 9,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b1a36b07-57a4-444f-9c40-2b6169358e27",
    "title": "“Smittestopp”: If you want your freedom back, download now",
    "abstract": "<jats:p> The intervention attempts to engage critically with the Smittestopp app as a specifically Norwegian technofix. Culturally and politically, much of the Covid-19 response and the success of social distancing rules have been organized around the widespread trust in the government and public health authorities, and a focus on the citizens’ duty to contribute to the dugnaðr. The intervention argues that Smittestopp has been co-created by the mobilization of trust and dugnaðr, resulting in the launch of an incomplete and poorly defined data-hoarding product with significant vulnerabilities. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720939985",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Kristin B Sandvik"
      ],
      "url": "https://doi.org/10.1177/2053951720939985",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 70,
      "is_referenced_by_count": 33,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e1d799de-de97-45fa-af8e-66372ea78176",
    "title": "Mandatory age verification for pornography access: Why it can't and won't ‘save the children’",
    "abstract": "<jats:p>Age verification is currently gaining traction among some western democracies as a means to restrict minors’ access to online pornography. In this article we consider the ramifications of applying age estimation software to this task. We analyse a public dataset of 10,139 facial images processed through a commonly used high-performance convolutional neural network approach and find significant inconsistencies in classification performance. Notably, the software demonstrates racial bias, with highest accuracy for the Caucasian category and lowest accuracy for the African category. It also displays age and gender bias, with lower accuracy for young males compared to young females. In addition to underwhelming technical performance, we argue that the concept of employing automated processes to restrict access to pornography is not only problematic but fundamentally misconceived. The systems being proposed to automate age verification create greater user data privacy risks and divert resourcing that could be spent on strategies that are proven to support healthy sexual development. Ultimately, mandatory age verification systems create barriers to post-pubescent young people seeking information about sex online. Our study concludes that the underlying problem with age verification, therefore, is not only technical but more profoundly political: even if the system can be made to work, it should not be.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241252129",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Zahra Stardust",
        "Abdul Obeid",
        "Alan McKee",
        "Daniel Angus"
      ],
      "url": "https://doi.org/10.1177/20539517241252129",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 91,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9c6b32e9-6e02-4a87-b6ec-8090cbb1b76b",
    "title": "Learning from lines: Critical COVID data visualizations and the quarantine quotidian",
    "abstract": "<jats:p> In response to the ubiquitous graphs and maps of COVID-19, artists, designers, data scientists, and public health officials are teaming up to create counter-plots and subaltern maps of the pandemic. In this intervention, we describe the various functions served by these projects. First, they offer tutorials and tools for both dataviz practitioners and their publics to encourage critical thinking about how COVID-19 data is sourced and modeled—and to consider which subjects are not interpellated in those data sets, and why not. Second, they demonstrate how the pandemic’s spatial logics inscribe themselves in our immediate material landscapes. And third, they remind us of our capacity to personalize and participate in the creation of meaningful COVID visualizations—many of which represent other scales and dimensions of the pandemic, especially the quarantine quotidian. Together, the official maps and counter-plots acknowledge that the pandemic plays out differently across different scales: COVID-19 is about global supply chains and infection counts and TV ratings for presidential press conferences, but it is also about local dynamics and neighborhood mutual aid networks and personal geographies of mitigation and care. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720939236",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Emily Bowe",
        "Erin Simmons",
        "Shannon Mattern"
      ],
      "url": "https://doi.org/10.1177/2053951720939236",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 72,
      "is_referenced_by_count": 33,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "03b8e86b-6a25-4fa2-a7a6-a1aa4cac2f6a",
    "title": "Identifying and characterizing scientific authority-related misinformation discourse about hydroxychloroquine on twitter using unsupervised machine learning",
    "abstract": "<jats:p> This study investigates the types of misinformation spread on Twitter that evokes scientific authority or evidence when making false claims about the antimalarial drug hydroxychloroquine as a treatment for COVID-19. Specifically, we examined tweets generated after former U.S. President Donald Trump retweeted misinformation about the drug using an unsupervised machine learning approach called the biterm topic model that is used to cluster tweets into misinformation topics based on textual similarity. The top 10 tweets from each topic cluster were content coded for three types of misinformation categories related to scientific authority: medical endorsements of hydroxychloroquine, scientific information used to support hydroxychloroquine’s use, and a comparison group that included scientific evidence opposing hydroxychloroquine’s use. Results show a much higher volume of tweets featuring medical endorsements and use of supportive scientific information compared to accurate and updated scientific evidence, that misinformation-related tweets propagated for a longer time frame, and the majority of hydroxychloroquine Twitter discourse expressed positive views about the drug. Metadata from Twitter accounts found that prominent users within misinformation discourse were more likely to have media or political affiliation and explicitly expressed support for President Trump. Conversely, prominent accounts within the scientific opposition discourse primarily consisted of medical doctors or scientists but had far less influence in the Twitter discourse. Implications of these findings and connections to related social media research are discussed, as well as cognitive mechanisms for understanding susceptibility to misinformation and strategies to combat misinformation spread via online platforms. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211013843",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Michael Robert Haupt",
        "Jiawei Li",
        "Tim K Mackey"
      ],
      "url": "https://doi.org/10.1177/20539517211013843",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 52,
      "is_referenced_by_count": 28,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "174cb15c-d31e-4b6e-9068-5c79e143a57e",
    "title": "Stitching together the heterogeneous party: A complementary social data science experiment",
    "abstract": "The era of ‘big data’ studies and computational social science has recently given rise to a number of realignments within and beyond the social sciences, where otherwise distinct data formats – digital, numerical, ethnographic, visual, etc. – rub off and emerge from one another in new ways. This article chronicles the collaboration between a team of anthropologists and sociologists, who worked together for one week in an experimental attempt to combine ‘big’ transactional and ‘small’ ethnographic data formats. Our collaboration is part of a larger cross-disciplinary project carried out at the Danish Technical University (DTU), where high-resolution transactional data from smartphones allows for recordings of social networks amongst a freshman class (N = 800). With a parallel deployment of ethnographic fieldwork among the DTU students, this research set-up raises a number of questions concerning how to assemble disparate ‘data-worlds’ and to what epistemological and political effects? To address these questions, a specific social event – a lively student party – was singled out from the broader DTU dataset. Our experimental collaboration used recordings of Bluetooth signals between students’ phones to visualize the ebb and flow of social intensities at the DTU party, juxtaposing these with ethnographic field-notes on shifting party atmospheres. Tracing and reflecting on the process of combining heterogeneous data, the article offers a concrete case of how a ‘stitching together’ of digital and ethnographic data-worlds might take place.",
    "metadata": {
      "doi": "10.1177/2053951717736337",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Anders Blok",
        "Hjalmar B Carlsen",
        "Tobias B Jørgensen",
        "Mette M Madsen",
        "Snorre Ralund",
        "Morten A Pedersen"
      ],
      "url": "https://doi.org/10.1177/2053951717736337",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171773633",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 25,
      "is_referenced_by_count": 19,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c801ecb0-85f7-42b2-bf13-f757ea7f2bc8",
    "title": "Big Data and <i>The Phantom Public</i>: Walter Lippmann and the fallacy of data privacy self-management",
    "abstract": "<jats:p> In 1927, Walter Lippmann published The Phantom Public, denouncing the ‘mystical fallacy of democracy.’ Decrying romantic democratic models that privilege self-governance, he writes: “I have not happened to meet anybody, from a President of the United States to a professor of political science, who came anywhere near to embodying the accepted ideal of the sovereign and omnicompetent citizen.” Almost 90 years later, Lippmann’s pragmatism is as relevant as ever, and should be applied in new contexts where similar self-governance concerns persist. This paper does just that, repurposing Lippmann’s argument in the context of the ongoing debate over the role of the digital citizen in Big Data management. It is argued that proposals by the Federal Trade Commission, the White House and the US Congress, championing failed notice and choice privacy policy, perpetuate a self-governance fallacy comparable to Lippmann’s, referred to here as the fallacy of data privacy self-management. Even if the digital citizen had the faculties and the system for data privacy self-management, the digital citizen has little time for data governance. We desire the freedom to pursue the ends of digital production, without being inhibited by the means. We want privacy, and safety, but cannot complete all that is required for its protection. If it is true that the fallacy of democracy is similar to the fallacy of data privacy self-management, then perhaps the pragmatic solution is representative data management: a combination of non/for-profit digital dossier management via infomediaries that can ensure the protection of personal data, while freeing individuals from what Lippmann referred to as an ‘unattainable ideal.’ </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715608876",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Jonathan A Obar"
      ],
      "url": "https://doi.org/10.1177/2053951715608876",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 57,
      "is_referenced_by_count": 34,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1cfc5efc-19dd-4e2a-adf7-426b4c057922",
    "title": "The case for tracking misinformation the way we track disease",
    "abstract": "<jats:p> While public health organizations can detect disease spread, few can monitor and respond to real-time misinformation. Misinformation risks the public’s health, the credibility of institutions, and the safety of experts and front-line workers. Big Data, and specifically publicly available media data, can play a significant role in understanding and responding to misinformation. The Public Good Projects uses supervised machine learning to aggregate and code millions of conversations relating to vaccines and the COVID-19 pandemic broadly, in real-time. Public health researchers supervise this process daily, and provide insights to practitioners across a range of disciplines. Through this work, we have gleaned three lessons to address misinformation. (1) Sources of vaccine misinformation are known; there is a need to operationalize learnings and engage the pro-vaccination majority in debunking vaccine-related misinformation. (2) Existing systems can identify and track threats against health experts and institutions, which have been subject to unprecedented harassment. This supports their safety and helps prevent the further erosion of trust in public institutions. (3) Responses to misinformation should draw from cross-sector crisis management best practices and address coordination gaps. Real-time monitoring and addressing misinformation should be a core function of public health, and public health should be a core use case for data scientists developing monitoring tools. The tools to accomplish these tasks are available; it remains up to us to prioritize them. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211013867",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Erika Bonnevie",
        "Jennifer Sittig",
        "Joe Smyser"
      ],
      "url": "https://doi.org/10.1177/20539517211013867",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d6287878-2b48-417d-8a67-d887aa1c5b32",
    "title": "The paradox of active users",
    "abstract": "Twitter users vary widely in their level of activity. Active Twitter users not only tweet more often than others but they also tend to mention other users with higher frequency and the set of time stamped global positioning system (GPS) locations in their tweets are more complete. The time, location",
    "metadata": {
      "doi": "10.1177/2053951715606164",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Patrick Park",
        "Michael Macy"
      ],
      "url": "https://doi.org/10.1177/2053951715606164",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 11,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "98768305-cb1c-419c-bbec-00f57b38af1a",
    "title": "Investigating hybridity in artificial intelligence research",
    "abstract": "<jats:p> Research in the global field of artificial intelligence is increasingly hybrid in orientation. Researchers are beholden to the requirements of multiple intersecting spheres, such as scholarly, public, and commercial, each with their own language and logic. Relatedly, collaboration across disciplinary, sector and national borders is increasingly expected, or required. Using a dataset of 93,482 artificial intelligence publications, this article operationalises scholarly, public, and commercial spheres through citations, news mentions, and patent mentions, respectively. High performing publications (99th percentile) for each metric were separated into eight categories of influence. These comprised four blended categories of influence (news, patents and citations; news and patents; news and citations; patents and citations) and three single categories of influence (citations; news; patents), in addition to the ‘Other’ category of non-high performing publications. The article develops and applies two components of a new hybridity lens: evaluative hybridity and generative hybridity. Using multinomial logistic regression, selected aspects of knowledge production – research context, focus, artefacts, and collaborative configurations – were examined. The results elucidate key characteristics of knowledge production in the artificial intelligence field and demonstrate the utility of the proposed lens. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231180577",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Kate Williams",
        "Glen Berman",
        "Sandra Michalska"
      ],
      "url": "https://doi.org/10.1177/20539517231180577",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 55,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "42b2085f-10b1-4e94-a6f2-c07e76bfee24",
    "title": "Seeing like a driver: How workers repair, resist, and reinforce the platform's algorithmic visions",
    "abstract": "<jats:p> This article theorizes the relationship between two ways of “seeing” and organizing urban mobility markets: the abstract, algorithmic vision of the mobility platform and the experiential, relational vision of the platform driver. Using the case of mobility platforms in Jakarta, we empirically demonstrate how drivers experience the limitations of the platform's visions and how they deploy their own alternative visions of work and the city. We offer this drivers’ “View from Within” as a counterpoint to the visions of the platform, decentering the platform's visions as the sole arbiter of change and optimization in the city. At the same time, we disrupt the assumed binary between these views, showing how they exist in a complex dance of complementarity and contestation. We conclude with a discussion on the opportunities this entanglement presents for worker agency in the algorithmic market, the hurdles toward more “worker centered design” in platform economies and the tensions between globalizing technological solutions and their localized instantiations. Through this article, we argue for seeing deep, embedded relationships as culturally and historically important modes of urban life which technology has to interact with but cannot fully capture nor do away with. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221133780",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Rida Qadri",
        "Catherine D’Ignazio"
      ],
      "url": "https://doi.org/10.1177/20539517221133780",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 70,
      "is_referenced_by_count": 21,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "141863a9-0af0-4d87-b5c4-07c70c715918",
    "title": "Mass personalization: Predictive marketing algorithms and the reshaping of consumer knowledge",
    "abstract": "<jats:p> This paper focuses on the conception and use of machine-learning algorithms for marketing. In the last years, specialized service providers as well as in-house data scientists have been increasingly using machine learning to predict consumer behavior for large companies. Predictive marketing thus revives the old dream of one-to-one, perfectly adjusted selling techniques, now at an unprecedented scale. How do predictive marketing devices change the way corporations know and model their customers? Drawing from STS and the sociology of quantification, I propose to study the original ambivalence that characterizes the promise of a mass personalization, i.e. algorithmic processes in which the precise adjustment of prediction to unique individuals involves the computation of massive datasets. By studying algorithms in practice, I show how the active embedding of local preexisting consumer knowledge and punctual de-personalization mechanisms are keys to the epistemic and organizational success of predictive marketing. This paper argues for the study of algorithms in their contexts and suggests new perspectives on algorithmic objectivity. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720951581",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Baptiste Kotras"
      ],
      "url": "https://doi.org/10.1177/2053951720951581",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 73,
      "is_referenced_by_count": 39,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d0615c77-570f-48a0-b86e-d0e3d0e72399",
    "title": "Visual media analysis for Instagram and other online platforms",
    "abstract": "<jats:p> Instagram is currently the social media platform most associated with online images (and their analysis), but images from other platforms also can be collected and grouped, arrayed by similarity, stacked, matched, stained, labelled, depicted as network, placed side by side and otherwise analytically displayed. In the following, the initial focus is on Instagram, together with certain schools of thought such as Instagramism and Instagrammatics for its aesthetic and visual cultural study. Building on those two approaches, it subsequently focuses on other web and social media platforms, such as Google Image Search, Twitter, Facebook and 4chan. It provides demonstrations of how querying techniques create online image collections, and how these sets are analytically grouped through arrangements collectively referred to as metapictures. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211022370",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Richard Rogers"
      ],
      "url": "https://doi.org/10.1177/20539517211022370",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 118,
      "is_referenced_by_count": 45,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ded43969-e089-4fb7-a9ec-0bfb9cda7903",
    "title": "The role and nature of consent in government administrative data",
    "abstract": "<jats:p> This article draws on research undertaken by the authors as part of the Administrative Data Research Centre in England (ADRC-E). Between 2014 and 2017, we conducted four case studies on government administrative data for education, transport, energy and health. The purpose of the research was to examine stakeholder perspectives about the sharing, linking and re-use (secondary use) of government administrative data. In relation to the role and nature of consent given by data subjects for re-use, our study revealed significant variations in data provider and researcher attitudes. Although our study setting was England, we believe that the findings have wider resonance. Our analysis identified six factors which might account for the variations around consent: the specificities of the legislative framework governing the collection and processing of particular data; the type of data being collected and the relational context in which it is created; the broader information governance framework in which the data resides; the creating organization's approach to data release; the relative levels of risk aversity within the creating organization; and public perceptions and social attitudes. In conclusion, we consider whether consent is still the best mechanism available for data re-use, or whether a social contract model of data sharing should be developed. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718819560",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Anna Sexton",
        "Elizabeth Shepherd",
        "Oliver Duke-Williams",
        "Alexandra Eveleigh"
      ],
      "url": "https://doi.org/10.1177/2053951718819560",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 47,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8c012363-9ba5-49e5-aca7-01781887533c",
    "title": "Digital contact tracing in the pandemic cities: Problematizing the regime of traceability in South Korea",
    "abstract": "<jats:p> Since 2020, many countries worldwide have deployed digital contact tracing programs that rely on a range of digital sensors in the city to locate and map the routes of viral spread. Many critical commentaries have raised concerns about the privacy risks and trustworthiness of these programs. Extending these analyses, this paper opens up a different line of questioning that goes beyond privacy-centered single-axis critique of surveillance by considering digital contact tracing symptomatic of the broader changes in modes of urban governance that renders our cities traceable, knowable, and governable through data. Based on archival and real-time analysis of South Korean national and local COVID-19 dashboards, online forums, and interviews with South Korean public health practitioners, this paper offers a sociotechnical analysis of digital contact tracing that looks at the various intersections of state-political, bio-political, and techno-political power dynamics. In contrast to popular narratives that attributed the success of the Korean approach to digital contact tracing to its collectivist culture and smart city infrastructures, this paper suggests that the case can be better understood by looking at both the macro-level shift in the forms of governance that takes on a spatialized and networked character and the micro-level formation of moral responsibility that shape one's conduct as a health and safety-conscious citizens. As the latest realization of the expanding regime of traceability in digital/urban governance, the development of digital contract tracing is seen to parallel with concurrent changes occurring in multiple domains of life including knowledge production, cultural memory, and individual subjectivity. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221089294",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Chamee Yang"
      ],
      "url": "https://doi.org/10.1177/20539517221089294",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9a7db6f4-c7f5-4695-b10b-9a34a00c0864",
    "title": "The social construction of technological stasis: The stagnating data structure in OpenStreetMap",
    "abstract": "<jats:p> The article aims for examining the ‘technological stasis’ of the data structure in OpenStreetMap – the successful global collaborative geodata project devoted to ‘create and distribute free geographic data for the world’. Digital structures are strongly influenced by continuing stagnation. This technological stasis – the lack of change in technology – influences data in various ways, as demonstrated by the intensive discussion of the issue by computer scientists and software engineers. However, existing research describing stagnating software is often technic centred and fuzzy, while critical research is barely considering issues of technological stasis in the digital context at all. Therefore, this paper aims for enriching this body of knowledge in order to shed light on aging data structures. I reframe technological stasis with a social-constructivist perspective – using the approach of Social Construction of Technology – especially with the concept of technological frames. Based on the case example of OpenStreetMap, my findings suggest that the data structure – and its stasis – is the outcome of competing understandings and perspectives, shaped by power asymmetries. Although the data structure did not significantly change for more than 10 years, I demonstrate that this is not because of a lack of motivation, nor technological difficulties of carrying out such changes. The technological stasis is rather rooted in the dominant position of few project members who are able to change the software design; it is their perception of the project that defines how data should be stored and what features are dispensable. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718790591",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Matthias Plennert"
      ],
      "url": "https://doi.org/10.1177/2053951718790591",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 50,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ce1adfba-e986-4fd0-b840-fd1ea867c2ca",
    "title": "Algorithmic anxiety: Masks and camouflage in artistic imaginaries of facial recognition algorithms",
    "abstract": "<jats:p> This paper discusses prominent examples of what we call “algorithmic anxiety” in artworks engaging with algorithms. In particular, we consider the ways in which artists such as Zach Blas, Adam Harvey and Sterling Crispin design artworks to consider and critique the algorithmic normativities that materialize in facial recognition technologies. Many of the artworks we consider center on the face, and use either camouflage technology or forms of masking to counter the surveillance effects of recognition technologies. Analyzing their works, we argue they on the one hand reiterate and reify a modernist conception of the self when they conjure and imagination of Big Brother surveillance. Yet on the other hand, their emphasis on masks and on camouflage also moves beyond such more conventional critiques of algorithmic normativities, and invites reflection on ways of relating to technology beyond the affirmation of the liberal, privacy-obsessed self. In this way, and in particular by foregrounding the relational modalities of the mask and of camouflage, we argue academic observers of algorithmic recognition technologies can find inspiration in artistic algorithmic imaginaries. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719851532",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Patricia de Vries",
        "Willem Schinkel"
      ],
      "url": "https://doi.org/10.1177/2053951719851532",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 45,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "883164b9-2a61-46a9-9aff-9021af39f66c",
    "title": "Blind regards: Troubling data and their sentinels",
    "abstract": "<jats:p> A new generation of environmental satellites, the Sentinels, has recently been launched by the European Space Agency (ESA). Part of ESA’s Copernicus Programme, the sentinel mission has adopted an Open Data policy which intends to make different levels of data freely available via an online data hub. Sentinel data will support applications including land monitoring, emergency management and security and will thus form the evidence-base for a wide-range of local, regional, national and international decisions, from individual insurance claims to humanitarian interventions. By providing ever more data streams for monitoring and managing the planet, the sentinels institute a novel mode of visibility in terms of resolution, coverage and frequency. At the same time, they are co-constitutive of the increasing datafication of the environment. In the entwinement of heavenly gaze and data visions, I want to recover the work of ‘data fictions’ in order to demystify notions of visibility and calculability associated with “earth observation” and trouble its unquestioned pursuit of total monitoring. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716666301",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Tahani Nadim"
      ],
      "url": "https://doi.org/10.1177/2053951716666301",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 28,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "17cef599-0e29-40aa-ba70-9eea6450a4b2",
    "title": "The emergence of artificial intelligence ethics auditing",
    "abstract": "<jats:p> The emerging ecosystem of artificial intelligence (AI) ethics and governance auditing has grown rapidly in recent years in anticipation of impending regulatory efforts that encourage both internal and external auditing. Yet, there is limited understanding of this evolving landscape. We conduct an interview-based study of 34 individuals in the AI ethics auditing ecosystem across seven countries to examine the motivations, key auditing activities, and challenges associated with AI ethics auditing in the private sector. We find that AI ethics audits follow financial auditing stages, but tend to lack robust stakeholder involvement, measurement of success, and external reporting. Audits are hyper-focused on technically oriented AI ethics principles of bias, privacy, and explainability, to the exclusion of other principles and socio-technical approaches, reflecting a regulatory emphasis on technical risk management. Auditors face challenges, including competing demands across interdisciplinary functions, firm resource and staffing constraints, lack of technical and data infrastructure to enable auditing, and significant ambiguity in interpreting regulations and standards given limited (or absent) best practices and tractable regulatory guidance. Despite these roadblocks, AI ethics and governance auditors are playing a critical role in the early ecosystem: building auditing frameworks, interpreting regulations, curating practices, and sharing learnings with auditees, regulators, and other stakeholders. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241299732",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Daniel S Schiff",
        "Stephanie Kelley",
        "Javier Camacho Ibáñez"
      ],
      "url": "https://doi.org/10.1177/20539517241299732",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 52,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "06672336-79b7-41b4-bd7d-b57e1cf6a7d0",
    "title": "Personal choices and situated data: Privacy negotiations and the acceptance of household Intelligent Personal Assistants",
    "abstract": "The emergence of personal assistants in the form of smart speakers has begun to significantly alter people’s everyday experiences with technology. The rate at which household Intelligent Personal Assistants such as Amazon’s Echo and Google Home emerged in household spaces has been rapid. They have begun to move human–computer interaction from text-based to voice-activated input, offering a multiplicity of features through speech. The supporting infrastructure connects with artificial intelligence and the internet of things, allowing digital interfaces with domestic appliances, lighting systems, thermostats, media devices and more. Yet this also constitutes a significant new production of situated and sensitive data. This study focuses on how (potential) users negotiate and make choices about household Intelligent Personal Assistant use in connection with their data. This study is based on empirical research in Europe with early adopters in Germany and potential users in the Netherlands. This examination of users’ early stage technology acceptance considerations highlights particular practices and choices of users to either preserve their privacy or determine what is acceptable use for their data. Drawing on a simplified version of Unified Theory of Acceptance and Use of Technology 2, a quantitative model for technology acceptance, we demonstrate how acceptance of a household Intelligent Personal Assistants does not imply access to all household data, how users see usefulness in relation to a proliferation of devices, and note the recognition by users regarding the efforts needed for full use and acceptance. The study highlights the complexity of data production at a household level and how these devices produce myopic views of users for platforms.",
    "metadata": {
      "doi": "10.1177/2053951719891748",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Jason Pridmore",
        "Anouk Mols"
      ],
      "url": "https://doi.org/10.1177/2053951719891748",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395171989174",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 14,
      "is_referenced_by_count": 22,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b2e6bb00-61a0-42c3-ba22-730d8508577f",
    "title": "When research is the context: Cross-platform user expectations for social media data reuse",
    "abstract": "<jats:p> Social media provides unique opportunities for researchers to learn about a variety of phenomena—it is often publicly available, highly accessible, and affords more naturalistic observation. However, as research using social media data has increased, so too has public scrutiny, highlighting the need to develop ethical approaches to social media data use. Prior work in this area has explored users’ perceptions of researchers’ use of social media data in the context of a single platform. In this paper, we expand on that work, exploring how platforms and their affordances impact how users feel about social media data reuse. We present results from three factorial vignette surveys, each focusing on a different platform—dating apps, Instagram, and Reddit—to assess users’ comfort with research data use scenarios across a variety of contexts. Although our results highlight different expectations between platforms depending on the research domain, purpose of research, and content collected, we find that the factor with the greatest impact across all platforms is consent—a finding which presents challenges for big data researchers. We conclude by offering a sociotechnical approach to ethical decision-making. This approach provides recommendations on how researchers can interpret and respond to platform norms and affordances to predict potential data use sensitivities. The approach also recommends that researchers respond to the predominant expectation of notification and consent for research participation by bolstering awareness of data collection on digital platforms. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231164108",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Sarah Gilbert",
        "Katie Shilton",
        "Jessica Vitak"
      ],
      "url": "https://doi.org/10.1177/20539517231164108",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 42,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d708ddb5-6e6c-45bd-9df3-104095cd13e0",
    "title": "Ground truth tracings (GTT): On the epistemic limits of machine learning",
    "abstract": "<jats:p> There is a gap in existing critical scholarship that engages with the ways in which current “machine listening” or voice analytics/biometric systems intersect with the technical specificities of machine learning. This article examines the sociotechnical assemblage of machine learning techniques, practices, and cultures that underlie these technologies. After engaging with various practitioners working in companies that develop machine listening systems, ranging from CEOs, machine learning engineers, data scientists, and business analysts, among others, I bring attention to the centrality of “learnability” as a malleable conceptual framework that bends according to various “ground-truthing” practices in formalizing certain listening-based prediction tasks for machine learning. In response, I introduce a process I call Ground Truth Tracings to examine the various ontological translations that occur in training a machine to “learn to listen.” Ultimately, by further examining this notion of learnability through the aperture of power, I take insights acquired through my fieldwork in the machine listening industry and propose a strategically reductive heuristic through which the epistemological and ethical soundness of machine learning, writ large, can be contemplated. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221146122",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Edward B Kang"
      ],
      "url": "https://doi.org/10.1177/20539517221146122",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 39,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bb81d7bc-e101-4b4c-ab92-277d5ef010fc",
    "title": "Dashboard stories: How narratives told by predictive analytics reconfigure roles, risk and sociality in education",
    "abstract": "<jats:p> In this paper, we explore how the development and affordances of predictive analytics may impact how teachers and other educational actors think about and teach students and, more broadly, how society understands education. Our particular focus is on the data dashboards of learning support systems which are based on Machine Learning (ML). While previous research has focused on how these systems produce credible knowledge, we explore here how they also produce compelling, persuasive and convincing narratives. Our main argument is that particular kinds of stories are written by predictive analytics and written into their data dashboards. Based on a case study of a leading predictive analytics system, we explore how data dashboards imply causality between the ‘facts’ they are visualising. To do so, we analyse the stories they tell according to their spatial and temporal dimensions, characters and events, sequentiality as well as tellability. In the stories we identify, teachers are managers, students are at greater or lesser risk, and students’ sociality is reduced to machine-readable interactions. Overall, only data marked as individual behaviours becomes relevant to the system, rendering structural inequalities invisible. Reflecting on the implications of these systems, we suggest ways in which the uptake of these systems can interrupt such stories and reshape them in other directions. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211025561",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Juliane Jarke",
        "Felicitas Macgilchrist"
      ],
      "url": "https://doi.org/10.1177/20539517211025561",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 73,
      "is_referenced_by_count": 47,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4855f418-415d-461c-b71d-ae70a9c68541",
    "title": "Quali-quantitative methods beyond networks: Studying information diffusion on Twitter with the Modulation Sequencer",
    "abstract": "<jats:p> Although the rapid growth of digital data and computationally advanced methods in the social sciences has in many ways exacerbated tensions between the so-called ‘quantitative’ and ‘qualitative’ approaches, it has also been provocatively argued that the ubiquity of digital data, particularly online data, finally allows for the reconciliation of these two opposing research traditions. Indeed, a growing number of ‘qualitatively’ inclined researchers are beginning to use computational techniques in more critical, reflexive and hermeneutic ways. However, many of these claims for ‘quali-quantitative’ methods hinge on a single technique: the network graph. Networks are relational, allow for the questioning of rigid categories and zooming from individual cases to patterns at the aggregate. While not refuting the use of networks in these studies, this paper argues that there must be other ways of doing quali-quantitative methods. We first consider a phenomenon which falls between quantitative and qualitative traditions but remains elusive to network graphs: the spread of information on Twitter. Through a case study of debates about nuclear power on Twitter, we develop a novel data visualisation called the modulation sequencer which depicts the spread of URLs over time and retains many of the key features of networks identified above. Finally, we reflect on the role of such tools for the project of quali-quantitative methods. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718772137",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "David Moats",
        "Erik Borra"
      ],
      "url": "https://doi.org/10.1177/2053951718772137",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 64,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "41b7909c-20f2-4eb0-a680-5ba5131aee4e",
    "title": "Corrigendum",
    "abstract": "",
    "metadata": {
      "doi": "10.1177/2053951719863500",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [],
      "url": "https://doi.org/10.1177/2053951719863500",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171986350",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "not available"
    }
  },
  {
    "id": "431daa5f-7798-4f85-b140-c4badb612724",
    "title": "Algorithms and hegemony in the workplace: Negotiating design and values  in an Italian television platform",
    "abstract": "<jats:p> In recent years, several scholars have highlighted the necessity to scrutinize the practices and material settings in which algorithmic models are designed, in order to unpack the working activities and socio-cultural constructs underlying their production and deployment process. Drawing on a multisited ethnography, this paper investigates the practices of tech workers within the corporate environment of an internet television platform, the hierarchical relationships between different professional figures, and how these individuals frame algorithms and contribute to the enactment of these systems with their activities. Findings highlight the hierarchical organization of tech work and the subordination of operative figures to the goals imposed by business clients and to both internal and external forms of control. Specifically, it emerges how the subalternity of tech workers is materially and discursively constructed and forms of causal, dispositional and facilitative power exerted on them. In this environment, frictions, negotiations as well as concealing strategies by tech workers regarding the design and meaning of algorithms emerge, thus showing their cultural, contingent and multiple composition. Within the framework of Giddens’ structure/agency cycle, it is shown how everyday working activities and relationships contribute to the reproduction of hegemonic arrangements in the workplace, and how these hegemonic arrangements are at the core of algorithmic production, thus playing a key role in the framing, construction and enactment of these systems. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231182393",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Riccardo Pronzato"
      ],
      "url": "https://doi.org/10.1177/20539517231182393",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 65,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9f2cc086-60e4-4def-a6a9-3406bcf708da",
    "title": "Beyond manifestos: Exploring how political campaigns use online advertisements to communicate policy information and pledges",
    "abstract": "<jats:p> Social media platforms take on increasingly big roles in political advertising. Microtargeting techniques facilitate the display of tailored advertisements to specific subsegments of society. Scholars worry that such techniques might cause political information to be displayed to only very small subgroups of citizens. Or that targeted communication about policy could make the mandate of elected representatives more challenging to interpret. Policy information in general and pledges, in particular, have received much scientific scrutiny. Scholars have focused largely on party manifestos, but policy information and pledges communicated via online advertisements offer a new arena with new dynamics. This study uses Facebook’s ad library to describe how Dutch political campaigns advertise policy information and pledges in the run-up to the 2019 European Elections. The results show that much policy information is displayed to small subsegments of society. These findings provide evidence for concerns about pledge obfuscation, voter manipulation and mandate interpretation. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221095433",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Tom Dobber",
        "Claes de Vreese"
      ],
      "url": "https://doi.org/10.1177/20539517221095433",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "89dc834e-d277-4b53-89ba-b9bb6688518e",
    "title": "Corrigendum to Machine Anthropology: A View from International Relations",
    "abstract": "",
    "metadata": {
      "doi": "10.1177/20539517221080835",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [],
      "url": "https://doi.org/10.1177/20539517221080835",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "not available"
    }
  },
  {
    "id": "77249350-2cc6-4519-ab76-88a1071b1832",
    "title": "States of computing: On government organization and artificial intelligence in Canada",
    "abstract": "<jats:p> With technologies like machine learning and data analytics being deployed as privileged means to improve how contemporary bureaucracies work, many governments around the world have turned to artificial intelligence as a tool of statecraft. In that context, our paper uses Canada as a critical case to investigate the relationship between ideals of good government and good technology. We do so through not one, but two Trudeaus—celebrity Prime Minister Justin Trudeau (2015—…) and his equally famous father, former Prime Minister Pierre Elliott Trudeau (1968–1979, 1980–1984). Both shared a similar interest in new ideas and practices of both intelligent government and artificial intelligence. Influenced by Marshall McLuhan and his media theory, Pierre Elliott Trudeau deployed new communication technologies to restore centralized control in an otherwise decentralized state. Partly successful, he left his son with an informationally inclined political legacy, which decades later animated Justin Trudeau's own turn toward Big Data and artificial intelligence. Compared with one another, these two visions for both government and artificial intelligence illustrate the broader tensions between cybernetic and neoliberal approaches to government, which inform how new technologies are conceived of, and adopted, as political ones. As this article argues, Canada offers a paradigmatic case for how artificial intelligence is as much shaped by theories of government as by investments and innovations in computing research, which together delimit the contours of intelligence by defining which technical systems, people, and organizations come to be recognized as its privileged bearers. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221123304",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Théo Lepage-Richer",
        "Fenwick McKelvey"
      ],
      "url": "https://doi.org/10.1177/20539517221123304",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 105,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7794b3f5-d368-45d0-851e-9a729a541094",
    "title": "Archiving information from geotagged tweets to promote reproducibility and comparability in social media research",
    "abstract": "Sharing social media research datasets allows for reproducibility and peer-review, but it is very often difficult or even impossible to achieve due to legal restrictions and can also be ethically questionable. What is more, research data repositories and other research infrastructure and research support institutions are only starting to target social media researchers. In this paper, we present a practical solution to sharing social media data with the help of a social science data archive. Our aim is to contribute to the effort of enhancing comparability and reproducibility in social media research by taking some first steps towards setting standards for sustainable data archiving. We present a showcase for sharing social media data with the example of a big dataset containing geotagged tweets (several months of continued geotagged tweets from the United States from 2014 and 2015; nearly half a billion tweets in total) through a research data archive. We provide a general background to the process of long-term archiving of research data. After some consideration of the current obstacles for sharing and archiving social media data, we present our solution of archiving the specific dataset of geotagged tweets at the GESIS Data Archive for the Social Sciences, a publicly funded German data archive for secure and long-term archiving of social science data. We archived and documented tweet IDs and additional information to improve reproducibility of the initial research while also attending to ethical and legal considerations, and taking into account Twitter’s terms of service in particular.",
    "metadata": {
      "doi": "10.1177/2053951717736336",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Katharina Kinder-Kurlanda",
        "Katrin Weller",
        "Wolfgang Zenk-Möltgen",
        "Jürgen Pfeffer",
        "Fred Morstatter"
      ],
      "url": "https://doi.org/10.1177/2053951717736336",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171773633",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 24,
      "is_referenced_by_count": 24,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8a93c45a-40ab-4b0f-91a9-a6b9aec11fb0",
    "title": "Three maps and three misunderstandings: A digital mapping of climate diplomacy",
    "abstract": "<jats:p> This article proposes an original analysis of the international debate on climate change through the use of digital methods. Its originality is twofold. First, it examines a corpus of reports covering 18 years of international climate negotiations, a dataset never explored before through digital techniques. This corpus is particularly interesting because it provides the most consistent and detailed reporting of the negotiations of the United Nations Framework Convention on Climate Change. Second, in this paper we test an original approach to text analysis that combines automatic extractions and manual selection of the key issue-terms. Through this mixed approach, we tried to obtain relevant findings without imposing them on our corpus. The originality of our corpus and of our approach encouraged us to question some of the habits of digital research and confront three common misunderstandings about digital methods that we discuss in the first part of the article (section ‘Three misunderstandings on digital methods in social sciences’). In addition to reflecting on methodology, however, we also wanted to offer some substantial contribution to the understanding of UN-framed climate diplomacy. In the second part of the article (section ‘Three maps on climate negotiations’) we will therefore introduce some of the preliminary results of our analysis. By discussing three visualizations, we will analyze the thematic articulation of the climatic negotiations, the rise and fall of these themes over time and the visibility of different countries in the debate. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714543804",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "Tommaso Venturini",
        "Nicolas Baya Laffite",
        "Jean-Philippe Cointet",
        "Ian Gray",
        "Vinciane Zabban",
        "Kari De Pryck"
      ],
      "url": "https://doi.org/10.1177/2053951714543804",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 46,
      "is_referenced_by_count": 40,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "59af80d2-e9a8-4660-b077-b6dbcb2a303b",
    "title": "Justitia ex machina: The impact of an AI system on legal decision-making and discretionary authority",
    "abstract": "<jats:p> Governments increasingly use algorithms to inform or supplant decision-making. Artificial Intelligence systems in particular are considered objective, consistent and efficient decision-makers, but have also been shown to be fallible. Furthermore, the adoption of artificial intelligence (AI) in government is fraught with challenges which are only partly understood and rarely studied in practice. In this paper, we draw on science and technology studies and human computer interaction and report on a critical case study of the development and use of an AI system for processing traffic violation appeal at a Dutch court. Although much empirical work on algorithms in practice is primarily observational in nature, we employ a canonical action research approach and actively participate in the development of the AI system. We draw on data collected in the form of interviews, observations, documents and a user-experiment. Based on this material we provide: 1. An in-depth empirical account of the tensions between street-level bureaucrats, screen-level bureaucrats and street-level algorithms; 2. An analysis of the differences between decisions made by, with and without the AI system and find that use of the AI systems impacts decisions made by legal experts; 3. A confirmation of earlier work that finds AI systems can best be applied in support of legal-decision making and demonstrate how the decision-making process of the traffic violation cases may mitigate some of the risks of algorithmic decision-making. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241255101",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Daan Kolkman",
        "Floris Bex",
        "Nitin Narayan",
        "Manuella van der Put"
      ],
      "url": "https://doi.org/10.1177/20539517241255101",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 65,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "156f9510-a4a6-4e60-95c5-318f848988bc",
    "title": "Countering misinformation: A multidisciplinary approach",
    "abstract": "<jats:p> The article explores the concept of infodemics during the COVID-19 pandemic, focusing on the propagation of false or inaccurate information proliferating worldwide throughout the SARS-CoV-2 health crisis. We provide an overview of disinformation, misinformation and malinformation and discuss the notion of “fake news”, and highlight the threats these phenomena bear for health policies and national and international security. We discuss the mis-/disinformation as a significant challenge to the public health, intelligence, and policymaking communities and highlight the necessity to design measures enabling the prevention, interdiction, and mitigation of such threats. We then present an overview of selected opportunities for applying technology to study and combat disinformation, outlining several approaches currently being used to understand, describe, and model the phenomena of misinformation and disinformation. We focus specifically on complex networks, machine learning, data- and text-mining methods in misinformation detection, sentiment analysis, and agent-based models of misinformation spreading and the detection of misinformation sources in the network. We conclude with the set of recommendations supporting the World Health Organization’s initiative on infodemiology. We support the implementation of integrated preventive procedures and internationalization of infodemic management. We also endorse the application of the cross-disciplinary methodology of Crime Science discipline, supplemented by Big Data analysis and related information technologies to prevent, disrupt, and detect mis- and disinformation efficiently. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211013848",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Kacper T Gradoń",
        "Janusz A. Hołyst",
        "Wesley R Moy",
        "Julian Sienkiewicz",
        "Krzysztof Suchecki"
      ],
      "url": "https://doi.org/10.1177/20539517211013848",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 97,
      "is_referenced_by_count": 42,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f528a418-f085-4354-ac7a-c8e938213dc3",
    "title": "Datastructuring—Organizing and curating digital traces into action",
    "abstract": "<jats:p> Digital transformations and processes of “datafication” fundamentally reshape how information is produced, circulated and given meaning. In this article, we provide a concept of “datastructuring” which seeks to capture this reshaping as both a product of and productive of social activity. To do this we focus on (1) how new forms of social action map onto and are enabled by technological changes related to datafication, and (2) how new forms of datafied social action constitute a form of knowledge production which becomes embedded in technologies themselves. We illustrate the potential of the datastructuring concept with empirical examples which also serve to highlight some new avenues for research and some empirical questions to explore further. We suggest a focus on datastructuring can ignite scholarly debates across disciplines that may share an interest in the technological configurations, sorting activities, and other socio-material forces that shape digital spaces, but which are rarely brought together. Such cross-disciplinary conceptualizations may give more attention to how information is structured and organized, becomes “algorithmically recognizable”, and emerges as (in)visible in digital, datafied spaces. Such a concept, we suggest, may help us better understand the novel ways in which “backstage datawork” and “data sorting processes” gain traction in political interventions, commercial processes, and social ordering. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718799114",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Mikkel Flyverbom",
        "John Murray"
      ],
      "url": "https://doi.org/10.1177/2053951718799114",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 62,
      "is_referenced_by_count": 37,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "082ee24a-863f-4042-a38a-3e506ffe7816",
    "title": "Participatory action research in critical data studies: Interrogating AI from a South–North approach",
    "abstract": "<jats:p>In this article, we draw inspiration from participatory action research (PAR) and the work of Latin American thinkers such as Freire and Fals Borda to interrogate artificial intelligence (AI). We propose a South-North flow by utilising PAR approaches that stem from Latin America, challenging how the North's centrality is taken for granted regarding AI epistemologies, experiences, and understandings. Conducting workshops in London with a diverse group of students, tech workers and activists, we argue that PAR can not only empower marginalised communities in the Global South; we can also learn more from its application in the Global North, in contexts where people deal with different struggles. Our analysis delves into three specific concepts around AI and data (in)justice: autonomy, empathy and dialogue. First, inspired by PAR principles, participants started to problematise what they called an empty interpretation of empathy, establishing parallels with transnational dynamics of data capitalism, which disadvantage marginalised communities in the Global South. Second, PAR offered a critical lens to analyse issues of AI and autonomy in ways that are less individualistic and more collective and politically engaged. Third, PAR's dialogical spirit enabled participants to locate various intersections between AI and dialogue. Critiquing the idea of a superior AI, participants were reminded of the possibilities offered by human intelligence and the combination of thinking, making and feeling or what Fals Borda (2003. Ante la crisis del país: I deas acción para el cambio, 1st. Ed. Bogotá: Panamericana) calls our sentipensante nature.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241235869",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Andrea Medrado",
        "Pieter Verdegem"
      ],
      "url": "https://doi.org/10.1177/20539517241235869",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 42,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "82ace9bc-c40d-4977-97f5-e81a04042a0a",
    "title": "Data associations and the protection of reputation online in Australia",
    "abstract": "<jats:p> This article focuses upon defamation law in Australia and its struggles to adjust to the digital landscape, to illustrate the broader challenges involved in the governance and regulation of data associations. In many instances, online publication will be treated by the courts in a similar fashion to traditional forms of publication. What is more contentious is the question of who, if anyone, should bear the responsibility for digital forms of defamatory publication which result not from an individual author’s activity online but rather from algorithmic associations. This article seeks, in part, to analyse this question, by reference to the Australian case law and associated scholarship regarding search engine liability. Reflecting on the tensions involved here offers us a fresh perspective on defamation law through the conceptual lens of data associations. Here the focus of the article shifts to explore some wider questions posed for defamation law by big data. Defamation law may come to play a significant role in emerging frameworks for algorithmic accountability, but these developments also call into question many of its traditional concepts and assumptions. It may be time to think differently about defamation and to consider its interrelationship with privacy, speech and data protection more fully. As a result, I conclude that the courts and policymakers need to engage more deeply and explicitly with the rationale(s) for the protection of reputation and that more thought needs to be given to changing conceptions of reputation in the context of data associations. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717709829",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Daniel Joyce"
      ],
      "url": "https://doi.org/10.1177/2053951717709829",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 18,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "954841ab-0c8c-416b-80b3-c370d3cfe0b0",
    "title": "How should we theorize algorithms? Five ideal types in analyzing algorithmic normativities",
    "abstract": "<jats:p>The power of algorithms has become a familiar topic in society, media, and the social sciences. It is increasingly common to argue that, for instance, algorithms automate inequality, that they are biased black boxes that reproduce racism, or that they control our money and information. Implicit in many of these discussions is that algorithms are permeated with normativities, and that these normativities shape society. The aim of this editorial is double: First, it contributes to a more nuanced discussion about algorithms by discussing how we, as social scientists, think about algorithms in relation to five theoretical ideal types. For instance, what does it mean to go under the hood of the algorithm and what does it mean to stay above it? Second, it introduces the contributions to this special theme by situating them in relation to these five ideal types. By doing this, the editorial aims to contribute to an increased analytical awareness of how algorithms are theorized in society and culture. The articles in the special theme deal with algorithms in different settings, ranging from farming, schools, and self-tracking to AIDS, nuclear power plants, and surveillance. The contributions thus explore, both theoretically and empirically, different settings where algorithms are intertwined with normativities.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719867349",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Francis Lee",
        "Lotta Björklund Larsen"
      ],
      "url": "https://doi.org/10.1177/2053951719867349",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171986734",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 38,
      "is_referenced_by_count": 31,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "34152170-0d27-4a52-a616-0ee533af366b",
    "title": "Surveillance capitalism and systemic digital risk: The imperative to collect and connect and the risks of interconnectedness",
    "abstract": "<jats:p> Zuboff's The Age of Surveillance Capitalism provides a powerful analysis of the emergence of surveillance capitalism as a particular type of informational capitalism. Many of the important impacts of this project of creating larger and more integrated systems of ‘behavioural surplus’ are captured powerfully by Zuboff; yet as different risk and organisational scholars such as Beck, Perrow, and Vaughan have argued, integrated systems often do not function as intended. While the imperfection of these systems may raise the possibility that surveillance capitalism may not be as bad as Zuboff suggests, there is also a way in which these systems not functioning as intended can make surveillance capitalism an even more dystopian possibility. In this vein, this paper asks: what are the consequences when the tools of a surveillance capitalist society break down? This paper argues that it is by thinking through Zuboff's framework that we can identify the systemic fragility of a surveillance capitalist society. This systemic fragility emerges through how surveillance capitalism generates imperatives towards the maximal collection of data for exploitation, which in turn generates a corresponding imperative to connect all aspects of life. Both of these imperatives, of collect and connect, in turn create an immensely fragile digital system, which has vast ramifications throughout social life, such that small imperfections and gaps in the system can magnify risk throughout society. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231177621",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Dean Curran"
      ],
      "url": "https://doi.org/10.1177/20539517231177621",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 83,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "30a99eed-dbc6-49e5-9d49-9928bbd1d861",
    "title": "Platform sub-imperialism",
    "abstract": "<jats:p> This commentary explores Brazil's role in Latin American platform capitalism, integrating Ruy Mauro Marini's theoretical framework with contemporary studies of platform capitalism. It examines the connections between Latin American platforms, overexploitation, and data accumulation, leading to the concept of platform sub-imperialism: The emergence of certain Southern countries as platform sub-imperialist powers, acting as regional centers of data and capital accumulation through the expansion of their platforms into neighboring countries. This positioning constitutes an intermediate state between hegemonic nations and “digital colonies” in the international division of platform labor, data accumulation, and technological dependency. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241249410",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Kenzo Soares Seto"
      ],
      "url": "https://doi.org/10.1177/20539517241249410",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 27,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "56742ea9-418d-4fec-a145-123f02d6d5a9",
    "title": "Social determinants of health in the Big Data mode of population health risk calculation",
    "abstract": "<jats:p> Amidst the climate of crisis surrounding the rise in opioid-related overdose in the USA, early in 2019, Google and Deloitte launched ‘Opioid360’. Here came a platform combining browser histories, credit, insurance, social media, and traditional survey data to sell the service of risk calculation in population health. Opioid360's approach to automating risk calculation not only promised to identify persons ‘at risk’ of opioid dependence, but also paved the way for broader applications anticipating common chronic diseases and coordinating logistical operations involved in pandemic response. Beginning with this experimental platform, this paper develops an analysis of the Big Data mode of risk calculation - an epistemological and political shift that involves technology companies, investors, insurers, governments, and public health institutions. The analysis focuses on the re-emergence of ‘social determinants of health’ (SDOH) in the rhetoric accompanying novel analytic platforms that estimate, calculate, and compute individual health risks. While the treatment of SDOH has always been a site of political contestation within the discipline of public health, powerful interests are crystallising around the concept and instrumentalising it in platforms that sell algorithmic prediction. Silicon Valley's breed of asset-oriented technoscience appears not only to be amplifying the behaviouralist elements of public health. Among the stakes of the Big Data mode is the paradoxical retreat from changing social conditions that contribute to the prevalence of health and illness in populations; and instead, the promotion of an apparatus for pricing and exchanging individual risk or excluding from services those who bear risk most acutely. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211062881",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Rachel Rowe"
      ],
      "url": "https://doi.org/10.1177/20539517211062881",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 65,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "61339295-2022-488a-a017-e125dcbdba3c",
    "title": "A critical analysis of digital phenotyping  and the neuro-digital complex in psychiatry",
    "abstract": "<jats:p> This article critically examines the emergence and uses of digital phenotyping in contemporary psychiatry. From an analysis of its discourses and practices, we show that digital phenotyping diffusion is directly related to its promise to solve some of the major impasses of the so-called \"neuro-turn\" in contemporary psychiatry. However, more than a new tool to address old objects of pre-digital psychiatry, we consider digital phenotyping as participating from a new onto-epistemological matrix, the “neuro-digital complex,” which entails the redefinition of psychiatric objects (e.g., brain and mind), diagnostic categories and procedures, subjectivities (e.g., users of mental health apps), and the emergence of a new regime of truth which promises to reveal the neuropsychological core at the individual scale. Despite this techno-utopia, digital phenotyping does not produce neutral mirrors for self-knowledge. We show that it resorts to population statistics, grounded truth data sets built with pre-digital neuropsychological assumptions, and human categorization processes. Nevertheless, we propose not to approach this gap as a misleading ideological fact but to emphasize its productive possibilities. From this perspective, the gap becomes the measure between whom we think we are and who we really are, working as a guide to conduct our lives in neuropsychological terms. Thus, we conclude that, rather than providing personalized diagnoses and treatments, digital phenotyping produces individualized pathways to normalization and neuropsychologization. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221149097",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Rodrigo De La Fabián",
        "Álvaro Jiménez-Molina",
        "Francisco Pizarro Obaid"
      ],
      "url": "https://doi.org/10.1177/20539517221149097",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 123,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1b08da31-14e9-4973-ab82-ed1987c7d5e8",
    "title": "The social imaginaries of data activism",
    "abstract": "<jats:p> Data activism, promoting new forms of civic and political engagement, has emerged as a response to problematic aspects of datafication that include tensions between data openness and data ownership, and asymmetries in terms of data usage and distribution. In this article, we discuss MyData, a data activism initiative originating in Finland, which aims to shape a more sustainable citizen-centric data economy by means of increasing individuals' control of their personal data. Using data gathered during long-term participant-observation in collaborative projects with data activists, we explore the internal tensions of data activism by first outlining two different social imaginaries – technological and socio-critical – within MyData, and then merging them to open practical and analytical space for engaging with the socio-technical futures currently in the making. While the technological imaginary favours data infrastructures as corrective measures, the socio-critical imaginary questions the effectiveness of technological correction. Unpacking them clarifies the kinds of political and social alternatives that different social imaginaries ascribe to the notions underlying data activism, and highlights the need to consider the social structures in play. The more far-reaching goal of our exercise is to provide practical and analytical resources for critical engagement in the context of data activism. By merging technological and socio-critical imaginaries in the work of reimagining governing structures and knowledge practices alongside infrastructural arrangements, scholars can depart from the most obvious forms of critique, influence data activism practice, and formulate data ethics and data futures. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718821146",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Tuukka Lehtiniemi",
        "Minna Ruckenstein"
      ],
      "url": "https://doi.org/10.1177/2053951718821146",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 59,
      "is_referenced_by_count": 74,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5a0e83e9-1d79-49fe-8ac2-696f3258ffd0",
    "title": "After visibility: Data as a factor of production in Douyin e-commerce",
    "abstract": "<jats:p> Since 2020, Douyin, an app known for its interactive entertainment and vibrant youth cultures, has risen to dominance in the retail sector. Douyin stands out by making paid traffic a significant revenue stream alongside commissions. This strategy, which restricts organic growth, compels sellers to make additional investments in traffic. Drawing from Douyin walkthroughs and the company's business development presentations, this article analyzes how audience attention and platform traffic are manufactured and integrated with retail in the context of China's recent national policy that positions data as a factor of production equal to labor, land, technology, and capital. In contrast to Instagram, traffic conversion into sales takes precedence over product visibility on Douyin. In this process, Douyin actively uses user data to manufacture high-traffic keywords with buying intent. This involves measurements employing surveillance technologies that span image and speech recognition, keywords, performance metrics, and pricing algorithms. The article argues that Douyin e-commerce cannot be fully explained by the current visibility research paradigm centered on metrics such as likes, shares, and comments, which are considered indications of interests and preferences. It is suggested that Douyin uses historical data to invoke momentary interests and produce desired user actions for conversion. Traffic investment alone cannot result in the conversion of momentary interests into sales; it needs to be combined with pricing that incorporates discounts, coupons, and reductions. The integration of traffic investment with pricing strategy has emerged as a dominant e-commerce practice that fosters retail growth. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241309883",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Shuaishuai Wang"
      ],
      "url": "https://doi.org/10.1177/20539517241309883",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 47,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ec31afee-506a-451c-8ada-15e97b0fbc49",
    "title": "Cambridge Analytica’s black box",
    "abstract": "<jats:p> The Cambridge Analytica–Facebook scandal led to widespread concern over the methods deployed by Cambridge Analytica to target voters through psychographic profiling algorithms, built upon Facebook user data. The scandal ultimately led to a record-breaking $5 billion penalty imposed upon Facebook by the Federal Trade Commission (FTC) in July 2019. The FTC action, however, has been criticized as failing to adequately address the privacy and other harms emanating from Facebook’s release of approximately 87 million Facebook users’ data, which was exploited without user authorization. This Essay summarizes the FTC’s response to the Cambridge Analytica–Facebook scandal. It concludes that the scandal focuses attention on the need to explore the potential for embedding due process-type inquiries and protections within the enforcement actions by regulatory agencies such as the FTC. These protections are increasingly important in addressing the problem of “black boxing the voter” that is now presented by data- and algorithmic-driven companies such as Cambridge Analytica and Facebook. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720938091",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Margaret Hu"
      ],
      "url": "https://doi.org/10.1177/2053951720938091",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 61,
      "is_referenced_by_count": 54,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "04b9d255-da00-4cf2-af4b-29cbf9f538de",
    "title": "Data critique and analytical opportunities for very large Facebook Pages: Lessons learned from exploring “We are all Khaled Said”",
    "abstract": "<jats:p> This paper discusses the empirical, Application Programming Interface (API)-based analysis of very large Facebook Pages. Looking in detail at the technical characteristics, conventions, and peculiarities of Facebook’s architecture and data interface, we argue that such technical fieldwork is essential to data-driven research, both as a crucial form of data critique and as a way to identify analytical opportunities. Using the “We are all Khaled Said” Facebook Page, which hosted the activities of nearly 1.9 million users during the Egyptian Revolution and beyond, as empirical example, we show how Facebook’s API raises important questions about data detail, completeness, consistency over time, and architectural complexity. We then outline an exploratory approach and a number of analytical techniques that take the API and its idiosyncrasies as a starting point for the concrete investigation of a large dataset. Our goal is to close the gap between Big Data research and research about Big Data by showing that the critical investigation of technicity is essential for empirical research and that attention to the particularities of empirical work can provide a deeper understanding of the various issues Big Data research is entangled with. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715614980",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Bernhard Rieder",
        "Rasha Abdulla",
        "Thomas Poell",
        "Robbert Woltering",
        "Liesbeth Zack"
      ],
      "url": "https://doi.org/10.1177/2053951715614980",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 53,
      "is_referenced_by_count": 32,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "982fcc19-88dd-4477-90db-2efd27b5f6ef",
    "title": "Expansive and extractive networks of Web3",
    "abstract": "<jats:p> The self-proclaimed usurper of Web 2.0, Web3 quickly became the center of attention. Not long ago, the public discourse was saturated with projects, promises, and peculiarities of Web3. Now the spotlight has swung around to focus on the many faults, failures, and frauds of Web3. The cycles of technological trends and investment bubbles seem to be accelerating in such a way as to escape any attempt at observing them in motion before they crash, and then everybody moves on to the next thing. Importantly, Web3 was not an anomaly or curiosity in the broader tech industry. It articulates patterns that existed before Web3 and will exist after. Web3 should be understood as a case study of innovation within the dominant model of Silicon Valley venture capitalism. Our focus in this article is on understanding how the movement around Web3 formed through an interplay between (1) normative concepts and contestations related to ideas of “decentralization” and (2) political economic interests and operations related to the dynamics of fictitious capital. By offering a critical analysis of Web3, our goal is also to show how any even potentially progressive (or as we call them “expansive”) forms of Web3 development struggle for success, recognition, and attention due to the wild excesses of hype and investment devoted to “extractive” forms of Web3. In the process, they provide us a better view of how different arrangements of technopolitics can exist at the same time, side-by-side, in complicated ways. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231159629",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Jathan Sadowski",
        "Kaitlin Beegle"
      ],
      "url": "https://doi.org/10.1177/20539517231159629",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 73,
      "is_referenced_by_count": 16,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "467ed8c1-b288-49e1-8a35-4449cb12d852",
    "title": "Sounding out voice biometrics: Comparing and contrasting how the state and the private sector determine identity through voice",
    "abstract": "<jats:p> The voice biometrics industry is promised today as a new center of digital innovation. Tech companies and state agencies are massively investing in speech recognition and analysis systems, pushed by the belief that the acoustics of voice contain unique individual characteristics to convert into information and value through artificial intelligence. This article responds to this current development by exploring the under-researched datafication of the auditory realm to reveal how the sound of voice is emerging as a site for identity construction by both states and corporations. To do so, we look at two different case studies. First, we examine a patent granted to the streaming service Spotify, which aims to improve the platform's music recommendation system by analyzing users’ speech. Second, we discuss the use of voice biometrics in German asylum procedures, where the country of origin of undocumented asylum seekers is determined through accent analysis. Through these seemingly distinct case studies, we identify not only the common assumptions behind the rationale for adopting voice biometrics, but also important differences in the way the private sector and the State determine identity through the analysis of the sounding voice. These two entities are rarely examined together and are often conflated when addressing practices of auditory surveillance. Thus, our comparative and contrastive approach contributes to existing scholarship that questions the claimed efficiency and ethics of voice biometrics’ extractive practices, further defining the operations and assumptions of the private sector and the State. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241297889",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Daniel Leix Palumbo",
        "Robert Prey"
      ],
      "url": "https://doi.org/10.1177/20539517241297889",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 84,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "eb7349b0-a436-4674-8a78-9a337d1c824a",
    "title": "Liberal luxury: Decentering Snowden, surveillance and privilege",
    "abstract": "<jats:p> This paper reflects on the continued potency of veillance theories to traverse beyond the taxonomies of surveillance inside liberal democracies. It provides a commentary on the ability of sousveillance to destabilise and disrupt suer/violence by shifting its focus from the centre to the periphery, where Big Data surveillance is tantamount to sur/violence. In these peripheral political spaces, surveillance is not framed by concerns over privacy, democracy and civil society; rather, it is a matter of life and death, a technique of both biopolitical and thanatopolitical power. I argue that the universalist, and universalizing, debates over surveillance cannot be mapped through the anxieties of privileged middle classes as they would neither transcend nor make possible alternative ways of tackling the intersection of surveillance and violence so long as they are couched in the liberal concerns for democracy. I call this phenomenon “liberal luxury,” whereby debates over surveillance have over-emphasised liberal proclivities at the expense of disengaging those peripheral populations most severely affected by sur/violence. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716679676",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Piro Rexhepi"
      ],
      "url": "https://doi.org/10.1177/2053951716679676",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 9,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1e9c7e5c-2c82-45b0-a1fa-953720de00fe",
    "title": "Analyzing and interpreting “imperfect” Big Data in the 1600s",
    "abstract": "<jats:p> One of the characteristics of Big Data is that it often involves “imperfect” information. This paper examines the work of John Graunt (1620–1674) in the tabulation of diseases in London and the development of a life table using the “imperfect data” contained in London’s Bills of Mortality in the 1600s. London’s Bills of Mortality were Big Data for the 1600s, as they included information collected over time, the depth and accuracy of which improved gradually. The main shortcoming of the data available at the time was its nonuniform upkeep and the lack of depth of variables included at its outset. Due to these characteristics, it provides a perfect model for the examination of imperfect Big Data, as it has been analyzed, criticized, and interpreted repeatedly since the 1600s. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715609082",
      "type": "journal-article",
      "published": [
        2016,
        6,
        1
      ],
      "authors": [
        "Dennis J Mazur"
      ],
      "url": "https://doi.org/10.1177/2053951715609082",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 31,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0b4aa56f-ee89-4abf-948b-1bb4cec37b23",
    "title": "Online fraud detection: ‘In the moment’ digital accountability in a data-sensitive setting",
    "abstract": "<jats:p> Recent years have seen significant increases in online fraud. The fact that online fraud represents a major challenge to law enforcement due to its complexities and global impact has led to the emergence of other organisations – such as Customer Service Centres – taking a key role in ‘policing’ fraudulent activities. However, the responses made by these specialist organisations remain opaque and outside the scope of regimes that regulate law enforcement agencies. In this article we address this opacity through our study of a Customer Service Centre that makes decisions on what constitutes online fraud in cases of card-not-present payments. We carefully work through these decision-making processes to explore the immediate pressures made manifest in decisions on fraud around, for example, cost and timeliness. These pressures become apparent in the particular arrangements of accountability and responsibility in decisions on online fraud and cut what might otherwise be lengthy procedures following these decisions. As a result we suggest that accountability in these fraud cases is managed and held ‘in the moment’ within the Centre. The article contributes to our understanding of online fraud and to the growing debate on digital accountability. The article provides avenues for further exploration of the challenges of moving from internal to external accountability in relation to largely opaque and data-sensitive settings where accountability relations are held ‘in the moment.’ </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241266403",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Semire Yekta",
        "Daniel Neyland"
      ],
      "url": "https://doi.org/10.1177/20539517241266403",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 45,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "51575137-ac53-4250-a985-6292ca11fd37",
    "title": "The cancer multiple: Producing and translating genomic big data into oncology care",
    "abstract": "<jats:p> This article provides an ethnographic account of how Big Data biology is produced, interpreted, debated, and translated in a Big Data-driven cancer clinical trial, entitled “Personalized OncoGenomics,” in Vancouver, Canada. We delve into epistemological differences between clinical judgment, pathological assessment, and bioinformatic analysis of cancer. To unpack these epistemological differences, we analyze a set of gazes required to produce Big Data biology in cancer care: clinical gaze, molecular gaze, and informational gaze. We are concerned with the interactions of these bodily gazes and their interdependence on each other to produce Big Data biology and translate it into clinical knowledge. To that end, our central research questions ask: How do medical practitioners and data scientists interact, contest, and collaborate to produce and translate Big Data into clinical knowledge? What counts as actionable and reliable data in cancer decision-making? How does the explicability or translatability of genomic Big Data come to redefine or contradict medical practice? The article contributes to current debates on whether Big Data engenders new questions and approaches to biology, or Big Data biology is merely an extension of early modern natural history and biology. This ethnographic account will highlight how genomic Big Data, which underpins the mechanism of personalized medicine, allows oncologists to understand and diagnose cancer in a different light, but it does not revolutionize or disrupt medical oncology on an institutional level. Rather, personalized medicine is interdependent on different styles of (medical) thought, gaze, and practice to be produced and made intelligible. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720978991",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Tiên-Dung Hà",
        "Peter A. Chow-White"
      ],
      "url": "https://doi.org/10.1177/2053951720978991",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 36,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "218ce16c-e0dc-46cc-af83-616540cdaa79",
    "title": "Data ideologies of an interested public: A study of grassroots open government data intermediaries",
    "abstract": "<jats:p> Government officials claim open data can improve internal and external communication and collaboration. These promises hinge on “data intermediaries”: extra-institutional actors that obtain, use, and translate data for the public. However, we know little about why these individuals might regard open data as a site of civic participation. In response, we draw on Ilana Gershon to conceptualize culturally situated and socially constructed perspectives on data, or “data ideologies.” This study employs mixed methodologies to examine why members of the public hold particular data ideologies and how they vary. In late 2015 the authors engaged the public through a commission in a diverse city of approximately 500,000. Qualitative data was collected from three public focus groups with residents. Simultaneously, we obtained quantitative data from surveys. Participants’ data ideologies varied based on how they perceived data to be useful for collaboration, tasks, and translations. Bucking the “geek” stereotype, only a minority of those surveyed (20%) were professional software developers or engineers. Although only a nascent movement, we argue open data intermediaries have important roles to play in a new political landscape. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717690750",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Andrew Schrock",
        "Gwen Shaffer"
      ],
      "url": "https://doi.org/10.1177/2053951717690750",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 41,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "deca2eab-7b5a-4a13-9949-ff2c62e0fe8c",
    "title": "The machine that ate bad people: The ontopolitics of the precrime assemblage",
    "abstract": "<jats:p> This article examines the “aesthetic” and “prescient” turn in the surveillant assemblage and the various ways in which risk technologies in local law enforcement are reshaping the post hoc traditions of the criminal justice system. The rise of predictive policing and crime prevention software illustrate not only how the world of risk management solutions for public security is shifting from sovereign borders to inner-city streets but also how the practices of authorization are allowing software systems to become proxy forms of sovereign power. The article also examines how corporate strategies and law enforcement initiatives align themselves through media, connectivity, and consumer-oriented opt-in strategies that endeavor to “mold” and “deputize” ordinary individuals into obedient and patriotic citizens. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716682538",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Peter Mantello"
      ],
      "url": "https://doi.org/10.1177/2053951716682538",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 44,
      "is_referenced_by_count": 23,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bc912677-db65-4683-863a-513fa7395ffb",
    "title": "Algorithms as folding: Reframing the analytical focus",
    "abstract": "<jats:p>This article proposes an analytical approach to algorithms that stresses operations of folding. The aim of this approach is to broaden the common analytical focus on algorithms as biased and opaque black boxes, and to instead highlight the many relations that algorithms are interwoven with. Our proposed approach thus highlights how algorithms fold heterogeneous things: data, methods and objects with multiple ethical and political effects. We exemplify the utility of our approach by proposing three specific operations of folding— proximation, universalisation and normalisation. The article develops these three operations through four empirical vignettes, drawn from different settings that deal with algorithms in relation to AIDS, Zika and stock markets. In proposing this analytical approach, we wish to highlight the many different attachments and relations that algorithms enfold. The approach thus aims to produce accounts that highlight how algorithms dynamically combine and reconfigure different social and material heterogeneities as well as the ethical, normative and political consequences of these reconfigurations.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719863819",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Francis Lee",
        "Jess Bier",
        "Jeffrey Christensen",
        "Lukas Engelmann",
        "Claes-Fredrik Helgesson",
        "Robin Williams"
      ],
      "url": "https://doi.org/10.1177/2053951719863819",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171986381",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 40,
      "is_referenced_by_count": 24,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "eedcc40a-f4b8-4516-a389-3a0db5de28a8",
    "title": "A proxy for privacy uncovering the surveillance ecology of mobile apps",
    "abstract": "<jats:p> The article develops a methodological and empirical approach for gauging the ways Big Data can be collected and distributed through mobile apps. This approach focuses on the infrastructural components that condition the disclosure of smartphone users’ data – namely the permissions that apps request and the third-party corporations they work with. We explore the surveillance ecology of mobile apps and thereby the privacy implications of everyday smartphone use through three analytical perspectives: The first focuses on the ‘appscapes’ of individual smartphone users and investigates the consequences of which and how many mobile apps users download on their phones; the second compares different types of apps in order to study the app ecology and the relationships between app and third-party service providers; and the third focuses on a particular app category and discusses the functional as well as the commercial incentives for permissions and third-party collaborations. Thereby, the article advances an interdisciplinary dialogue between critical data studies, political economy and app studies, and pushes an empirical and critical perspective on mobile communication, app ecologies and data economies. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720942543",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Signe Sophus Lai",
        "Sofie Flensburg"
      ],
      "url": "https://doi.org/10.1177/2053951720942543",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 47,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "435fdbb7-f33c-441a-8565-616093f01559",
    "title": "In defense of forensic social science",
    "abstract": "<jats:p> Like the navigation tools that freed ancient sailors from the need to stay close to the shoreline—eventually affording the discovery of new worlds—Big Data might open us up to new sociological possibilities by freeing us from the shackles of hypothesis testing. But for that to happen we need forensic social science: the careful compilation of evidence from unstructured digital traces as a means to generate new theories. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715601145",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Amir Goldberg"
      ],
      "url": "https://doi.org/10.1177/2053951715601145",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 6,
      "is_referenced_by_count": 33,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "39fc223e-18e4-4ab3-bf80-ace8fed8078c",
    "title": "Taking a critical look at the critical turn  in data science: From “data feminism”  to transnational feminist data science",
    "abstract": "<jats:p> Through a critical analysis of recent developments in the theory and practice of data science, including nascent feminist approaches to data collection and analysis, this commentary aims to signal the need for a transnational feminist orientation towards data science. I argue that while much needed in the context of persistent algorithmic oppression, a Western feminist lens limits the scope of problems, and thus—solutions, critical data scholars, and scientists can consider. A resolutely transnational feminist approach on the other hand, can provide data theorists and practitioners with the hermeneutic tools necessary to identify and disrupt instances of injustice in a more inclusive and comprehensive manner. A transnational feminist orientation to data science can pay particular attention to the communities rendered most vulnerable by algorithmic oppression, such as women of color and populations in non-Western countries. I present five ways in which transnational feminism can be leveraged as an intervention into the current data science canon. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221112901",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Zhasmina Tacheva"
      ],
      "url": "https://doi.org/10.1177/20539517221112901",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 36,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2d2d0604-f5f3-44c5-9a5e-ad8d51414be8",
    "title": "The politics of constructing health data spaces: Border work and the stickiness of fragmentation",
    "abstract": "<jats:p>This article explores the construction of health data spaces through the lens of border work. It provides insights into the complex attachments and detachments that come to the fore when establishing centralized health data access bodies in the Nordic countries. By comparing Denmark, Norway, and Finland, the study unveils a variety of border work practices. These practices include the complex interplay between national infrastructures, local practices, and regulatory frameworks, the management of continuous attachments through additional loops, and negotiations over public-private borders. The study shows that, despite policy goals envisioning health data access bodies as seamless one-stop shops for ‘detached’ data, the data remains attached to places, institutions, people, and countries. Consequently, new data spaces tend to emerge and co-exist with existing ones. Our analysis of the Nordic experiences offers valuable lessons and critical insights for ongoing efforts to build a European Health Data Space. We further suggest that this stickiness of fragmentation might be a common feature of big data policy efforts.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517251320012",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Heidrun Åm",
        "Lotte Groth Jensen",
        "Rasmus Mølgaard Hansen",
        "Karoliina Snell",
        "Heta Tarkkala",
        "Aaro Tupasela"
      ],
      "url": "https://doi.org/10.1177/20539517251320012",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 57,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ab0a8252-a88a-43ac-9138-b83ee0104f6e",
    "title": "Simulation and the reality gap: Moments in a prehistory of synthetic data",
    "abstract": "<jats:p>\n            This paper sketches a prehistory of synthetic data in the development of simulation technologies. Synthetic data is connected to simulation by the technical problem of the reality gap: the gap between the synthetic data a model is trained on and the real-world data it is deployed on. The reality gap is presented as a novelty both generated and solved by synthetic data. We demonstrate that the reality gap has plagued simulation technologies since their inception in the mid-20th century. We contend that the reality gap is not something synthetic data can solve. To illustrate this, we examine three episodes in the prehistory of synthetic data. These episodes are representative of three distinct\n            <jats:italic>regimes of simulation</jats:italic>\n            : (a) the\n            <jats:italic>statistical regime</jats:italic>\n            , (b) the\n            <jats:italic>discrete-event</jats:italic>\n            regime, and (c) the\n            <jats:italic>visual</jats:italic>\n            -\n            <jats:italic>interactive regime</jats:italic>\n            . Each regime reveals a reality gap; from before the advent of digital computers to the present. Synthetic data, like simulations, require data about a given domain in order to model it. It requires the real-world data which it purports to dispense with. The reality gap is thus an epistemological issue as well as a technical one. We argue that it is also a political economic issue: it complicates existing means of producing data, adding new layers of mediation and labor. Synthetic data thus indicates the emergence of an alternative stack for the production of AI systems. This suggests that the political economy of AI must take account of the proliferation of new technical means for creating data.\n          </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241309884",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "James Steinhoff",
        "Sam Hind"
      ],
      "url": "https://doi.org/10.1177/20539517241309884",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 93,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a1021a7c-77e0-4f3b-85d0-6a4f6496b883",
    "title": "The importance of algorithm skills for informed Internet use",
    "abstract": "<jats:p> Using the Internet means encountering algorithmic processes that influence what information a user sees or hears. Existing research has shown that people's algorithm skills vary considerably, that they develop individual theories to explain these processes, and that their online behavior can reflect these understandings. Yet, there is little research on how algorithm skills enable people to use algorithms to their own benefit and to avoid harms they may elicit. To fill this gap in the literature, we explore the extent to which people understand how the online systems and services they use may be influenced by personal data that algorithms know about them, and whether users change their behavior based on this understanding. Analyzing 83 in-depth interviews from five countries about people's experiences with researching and searching for products and services online, we show how being aware of personal data collection helps people understand algorithmic processes. However, this does not necessarily enable users to influence algorithmic output, because currently, options that help users control the level of customization they encounter online are limited. Besides the empirical contributions, we discuss research design implications based on the diversity of the sample and our findings for studying algorithm skills. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231168100",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Jonathan Gruber",
        "Eszter Hargittai"
      ],
      "url": "https://doi.org/10.1177/20539517231168100",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 72,
      "is_referenced_by_count": 20,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b675430d-122f-491f-9cbc-f3ca66a79f3a",
    "title": "FAIR data sharing: An international perspective on why medical researchers  are lagging behind",
    "abstract": "<jats:p> FAIR data, that is, Findable, Accessible, Interoperable, and Reusable data, and Big Data intersect across issues related to data storage, access, and processing. The solution-oriented FAIR principles serve an integral role in improving Big Data; yet to date, the implementation of FAIR in multiple sectors has been fragmented. We conducted an exploratory analysis to identify incentives and barriers in creating FAIR data in the medical sector using digital concept mapping, a systematic mixed methods approach. Thirty-eight principal investigators (PIs) were recruited from North America, Europe, and Oceania. Our analysis revealed five clusters rated according to perceived relevance: ‘Efficiency and collaboration’ (rating 7.23), ‘Privacy and security’ (rating 7.18), ‘Data management standards’ (rating 7.16), ‘Organization of services’ (rating 6.98), and ‘Ownership’ (rating 6.28). All five clusters scored relatively high and within a narrow range (i.e., 6.28–7.69), implying that each cluster likely influences researchers’ decision-making processes. PIs harbor a positive view of FAIR data sharing, as exemplified by participants highly prioritizing ‘Efficiency and collaboration’. However, the other four clusters received only modestly lower ratings and largely contained barriers to FAIR data sharing. When viewed collectively, the benefits of efficiency and collaboration may not be sufficient in propelling FAIR data sharing. Arguably, until more of these reported barriers are addressed, widespread support of FAIR data will not translate into widespread practice. This research lays the preliminary foundation for conducting targeted large-scale research into FAIR data practices in the medical research community. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231171052",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Linda Rainey",
        "Jennifer E Lutomski",
        "Mireille JM Broeders"
      ],
      "url": "https://doi.org/10.1177/20539517231171052",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 30,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "60ff46a9-554f-4fdb-a9fb-44b33c9c80cc",
    "title": "Web3 as ‘self-infrastructuring’: The challenge is how",
    "abstract": "<jats:p> The term ‘Web3’ refers to the practices of participating in digital infrastructures through the ability to read, write and coordinate digital assets. Web3 is hailed as an alternative to the failings of big tech, offering a participatory mode of digital self-organizing and shared ownership of digital infrastructure through software-encoded governance rules and participatory practices. Yet, very few analytical frameworks have been presented in academic literature by which to approach Web3. This piece draws on the theoretical lens of infrastructure studies to offer an analytical framework to approach the emergent field of Web3 as an exploration in ‘how to infrastructure’ through prefigurative self-infrastructuring. Drawing on qualitative examples from digital ethnographic methods, I demonstrate how the origins of Web3 reveal the intentions of its creators as a political tool of prefiguration, yet its practices reveal the inherent tension of expressing these ideals in coherent technical and institutional infrastructure. Thus, I argue that one of the fundamental challenges Web3 is negotiating through technical and governance experiments is ‘how to self-infrastructure?’. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231159002",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Kelsie Nabben"
      ],
      "url": "https://doi.org/10.1177/20539517231159002",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 41,
      "is_referenced_by_count": 21,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bb3e21ea-20b5-4cc9-97d1-23009093c8a6",
    "title": "Understanding user interactions and perceptions of AI risk in Singapore",
    "abstract": "<jats:p> Artificial Intelligence (AI) is becoming increasingly prevalent and its application highly sophisticated. Concerns about AI's vulnerabilities and future threats have, however, long been debated among scientists and the tech community. By integrating Beck's theory of risk society with an audience-centered sense-making approach, we seek to understand the effects of AI on the general public's daily lives and their concerns when they adopt AI technology. Five focus groups with 36 participants from Singapore, a technologically advanced country, were conducted to investigate their risk perceptions of AI and AI-powered technology. We found that participants were not passive consumers of content showing up on their news feeds; indeed, some participants attempted to outsmart the algorithms. They were aware that tech companies often tweak algorithms to personalize content and drive consumers into rabbit holes. Nevertheless, despite a certain level of awareness and sporadic attempts to “outsmart” the system, many users might still be influenced by these algorithms, underscoring the extent to which consumers are often manipulated by smart tech powered by AI. We discuss the theoretical and policy implications of our findings by looking at the contextual factors. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231213823",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Taberez Ahmed Neyazi",
        "Sheryl Wei Ting Ng",
        "Mitchell Hobbs",
        "Audrey Yue"
      ],
      "url": "https://doi.org/10.1177/20539517231213823",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 74,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0065e10c-f15c-4844-99c6-6bd3298e97f7",
    "title": "Conditional trust: Citizens’ council on data-driven media personalisation and public expectations of transparency and accountability",
    "abstract": "<jats:p> This article presents findings from a rigorous, three-wave series of qualitative research into public expectations of data-driven media technologies, conducted in England, United Kingdom. Through a range of carefully chosen scenarios and deliberations around the risks and benefits afforded by data-driven media personalisation technologies and algorithms, we paid close attention to citizens’ voices as our multidisciplinary team sought to engage the public on what ‘good’ might look like in the context of media personalisation. We paid particular attention to risks and opportunities, examining practical use-cases and scenarios, and our three-wave councils culminated in citizens producing recommendations for practice and policy. In this article, we focus particularly on citizens’ ethical assessment, critique and improvements proposed on media personalisation methods in relation to benefits, fairness, safety, transparency and accountability. Our findings demonstrate that public expectations and trust in data-driven technologies are, fundamentally, conditional, with significant emphasis placed on transparency, inclusiveness and accessibility. Our findings also point to the context dependency of public expectations, which appears more pertinent to citizens, in hard political as opposed to entertainment spaces. Our conclusions are significant for global data-driven media personalisation environments – in terms of embedding citizens’ focus on transparency and accountability, but equally, also, we argue that strengthening research methodology, innovatively and rigorously to build in citizen voices at the very inception and core of design – must become a priority in technology development. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231184892",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Yen Nee Wong",
        "Rhia Jones",
        "Ranjana Das",
        "Philip Jackson"
      ],
      "url": "https://doi.org/10.1177/20539517231184892",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 75,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "81aa672d-16e2-497e-850f-37554c33b95e",
    "title": "Emotional labour in the collaborative data practices of repurposing healthcare data and building data technologies",
    "abstract": "<jats:p> This article focuses on emotions, conceptualised as emotional labour, evoked during data practices used to repurpose and enable healthcare data journeys for Finnish public healthcare. Combined approaches from critical data studies and the sociology of emotions were used to contribute to a better understanding of the mundane but often invisible work of the emotions of experts involved in data practices, such as facilitating data journeys and building data technologies. The article is based on a two-and-a-half-year ethnographic study conducted in a Finnish regional public healthcare and social service organisation. The study results were derived from the analysis of 39 interviews and fieldnotes produced by observing 170 h of various meetings, events and work activities performed by experts. The results were organised into three forms of observed experts’ emotional labour related to three phases of healthcare data journeys: (a) caring for data production and preparing data for travel, (b) managing excitement and frustration in data processing for continually building the data management system, and (c) reassuring users in making sense of obtained data analytics. The results contribute to a greater understanding of the emotions and emotional labour generated by healthcare data journeys and in relation to the volatile nature of healthcare data and the collaborative character of data practices. This work advocates for a better recognition of the emotional aspects of data practices and their implications on data-based knowledge and datafication processes in healthcare. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221098413",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Marta Choroszewicz"
      ],
      "url": "https://doi.org/10.1177/20539517221098413",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 46,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6e6ea7dc-da89-4cb4-924f-d6eeed05c9e9",
    "title": "Artificial intelligence ethics by design. Evaluating public perception on the importance of ethical design principles of artificial intelligence",
    "abstract": "<jats:p> Despite the immense societal importance of ethically designing artificial intelligence, little research on the public perceptions of ethical artificial intelligence principles exists. This becomes even more striking when considering that ethical artificial intelligence development has the aim to be human-centric and of benefit for the whole society. In this study, we investigate how ethical principles (explainability, fairness, security, accountability, accuracy, privacy, and machine autonomy) are weighted in comparison to each other. This is especially important, since simultaneously considering ethical principles is not only costly, but sometimes even impossible, as developers must make specific trade-off decisions. In this paper, we give first answers on the relative importance of ethical principles given a specific use case—the use of artificial intelligence in tax fraud detection. The results of a large conjoint survey ([Formula: see text]) suggest that, by and large, German respondents evaluate the ethical principles as equally important. However, subsequent cluster analysis shows that different preference models for ethically designed systems exist among the German population. These clusters substantially differ not only in the preferred ethical principles but also in the importance levels of the principles themselves. We further describe how these groups are constituted in terms of sociodemographics as well as opinions on artificial intelligence. Societal implications, as well as design challenges, are discussed. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221092956",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Kimon Kieslich",
        "Birte Keller",
        "Christopher Starke"
      ],
      "url": "https://doi.org/10.1177/20539517221092956",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 72,
      "is_referenced_by_count": 83,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d4aa45c7-90fd-4590-89bc-2db9371da01e",
    "title": "Different types of COVID-19 misinformation have different emotional valence on Twitter",
    "abstract": "<jats:p> The spreading of COVID-19 misinformation on social media could have severe consequences on people's behavior. In this paper, we investigated the emotional expression of misinformation related to the COVID-19 crisis on Twitter and whether emotional valence differed depending on the type of misinformation. We collected 17,463,220 English tweets with 76 COVID-19-related hashtags for March 2020. Using Google Fact Check Explorer API we identified 226 unique COVID-19 false stories for March 2020. These were clustered into six types of misinformation (cures, virus, vaccine, politics, conspiracy theories, and other). Applying the 226 classifiers to the Twitter sample we identified 690,004 tweets. Instead of running the sentiment on all tweets we manually coded a random subset of 100 tweets for each classifier to increase the validity, reducing the dataset to 2,097 tweets. We found that only a minor part of the entire dataset was related to misinformation. Also, misinformation in general does not lean towards a certain emotional valence. However, looking at comparisons of emotional valence for different types of misinformation uncovered that misinformation related to “virus” and “conspiracy” had a more negative valence than “cures,” “vaccine,” “politics,” and “other.” Knowing from existing studies that negative misinformation spreads faster, this demonstrates that filtering for misinformation type is fruitful and indicates that a focus on “virus” and “conspiracy” could be one strategy in combating misinformation. As emotional contexts affect misinformation spreading, the knowledge about emotional valence for different types of misinformation will help to better understand the spreading and consequences of misinformation. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211041279",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Marina Charquero-Ballester",
        "Jessica G Walter",
        "Ida A Nissen",
        "Anja Bechmann"
      ],
      "url": "https://doi.org/10.1177/20539517211041279",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 46,
      "is_referenced_by_count": 40,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1700314b-5fc6-4130-beff-f6d5f20a2e50",
    "title": "Data deprivations, data gaps and digital divides: Lessons from the COVID-19 pandemic",
    "abstract": "<jats:p> This paper draws lessons from the COVID-19 pandemic for the relationship between data-driven decision making and global development. The lessons are that (i) users should keep in mind the shifting value of data during a crisis, and the pitfalls its use can create; (ii) predictions carry costs in terms of inertia, overreaction and herding behaviour; (iii) data can be devalued by digital and data deluges; (iv) lack of interoperability and difficulty reusing data will limit value from data; (v) data deprivation, digital gaps and digital divides are not just a by-product of unequal global development, but will magnify the unequal impacts of a global crisis, and will be magnified in turn by global crises; (vi) having more data and even better data analytical techniques, such as artificial intelligence, does not guarantee that development outcomes will improve; (vii) decentralised data gathering and use can help to build trust – particularly important for coordination of behaviour. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211025545",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Wim Naudé",
        "Ricardo Vinuesa"
      ],
      "url": "https://doi.org/10.1177/20539517211025545",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 87,
      "is_referenced_by_count": 26,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9a3214f8-acbe-425f-a540-6d13d7850d02",
    "title": "Fairer machine learning in the real world: Mitigating discrimination without collecting sensitive data",
    "abstract": "Decisions based on algorithmic, machine learning models can be unfair, reproducing biases in historical data used to train them. While computational techniques are emerging to address aspects of these concerns through communities such as discrimination-aware data mining (DADM) and fairness, accountability and transparency machine learning (FATML), their practical implementation faces real-world challenges. For legal, institutional or commercial reasons, organisations might not hold the data on sensitive attributes such as gender, ethnicity, sexuality or disability needed to diagnose and mitigate emergent indirect discrimination-by-proxy, such as redlining. Such organisations might also lack the knowledge and capacity to identify and manage fairness issues that are emergent properties of complex sociotechnical systems. This paper presents and discusses three potential approaches to deal with such knowledge and information deficits in the context of fairer machine learning. Trusted third parties could selectively store data necessary for performing discrimination discovery and incorporating fairness constraints into model-building in a privacy-preserving manner. Collaborative online platforms would allow diverse organisations to record, share and access contextual and experiential knowledge to promote fairness in machine learning systems. Finally, unsupervised learning and pedagogically interpretable algorithms might allow fairness hypotheses to be built for further selective testing and exploration. Real-world fairness challenges in machine learning are not abstract, constrained optimisation problems, but are institutionally and contextually grounded. Computational fairness tools are useful, but must be researched and developed in and with the messy contexts that will shape their deployment, rather than just for imagined situations. Not doing so risks real, near-term algorithmic harm.",
    "metadata": {
      "doi": "10.1177/2053951717743530",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Michael Veale",
        "Reuben Binns"
      ],
      "url": "https://doi.org/10.1177/2053951717743530",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171774353",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 55,
      "is_referenced_by_count": 198,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "abdafa19-ab38-4eb8-ae23-bbb500cd8a4d",
    "title": "No amount of “AI” in content moderation will solve filtering’s prior-restraint problem",
    "abstract": "<jats:p> Contemporary policy debates about managing the enormous volume of online content have taken a renewed focus on upload filtering, automated detection of potentially illegal content, and other “proactive measures”. Often, policymakers and tech industry players invoke artificial intelligence as the solution to complex challenges around online content, promising that AI is a scant few years away from resolving everything from hate speech to harassment to the spread of terrorist propaganda. Missing from these promises, however, is an acknowledgement that proactive identification and automated removal of user-generated content raises problems beyond issues of “accuracy” and overbreadth--problems that will not be solved with more sophisticated AI. In this commentary, I discuss how the technical realities of content filtering stack up against the protections for freedom of expression in international human rights law. As policymakers and companies around the world turn to AI for communications governance, it is crucial that we recall why legal protections for speech have included presumptions against prior censorship, and consider carefully how proactive content moderation will fundamentally re-shape the relationship between rules, people, and their speech. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720920686",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Emma J Llansó"
      ],
      "url": "https://doi.org/10.1177/2053951720920686",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172092068",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 6,
      "is_referenced_by_count": 21,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "87d03363-a38f-4c2f-9955-dc8caff96a1b",
    "title": "Co-design and ethical artificial intelligence for health: An agenda for critical research and practice",
    "abstract": "<jats:p> Applications of artificial intelligence/machine learning (AI/ML) in health care are dynamic and rapidly growing. One strategy for anticipating and addressing ethical challenges related to AI/ML for health care is patient and public involvement in the design of those technologies – often referred to as ‘co-design’. Co-design has a diverse intellectual and practical history, however, and has been conceptualized in many different ways. Moreover, AI/ML introduces challenges to co-design that are often underappreciated. Informed by perspectives from critical data studies and critical digital health studies, we review the research literature on involvement in health care, and involvement in design, and examine the extent to which co-design as commonly conceptualized is capable of addressing the range of normative issues raised by AI/ML for health care. We suggest that AI/ML technologies have amplified and modified existing challenges related to patient and public involvement, and created entirely new challenges. We outline three pitfalls associated with co-design for ethical AI/ML for health care and conclude with suggestions for addressing these practical and conceptual challenges. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211065248",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Joseph Donia",
        "James A. Shaw"
      ],
      "url": "https://doi.org/10.1177/20539517211065248",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 127,
      "is_referenced_by_count": 47,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b70844b5-9e72-48a9-a698-3822f173b25c",
    "title": "Establishing a social licence for Financial Technology: Reflections on the role of the private sector in pursuing ethical data practices",
    "abstract": "Current attention directed at ethical dimensions of data and Artificial Intelligence have led to increasing recognition of the need to secure and maintain public support for uses (and reuses) of people’s data. This is essential to establish a “Social Licence” for current and future practices. The notion of a “Social Licence” recognises that there can be meaningful differences between what is legally permissible and what is socially acceptable. Establishing a Social Licence entails public engagement to build relationships of trust and ensure that practices align with public values. While the concept of the Social Licence is well-established in other sectors – notably in relation to extractive industries – it has only very recently begun to be discussed in relation to digital innovation and data-intensive industries. This article therefore draws on existing literature relating to the Social Licence in extractive industries to explore the potential approaches needed to establish a Social Licence for emerging data-intensive industries. Additionally, it draws on well-established literature relating to trust (from psychology and organisational science) to examine the relevance of trust, and trustworthiness, for emerging practices in data-intensive industries. In doing so the article considers the extent to which pursuing a Social Licence might complement regulation and inform codes of practice to place ethical and social considerations at the heart of industry practice. We focus on one key industry: Financial Technology. We demonstrate the importance of combining technical and social approaches to address ethical challenges in data-intensive innovation (particularly relating to Artificial Intelligence) and to establish relationships of trust to underpin a Social Licence for Financial Technology. Such approaches are needed across all areas and industries of data-intensive innovation to complement regulation and inform the development of ethical codes of practice. This is important to underpin culture change and to move beyond rhetorical commitments to develop best practice putting ethics at the heart of innovation.",
    "metadata": {
      "doi": "10.1177/2053951720908892",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Mhairi Aitken",
        "Ehsan Toreini",
        "Peter Carmichael",
        "Kovila Coopamootoo",
        "Karen Elliott",
        "Aad van Moorsel"
      ],
      "url": "https://doi.org/10.1177/2053951720908892",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172090889",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 36,
      "is_referenced_by_count": 30,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c375f1eb-1e59-4c66-b78a-fbb9f5885387",
    "title": "Algorithmic content moderation: Technical and political challenges in the automation of platform governance",
    "abstract": "As government pressure on major technology companies builds, both firms and legislators are searching for technical solutions to difficult platform governance puzzles such as hate speech and misinformation. Automated hash-matching and predictive machine learning tools – what we define here as algorithmic moderation systems – are increasingly being deployed to conduct content moderation at scale by major platforms for user-generated content such as Facebook, YouTube and Twitter. This article provides an accessible technical primer on how algorithmic moderation works; examines some of the existing automated tools used by major platforms to handle copyright infringement, terrorism and toxic speech; and identifies key political and ethical issues for these systems as the reliance on them grows. Recent events suggest that algorithmic moderation has become necessary to manage growing public expectations for increased platform responsibility, safety and security on the global stage; however, as we demonstrate, these systems remain opaque, unaccountable and poorly understood. Despite the potential promise of algorithms or ‘AI’, we show that even ‘well optimized’ moderation systems could exacerbate, rather than relieve, many existing problems with content policy as enacted by platforms for three main reasons: automated moderation threatens to (a) further increase opacity, making a famously non-transparent set of practices even more difficult to understand or audit, (b) further complicate outstanding issues of fairness and justice in large-scale sociotechnical systems and (c) re-obscure the fundamentally political nature of speech decisions being executed at scale.",
    "metadata": {
      "doi": "10.1177/2053951719897945",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Robert Gorwa",
        "Reuben Binns",
        "Christian Katzenbach"
      ],
      "url": "https://doi.org/10.1177/2053951719897945",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395171989794",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 23,
      "is_referenced_by_count": 391,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "42ee31d5-be1e-49e8-904c-0a24e63b309a",
    "title": "Data infrastructure literacy",
    "abstract": "<jats:p> A recent report from the UN makes the case for “global data literacy” in order to realise the opportunities afforded by the “data revolution”. Here and in many other contexts, data literacy is characterised in terms of a combination of numerical, statistical and technical capacities. In this article, we argue for an expansion of the concept to include not just competencies in reading and working with datasets but also the ability to account for, intervene around and participate in the wider socio-technical infrastructures through which data is created, stored and analysed – which we call “data infrastructure literacy”. We illustrate this notion with examples of “inventive data practice” from previous and ongoing research on open data, online platforms, data journalism and data activism. Drawing on these perspectives, we argue that data literacy initiatives might cultivate sensibilities not only for data science but also for data sociology, data politics as well as wider public engagement with digital data infrastructures. The proposed notion of data infrastructure literacy is intended to make space for collective inquiry, experimentation, imagination and intervention around data in educational programmes and beyond, including how data infrastructures can be challenged, contested, reshaped and repurposed to align with interests and publics other than those originally intended. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718786316",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Jonathan Gray",
        "Carolin Gerlitz",
        "Liliana Bounegru"
      ],
      "url": "https://doi.org/10.1177/2053951718786316",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 86,
      "is_referenced_by_count": 147,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7283ecaf-9630-4b83-bcf4-cd25156bfc8d",
    "title": "Big Data, new epistemologies and paradigm shifts",
    "abstract": "<jats:p> This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities, and assesses the extent to which they are engendering paradigm shifts across multiple disciplines. In particular, it critically explores new forms of empiricism that declare ‘the end of theory’, the creation of data-driven rather than knowledge-driven science, and the development of digital humanities and computational social sciences that propose radically different ways to make sense of culture, history, economy and society. It is argued that: (1) Big Data and new data analytics are disruptive innovations which are reconfiguring in many instances how research is conducted; and (2) there is an urgent need for wider critical reflection within the academy on the epistemological implications of the unfolding data revolution, a task that has barely begun to be tackled despite the rapid changes in research practices presently taking place. After critically reviewing emerging epistemological positions, it is contended that a potentially fruitful approach would be the development of a situated, reflexive and contextually nuanced epistemology. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714528481",
      "type": "journal-article",
      "published": [
        2014,
        4,
        1
      ],
      "authors": [
        "Rob Kitchin"
      ],
      "url": "https://doi.org/10.1177/2053951714528481",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 61,
      "is_referenced_by_count": 1308,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1fc68c3b-8071-4886-adf6-898fae7e1181",
    "title": "Big Data from the bottom up",
    "abstract": "<jats:p> This short article argues that an adequate response to the implications for governance raised by ‘Big Data’ requires much more attention to agency and reflexivity than theories of ‘algorithmic power’ have so far allowed. It develops this through two contrasting examples: the sociological study of social actors used of analytics to meet their own social ends (for example, by community organisations) and the study of actors’ attempts to build an economy of information more open to civic intervention than the existing one (for example, in the environmental sphere). The article concludes with a consideration of the broader norms that might contextualise these empirical studies, and proposes that they can be understood in terms of the notion of voice, although the practical implementation of voice as a norm means that voice must sometimes be considered via the notion of transparency. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714539277",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "Nick Couldry",
        "Alison Powell"
      ],
      "url": "https://doi.org/10.1177/2053951714539277",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 24,
      "is_referenced_by_count": 119,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "110ca4d1-2208-464a-af5f-62c326107b67",
    "title": "The price of certainty: How the politics of pandemic data demand an ethics of care",
    "abstract": "<jats:p> The Covid-19 pandemic broke on a world whose grip on epistemic trust was already in disarray. The first months of the pandemic saw many governments publicly performing reliance on epidemiological and modelling expertise in order to signal that data would be the basis for justifying whatever population-level measures of control were judged necessary. But comprehensive data has not become available, and instead scientists, policymakers and the public find themselves in a situation where policy inputs determine the data available and vice versa. This essay asks how we can live with what Amoore has termed ‘post-Cartesian doubt’ in situations of existential risk, and what kind of approach to science and data can answer the moral and human demands of a situation such as the Covid-19 pandemic. I suggest that science and policy could be able to control the pandemic better by addressing the sources of uncertainty and missing data not as gaps in the information landscape, but as individuals who are likely to be members of less-visible and less powerful groups including low-wage workers, the elderly, migrants, prisoners and others. This would shift both data use and policy toward an ethics of care, an embodied approach which asks what people need and how they behave in relation to each other, rather than how to manage population-level behaviour. This approach, I argue, is more appropriate for pandemic response than a utilitarian calculation of how many people each country should expect to lose as a result of the disease. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720942539",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Linnet Taylor"
      ],
      "url": "https://doi.org/10.1177/2053951720942539",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 38,
      "is_referenced_by_count": 37,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1715b3c3-d9a7-4ef6-84f8-49de64254b77",
    "title": "Datatrust: Or, the political quest for numerical evidence and the epistemologies of Big Data",
    "abstract": "<jats:p> Recently, there has been renewed interest in so-called evidence-based policy making. Enticed by the grand promises of Big Data, public officials seem increasingly inclined to experiment with more data-driven forms of governance. But while the rise of Big Data and related consequences has been a major issue of concern across different disciplines, attempts to develop a better understanding of the phenomenon's historical foundations have been rare. This short commentary addresses this gap by situating the current push for numerical evidence within a broader socio-political context, demonstrating how the epistemological claims of Big Data science intersect with specific forms of trust, truth, and objectivity. We conclude by arguing that regulators' faith in numbers can be attributed to a distinct political culture, a representative democracy undermined by pervasive public distrust and uncertainty. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716649398",
      "type": "journal-article",
      "published": [
        2016,
        6
      ],
      "authors": [
        "Gernot Rieder",
        "Judith Simon"
      ],
      "url": "https://doi.org/10.1177/2053951716649398",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 43,
      "is_referenced_by_count": 57,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "92a19560-842a-4779-b7d8-9d3d19b18f4d",
    "title": "Inflated granularity: Spatial “Big Data” and geodemographics",
    "abstract": "<jats:p> Data analytics, particularly the current rhetoric around “Big Data”, tend to be presented as new and innovative, emerging ahistorically to revolutionize modern life. In this article, we situate one branch of Big Data analytics, spatial Big Data, through a historical predecessor, geodemographic analysis, to help develop a critical approach to current data analytics. Spatial Big Data promises an epistemic break in marketing, a leap from targeting geodemographic areas to targeting individuals. Yet it inherits characteristics and problems from geodemographics, including a justification through the market, and a process of commodification through the black-boxing of technology. As researchers develop sustained critiques of data analytics and its effects on everyday life, we must so with a grounding in the cultural and historical contexts from which data technologies emerged. This article and others (Barnes and Wilson, 2014) develop a historically situated, critical approach to spatial Big Data. This history illustrates connections to the critical issues of surveillance, redlining, and the production of consumer subjects and geographies. The shared histories and structural logics of spatial Big Data and geodemographics create the space for a continued critique of data analyses’ role in society. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715601144",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Craig M Dalton",
        "Jim Thatcher"
      ],
      "url": "https://doi.org/10.1177/2053951715601144",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 123,
      "is_referenced_by_count": 42,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "21d050d5-d2be-4d59-9a44-4de13be0cb92",
    "title": "Heuristics of the algorithm: Big Data, user interpretation and institutional translation",
    "abstract": "<jats:p> Intelligence on mass media audiences was founded on representative statistical samples, analysed by statisticians at the market departments of media corporations. The techniques for aggregating user data in the age of pervasive and ubiquitous personal media (e.g. laptops, smartphones, credit cards/swipe cards and radio-frequency identification) build on large aggregates of information (Big Data) analysed by algorithms that transform data into commodities. While the former technologies were built on socio-economic variables such as age, gender, ethnicity, education, media preferences (i.e. categories recognisable to media users and industry representatives alike), Big Data technologies register consumer choice, geographical position, web movement, and behavioural information in technologically complex ways that for most lay people are too abstract to appreciate the full consequences of. The data mined for pattern recognition privileges relational rather than demographic qualities. We argue that the agency of interpretation at the bottom of market decisions within media companies nevertheless introduces a ‘heuristics of the algorithm’, where the data inevitably becomes translated into social categories. In the paper we argue that although the promise of algorithmically generated data is often implemented in automated systems where human agency gets increasingly distanced from the data collected (it is our technological gadgets that are being surveyed, rather than us as social beings), one can observe a felt need among media users and among industry actors to ‘translate back’ the algorithmically produced relational statistics into ‘traditional’ social parameters. The tenacious social structures within the advertising industries work against the techno-economically driven tendencies within the Big Data economy. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715608406",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Göran Bolin",
        "Jonas Andersson Schwarz"
      ],
      "url": "https://doi.org/10.1177/2053951715608406",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 67,
      "is_referenced_by_count": 49,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "82f98eb6-1be4-47e4-ab05-0cf2f8c5d004",
    "title": "The (Big) Data-security assemblage: Knowledge and critique",
    "abstract": "<jats:p> The Snowden revelations and the emergence of ‘Big Data’ have rekindled questions about how security practices are deployed in a digital age and with what political effects. While critical scholars have drawn attention to the social, political and legal challenges to these practices, the debates in computer and information science have received less analytical attention. This paper proposes to take seriously the critical knowledge developed in information and computer science and reinterpret their debates to develop a critical intervention into the public controversies concerning data-driven security and digital surveillance. The paper offers a two-pronged contribution: on the one hand, we challenge the credibility of security professionals’ discourses in light of the knowledge that they supposedly mobilize; on the other, we argue for a series of conceptual moves around data, human–computer relations, and algorithms to address some of the limitations of existing engagements with the Big Data-security assemblage. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715609066",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Claudia Aradau",
        "Tobias Blanke"
      ],
      "url": "https://doi.org/10.1177/2053951715609066",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 67,
      "is_referenced_by_count": 74,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "22f930d5-f860-4142-9716-dcce5e995281",
    "title": "Isomorphism through algorithms: Institutional dependencies in the case of Facebook",
    "abstract": "<jats:p> Algorithms and data-driven technologies are increasingly being embraced by a variety of different sectors and institutions. This paper examines how algorithms and data-driven technologies, enacted by an organization like Facebook, can induce similarity across an industry. Using theories from organizational sociology and neoinstitutionalism, this paper traces the bureaucratic roots of Big Data and algorithms to examine the institutional dependencies that emerge and are mediated through data-driven and algorithmic logics. This type of analysis sheds light on how organizational contexts are embedded into algorithms, which can then become embedded within other organizational and individual practices. By investigating technical practices as organizational and bureaucratic, discussions about accountability and decision-making can be reframed. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718757253",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Robyn Caplan",
        "danah boyd"
      ],
      "url": "https://doi.org/10.1177/2053951718757253",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 65,
      "is_referenced_by_count": 118,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ea434898-bd5d-43e5-9d8e-72456f380843",
    "title": "The Chilling Effects of Digital Dataveillance: A Theoretical Model and an Empirical Research Agenda",
    "abstract": "<jats:p> People's sense of being subject to digital dataveillance can cause them to restrict their digital communication behavior. Such a chilling effect is essentially a form of self-censorship in everyday digital media use with the attendant risks of undermining individual autonomy and well-being. This article combines the existing theoretical and limited empirical work on surveillance and chilling effects across fields with an analysis of novel data toward a research agenda. The institutional practice of dataveillance—the automated, continuous, and unspecific collection, retention, and analysis of digital traces—affects individual behavior. A mechanism-based causal model based on the theory of planned behavior is proposed for the micro level: An individual's increased sense of dataveillance causes their subjective probability assigned to negative outcomes of digital communication behavior to increase and attitudes toward this communication to become less favorable, ultimately decreasing the intention to engage in it. In aggregate and triggered through successive salience shocks such as data scandals, dataveillance is accordingly hypothesized to lower the baseline of free digital communication in a society through the chilling effects mechanism. From the developed theoretical model, a set of methodological consequences and questions for future studies are derived. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211065368",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Moritz Büchi",
        "Noemi Festic",
        "Michael Latzer"
      ],
      "url": "https://doi.org/10.1177/20539517211065368",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 94,
      "is_referenced_by_count": 60,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2ac618bf-1e7d-4d55-9404-9cfb54bdbae9",
    "title": "Empathic media and advertising: Industry, policy, legal and citizen perspectives (the case for intimacy)",
    "abstract": "<jats:p> Drawing on interviews with people from the advertising and technology industry, legal experts and policy makers, this paper assesses the rise of emotion detection in digital out-of-home advertising, a practice that often involves facial coding of emotional expressions in public spaces. Having briefly outlined how bodies contribute to targeting processes and the optimisation of the ads themselves, it progresses to detail industrial perspectives, intentions and attitudes to data ethics. Although the paper explores possibilities of this sector, it pays careful attention to existing practices that claim not to use personal data. Centrally, it argues that scholars and regulators need to pay attention to the principle of intimacy. This is developed to counter weaknesses in privacy that is typically based on identification. Having defined technologies, use cases, industrial perspectives, legal views and arguments about jurisprudence, the paper discusses this ensemble of perspectives in light of a nationwide survey about how UK citizens feel about the potential for emotion detection in out-of-home advertising. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716666868",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Andrew McStay"
      ],
      "url": "https://doi.org/10.1177/2053951716666868",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 37,
      "is_referenced_by_count": 33,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "48551eb5-4ed5-4fcd-8aa3-7cec5dbdc2f2",
    "title": "Politics of data reuse in machine learning systems: Theorizing reuse entanglements",
    "abstract": "<jats:p> Policy discussions and corporate strategies on machine learning are increasingly championing data reuse as a key element in digital transformations. These aspirations are often coupled with a focus on responsibility, ethics and transparency, as well as emergent forms of regulation that seek to set demands for corporate conduct and the protection of civic rights. And the Protective measures include methods of traceability and assessments of ‘good’ and ‘bad’ datasets and algorithms that are considered to be traceable, stable and contained. However, these ways of thinking about both technology and ethics obscure a fundamental issue, namely that machine learning systems entangle data, algorithms and more-than-human environments in ways that challenge a well-defined separation. This article investigates the fundamental fallacy of most data reuse strategies as well as their regulation and mitigation strategies that data can somehow be followed, contained and controlled in machine learning processes. Instead, the article argues that we need to understand the reuse of data as an inherently entangled phenomenon. To examine this tension between the discursive regimes and the realities of data reuse, we advance the notion of reuse entanglements as an analytical lens. The main contribution of the article is the conceptualization of reuse that places entanglements at its core and the articulation of its relevance using empirical illustrations. This is important, we argue, for our understanding of the nature of data and algorithms, for the practical uses of data and algorithms and our attitudes regarding ethics, responsibility and regulation. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221139785",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Nanna Bonde Thylstrup",
        "Kristian Bondo Hansen",
        "Mikkel Flyverbom",
        "Louise Amoore"
      ],
      "url": "https://doi.org/10.1177/20539517221139785",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 76,
      "is_referenced_by_count": 16,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c9c5cc0b-e7f9-4257-a69b-9b2ac1e6cb82",
    "title": "The value of sharing: Branding and behaviour in a life and health insurance company",
    "abstract": "<jats:p> As Big Data, the Internet of Things and insurance collide, so too, do the best and the worst of our futures. Insurance is summoned as an example of the interference in our private lives that is already underway everywhere. In this paper, we pause to reflect on this argument. Can changes in the way insurance measures the value of behaviour really serve as an example of the individual and social harms of datafication? How do we know? Insurance is a mathematical relationship staged between individuals and groups, between risk and uncertainty, between distribution and assessment, between the value of sharing and the sharing of value. We use the case study of Discovery International, owner of Vitality, the market leading brand in behavioural insurance to consider how behaviour is being branded and how the brand behaves. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720950350",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Hugo Jeanningros",
        "Liz McFall"
      ],
      "url": "https://doi.org/10.1177/2053951720950350",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 24,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7cefa546-a22f-44c3-ab99-d2166cda0b29",
    "title": "Auto-essentialization: Gender in automated facial analysis as extended colonial project",
    "abstract": "<jats:p> Scholars are increasingly concerned about social biases in facial analysis systems, particularly with regard to the tangible consequences of misidentification of marginalized groups. However, few have examined how automated facial analysis technologies intersect with the historical genealogy of racialized gender—the gender binary and its classification as a highly racialized tool of colonial power and control. In this paper, we introduce the concept of auto-essentialization: the use of automated technologies to re-inscribe the essential notions of difference that were established under colonial rule. We consider how the face has emerged as a legitimate site of gender classification, despite being historically tied to projects of racial domination. We examine the history of gendering the face and body, from colonial projects aimed at disciplining bodies which do not fit within the European gender binary, to sexology's role in normalizing that binary, to physiognomic practices that ascribed notions of inferiority to non-European groups and women. We argue that the contemporary auto-essentialization of gender via the face is both racialized and trans-exclusive: it asserts a fixed gender binary and it elevates the white face as the ultimate model of gender difference. We demonstrate that imperialist ideologies are reflected in modern automated facial analysis tools in computer vision through two case studies: (1) commercial gender classification and (2) the security of both small-scale (women-only online platforms) and large-scale (national borders) spaces. Thus, we posit a rethinking of ethical attention to these systems: not as immature and novel, but as mature instantiations of much older technologies. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211053712",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Morgan Klaus Scheuerman",
        "Madeleine Pape",
        "Alex Hanna"
      ],
      "url": "https://doi.org/10.1177/20539517211053712",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 87,
      "is_referenced_by_count": 38,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c0588659-df44-4dd7-8423-7b44b1fcd254",
    "title": "Caution: Rumors ahead—A case study on the debunking of false information on Twitter",
    "abstract": "<jats:p> As false information may spread rapidly on social media, a profound understanding of how it can be debunked is required. This study offers empirical insights into the development of rumors after they are debunked, the various user groups who are involved in the process, and their network structures. As crisis situations are highly sensitive to the spread of rumors, Twitter posts from during the 2017 G20 summit are examined. Tweets regarding five rumors that were debunked during this event were manually coded into the following categories: rumor, debunking message, uncertainty about rumor, uncertainty about debunking message, and others. Our findings show that rumors which are debunked early and vehemently by official sources are the most likely to be stopped. When individuals participate in the process, they typically do so by sharing uncommented media content, as opposed to contributing user-generated content. Depending on the conditions in which a rumor arises, different network structures can be found. Since some rumors are easier for individuals to verify than others, our results have implications for the priorities of journalists and official sources. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720980127",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Anna-Katharina Jung",
        "Björn Ross",
        "Stefan Stieglitz"
      ],
      "url": "https://doi.org/10.1177/2053951720980127",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 63,
      "is_referenced_by_count": 24,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e58ce111-3103-41bb-a5bd-301b5fa8bff6",
    "title": "Inequalities in privacy cynicism: An intersectional analysis of agency constraints",
    "abstract": "<jats:p> A growing body of research highlights a trend toward widespread attitudes of privacy cynicism, apathy and resignation among Internet users. In this work, we extend these discussions by concentrating on the concept of user agency. Specifically, we examine how five types of structural constraints—interpersonal, cultural, technological, economic and political—restrict user agency and contribute to the prevalence of privacy cynicism as a common response. Drawing on critical data studies and adopting an intersectional lens, we demonstrate how these constraints disproportionately impact various social groups unequally, leading to a disparate distribution of agency and privacy cynicism. Furthermore, we contend that the sense of powerlessness engendered by excessive constraints on user agency can, in turn, exacerbate user vulnerability to such constraints, potentially initiating a vicious cycle of disempowerment. The article enriches the field of privacy research by linking the traditionally individual-focused and psychological dimensions of privacy with critical surveillance studies and by proposing potential interventions to mitigate privacy cynicism. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241232629",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Christian Pieter Hoffmann",
        "Christoph Lutz",
        "Giulia Ranzini"
      ],
      "url": "https://doi.org/10.1177/20539517241232629",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 135,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b94e14e0-912a-4bf6-ba96-ab4d143869d2",
    "title": "To predict and to manage. Predictive policing in the United States",
    "abstract": "<jats:p> This article offers a detailed examination of the content of predictive policing applications. Crime prediction machines are used by governments to shape the moral behavior of police. They serve not only to predict when and where crime is likely to occur, but also to regulate police work. They calculate equivalence ratios, distributing security across the territory based on multiple cost and social justice criteria. Tracing the origins of predictive policing in the Compstat system, this article studies the shift from machines to explore intuitions (where police officers still have control over the machine) to applications removing the reflexive dimension of proactivity, thus turning prediction into the medium for “dosage” metrics of police work quantities. Finally, the article discusses how, driven by a critical movement denouncing the discriminatory biases of predictive machines, developers seek to develop techniques to audit training dataset and ways to calculate the reasonable amount of stop and frisk over the population. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719861703",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Bilel Benbouzid"
      ],
      "url": "https://doi.org/10.1177/2053951719861703",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 38,
      "is_referenced_by_count": 37,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d747ed35-ef2d-4b5d-8541-0a90394ad8aa",
    "title": "Clouded data: Privacy and the promise of encryption",
    "abstract": "<jats:p> Personal data is highly vulnerable to security exploits, spurring moves to lock it down through encryption, to cryptographically ‘cloud’ it. But personal data is also highly valuable to corporations and states, triggering moves to unlock its insights by relocating it in the cloud. We characterise this twinned condition as ‘clouded data’. Clouded data constructs a political and technological notion of privacy that operates through the intersection of corporate power, computational resources and the ability to obfuscate, gain insights from and valorise a dependency between public and private. First, we survey prominent clouded data approaches (blockchain, multiparty computation, differential privacy, and homomorphic encryption), suggesting their particular affordances produce distinctive versions of privacy. Next, we perform two notional code-based experiments using synthetic datasets. In the field of health, we submit a patient’s blood pressure to a notional cloud-based diagnostics service; in education, we construct a student survey that enables aggregate reporting without individual identification. We argue that these technical affordances legitimate new political claims to capture and commodify personal data. The final section broadens the discussion to consider the political force of clouded data and its reconstitution of traditional notions such as the public and the private. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719848781",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Luke Munn",
        "Tsvetelina Hristova",
        "Liam Magee"
      ],
      "url": "https://doi.org/10.1177/2053951719848781",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 75,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "08e7b6a2-373d-4950-af97-0d1aba53ffde",
    "title": "Big ideas, small data: Opportunities and challenges for data science and the social services sector",
    "abstract": "<jats:p> The social services sector, comprised of a constellation of programs meeting critical human needs, lacks the resources and infrastructure to implement data science tools. As the use of data science continues to expand, it has been accompanied by a rise in interest and commitment to using these tools for social good. This commentary examines overlooked, and under-researched limitations of data science applications in the social sector—the volume, quality, and context of the available data that currently exists in social service systems require unique considerations. We explore how the presence of small data within the social service contexts can result in extrapolation; if not properly considered, data science can negatively impact the organizations data scientists are trying to assist. We conclude by proposing three ways data scientists interested in working within the social services sector can enhance their contributions to the field: refining and leveraging available data, improving collaborations, and respecting data limitations. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231171051",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Geri Louise Dimas",
        "Lauri Goldkind",
        "Renata Konrad"
      ],
      "url": "https://doi.org/10.1177/20539517231171051",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 21,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c2f6384c-d82e-4465-82eb-e2e8c35e9873",
    "title": "Beyond opening up the black box: Investigating the role of algorithmic systems in Wikipedian organizational culture",
    "abstract": "Scholars and practitioners across domains are increasingly concerned with algorithmic transparency and opacity, interrogating the values and assumptions embedded in automated, black-boxed systems, particularly in user-generated content platforms. I report from an ethnography of infrastructure in Wikipedia to discuss an often understudied aspect of this topic: the local, contextual, learned expertise involved in participating in a highly automated social–technical environment. Today, the organizational culture of Wikipedia is deeply intertwined with various data-driven algorithmic systems, which Wikipedians rely on to help manage and govern the “anyone can edit” encyclopedia at a massive scale. These bots, scripts, tools, plugins, and dashboards make Wikipedia more efficient for those who know how to work with them, but like all organizational culture, newcomers must learn them if they want to fully participate. I illustrate how cultural and organizational expertise is enacted around algorithmic agents by discussing two autoethnographic vignettes, which relate my personal experience as a veteran in Wikipedia. I present thick descriptions of how governance and gatekeeping practices are articulated through and in alignment with these automated infrastructures. Over the past 15 years, Wikipedian veterans and administrators have made specific decisions to support administrative and editorial workflows with automation in particular ways and not others. I use these cases of Wikipedia’s bot-supported bureaucracy to discuss several issues in the fields of critical algorithms studies; critical data studies; and fairness, accountability, and transparency in machine learning—most principally arguing that scholarship and practice must go beyond trying to “open up the black box” of such systems and also examine sociocultural processes like newcomer socialization.",
    "metadata": {
      "doi": "10.1177/2053951717730735",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "R Stuart Geiger"
      ],
      "url": "https://doi.org/10.1177/2053951717730735",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171773073",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 37,
      "is_referenced_by_count": 44,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0f897578-39dc-4f19-9435-446c783af3c8",
    "title": "Turning biases into hypotheses through method: A logic of scientific discovery for machine learning",
    "abstract": "<jats:p> Machine learning (ML) systems have shown great potential for performing or supporting inferential reasoning through analyzing large data sets, thereby potentially facilitating more informed decision-making. However, a hindrance to such use of ML systems is that the predictive models created through ML are often complex, opaque, and poorly understood, even if the programs “learning” the models are simple, transparent, and well understood. ML models become difficult to trust, since lay-people, specialists, and even researchers have difficulties gauging the reasonableness, correctness, and reliability of the inferences performed. In this article, we argue that bridging this gap in the understanding of ML models and their reasonableness requires a focus on developing an improved methodology for their creation. This process has been likened to “alchemy” and criticized for involving a large degree of “black art,” owing to its reliance on poorly understood “best practices”. We soften this critique and argue that the seeming arbitrariness often is the result of a lack of explicit hypothesizing stemming from an empiricist and myopic focus on optimizing for predictive performance rather than from an occult or mystical process. We present some of the problems resulting from the excessive focus on optimizing generalization performance at the cost of hypothesizing about the selection of data and biases. We suggest embedding ML in a general logic of scientific discovery similar to the one presented by Charles Sanders Peirce, and present a recontextualized version of Peirce’s scientific hypothesis adjusted to ML. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211020775",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Simon Aagaard Enni",
        "Maja Bak Herrie"
      ],
      "url": "https://doi.org/10.1177/20539517211020775",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 68,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "77f8a1ac-6205-44df-8447-1a0acc0c7f5a",
    "title": "Heritage-based tribalism in Big Data ecologies: Deploying origin myths for antagonistic othering",
    "abstract": "<jats:p> This article presents a conceptual and methodological framework to study heritage-based tribalism in Big Data ecologies by combining approaches from the humanities, social and computing sciences. We use such a framework to examine how ideas of human origin and ancestry are deployed on Twitter for purposes of antagonistic ‘othering’. Our goal is to equip researchers with theory and analytical tools for investigating divisive online uses of the past in today’s networked societies. In particular, we apply notions of heritage, othering and neo-tribalism, and both data-intensive and qualitative methods to the case of people’s engagements with the news of Cheddar Man’s DNA on Twitter. We show that heritage-based tribalism in Big Data ecologies is uniquely shaped as an assemblage by the coalescing of different forms of antagonistic othering. Those that co-occur most frequently are the ones that draw on ‘Views on Race’, ‘Trust in Experts’ and ‘Political Leaning’. The framings of the news that were most influential in triggering heritage-based tribalism were introduced by both right- and left-leaning newspaper outlets and by activist websites. We conclude that heritage-themed communications that rely on provocative narratives on social media tend to be labelled as political and not to be conducive to positive change in people’s attitudes towards issues such as racism. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211003310",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Chiara Bonacchi",
        "Marta Krzyzanska"
      ],
      "url": "https://doi.org/10.1177/20539517211003310",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 59,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "00efdb1a-857d-4740-9db0-4af16f1c74b0",
    "title": "Situating questions of data, power, and racial formation",
    "abstract": "<jats:p> This special theme of Big Data &amp; Society explores connections, relationships, and tensions that coalesce around data, power, and racial formation. This collection of articles and commentaries builds upon scholarly observations of data substantiating and transforming racial hierarchies. Contributors consider how racial projects intersect with interlocking systems of oppression across concerns of class, coloniality, dis/ability, gendered difference, and sexuality across contexts and jurisdictions. In doing so, this special issue illuminates how data can both reinforce and challenge colorblind ideologies as well as how data might be mobilized in support of anti-racist movements. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221090938",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Renee Shelby",
        "Kathryn Henne"
      ],
      "url": "https://doi.org/10.1177/20539517221090938",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 48,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "15aa872e-185b-438e-9187-f5381dcb8ac7",
    "title": "Unveiling the layers of data activism: The organising of civic innovation to fight corruption in Brazil",
    "abstract": "<jats:p>Developed by tech-savvy citizens, Rosie is a bot that autonomously checks the public spending of elected representatives of the Brazilian Lower Chamber and uses Twitter to engage peoplein discussing suspicious findings. Rosie is the most visible face of Operação Serenata de Amor (Operation Love Serenade), a data-enabled activism initiative that revolves around the creation, use and dissemination of open data to hold politicians accountable and empower citizens to react against the misuse of public funds. The article draws on an original data set – including interviews, participant online observation notes and secondary qualitative materials – to examine Operação Serenata de Amor, focusing on how material and symbolic elements related to both human and non-human actors shape the organisational patterns of this type of initiative. The findings suggest that there are three organisational patterns, each with further specific challenges, based on the presence of three modes of participation that depend on different types of engagement with digital technologies and data. Findings indicate that data-enabled activism can emerge with typical characteristics and values of tech startups, such as the goal of creating a sustainable budget and providing strategic content by validating it with user feedback, while also retaining some traits of online activism, such as ad hoc and temporal networks of highly autonomous actors concerned with specific contentious issues. In this respect, the eventual demobilisation of Operação Serenata de Amor's initiators due to commercial values and struggles to maintain it active and engaging can be seen as a cautionary tale for data-enabled activism, particularly for initiatives closely associated with civic innovation and social tech startups.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231190078",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Fernanda Odilla",
        "Alice Mattoni"
      ],
      "url": "https://doi.org/10.1177/20539517231190078",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 61,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3429ef2f-4158-4916-bc0e-a333b88c4700",
    "title": "‘Hacking multitude’ and Big Data: Some insights from the Turkish ‘digital coup’",
    "abstract": "<jats:p> The paper presents my first findings and reflections on how ordinary people may opportunistically and unpredictably respond to Internet censorship and tracking. I try to capture this process with the concept of ‘hacking multitude'. Working on a case study of the Turkish government's block of the social media platform Twitter (March 2014), I argue that during systemic data choke-points, a multitude of users might acquire a certain degree of reflexivity over ubiquitous software of advanced techno-capitalism. Resisting naïve parallels between urban streets and virtual global streets, the article draws on Fuller's ‘media ecologies' to make sense of complex and dynamic interactions between processes and materialities, strategies of communication and mundane practices. Such a dense space is mostly invisible to network and traffic analysis, although it comes alive under the magnifying lens of digital ethnography. As the Turkish government tried to stop protesters on both the urban and the Twitter spheres, alternative material configurations and new hybrid formations and practices emerged. I try to bring this process alive following the traces – that is, a combination of digital data and materialities – of a social space between the protest for Twitter access, the ‘digital coup' and the interactions that this situation determined. In the final section, I briefly explore two research trajectories which can further develop my initial formulation of a ‘hacking multitude'. I argue that a generalisation of hacking/multitude is problematic for the political, cultural or economic processes more directly associated with Big Data. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715580599",
      "type": "journal-article",
      "published": [
        2015,
        5,
        1
      ],
      "authors": [
        "Paolo Cardullo"
      ],
      "url": "https://doi.org/10.1177/2053951715580599",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 34,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5c47daef-9e71-4ec9-9498-54926fdd2b5d",
    "title": "Sharenting and social media properties: Exploring vicarious data harms and sociotechnical mitigations",
    "abstract": "<jats:p> In this paper, we demonstrate how social media technologies can co-produce data-related harms unless preventative measures are instituted. To this end, we draw on a passive ethnography of a public Facebook group in the UK practicing sharenting which occurs when parents and guardians post sensitive and identifying information about children in their care on social media. Theoretically, we draw on the ‘harm translation’ concept from digital criminology and the ‘seductions of crime’ perspective from cultural criminology. Further we analyse documents on the operations of Facebook's content filtering algorithms published by Meta (Facebook's parent company). With insights from these sources, we demonstrate how platform technologies go beyond facilitation to the inadvertent co-production of harm via embedded mediative properties that shape user perception and action. We show that, in the specific context of sharenting, the properties invite rather than simply facilitate the practice and can also invite subsequent misuses of child-centric data. Through our analysis of these dynamics, we set out an empirical basis for challenging reductive depictions of social media technologies as solely facilitative of human action including harmful conduct. We also outline our vision to integrate insights from the analysis into a new sociotechnical harm prevention framework informed by Natural Language Processing approaches. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231219243",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Pamela Ugwudike",
        "Silke Roth",
        "Anita Lavorgna",
        "Stuart E. Middleton",
        "Natalie Djohari",
        "Morena Tartari",
        "Arpan Mandal"
      ],
      "url": "https://doi.org/10.1177/20539517231219243",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 55,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b0acb8df-bec5-4a52-b60e-4ee67176775d",
    "title": "Designing for justice in freelancing: Testing platform interventions to minimise discrimination in online labour markets",
    "abstract": "<jats:p> Online labour markets (OLMs) are a vital source of income for globally diverse and dispersed freelancers. Despite their promise of neutrality, OLMs are known to perpetuate hiring discrimination, vested in how OLMs are designed and what kinds of interactions they enable between freelancers and hirers. In this study, we go beyond understanding mechanisms of hiring discrimination in OLMs, to identifying platform design features that can minimise hiring discrimination. To do so, we draw on a methodology guided by the design justice ethos. Drawing on a survey on UK-based freelancers and interviews with a purposefully drawn sub-sample, we collaboratively identify five platform design interventions to minimise hiring discrimination in OLMs: community composition, identity-signalling flairs, text only reviews, union membership, and an antidiscrimination prompt. The core of our study is an innovative experiment conducted on a purpose-built, mock OLM, Mock-Freelancer.com. On this mock OLM, we experimentally test mechanisms of discrimination, including how these mechanisms fare under the five altered platform design interventions through a discrete-choice experiment. We find that both community and flairs were important in encouraging the hiring of women and non-White freelancers. We also establish that anonymity universally disadvantages freelancers. We conclude with recommendations to design OLMs that minimise labour market discrimination. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241232631",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Siân Brooke",
        "Aliya Hamid Rao"
      ],
      "url": "https://doi.org/10.1177/20539517241232631",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 51,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6d0f4beb-7998-46e6-8957-6e44bdcfd62e",
    "title": "Algorithmic camouflage: Exploring the shadowbans imposed by algorithms to moderate the content of Chinese gay men",
    "abstract": "<jats:p> This study employs semistructured interviews and algorithmic ethnography to explore how algorithmic shadowbans have been used to moderate content related to Chinese gay men and achieve targeted algorithmic governance. Through a multimethod approach combining both thematic analysis and discourse analysis, this study claims that algorithms impose seemingly tolerant but actually restrictive shadowbans, which are thematized as “(im)permissible searching” and “(un)smooth posting,” on Chinese gay men. This study conceptualizes such algorithmic shadowbans as “algorithmic camouflage,” emphasizing the opacity of the roles, behaviors, and purposes of algorithms toward specific users from an interactive perspective, highlighting the “hypocrisy” of algorithms. Under hypocritical algorithmic shadowbans, this study suggests that a highly camouflaged “de-gaying” discourse—through compositions of dehumanization, de-emotionalization, and dramatization—is being shaped by algorithms on Chinese digital platforms. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241296037",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Longxuan Zhao"
      ],
      "url": "https://doi.org/10.1177/20539517241296037",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 72,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "02a74be7-4b36-4467-a40c-e850f0dcd3f8",
    "title": "Problem-solving? No, problem-opening! A method to reframe and teach data ethics as a transdisciplinary endeavour",
    "abstract": "<jats:p> Starting from the recognition of the limits of today's common essentialist and axiological understandings of data and ethics, in this article we make the case for an ecosystemic understanding of data ethics (for the city) that accounts for the inherent value-laden entanglements and unintended (both positive and negative) consequences of the development, implementation, and use of data-driven technologies in real-life contexts. To operationalize our view, we conceived and taught a master course titled ‘Ethics for the data-driven city’ delivered within the Department of Urbanism at the Delft University of Technology. By endorsing a definition of data as a sociotechnical process, of ethics as a collective practice, and of the city as a complex system, the course enacts a transdisciplinary approach and problem-opening method that compel students to recognize and tackle the unavoidable multifacetedness of all ethical stances, as well as the intrinsic open-endedness of all tech solutions, thus seeking a fair balance for the whole data-driven urban environment. The article discusses the results of the teaching experience, which took the form of a research-and-design workshop, alongside the students’ feedback and further pedagogical developments. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241270687",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Stefano Calzati",
        "Hendrik Ploeger"
      ],
      "url": "https://doi.org/10.1177/20539517241270687",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 79,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9363e098-b48d-40f4-b1ba-8625081ae752",
    "title": "Between technical features and analytic capabilities: Charting a relational affordance space for digital social analytics",
    "abstract": "<jats:p> Digital social analytics is a subset of Big Data methods that is used to understand the social environment in which people and organizations have to act. This paper presents an analysis of eight projects that are experimenting with the use of these methods for various purposes. It shows that two specific technological features influence the work with such methods in all the cases. The first concerns the need to distribute choices about the structure of data to third-party actors and the second concerns the need to balance machine intelligence and human intuition when automating the analysis. These features set specific conditions for knowledge production, and the paper identifies two opposite approaches for engaging with each of these conditions. These features and approaches are finally combined into a two-dimensional affordance space that illustrates how there is flexibility in the way project leaders interact with the features of the data environment. It thereby also shows how digital social analytics come to have different affordances for different projects. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714568727",
      "type": "journal-article",
      "published": [
        2015,
        5,
        1
      ],
      "authors": [
        "Anders Koed Madsen"
      ],
      "url": "https://doi.org/10.1177/2053951714568727",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 31,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "794fc500-3704-4e38-9fff-130beda8c1d6",
    "title": "For a heterodox computational social science",
    "abstract": "<jats:p> The proliferation of digital data has been the impetus for the emergence of a new discipline for the study of social life: ‘computational social science’. Much research in this field is founded on the premise that society is a complex system with emergent structures that can be modeled or reconstructed through digital data. This paper suggests that computational social science serves practical and legitimizing functions for digital capitalism in much the same way that neoclassical economics does for neoliberalism. In recognition of this homology, this paper develops a critique of the complexity perspective of computational social science and argues for a heterodox computational social science founded on the meta-theory of critical realism that is critical, methodological pluralist, interpretative and explanative. This implies diverting computational social science’ computational methods and digital data so as to not be aimed at identifying invariant laws of social life, or optimizing state and corporate practices, but to instead be used as part of broader research strategies to identify contingent patterns, develop conjunctural explanations, and propose qualitatively different ways of organizing social life. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211047725",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Petter Törnberg",
        "Justus Uitermark"
      ],
      "url": "https://doi.org/10.1177/20539517211047725",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 128,
      "is_referenced_by_count": 21,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "66ef1a34-cb0a-458f-9161-ed16cad76fa3",
    "title": "A feeling for the algorithm: Diversity, expertise, and artificial intelligence",
    "abstract": "<jats:p> Diversity is often announced as a solution to ethical problems in artificial intelligence (AI), but what exactly is meant by diversity and how it can solve those problems is seldom spelled out. This lack of clarity is one hurdle to motivating diversity in AI. Another hurdle is that while the most common perceptions about what diversity is are too weak to do the work set out for them, stronger notions of diversity are often defended on normative grounds that fail to connect to the values that are important to decision-makers in AI. However, there is a long history of research in feminist philosophy of science and a recent body of work in social epistemology that taken together provide the foundation for a notion of diversity that is both strong enough to do the work demanded of it, and can be defended on epistemic grounds that connect with the values that are important to decision-makers in AI. We clarify and defend that notion here by introducing emergent expertise as a network phenomenon wherein groups of workers with expertise of different types can gain knowledge not available to any individual alone, as long as they have ways of communicating across types of expertise. We illustrate the connected epistemic and ethical benefits of designing technology with diverse groups of workers using the examples of an infamous racist soap dispenser, and the millimeter wave scanners used in US airport security. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231224247",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Catherine Stinson",
        "Sofie Vlaad"
      ],
      "url": "https://doi.org/10.1177/20539517231224247",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 71,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "87ca73cc-baff-4471-8cc3-9b6ee7be6658",
    "title": "Data as environment, environment as data: One Health in collaborative data-intensive science",
    "abstract": "<jats:p> This article analyses the operationalization of One Health in the context of data-intensive science in response to the COVID-19 outbreak. Building on ethnographic field research and revisiting the lives of a knowledge infrastructure of interdisciplinary collaboration set up online in the early phase of the COVID-19 health emergency, the article develops the notion of “data as environment.” This environment is a contact structure that entangles knowledge systems, subjects, processing tools, and mediated bio-socialities in processes of data-intensive knowledge co-production. Claims for new collaborative approaches between the biomedical, environmental, and social sciences are increasingly marked by the emergence of digital knowledge-making infrastructure that leverages data, knowledge, and expertise from different disciplines and sectors to increase scientific productivity via data-sharing technologies. Yet, digital knowledge-making infrastructures appear self-evident when they are in place, while data are often conceived as inert and disembodied information units separated from social relations of research. The argument that data are an environment expands anthropological thinking on data and digital knowledge-making infrastructures by enlightening political-ethical questions that are at stake in the emerging technoscientific worlds of the Anthropocene. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241234275",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Lucilla Barchetta",
        "Roberta Raffaetà"
      ],
      "url": "https://doi.org/10.1177/20539517241234275",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 52,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "06e51935-73d8-4961-a754-c4573911187b",
    "title": "How pro- and anti-abortion activists  use encrypted messaging apps in  post-<i>Roe</i> America",
    "abstract": "<jats:p> In a post- Roe America, abortion-rights activists are scrambling to protect reproductive rights. Communication on open social media platforms like Facebook can now be used to prosecute those seeking an illegal abortion in a frightening entanglement of technology corporations and the state. Building on surveillance studies and feminist scholarship, we analyze 22 interviews with pro- and anti-abortion activists and pro-encryption activists to answer: How will encrypted messaging apps be relevant for pro- and anti-abortion activists post- Roe? We find that while encrypted messaging apps are used by activists on either side of the abortion debate, their motivations for use range from mere convenience to supplanting state and corporate surveillance. We thus argue that encryption can act as a feminist tool to usurp patriarchal surveillance but must be used in combination with a holistic privacy framework. This framework may include care-motivated, community-centered, relational surveillance. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231221736",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Zelly C Martin",
        "Martin Johannes Riedl",
        "Samuel C Woolley"
      ],
      "url": "https://doi.org/10.1177/20539517231221736",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 92,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7c5ab15b-7d4a-4ea7-8bb2-b44efa9fdaea",
    "title": "Because the machine can discriminate: How machine learning serves and transforms biological explanations of human difference",
    "abstract": "<jats:p> Research on scientific/intellectual movements, and social movements generally, tends to focus on resources and conditions outside the substance of the movements, such as funding and publication opportunities or the prestige and networks of movement actors. Drawing on Pinch’s theory of technologies as institutions, I argue that research methods can also serve as resources for scientific movements by institutionalizing their ideas in research practice. I demonstrate the argument with the case of neuroscience, where the adoption of machine learning changed how scientists think about measurement and modeling of group difference. This provided an opportunity for members of the sex difference movement by offering a ‘truly categorical’ quantitative methodology that aligned more closely with their understanding of male and female brains and bodies as categorically distinct. The result was a flurry of publications and symbiotic relationships with other researchers that rescued a scientific movement which had been growing increasingly untenable under the prior methodological regime of univariate, frequentist analyses. I call for increased sociological attention to the inner workings of technologies that we typically black box in light of their potential consequences for the social world. I also suggest that machine learning in particular might have wide-reaching implications for how we conceive of human groups beyond sex, including race, sexuality, criminality, and political position, where scientists are just beginning to adopt its methods. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231155060",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Jeffrey W. Lockhart"
      ],
      "url": "https://doi.org/10.1177/20539517231155060",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 80,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "47773eda-8fe3-4863-a10f-f52c95c7da21",
    "title": "Corrigendum to Computational challenges to test and revitalize Claude Lévi-Strauss transformational methodology",
    "abstract": "",
    "metadata": {
      "doi": "10.1177/20539517211054314",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [],
      "url": "https://doi.org/10.1177/20539517211054314",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "not available"
    }
  },
  {
    "id": "3a8ff1a9-914a-49c9-8762-03c9a5f8eb16",
    "title": "Learning machine learning: On the political economy of big tech's online AI courses",
    "abstract": "<jats:p> Machine learning (ML) algorithms are still a novel research object in the field of media studies. While existing research focuses on concrete software on the one hand and the socio-economic context of the development and use of these systems on the other, this paper studies online ML courses as a research object that has received little attention so far. By pursuing a walkthrough and critical discourse analysis of Google's Machine Learning Crash Course and IBM's introductory course to Machine Learning with Python, we not only shed light on the technical knowledge, assumptions, and dominant infrastructures of ML as a field of practice, but also on the economic interests of the companies providing the courses. We demonstrate how the online courses further support Google and IBM to consolidate and even expand their position of power by recruiting new AI talent and by securing their infrastructures and models to become the dominant ones. Further, we show how the companies not only influence greatly how ML is represented, but also how these representations in turn influence and direct current ML research and development, as well as the societal effects of their products. Here, they boast an image of fair and democratic artificial intelligence, which stands in stark contrast to the ubiquity of their corporate products and the advertised directives of efficiency and performativity the companies strive for. This underlines the need for alternative infrastructures and perspectives. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231153806",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Inga Luchs",
        "Clemens Apprich",
        "Marcel Broersma"
      ],
      "url": "https://doi.org/10.1177/20539517231153806",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 76,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6d2e0726-686f-465e-bb43-f8d0623e76f6",
    "title": "Dashboard design and the ‘datafied’ driving experience",
    "abstract": "<jats:p> In this article, I consider how the redesign of vehicle dashboards has restructured car-related data processes. I do so by charting the emergence of two such processes enabled by the redesign of vehicle dashboards: firstly, the transformation of ‘geodata’ into ‘navigational data’ with the integration of voice-activated navigation systems into vehicle dashboards, and secondly, the transformation of ‘vehicle data’ into ‘driving data’ in the convergence, and customization, of dashboard features and functionality. Both transformations are enabled through strategic design decisions, persuading drivers to participate in novel practices they might otherwise not. Firstly, in that voice-activation is depicted as a seamless, unmediated interface between the normal, natural speech of a driver, and the vehicle itself. Secondly, through the strategy of control, the driver is persuaded to believe they have full(er) customizable power within, and of, the vehicle. The systems discussed here – a voice-activated navigation system built on the What3words platform, and a ‘widescreen’ dashboard in a range of Mercedes-Benz vehicles – are representative of broader efforts within the automotive industry to cultivate a newly ‘datafied’ driving experience. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211049862",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Sam Hind"
      ],
      "url": "https://doi.org/10.1177/20539517211049862",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 92,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1e1c1c40-e052-4f8e-8809-52a9f1295fac",
    "title": "Epistemologies of predictive policing: Mathematical social science, social physics and machine learning",
    "abstract": "<jats:p> Predictive policing has become a new panacea for crime prevention. However, we still know too little about the performance of computational methods in the context of predictive policing. The paper provides a detailed analysis of existing approaches to algorithmic crime forecasting. First, it is explained how predictive policing makes use of predictive models to generate crime forecasts. Afterwards, three epistemologies of predictive policing are distinguished: mathematical social science, social physics and machine learning. Finally, it is shown that these epistemologies have significant implications for the constitution of predictive knowledge in terms of its genesis, scope, intelligibility and accessibility. It is the different ways future crimes are rendered knowledgeable in order to act upon them that reaffirm or reconfigure the status of criminological knowledge within the criminal justice system, direct the attention of law enforcement agencies to particular types of crimes and criminals and blank out others, satisfy the claim for the meaningfulness of predictions or break with it and allow professionals to understand the algorithmic systems they shall rely on or turn them into a black box. By distinguishing epistemologies and analysing their implications, this analysis provides insight into the techno-scientific foundations of predictive policing and enables us to critically engage with the socio-technical practices of algorithmic crime forecasting. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211003118",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Jens Hälterlein"
      ],
      "url": "https://doi.org/10.1177/20539517211003118",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 86,
      "is_referenced_by_count": 19,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a0c685d1-d20e-48f8-b587-8551b82cbab6",
    "title": "Outlier bias: AI classification of curb ramps, outliers, and context",
    "abstract": "<jats:p> Technologies in the smart city, such as autonomous vehicles and delivery robots, promise to increase the mobility and freedom of people with disabilities. These technologies have also failed to “see” or comprehend wheelchair riders, people walking with service animals, and people walking with bicycles—all outliers to machine learning models. Big data and algorithms have been amply critiqued for their biases—harmful and systematic errors—but the harms that arise from AI's inherent inability to handle nuance, context, and exception have been largely overlooked. In this paper, I run two machine learning models across nine cities in the United States to attempt to fill a gap in data about the location of curb ramps. I find that while curb ramp prediction models may achieve up to 88% accuracy, the rate of accuracy varied in context in ways both predictable and unpredictable. I look closely at cases of unpredictable error (outlier bias), by triangulating with aerial and street view imagery. The sampling of cases shows that while it may be possible to conjecture about patterns in these errors, there is nothing clearly systematic. While more data and bigger models might improve the accuracy somewhat, I propose that a bias toward outliers is something fundamental to machine learning models which gravitate to the mean and require unbiased and not missing data. I conclude by arguing that universal design or design for the outliers is imperative for justice in the smart city where algorithms and data are increasingly embedded as infrastructure. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231203669",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Shiloh Deitz"
      ],
      "url": "https://doi.org/10.1177/20539517231203669",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 78,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a6fa6019-f20a-46e6-b9cc-02112c7c223e",
    "title": "Communicative strategies for building public confidence in data governance: Analyzing Singapore's COVID-19 contact-tracing initiatives",
    "abstract": "<jats:p> Effective social data governance rests on a bedrock of social support. Without securing trust from the populace whose information is being collected, analyzed, and deployed, policies on which such data are based will be undermined by a lack of public confidence. The COVID-19 pandemic has accelerated digitalization and datafication by governments for the purposes of contact tracing and epidemiological investigation. However, concerns about surveillance and data privacy have stunted the adoption of such contact-tracing initiatives. This commentary analyzes Singapore's contact-tracing initiative to uncover the reasons for public resistance and efforts by the state to address them. The government's contact-tracing program encompassing its proprietary TraceTogether app and physical token initially triggered vociferous public criticisms of Big Brother style surveillance. Using a dialogic communication framework, we analyze the TraceTogether initiative to interrogate the communicative strategies that were used to overcome public resistance. We argue that these strategies reflect a top-down approach that prioritizes transactional dissemination of information, in line with Singapore's technocratic stance toward governance. We further assert that such communicative tactics represent missed opportunities to foster public confidence in social data governance through greater trust building. We propose solutions for more dialogic communicative forms that build trust, so that officials can develop a sound understanding of the public concerns, increase the level of public engagement, and incorporate public feedback into policies that govern data use. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221104086",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Gordon Kuo Siong Tan",
        "Sun Sun Lim"
      ],
      "url": "https://doi.org/10.1177/20539517221104086",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 23,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "24b1f3a0-681b-4596-bf0c-69fdbf9178cf",
    "title": "Big Data and historical social science",
    "abstract": "<jats:p> “Big Data” can revolutionize historical social science if it arises from substantively important contexts and is oriented towards answering substantively important questions. Such data may be especially important for answering previously largely intractable questions about the timing and sequencing of events, and of event boundaries. That said, “Big Data” makes no difference for social scientists and historians whose accounts rest on narrative sentences. Since such accounts are the norm, the effects of Big Data on the practice of historical social science may be more limited than one might wish. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715612497",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Peter Bearman"
      ],
      "url": "https://doi.org/10.1177/2053951715612497",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 17,
      "is_referenced_by_count": 17,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1c462362-92cd-47eb-83dd-974bcf5c3329",
    "title": "Datafied knowledge production: Introduction to the special theme",
    "abstract": "<jats:p>Framing datafication as new form of knowledge production has become a trope in both academic and commercial contexts. This special theme examines and ultimately rejects the familiar grand claims of datafication, to instead pay attention to emergent conversations that seek to take a more nuanced stock of the status and nature of datafied knowledge production. The articles in this special theme thus engage with datafied knowledge production through elaborate explorations of how datafied knowledge depends on the contexts of its production and the forms of knowledge production that precede it in those contexts. Our basic argument is that while the resources, material features and analytical operations involved in datafied knowledge production may be different, many fundamental concerns about epistemology, ontology and methods remain relevant to understand what shapes it. We still need to understand and explicate the assumptions, operations and consequences of emergent forms of knowledge production. If datafied knowledge production is neither a clean revolutionary break with past forms of knowledge production nor a balloon of pure hype, the articles in this special theme ask: what does the phenomenon of datafied knowledge production look like? Which digital and datafied infrastructures support its future development? And what potentialities and limits do such forms of analysis and knowledge production contain?</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719875985",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Nanna Bonde Thylstrup",
        "Mikkel Flyverbom",
        "Rasmus Helles"
      ],
      "url": "https://doi.org/10.1177/2053951719875985",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171987598",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 20,
      "is_referenced_by_count": 17,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5a1da502-4ca3-45a8-9782-74dff1ff19d1",
    "title": "Corrigendum to Heritage  transformations",
    "abstract": "",
    "metadata": {
      "doi": "10.1177/20539517211048764",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [],
      "url": "https://doi.org/10.1177/20539517211048764",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "not available"
    }
  },
  {
    "id": "eb7b31e2-adea-4e4a-a51d-2c09312f8bdf",
    "title": "Automated informed consent",
    "abstract": "<jats:p> Online privacy policies or terms and conditions ideally provide users with information about how their personal data are being used. The reality is that very few users read them: they are long, often hard to understand, and ubiquitous. The average internet user cannot realistically read and understand all aspects that apply to them and thus give informed consent to the companies who use their personal data. In this article, we provide a basic overview of a solution to the problem. We suggest that software could allow users to delegate the consent process and consent could thus be automated. The article investigates the practical feasibility of this idea. After suggesting that it is feasible, we develop some normative issues that we believe should be addressed before automated consent is implemented. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241289439",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Adam John Andreotta",
        "Björn Lundgren"
      ],
      "url": "https://doi.org/10.1177/20539517241289439",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 37,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a0d5e2d9-9127-48e0-bac2-f5311940a973",
    "title": "Soft skills and hard numbers: Gender discourse in human resources",
    "abstract": "<jats:p> The cultural rise of “big data” in the recent years has pressured a number of occupations to make an epistemological shift toward data-driven science. Though expressed as a professional move, this article argues that the push incorporates gendered assumptions that disadvantage women. Using the human resource occupation as an example, I demonstrate how normative perceptions of feminine “soft skills” are seen as irreconcilable with the masculine “hard numbers” of a data-driven epistemology. The history of human resources reflects how assumptions of a biological fit with an occupation limit what women can convincingly describe as her skillsets. However, challenging this cannot stay within the confines of the occupation itself. To undo sexist thinking, it is necessary to understand the broader networks of patriarchal power that dictate how value is defined in corporate environments, especially within other high status professions in business. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716674237",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Renyi Hong"
      ],
      "url": "https://doi.org/10.1177/2053951716674237",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 77,
      "is_referenced_by_count": 22,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bcc52924-af16-454d-b818-6a75a859e433",
    "title": "Constructing global data: Automated techniques in ecological monitoring, precaution and reification of risk",
    "abstract": "<jats:p> Automatic aggregation of large-scale data is increasingly conceived as central in the production of ecological knowledge. This article examines the implications of the employment of automation techniques and ‘data-driven analysis’ in long-term biodiversity monitoring. What are the pathways and paradoxes in the possible public acceptance of automated data-sets as a trustworthy source for use in global protection and regulation of biodiversity? This article suggests that the precautionary discourse aid topdown measures for the public acceptability of the use of such techniques. Automated biodiversity monitoring offers distinctive advantages to further precautionary goals in terms of a faster, cost-effective and less messy way of collecting data, at a large scale over long periods of time. However, it contradicts other values implied through precaution – for instance the opacity and reification of the construction of risk. How do the specific forms of data-making relate with specific forms of risk governance, and what implications does this have for helping us to understand appropriate ways of political representation in governance? Can paradoxes attendant to introducing a form of construction of data help understand the nature of the exercise of governmental power? </jats:p><jats:sec><jats:title/><jats:p> [Box: see text] </jats:p></jats:sec>",
    "metadata": {
      "doi": "10.1177/2053951718779407",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Naveen Thayyil"
      ],
      "url": "https://doi.org/10.1177/2053951718779407",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 55,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1b5eda07-aebc-468d-9a82-b16e5e02e2bd",
    "title": "Artificial intelligence and personalization of insurance: Failure or delayed ignition?",
    "abstract": "<jats:p> In insurance, there is still a significant gap between the anticipated disruption, due to big data and machine learning algorithms, and the actual implementation of behaviour-based personalization, as described by Meyers (2018). Here, we identify eight key factors that serve as fundamental obstacles to the radical transformation of insurance guarantees, aiming to closely align them with the risk profile of each policyholder. These obstacles include the collective nature of insurance, the entrenched beliefs of some insurance companies, challenges related to data collection and use for personalized pricing, limited interest from insurers in adopting new models as well as policyholders’ reluctance towards embracing connected devices. Additionally, the hurdles of explainability, insurer inertia and ethical or societal considerations further complicate the path toward achieving highly individualized insurance pricing. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241291817",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Arthur Charpentier",
        "Xavier Vamparys"
      ],
      "url": "https://doi.org/10.1177/20539517241291817",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 62,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "78574c0d-5782-4d61-8914-5c03b5447444",
    "title": "Developing a feeling for error: Practices of monitoring and modelling air pollution data",
    "abstract": "<jats:p> This paper is based on ethnographic research of data practices in a public health project called Weather Health and Air Pollution. (All names are pseudonyms.) I examine two different kinds of practices that make air pollution data, focusing on how they relate to particular modes of sensing and articulating air pollution. I begin by describing the interstitial spaces involved in making measurements of air pollution at monitoring sites and in the running of a computer simulation. Specifically, I attend to a shared dimension of these practices, the checking of a numerical reading for error. Checking a measurement for error is routine practice and a fundamental component of making data, yet these are also moments of interpretation, where the form and meaning of numbers are ambiguous. Through two case studies of modelling and monitoring data practices, I show that making a ‘good’ (error free) measurement requires developing a feeling for the instrument–air pollution interaction in terms of the intended functionality of the measurements made. These affective dimensions of practice are useful analytically, making explicit the interaction of standardised ways of knowing and embodied skill in stabilising data. I suggest that environmental data practices can be studied through researchers’ materialisation of error, which complicate normative accounts of Big Data and highlight the non-linear and entangled relations that are at work in the making of stable, accurate data. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716658061",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Emma Garnett"
      ],
      "url": "https://doi.org/10.1177/2053951716658061",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 45,
      "is_referenced_by_count": 23,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "43799a44-c7b6-4145-8fad-110f8d547a22",
    "title": "Analysing discourse around COVID-19 in the Australian Twittersphere: A real-time corpus-based analysis",
    "abstract": "<jats:p> Public discourse about the COVID-19 that appears on Twitter and other social media platforms provides useful insights into public concerns and responses to the pandemic. However, acknowledging that public discourse around COVID-19 is multi-faceted and evolves over time poses both analytical and ontological challenges. Studies that use text-mining approaches to analyse responses to major events commonly treat public discourse on social media as an undifferentiated whole, without systematically examining the extent to which that discourse consists of distinct sub-discourses or which phases characterize its development. They also confound structured behavioural data (i.e., tagging) with unstructured user-generated data (i.e., content of tweets) in their sampling methods. The present study aims to demonstrate how one might go about addressing both of these sets of challenges by combining corpus linguistic methods with a data-driven text-mining approach to gain a better understanding of how the public discourse around COVID-19 developed over time and what topics combine to form this discourse in the Australian Twittersphere over a period of nearly four months. By combining text mining and corpus linguistics, this study exemplifies how both approaches can complement each other productively. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211021437",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Martin Schweinberger",
        "Michael Haugh",
        "Sam Hames"
      ],
      "url": "https://doi.org/10.1177/20539517211021437",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 41,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bc50fea5-6540-4b5e-a780-0e6e5f1410c9",
    "title": "Governing teachers through datafication: Physical–virtual hybridity and language interoperability in teacher accountability",
    "abstract": "<jats:p> In this paper, we draw on Foucault's and Deleuze's theorisations of discipline and control, respectively, to understand a teacher accountability system in the US state of Texas: the Texas Teacher Evaluation and Support System (hereafter, T-TESS). Specifically, we focus on the interplay of physical and virtual modes of governance – which we develop here as physical– virtual hybridity – and the techniques that make these physical and virtual domains compatible via language interoperability, with T-TESS deployed as a representative empirical case to show how such technologies work to govern teacher subjectivity. First, in-person appraiser meetings and observations re-code teachers’ linguistic behaviours, so their physical bodies and practices can become legible to and interoperable with the hybrid T-TESS system. This avoids any possible syntax errors between the linguistic expression of physical teacher speech and the digital coding language of T-TESS. Second, these digital bodies of data can now be viewed as proxies for the physical teacher body in the classroom, allowing the constant modulation in physical space (teacher bodies) and digital space (bodies of data). This is the physical–virtual hybridity of T-TESS, whereby discipline and control work symbiotically to govern both the physical and the digital expressions of teachers and their teaching. In this way, the disciplining of teachers’ language has profound effects on teachers’ bodies, both corporeal and digital. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221137553",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Jessica Holloway",
        "Steven Lewis"
      ],
      "url": "https://doi.org/10.1177/20539517221137553",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 57,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9a678200-f637-48b9-8040-284f4609cc19",
    "title": "Digitalisation, democracy and the GDPR: The efforts of DPAs to defend democratic principles despite the limitations of the GDPR",
    "abstract": "<jats:p> This article discusses the perspectives of European Union (EU) / European Economic Area Data Protection Authorities (DPAs) on their role in protecting democratic rights and freedoms in digitalised societies. Data Protection Authorities, which are independent regulators, are responsible for implementing the EU's General Data Protection Regulation in their respective countries. The views of DPAs are important given their special role in monitoring newly emerging digital technologies and how their use may impact on the functioning of democracies. The article highlights three key themes which emerged in interviews with 18 DPAs in answer to the question about what they consider to be the greatest challenges to democratic freedoms. These are: (1) threats to elections due to the manipulation of voters; (2) discriminatory effects of automated decision-making; and (3) broader chilling effects on democratic norms due to ubiquitous surveillance. The article then analyses the solutions named by DPAs to mitigate these challenges to identify their governing, or political, rationalities. The paper finds that the solutions available to DPAs to manage democratic harms tend to emphasise individual over collective responsibility and are connected to broader currents of neoliberal governance. The paper highlights the ways in which some DPAs act as important critical voices within their respective jurisdictions to draw political attention to potentially anti-democratic effects of certain practices, such as profiling, or to the model of digitalisation as it is currently constructed. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241291815",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Michaela Padden",
        "Andreas Öjehag-Pettersson"
      ],
      "url": "https://doi.org/10.1177/20539517241291815",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fb384cb6-9b09-4546-ab30-02f7fd40c3eb",
    "title": "Erratum to The Thick Machine: Anthropological AI between explanation and explication",
    "abstract": "",
    "metadata": {
      "doi": "10.1177/20539517221126334",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [],
      "url": "https://doi.org/10.1177/20539517221126334",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "not available"
    }
  },
  {
    "id": "d59152b5-9c47-44de-8707-b8d0eaf7141d",
    "title": "Reparations of the horse? Algorithmic reparation and overspecialized remedies",
    "abstract": "<jats:p> In his seminal article, “Cyberspace and the Law of the Horse,” Frank Easterbrook criticized the scholarly trend of developing overspecialized legal approaches to emerging technologies. Easterbrook argued that these approaches are confusing, shallow, and superfluous. Algorithmic reparation has emerged as a framework for addressing algorithmic systems’ role in inequity and injustice. One understanding of algorithmic reparation is as a method for repairing algorithmic harms. This article examines how this understanding fares against the “law of the horse” critique by posing two questions. First, is algorithmic reparation overspecialized in its methods? Second, is algorithmic reparation overspecialized in the harm it targets? If its methods are too particularized, then algorithmic reparation will only work within a narrow range of circumstances and may undercut a more robust conception of remedies for algorithmic injustice. If the harm it targets is too particularized, then algorithmic reparation will result in incomplete or misguided redress of harms. We determine that algorithmic reparation is not too specific in its methods by demonstrating how–under algorithmic reparation principles–existing methods for reparations can be applied to address algorithmic harm. We also determine that algorithmic reparation can sometimes be too narrow in the harm it targets, which can reduce its effectiveness. When an algorithmic system is both necessary and sufficient for a harm to occur, algorithmic reparation is an effective method of redress. But when an algorithmic system is not necessary and sufficient for a given harm, algorithmic reparation may be incomplete, only temporarily effective, or miss the mark entirely. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241270670",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Colin Doyle",
        "Melissa Alvarez-Garcia",
        "Pelle Tracey",
        "Gabriel Grill",
        "Cedric Whitney",
        "Lauren M Chambers"
      ],
      "url": "https://doi.org/10.1177/20539517241270670",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 45,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "91e0dfc8-a2db-439a-9d9e-5fa7484e0fe4",
    "title": "Accounting for the social: Investigating commensuration and Big Data practices at Facebook",
    "abstract": "<jats:p> This study explores Big Data practices at Facebook through an investigation of the role of commensuration or ‘the transformation of different qualities into a common metric’ in the structuration of analysis and interaction with a major online social media platform. It proposes a conceptual framework and demonstrates the empirical potential of a pragmatic approach based on reading published materials and available documentation. Facebook’s Data Warehousing and Analytics Infrastructure serves as an illustrative example to begin tracing out and describe data assemblages in more detail. In being attentive to the motivations, drivers and challenges engineers face when dealing with Big Data, it is argued that their solutions can enable and support but also constrain specific analytical and transactional capabilities or data flows between various devices and actors. The analysis thus moves beyond methodological critiques of the utility of Big Data that lack empirical support and specificity. It is further argued that analytics not just describe but also actively participate in the enactment of social worlds, thereby opening possibilities for new markets or market segments to arise. Online sociality accounts for a model of the social that makes it visible and measurable qua markets inviting data recontextualisation and the creation of value along multiple axes. Contra Facebook’s claim to make the web more ‘social’, an investigation of commensuration brings to the fore the question how the social is accounted for in the first place. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716631365",
      "type": "journal-article",
      "published": [
        2016,
        6,
        1
      ],
      "authors": [
        "Fernando N van der Vlist"
      ],
      "url": "https://doi.org/10.1177/2053951716631365",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 126,
      "is_referenced_by_count": 18,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f3c20a5e-8d94-4c16-abad-ddeb5c50805b",
    "title": "Conceptual frameworks for social and cultural Big Data analytics: Answering the epistemological challenge",
    "abstract": "<jats:p> This paper aims to contribute to the development of tools to support an analysis of Big Data as manifestations of social processes and human behaviour. Such a task demands both an understanding of the epistemological challenge posed by the Big Data phenomenon and a critical assessment of the offers and promises coming from the area of Big Data analytics. This paper draws upon the critical social and data scientists’ view on Big Data as an epistemological challenge that stems not only from the sheer volume of digital data but, predominantly, from the proliferation of the narrow-technological and the positivist views on data. Adoption of the social-scientific epistemological stance presupposes that digital data was conceptualised as manifestations of the social. In order to answer the epistemological challenge, social scientists need to extend the repertoire of social scientific theories and conceptual frameworks that may inform the analysis of the social in the age of Big Data. However, an ‘epistemological revolution’ discourse on Big Data may hinder the integration of the social scientific knowledge into the Big Data analytics. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718823815",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Lucy Resnyansky"
      ],
      "url": "https://doi.org/10.1177/2053951718823815",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 101,
      "is_referenced_by_count": 22,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "928e77a8-9177-4ebe-92c1-ef1732eca126",
    "title": "State of urgency: Surveillance, power, and algorithms in France’s state of emergency",
    "abstract": "The recent terrorist attacks and ongoing state of emergency in France have brought questions of police surveillance into the public spotlight, making it increasingly important to understand how police attain data from citizens. Since 2005, the French police have been using IBM’s computer program, i2 Analyst’s Notebook, to aggregate information and craft criminal narratives. This technology serves to quickly connect suspects with crimes, looking for as many associations as possible, ranking and visualizing them based on level of importance. Recently, surveillance and state power have been theorized as having shifted to a posthegemonic, order. Drawing from literature on power, surveillance, and identity, this paper considers the various ways that algorithms can impact policing under a state of emergency by comparing the technical protocol of i2 Analyst’s Notebook with the administrative protocol of the French state. Using i2 Analyst’s Notebook as an example, this paper argues that posthegemonic theories of power have their place in determining how algorithms can be used for surveillance, but that they cannot completely explain their use under the state of emergency.",
    "metadata": {
      "doi": "10.1177/2053951717736338",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Kyle Kubler"
      ],
      "url": "https://doi.org/10.1177/2053951717736338",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171773633",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 17,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1b56df68-419b-4632-af79-6f8d0aec33d1",
    "title": "Big Data and central banks",
    "abstract": "<jats:p> This commentary recaps a Centre for Central Banking Studies event held at the Bank of England on 2–3 July 2014. The article covers three main points. First, it situates the Centre for Central Banking Studies event within the context of the Bank’s Strategic Plan and initiatives. Second, it summarises and reflects on major themes from the event. Third, the article links central banks’ emerging interest in Big Data approaches with their broader uptake by other economic agents. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715579469",
      "type": "journal-article",
      "published": [
        2015,
        5,
        1
      ],
      "authors": [
        "David Bholat"
      ],
      "url": "https://doi.org/10.1177/2053951715579469",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 25,
      "is_referenced_by_count": 24,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9f961f33-ab2e-4f17-9218-744ba9ba9481",
    "title": "Personalization and probabilities: Impersonal propensities in online grocery shopping",
    "abstract": "<jats:p> Accounts of big data practices often assume that they target individuals. Personalization, with all the risks of discrimination and bias it entails, has been the critical focus in accounts of consumption, government, social media, and health. This paper argues that personalization through models using large-scale data is part of a more expansive change in probabilization that, in principle, is not reducible to individual or ‘personal’ attributes and actions. It describes the ‘personalization’ of an online grocery shopping recommender system to list a small number of grocery items of personal relevance for each of the millions of online grocery shoppers at a major UK supermarket chain. Drawing on a theory of probability proposed by the philosopher of science Karl Popper and anthropological work on shopping, it suggests that the attempt to generate personalized predictions necessarily incorporates impersonal relations to others and things. Using a mixture of discourse analysis and code-based reconstruction of key elements of the recommender system, it suggests that personalization is one facet of an open-ended weave of propensities associated with people and things in contemporary big data configurations. The paper explores how, in the context of recommender systems, the constitutive incompleteness of shopping lists, their propensity to expand or change, might be more important than their capacity to be personalized. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718778310",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Adrian Mackenzie"
      ],
      "url": "https://doi.org/10.1177/2053951718778310",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 51,
      "is_referenced_by_count": 19,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e5ec3881-cead-4bea-8fa8-2be0455550e8",
    "title": "“More like a support tool”: Ambivalences around digital health from medical developers’ perspective",
    "abstract": "<jats:p> Against the background of the increasing importance of digitization in health care, the paper examines how medical practitioners who are involved in the development of digital health technologies legitimate and criticize the implementation and use of digital health technologies. Adopting an institutional logics perspective, the study is based on qualitative interviews with persons working at the interface of medicine and digital technologies development in Switzerland. The findings indicate that the developers believe that digital health technologies could harmonize current conflicts between an increasing economization of the health care system and professional–ethical demands. At the same time, however, they show that digital technologies can undermine the demand for medical autonomy, a central element of the medical ethos. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951721996733",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Sarah Lenz"
      ],
      "url": "https://doi.org/10.1177/2053951721996733",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 58,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5e0e2283-e49a-40f3-9f73-e6ccbd844dc1",
    "title": "For a situational analytics: An interpretative methodology for the study of situations in computational settings",
    "abstract": "<jats:p> This article introduces an interpretative approach to the analysis of situations in computational settings called situational analytics. I outline the theoretical and methodological underpinnings of this approach, which is still under development, and show how it can be used to surface situations from large data sets derived from online platforms such as YouTube. Situational analytics extends to computationally-mediated settings a qualitative methodology developed by Adele Clarke, Situational Analysis (2005), which uses data mapping to detect heterogeneous entities in fieldwork data to determine ‘what makes a difference’ in a situation. Situational analytics scales up this methodology to analyse situations latent in computational data sets with semi-automated methods of textual and visual analysis. I discuss how this approach deviates from recent analyses of situations in computational social science, and argue that Clarke’s framework renders tractable a fundamental methodological problem that arises in this area of research: while social researchers turn to computational settings in order to analyse social life, the social processes unfolding in these envirnoments are fundamentally affected by the computational architectures in which they occur. Situational analytics offers a way to address this problematic by making a heterogeneously composed situation – involving social, technical and media elements – the unit of computational analysis. To conclude, I show how situational analytics can be applied in a case study of YouTube videos featuring intelligent vehicles and discuss how situational analysis itself needs to be elaborated if we are to come to terms with computational transformations of the situational fabric of social life. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720949571",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Noortje Marres"
      ],
      "url": "https://doi.org/10.1177/2053951720949571",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 48,
      "is_referenced_by_count": 21,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "216b2d66-56b5-40d5-981c-13ad0ad7e625",
    "title": "Data artivism and feminicide",
    "abstract": "<jats:p>Data has become a key format for activists to visibilizar (make visible/call attention to) and denounce social issues. Drawing on the concept of “artivism,” we name as data artivism those works that visually intervene in the contestation around an issue by mobilizing art and craft as a form of resistance and as a method to visualize data. In this commentary, we share three examples of data artivism on the issue of feminicide. Our aim is to inspire the fields of critical data and data visualization studies to engage more deeply with art and find common language with artists, activists and advocacy groups (particularly those in Latin America), who are going beyond conventional visualization to reveal a range of alternative ways to mobilize data.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231215356",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Helena Suárez Val",
        "Catherine D'Ignazio",
        "Jimena Acosta Romero",
        "Melissa Q Teng",
        "Silvana Fumega"
      ],
      "url": "https://doi.org/10.1177/20539517231215356",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 33,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1f79add7-9850-46b8-908a-6a068fb01573",
    "title": "Can the obstacles to privacy self-management be overcome? Exploring the consent intermediary approach",
    "abstract": "In privacy self-management, people are expected to perform cost–benefit analysis on the use of their personal data, and only consent when their subjective benefits outweigh the costs. However, the ubiquitous collection of personal data and Big Data analytics present increasing challenges to successful privacy management. A number of services and research initiatives have proposed similar solutions to provide people with more control over their data by consolidating consent decisions under a single interface. We have named this the ‘consent intermediary’ approach. In this paper, we first identify the eight obstacles to privacy self-management which make cost–benefit analysis conceptually and practically challenging. We then analyse to which extent consent intermediaries can help overcome the obstacles. We argue that simply bringing consent decisions under one interface offers limited help, but that the potential of this approach lies in leveraging the intermediary position to provide aides for privacy management. We find that with suitable tools, some of the more practical obstacles indeed can become solvable, while others remain fundamentally insuperable within the individuated privacy self-management model. Attention should also be paid to how the consent intermediaries may take advantage of the power vested in the intermediary positions between users and other services.",
    "metadata": {
      "doi": "10.1177/2053951717721935",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Tuukka Lehtiniemi",
        "Yki Kortesniemi"
      ],
      "url": "https://doi.org/10.1177/2053951717721935",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171772193",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 27,
      "is_referenced_by_count": 23,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "26dd3ad0-c48d-40fa-9855-7568e28c64ce",
    "title": "Utopia of abstraction: Digital organizations and the promise of sovereignty",
    "abstract": "<jats:p> Digital organizations form part of the new wave of blockchain technologies, following Bitcoin and related cryptocurrencies. “Utopia of Abstraction” offers an analysis of the utopian promise of digital organizations through a reading of one such project, Colony. We provide a critique of the ideology of Colony's white paper, supplemented by readings of pages from its website, as a member of a genre of texts that promote their products through seemingly neutral, technical descriptions. Colony's texts suggest an abstract, contextless and scaleless organizational solution—powered by smart contracts on a blockchain—that, according to its proponents, might be applied to any social situation, from small firm to state-level governance. For its users, this organization combines a promise of sovereignty removed from that of the state, as well as implied financial returns. Our reading of Colony echoes the critiques of scholars arguing that cyberlibertarianism is a dominant politic of blockchain technologies. Furthermore, drawing on critiques of code as law and the elision of the social in smart contracts, we argue that Colony's vision presents a model of technical organization that substitutes for the state in the context of waning popular sovereignty. We ultimately suggest an understanding of digital organizations reminiscent of the settler colonial situation: the assumption of an empty social space to be filled, and the promise of sovereignty and riches for those occupying it. Analysis of these logics is relevant as hype increases around non-fungible tokens, Web3, and the corporate metaverse as well as data practices more widely. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221084587",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Tim Corballis",
        "Max Soar"
      ],
      "url": "https://doi.org/10.1177/20539517221084587",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bd68dca1-59d3-40a0-8f52-a2563667b02f",
    "title": "Perils of data-driven equity: Safety-net care and big data’s elusive grasp on health inequality",
    "abstract": "<jats:p>Large-scale data systems are increasingly envisioned as tools for justice, with big data analytics offering a key opportunity to advance health equity. Health systems face growing public pressure to collect data on patient “social factors,” and advocates and public officials seek to leverage such data sources as a means of system transformation. Despite the promise of this “data-driven” strategy, there is little empirical work that examines big data in action directly within the sites of care expected to transform. In this article, I present a case study on one such initiative, focusing on a large public safety-net health system’s initiation of sexual orientation and gender identity (SOGI) data collection within the clinical setting. Drawing from ethnographic fieldwork and in-depth interviews with providers, staff, and administrators, I highlight three main challenges that elude big data’s grasp on inequality: (1) provider and staff’s limited understanding of the social significance of data collection; (2) patient perception of the cultural insensitivity of data items; and (3) clinic need to balance data requests with competing priorities within a constrained time window. These issues reflect structural challenges within safety-net care that big data alone are unable to address in advancing social justice. I discuss these findings by considering the present data-driven strategy alongside two complementary courses of action: diversifying the health professions workforce and clinical education reform. To truly advance justice, we need more than “just data”: we need to confront the fundamental conditions of social inequality.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720928097",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Taylor M Cruz"
      ],
      "url": "https://doi.org/10.1177/2053951720928097",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172092809",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 22,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "31b718e7-a067-4bc7-b414-d9baa8b2f58c",
    "title": "Relational data paradigms: What do we learn by taking the materiality of databases seriously?",
    "abstract": "<jats:p> Although databases have been well-defined and thoroughly discussed in the computer science literature, the actual users of databases often have varying definitions and expectations of this essential computational infrastructure. Systems administrators and computer science textbooks may expect databases to be instantiated in a small number of technologies (e.g., relational or graph-based database management systems), but there are numerous examples of databases in non-conventional or unexpected technologies, such as spreadsheets or other assemblages of files linked through code. Consequently, we ask: How do the materialities of non-conventional databases differ from or align with the materialities of conventional relational systems? What properties of the database do the creators of these artifacts invoke in their rhetoric describing these systems—or in the data models underlying these digital objects? To answer these questions, we conducted a close analysis of four non-conventional scientific databases. By examining the materialities of information representation in each case, we show how scholarly communication regimes shape database materialities— and how information organization paradigms shape scholarly communication. These cases show abandonment of certain constraints of relational database construction alongside maintenance of some key relational data organization strategies. We discuss the implications that these relational data paradigms have for data use, preservation, and sharing, and discuss the need to support a plurality of data practices and paradigms. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720934838",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Andrea K Thomer",
        "Karen M Wickett"
      ],
      "url": "https://doi.org/10.1177/2053951720934838",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172093483",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 45,
      "is_referenced_by_count": 18,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c743c832-d417-419b-90c5-e6107f14a08b",
    "title": "Big Data: From modern fears to enlightened and vigilant embrace of new beginnings",
    "abstract": "<jats:p> In The Black Box Society, Frank Pasquale develops a critique of asymmetrical power: corporations’ secrecy is highly valued by legal orders, but persons’ privacy is continually invaded by these corporations. This response proceeds in three stages. I first highlight important contributions of The Black Box Society to our understanding of political and legal relationships between persons and corporations. I then critique a key metaphor in the book (the one-way mirror, Pasquale’s image of asymmetrical surveillance), and the role of transparency and ‘watchdogging’ in its primary policy prescriptions. I then propose ‘relational selfhood’ as an important new way of theorizing interdependence in an era of artificial intelligence and Big Data, and promoting optimal policies in these spheres. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720936708",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Nicole Dewandre"
      ],
      "url": "https://doi.org/10.1177/2053951720936708",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 14,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2f298a67-4cbd-42b7-8402-e39a9a64a922",
    "title": "Big data and Belmont: On the ethics and research implications of consumer-based datasets",
    "abstract": "<jats:p> Consumer-based datasets are the products of data brokerage firms that agglomerate millions of personal records on the adult US population. This big data commodity is purchased by both companies and individual clients for purposes such as marketing, risk prevention, and identity searches. The sheer magnitude and population coverage of available consumer-based datasets and the opacity of the business practices that create these datasets pose emergent ethical challenges within the computational social sciences that have begun to incorporate consumer-based datasets into empirical research. To directly engage with the core ethical debates around the use of consumer-based datasets within social science research, I first consider two case study applications of consumer-based dataset-based scholarship. I then focus on three primary ethical dilemmas within consumer-based datasets regarding human subject research, participant privacy, and informed consent in conversation with the principles of the seminal Belmont Report. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211048183",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Remy Stewart"
      ],
      "url": "https://doi.org/10.1177/20539517211048183",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 54,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b52ebe02-3201-4df9-9dc0-11252b6b6bf3",
    "title": "Why Personal Dreams Matter: How professionals affectively engage with the promises surrounding data-driven healthcare in Europe",
    "abstract": "<jats:p> Recent buzzes around big data, data science and artificial intelligence portray a data-driven future for healthcare. As a response, Europe's key players have stimulated the use of big data technologies to make healthcare more efficient and effective. Critical Data Studies and Science and Technology Studies have developed many concepts to reflect on such overly positive narratives and conduct critical policy evaluations. In this study, we argue that there is also much to be learned from studying how professionals in the healthcare field affectively engage with this strong European narrative in concrete big data projects. We followed twelve hospital-based big data pilots in eight European countries and interviewed 145 professionals (including legal, governance and ethical experts, healthcare staff and data scientists) between 2018 and 2020. In this study, we introduce the metaphor of dreams to describe how professionals link the big data promises to their own frustrations, ideas, values and experiences with healthcare. Our research answers the question: how do professionals in concrete data-driven initiatives affectively engage with European Union's data hopes in their ‘dreams’ – and with what consequences? We describe the dreams of being seen, of timeliness, of connectedness and of being in control. Each of these dreams emphasizes certain aspects of the grand narrative of big data in Europe, makes particular assumptions and has different consequences. We argue that including attention to these dreams in our work could help shine an additional critical light on the big data developments and stimulate the development of responsible data-driven healthcare. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211070698",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Marthe Stevens",
        "Rik Wehrens",
        "Johanna Kostenzer",
        "Anne Marie Weggelaar-Jansen",
        "Antoinette de Bont"
      ],
      "url": "https://doi.org/10.1177/20539517211070698",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 74,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "03130d42-d51f-4b79-bc0a-a8098cbfd0a9",
    "title": "Anthropographics in COVID-19 simulations",
    "abstract": "<jats:p> Data visualization researchers and designers have explored a range of approaches to ensure that non-expert audiences understand and derive value from their work. Using anthropomorphized data graphics—or anthropographics—is one strategy that can help create a connection between data and audiences. Anthropographics have been defined as “visualizations that represent data about people in a way that is intended to promote prosocial feelings (e.g. compassion or empathy) or prosocial behavior (e.g. donating or helping).” However, during the SARS-CoV-2 pandemic, anthropographics were used in data visualizations that had an expanded range of rhetorical goals beyond promoting prosocial feelings and behavior—for instance, informing people about the pandemic, persuading them to adopt certain behaviors, or memorializing those killed by the virus. In particular, anthropographics were used in visualized simulations to model possible futures for audiences, showing the spread and impact of the virus in various scenarios. These simulations used anthropomorphizing strategies in text as well as in graphics, along with interactive options that enabled audiences to explore personal connections with the data. As demonstrated through a close reading of several of these COVID-19 simulations, anthropographics can be viewed holistically as a design strategy that incorporates text and interactivity as well as graphical marks in representing data. Findings from this analysis suggest several additions to the design space for anthropographics. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221098414",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Madeleine Sorapure"
      ],
      "url": "https://doi.org/10.1177/20539517221098414",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 27,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e9408f26-421a-486b-bb6a-b19334d4486f",
    "title": "The unlikely encounter between von Foerster and Snowden: When second-order cybernetics sheds light on societal impacts of Big Data",
    "abstract": "<jats:p> Although information and communication technologies (ICT) have created hope for a shared pluralistic world, democratic principles are far from being respected in the public digital environment, and require a detailed knowledge of the laws by which they are governed. Von Foerster's conjecture is one of the early theoretical results that could help to understand these laws. Although neglected for a long time, the advent of the overlying layer of recommendation and ranking systems which is progressively occupying the web has given empirical evidences of this conjecture, which predicts the consequences of increasing inter-individual influences on social dynamics and the susceptibility of these latter to manipulation. With both von Foerster's conjecture and the Snowden revelations in the background, we analyse the impact of ICT on human societies and their governance, in view of the fact that they have a massive impact on the way in which people influence each other in their tastes and actions. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715621086",
      "type": "journal-article",
      "published": [
        2016,
        6,
        1
      ],
      "authors": [
        "David Chavalarias"
      ],
      "url": "https://doi.org/10.1177/2053951715621086",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 33,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b3334e9e-17d1-4070-944f-d0b37658ff43",
    "title": "Erratum to Taking a critical look at the critical turn in data science: From “data feminism” to transnational feminist data science",
    "abstract": "",
    "metadata": {
      "doi": "10.1177/20539517221118988",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [],
      "url": "https://doi.org/10.1177/20539517221118988",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "not available"
    }
  },
  {
    "id": "51a84709-1240-4125-8c72-3bf0c32382ea",
    "title": "‘The interface of the future’: Mixed reality, intimate data and imagined temporalities",
    "abstract": "<jats:p> This article examines discourses about mixed reality as a data-rich sensing technology – specifically, engaging with discourses of time as framed by developers, engineers and in corporate PR and marketing in a range of public facing materials. We focus on four main settings in which mixed reality is imagined to be used, and in which time was a dominant discursive theme – (1) the development of mixed reality by big tech companies, (2) the use of mixed reality for defence, (3) mixed reality as a technology for control of populations in civil society and (4) mixed reality as a technology used in workplace settings. Across these settings, the broad narrative is that mixed reality technologies afford overwhelmingly positive benefits like efficiency and security through their capture, relay and rendition of data (about the environment, about the body etc.) – affording a form of anticipatory power to the user. The framing of temporality, we argue, is underlain by social and political values, which represent certain interests, but leave others out in the imagination of mixed reality's technological advance. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211063689",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Ben Egliston",
        "Marcus Carter"
      ],
      "url": "https://doi.org/10.1177/20539517211063689",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 82,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "80041c33-3441-48b8-9a2e-9bfb84beb190",
    "title": "Big data for climate action or climate action for big data?",
    "abstract": "<jats:p> Under the banner of “data for good,” companies in the technology, finance, and retail sectors supply their proprietary datasets to development agencies, NGOs, and intergovernmental organizations to help solve an array of social problems. We focus on the activities and implications of the Data for Climate Action campaign, a set of public–private collaborations that wield user data to design innovative responses to the global climate crisis. Drawing on in-depth interviews, first-hand observations at “data for good” events, intergovernmental and international organizational reports, and media publicity, we evaluate the logic driving Data for Climate Action initiatives, examining the implications of applying commercial datasets and expertise to environmental problems. Despite the increasing adoption of Data for Climate Action paradigms in government and public sector efforts to address climate change, we argue Data for Climate Action is better seen as a strategy to legitimate extractive, profit-oriented data practices by companies than a means to achieve global goals for environmental sustainability. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720982032",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Maria I Espinoza",
        "Melissa Aronczyk"
      ],
      "url": "https://doi.org/10.1177/2053951720982032",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 55,
      "is_referenced_by_count": 27,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "adfb4e31-6928-4b03-819f-d1f0ec644c2f",
    "title": "Big Data and reality",
    "abstract": "<jats:p> DNA sequencers, Twitter, MRIs, Facebook, particle accelerators, Google Books, radio telescopes, Tumblr: what do these things have in common? According to the evangelists of “data science,” all of these are instruments for observing reality at unprecedentedly large scales and fine granularities. This perspective ignores the social reality of these very different technological systems, ignoring how they are made, how they work, and what they mean in favor of an exclusive focus on what they generate: Big Data. But no data, big or small, can be interpreted without an understanding of the process that generated them. Statistical data science is applicable to systems that have been designed as scientific instruments, but is likely to lead to confusion when applied to systems that have not. In those cases, a historical inquiry is preferable. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715608877",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Ryan Shaw"
      ],
      "url": "https://doi.org/10.1177/2053951715608877",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 15,
      "is_referenced_by_count": 19,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "25b24c8b-3a9f-4cb2-a973-b4d0f61c95e0",
    "title": "A chronology of tactics: Art tackles Big Data and the environment",
    "abstract": "<jats:p> Today data art is a full-fledged and maturing artistic practice. Like painting, artists are creating new visuals and representations with data. Like sculpture, artists are recombining bits to build something new out of the commonplace. Like photography, artists are using data to mirror or reflect contemporary society. In my own practice for the last 15 years I have been using data (both sourced and generated) to make works at the intersection of art, design and activism with a recent focus on environmental topics. It is my belief that through improved representation of, access to and public involvement with data we can increase understanding of important issues (such as environmental degradation) and provoke behavioural and systemic change. In this paper, I will examine the evolution of my work using data as my medium as well as outline tactics for data art to promote change. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716665869",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Brooke Singer"
      ],
      "url": "https://doi.org/10.1177/2053951716665869",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 23,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "388783a1-7a89-44aa-a46a-9d6d8bd4856c",
    "title": "Understanding the care.data conundrum: New information flows for economic growth",
    "abstract": "<jats:p> The analysis of data from electronic health records aspires to facilitate healthcare efficiencies and biomedical innovation. There are also ethical, legal and social implications from the handling of sensitive patient information. The paper explores the concerns, expectations and implications of the National Health Service (NHS) England care.data programme: a national data sharing initiative of linked electronic health records for healthcare and other research purposes. Using Nissenbaum’s contextual integrity of privacy framework through a critical Science and Technology Studies (STS) lens, it examines the way technologies and policies are developed to promote sustainability, governance and economic growth as the de facto social values, while reducing privacy to an individualistic preference. The state, acting as a new, central data broker reappropriates public ownership rights and establishes those information flows and transmission principles that facilitate the assetisation of NHS datasets for the knowledge economy. Various actors and processes from other contexts attempt to erode the public healthcare sector and privilege new information recipients. However, such data sharing initiatives in healthcare will be resisted if we continue to focus only on the monetary and scientific values of these datasets and keep ignoring their equally important social and ethical values. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716688490",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Paraskevas Vezyridis",
        "Stephen Timmons"
      ],
      "url": "https://doi.org/10.1177/2053951716688490",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 103,
      "is_referenced_by_count": 43,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4626b727-c29a-483a-b029-a25bb688586c",
    "title": "Personalization as a promise: Can Big Data change the practice of insurance?",
    "abstract": "<jats:p> The aim of this article is to assess the impact of Big Data technologies for insurance ratemaking, with a special focus on motor products.The first part shows how statistics and insurance mechanisms adopted the same aggregate viewpoint. It made visible regularities that were invisible at the individual level, further supporting the classificatory approach of insurance and the assumption that all members of a class are identical risks. The second part focuses on the reversal of perspective currently occurring in data analysis with predictive analytics, and how this conceptually contradicts the collective basis of insurance. The tremendous volume of data and the personalization promise through accurate individual prediction indeed deeply shakes the homogeneity hypothesis behind pooling. The third part attempts to assess the extent of this shift in motor insurance. Onboard devices that collect continuous driving behavioural data could import this new paradigm into these products. An examination of the current state of research on models with telematics data shows however that the epistemological leap, for now, has not happened. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720935143",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Laurence Barry",
        "Arthur Charpentier"
      ],
      "url": "https://doi.org/10.1177/2053951720935143",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172093514",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 53,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "01052718-6630-4586-889c-6768aa3cd331",
    "title": "Harvesting value: Corporate strategies of data assetization in agriculture and their socio-ecological implications",
    "abstract": "<jats:p> The global food system is characterized by market concentration and oligopoly. In our article, we focus on the most powerful input supply and machinery companies and analyze how these firms create value, both economic and otherwise, from big data. In digital capitalism, data is valorized across sectors; personal data is aggregated into large-scale datasets, a practice that feeds economic concentration and monopolization. Big data also has become central to the business model for agricultural companies; it is a claim made by the companies themselves. Yet, little is known about their specific strategies to do so. We aim to fill this gap, asking how is agricultural data transformed into value by the most powerful agribusinesses and ag-tech firms? </jats:p><jats:p> Through the lens of assetization, we examine corporate strategies for transforming agricultural data into value. We draw on literature from food studies, specifically political economic analyses of the historical practices of agricultural corporations, as well as literature from critical data studies that investigates data as an asset. For our analysis, we rely on a variety of gray literature and public-facing documents: financial documents, sustainability and shareholder reports, terms of use, license agreements, and news articles. Our results contribute to the critical data studies literature on agricultural big data by identifying three main strategies of assetization: securing relationships and dependence, price-setting and data sharing, and product development and targeted marketing. </jats:p><jats:p> The strategies have socio-ecological implications; our results indicate the reproduction of asymmetrical power relations in the agri-food system favoring corporations and the continuation of long-standing dynamics of inequalities. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241234279",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Sarah Hackfort",
        "Sarah Marquis",
        "Kelly Bronson"
      ],
      "url": "https://doi.org/10.1177/20539517241234279",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 81,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b0eef6a7-31fb-460d-9c88-61a6d297694d",
    "title": "Big Data ethics",
    "abstract": "<jats:p> The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714559253",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "Andrej Zwitter"
      ],
      "url": "https://doi.org/10.1177/2053951714559253",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 29,
      "is_referenced_by_count": 213,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9f9d0993-12f5-42fb-97a7-b5f8541446e8",
    "title": "AI Empire: Unraveling the interlocking systems of oppression in generative AI's global order",
    "abstract": "<jats:p>As artificial intelligence (AI) continues to captivate the collective imagination through the latest generation of generative AI models such as DALL-E and ChatGPT, the dehumanizing and harmful features of the technology industry that have plagued it since its inception only seem to deepen and intensify. Far from a “glitch” or unintentional error, these endemic issues are a function of the interlocking systems of oppression upon which AI is built. Using the analytical framework of “Empire,” this paper demonstrates that we live not simply in the “age of AI” but in the age of AI Empire. Specifically, we show that this networked and distributed global order is rooted in heteropatriarchy, racial capitalism, white supremacy, and coloniality and perpetuates its influence through the mechanisms of extractivism, automation, essentialism, surveillance, and containment. Therefore, we argue that any attempt at reforming AI from within the same interlocking oppressive systems that created it is doomed to failure and, moreover, risks exacerbating existing harm. Instead, to advance justice, we must radically transform not just the technology itself, but our ideas about it, and develop it from the bottom up, from the perspectives of those who stand the most risk of being harmed.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231219241",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Jasmina Tacheva",
        "Srividya Ramasubramanian"
      ],
      "url": "https://doi.org/10.1177/20539517231219241",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 115,
      "is_referenced_by_count": 27,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3be7372b-0ad0-4d09-9ee6-6c23c678065a",
    "title": "“AI will fix this” – The Technical, Discursive, and Political Turn to AI in Governing Communication",
    "abstract": "<jats:p> Technologies of “artificial intelligence” (AI) and machine learning (ML) are increasingly presented as solutions to key problems of our societies. Companies are developing, investing in, and deploying machine learning applications at scale in order to filter and organize content, mediate transactions, and make sense of massive sets of data. At the same time, social and legal expectations are ambiguous, and the technical challenges are substantial. </jats:p><jats:p> This is the introductory article to a special theme that addresses this turn to AI as a technical, discursive and political phenomena. The opening article contextualizes this theme by unfolding this multi-layered nature of the turn to AI. It argues that, whereas public and economic discourses position the widespread deployment of AI and automation in the governance of digital communication as a technical turn with a narrative of revolutionary breakthrough-moments and of technological progress, this development is at least similarly dependent on a parallel discursive and political turn to AI. The article positions the current turn to AI in the longstanding motif of the “technological fix” in the relationship between technology and society, and identifies a discursive turn to responsibility in platform governance as a key driver for AI and automation. In addition, a political turn to more demanding liability rules for platforms further incentivizes platforms to automatically screen their content for possibly infringing or violating content, and position AI as a solution to complex social problems. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211046182",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Christian Katzenbach"
      ],
      "url": "https://doi.org/10.1177/20539517211046182",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 46,
      "is_referenced_by_count": 29,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "adbdfb6c-6c9a-43de-929a-193e6dde11f3",
    "title": "The Nordic data imaginary",
    "abstract": "The Nordic countries aim to have a unique place within the European and global health data economy. They have extensive nationally maintained and centralized health data records, as well as numerous biobanks where data from individuals can be connected based on personal identification numbers. Much of this phenomenon can be attributed to the emergence and development of the Nordic welfare state, where Nordic countries sought to systematically collect large amounts of population data to guide decision making and improve the health and living conditions of the population. Recently, however, the so-called Nordic gold mine of data is being re-imagined in a wholly other context, where data and its ever-increasing logic of accumulation is seen as a driver for economic growth and private business development. This article explores the development of policies and strategies for health data economy in Denmark and Finland. We ask how nation states try to adjust and benefit from new pressures and opportunities to utilize their data resources in data markets. This raises questions of social sustainability in terms of states being producers, providers, and consumers of data. The data imaginaries related to emerging health data markets also provide insight into how a broad range of different data sources, ranging from hospital records and pharmacy prescriptions to biobank sample data, are brought together to enable “full-scale utilization” of health and welfare data.",
    "metadata": {
      "doi": "10.1177/2053951720907107",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Aaro Tupasela",
        "Karoliina Snell",
        "Heta Tarkkala"
      ],
      "url": "https://doi.org/10.1177/2053951720907107",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172090710",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 51,
      "is_referenced_by_count": 46,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3b7b5dff-8cd2-4807-a73e-d9d5ef0e8d93",
    "title": "Online Labour Index 2020: New ways to measure the world’s remote freelancing market",
    "abstract": "<jats:p> The Online Labour Index (OLI) was launched in 2016 to measure the global utilisation of online freelance work at scale. Five years after its creation, the OLI has become a point of reference for scholars and policy experts investigating the online gig economy. As the market for online freelancing work matures, a high volume of data and new analytical tools allow us to revisit half a decade of online freelance monitoring and extend the index's scope to more dimensions of the global online freelancing market. While (still) measuring the utilisation of online labour across countries and occupations by tracking the number of projects and tasks posted on major English-language platforms, the new Online Labour Index 2020 (OLI 2020) also tracks Spanish- and Russian-language platforms, reveals changes over time in the geography of labour supply and estimates female participation in the online gig economy. The rising popularity of software and tech work and the concentration of freelancers on the Indian subcontinent are examples of the insights that the OLI 2020 provides. The OLI 2020 delivers a more detailed picture of the world of online freelancing via an interactive online visualisation updated daily. It provides easy access to downloadable open data for policymakers, labour market researchers, and the general public ( www.onlinelabourobservatory.org ). </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211043240",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Fabian Stephany",
        "Otto Kässi",
        "Uma Rani",
        "Vili Lehdonvirta"
      ],
      "url": "https://doi.org/10.1177/20539517211043240",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 17,
      "is_referenced_by_count": 46,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f332dbbf-7733-42be-8660-f7cd18b27831",
    "title": "In search of the citizen in the datafication of public administration",
    "abstract": "<jats:p> The administrative reform of the datafied public administration places great emphasis on the classification, control, and prediction of citizen behavior and therefore has the potential to significantly impact citizen–state relations. There is a growing body of literature on data-oriented activism which aims to resist and counteract existing harmful data practices. However, little is known about the processes, policies, and political-economic structures that make datafication possible. There is a distinct research gap on situated and context-specific empirical research, which critically interrogates the premises, interests, and agendas of data-driven public administration and how stakeholders can impact them. This paper therefore studies the conditions of participation in public administration datafication. It asks the overall research question of how citizens are problematized and included in policy and practitioner discourse in the datafication of public administration. The paper takes Norway as its case and applies Cardullo and Kitchin’s scaffold of smart citizen participation at the system level. It makes use of a unique empirical insight into the field, consisting of a survey, interviews, and an extensive document analysis. Unexpectedly, we find that citizens and civil society are rarely engaged in this administrative reform. Instead, we identify a paternalistic, top-down, technocratic approach where the context, values, and agendas of datafication are obscured from the citizen. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221089302",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Heather Broomfield",
        "Lisa Reutter"
      ],
      "url": "https://doi.org/10.1177/20539517221089302",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 73,
      "is_referenced_by_count": 26,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "da92c240-d8ff-4172-a02d-78a1d644cd19",
    "title": "Of dog kennels, magnets, and hard drives: Dealing with Big Data peripheries",
    "abstract": "<jats:p> How did the 3.5-inch Winchester hard disk drive become the fundamental building block of the modern data center? In attempting to answer this question, I theorize the concept of \"data peripheries\" to attend to the awkward, uneven, and unintended outsides of data infrastructures. I explore the concept of data peripheries by first situating Big Data in one of its many unintended outsides—an unassuming dog kennel in Indiana housed in a former permanent magnet manufacturing plant. From the perspective of this dog kennel, I then build a history of the 3.5-inch Winchester hard disk drive, and weave this hard drive history through the industrial histories of rare earth mining and permanent magnet manufacturing, focusing principally on Magnequench, a former General Motors subsidiary, and its sale and movement of operations from Indiana to China in the mid-1990s and early 2000s. I then discuss how mobilities of rare earths, both as materials and political discourse, shape Big Data futures, and conclude by speculating on how using the situated lenses of data peripheries (such as this Indiana dog kennel) can open up new methods for studying the material entanglements of Big Data writ large. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211015430",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Zane Griffin Talley Cooper"
      ],
      "url": "https://doi.org/10.1177/20539517211015430",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 100,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d7b80046-6df2-4189-b92c-e5e713d3cf2a",
    "title": "Who benefits and how? Public expectations of public benefits from data-intensive health research",
    "abstract": "<jats:p> The digitization of society and academic research endeavours have led to an explosion of interest in the potential uses of population data in research. Alongside this, increasing attention is focussing on the conditions necessary for maintaining a social license for research practices. Previous research has pointed to the importance of demonstrating “public benefits” from research for maintaining public support, yet there has been very little consideration of what the term “public benefits” means or what public expectations of “public benefits” are. In order to address this pressing issue a series of deliberative workshops with members of the public were held across Scotland in May and June 2017. The workshops aimed to engage a cross-section of the Scottish population in in-depth discussions of the ways that the public – or publics – might benefit from data-intensive health research. The findings reported here discuss workshop participants’ understandings and expectations of health research; who they considered to be “the public” that should benefit from health research and; in what ways they felt “the public” should benefit. Workshop participants’ preference was clearly for the widest possible public benefit to be felt by all, but they also acknowledged the value in research aiming to primarily benefit vulnerable groups within society. A key focus of discussions was the extent to which workshop participants were confident that potential public benefits would be realised. A crucial consideration then is the extent to which mechanisms and political support are in place to realise and maximise the public benefits of data-intensive health research. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718816724",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Mhairi Aitken",
        "Carol Porteous",
        "Emily Creamer",
        "Sarah Cunningham-Burley"
      ],
      "url": "https://doi.org/10.1177/2053951718816724",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 29,
      "is_referenced_by_count": 24,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f89850d3-23c7-4133-aea9-cb6d88946b81",
    "title": "Public perceptions of good data management: Findings from a UK-based survey",
    "abstract": "<jats:p>Low levels of public trust in data practices have led to growing calls for changes to data-driven systems, and in the EU, the General Data Protection Regulation provides a legal motivation for such changes. Data management is a vital component of data-driven systems, but what constitutes ‘good’ data management is not straightforward. Academic attention is turning to the question of what ‘good data’ might look like more generally, but public views are absent from these debates. This paper addresses this gap, reporting on a survey of the public on their views of data management approaches, undertaken by the authors and administered in the UK, where departure from the EU makes future data legislation uncertain. The survey found that respondents dislike the current approach in which commercial organizations control their personal data and prefer approaches that give them control over their data, that include oversight from regulatory bodies or that enable them to opt out of data gathering. Variations of data trusts – that is, structures that provide independent stewardship of data – were also preferable to the current approach, but not as widely preferred as control, oversight and opt out options. These features therefore constitute ‘good data management’ for survey respondents. These findings align only in part with principles of good data identified by policy experts and researchers. Our findings nuance understandings of good data as a concept and of good data management as a practice and point to where further research and policy action are needed.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720935616",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Todd Hartman",
        "Helen Kennedy",
        "Robin Steedman",
        "Rhianne Jones"
      ],
      "url": "https://doi.org/10.1177/2053951720935616",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172093561",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 29,
      "is_referenced_by_count": 18,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "58eed9a9-6610-40f1-a44a-74375ba66c30",
    "title": "Plastic surveillance: Payment cards and the history of transactional data, 1888 to present",
    "abstract": "Modern payment cards encompass a bewildering array of consumer technologies, from credit and debit cards to stored-value and loyalty cards. But what unites all of these financial media is their connection to recordkeeping systems. Each swipe sends data hurtling through invisible infrastructures to verify accounts, record purchase details, exchange funds, and update balances. With payment cards, banks and merchants have been able to amass vast archives of transactional data. This information is a valuable asset in itself. It can be used for in-house data analytics programs or sold as marketing intelligence to third parties. This research examines the development of payment cards in the United States from the late 19th century to present, drawing attention to their fundamental relationship to identification, recordkeeping, and data mining. The history of payment cards, I argue, is not just a history of financial innovation and computing; it is also a history of Big Data and consumer surveillance. This history, moreover, provides insight into the growth of transactional data and the datafication of money in the digital economy.",
    "metadata": {
      "doi": "10.1177/2053951720907632",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Josh Lauer"
      ],
      "url": "https://doi.org/10.1177/2053951720907632",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172090763",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 63,
      "is_referenced_by_count": 18,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1e23a6fa-9d1a-4d13-a162-2b35fecc7495",
    "title": "Are the dead taking over Facebook? A Big Data approach to the future of death online",
    "abstract": "<jats:p> We project the future accumulation of profiles belonging to deceased Facebook users. Our analysis suggests that a minimum of 1.4 billion users will pass away before 2100 if Facebook ceases to attract new users as of 2018. If the network continues expanding at current rates, however, this number will exceed 4.9 billion. In both cases, a majority of the profiles will belong to non-Western users. In discussing our findings, we draw on the emerging scholarship on digital preservation and stress the challenges arising from curating the profiles of the deceased. We argue that an exclusively commercial approach to data preservation poses important ethical and political risks that demand urgent consideration. We call for a scalable, sustainable, and dignified curation model that incorporates the interests of multiple stakeholders. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719842540",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Carl J Öhman",
        "David Watson"
      ],
      "url": "https://doi.org/10.1177/2053951719842540",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 37,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "96473254-8904-4775-9742-9f5bb9b14d52",
    "title": "Data as asset? The measurement, governance, and valuation of digital personal data by Big Tech",
    "abstract": "<jats:p> Digital personal data is increasingly framed as the basis of contemporary economies, representing an important new asset class. Control over these data assets seems to explain the emergence and dominance of so-called “Big Tech” firms, consisting of Apple, Microsoft, Amazon, Google/Alphabet, and Facebook. These US-based firms are some of the largest in the world by market capitalization, a position that they retain despite growing policy and public condemnation—or “techlash”—of their market power based on their monopolistic control of personal data. We analyse the transformation of personal data into an asset in order to explore how personal data is accounted for, governed, and valued by Big Tech firms and other political-economic actors (e.g., investors). However, our findings show that Big Tech firms turn “users” and “user engagement” into assets through the performative measurement, governance, and valuation of user metrics (e.g., user numbers, user engagement), rather than extending ownership and control rights over personal data per se. We conceptualize this strategy as a form of “techcraft” to center attention on the means and mechanisms that Big Tech firms deploy to make users and user data measurable and legible as future revenue streams. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211017308",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Kean Birch",
        "DT Cochrane",
        "Callum Ward"
      ],
      "url": "https://doi.org/10.1177/20539517211017308",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 57,
      "is_referenced_by_count": 137,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f008da57-aefd-46b2-bfe6-fd6e52bf124c",
    "title": "Algorithms as organizational figuration: The sociotechnical arrangements of a fintech start-up",
    "abstract": "<jats:p> Building on critical approaches that understand algorithms in terms of communication, culture and organization, this paper offers the supplementary conceptualization of algorithms as organizational figuration, defined as material and meaningful sociotechnical arrangements that develop in spatiotemporal processes and are shaped by multiple enactments of affordance–agency relations. We develop this conceptualization through a case study of a Danish fintech start-up that uses machine learning to create opportunities for sustainable pensions investments. By way of ethnographic and literary methodology, we provide an in-depth analysis of the dynamic trajectory in and through which the organization gives shape to and takes shape from its key algorithmic tool, mapping the shifting sociotechnical arrangements of the start-up, from its initial search for a viable business model through the development of the algorithm to the public launch of its product. On this basis, we argue that conceptualizing algorithms as organizational figuration enables us to detail not only what algorithms do but also what they are. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211026702",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Sara Dahlman",
        "Ib T Gulbrandsen",
        "Sine N Just"
      ],
      "url": "https://doi.org/10.1177/20539517211026702",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 73,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bde465a6-653b-4f77-867d-abf5910d5292",
    "title": "When data is capital: Datafication, accumulation, and           extraction",
    "abstract": "<jats:p> The collection and circulation of data is now a central element of increasingly more sectors of contemporary capitalism. This article analyses data as a form of capital that is distinct from, but has its roots in, economic capital. Data collection is driven by the perpetual cycle of capital accumulation, which in turn drives capital to construct and rely upon a universe in which everything is made of data. The imperative to capture all data, from all sources, by any means possible influences many key decisions about business models, political governance, and technological development. This article argues that many common practices of data accumulation should actually be understood in terms of data extraction, wherein data is taken with little regard for consent and compensation. By understanding data as a form capital, we can better analyse the meaning, practices, and implications of datafication as a political economic regime. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718820549",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Jathan Sadowski"
      ],
      "url": "https://doi.org/10.1177/2053951718820549",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 91,
      "is_referenced_by_count": 495,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6168e97f-2300-4bde-9771-5ccf68ab3414",
    "title": "Making data science systems work",
    "abstract": "<jats:p> How are data science systems made to work? It may seem that whether a system works is a function of its technical design, but it is also accomplished through ongoing forms of discretionary work by many actors. Based on six months of ethnographic fieldwork with a corporate data science team, we describe how actors involved in a corporate project negotiated what work the system should do, how it should work, and how to assess whether it works. These negotiations laid the foundation for how, why, and to what extent the system ultimately worked. We describe three main findings. First, how already-existing technologies are essential reference points to determine how and whether systems work. Second, how the situated resolution of development challenges continually reshapes the understanding of how and whether systems work. Third, how business goals, and especially their negotiated balance with data science imperatives, affect a system’s working. We conclude with takeaways for critical data studies, orienting researchers to focus on the organizational and cultural aspects of data science, the third-party platforms underlying data science systems, and ways to engage with practitioners’ imagination of how systems can and should work. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720939605",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Samir Passi",
        "Phoebe Sengers"
      ],
      "url": "https://doi.org/10.1177/2053951720939605",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 45,
      "is_referenced_by_count": 51,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9a9aa3b4-6568-428e-8c75-96609cc658e6",
    "title": "Evolving data teams: Tensions between organisational structure and professional subculture",
    "abstract": "<jats:p>This study explores the integration of data journalism within three European legacy news organisations through the lens of organisational structure and professional culture. Interviews with data journalists and editors suggest that professional routines resonate with established data journalism epistemologies, values, and norms that appear to be constitutional for an inter-organisational data journalism subculture. At the same time, organisational structure either integrates the journalistic subculture by increasing levels of complexity, formalisation, and centralisation or rejects it by not accommodating it structurally or culturally. The three data teams work along epistemologies of computer-assisted reporting, investigative journalism, and data journalism but differentiate themselves through nuanced understandings of data journalism practice, driven by individual journalists. After a structureless episode, one team sets itself apart as it diverges from data-driven routines and orients itself towards technological and interdisciplinary interactive journalism. The findings show an interdependence of individual efforts, varying conceptualisations of data journalism practice, and interplay between organisational structure and professional culture.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720919964",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Florian Stalph"
      ],
      "url": "https://doi.org/10.1177/2053951720919964",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172091996",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 53,
      "is_referenced_by_count": 18,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "47d0da26-54c6-4017-a394-50b2714935a2",
    "title": "Transparency you can trust: Transparency requirements for artificial intelligence between legal norms and contextual concerns",
    "abstract": "<jats:p> Transparency is now a fundamental principle for data processing under the General Data Protection Regulation. We explore what this requirement entails for artificial intelligence and automated decision-making systems. We address the topic of transparency in artificial intelligence by integrating legal, social, and ethical aspects. We first investigate the ratio legis of the transparency requirement in the General Data Protection Regulation and its ethical underpinnings, showing its focus on the provision of information and explanation. We then discuss the pitfalls with respect to this requirement by focusing on the significance of contextual and performative factors in the implementation of transparency. We show that human–computer interaction and human-robot interaction literature do not provide clear results with respect to the benefits of transparency for users of artificial intelligence technologies due to the impact of a wide range of contextual factors, including performative aspects. We conclude by integrating the information- and explanation-based approach to transparency with the critical contextual approach, proposing that transparency as required by the General Data Protection Regulation in itself may be insufficient to achieve the positive goals associated with transparency. Instead, we propose to understand transparency relationally, where information provision is conceptualized as communication between technology providers and users, and where assessments of trustworthiness based on contextual factors mediate the value of transparency communications. This relational concept of transparency points to future research directions for the study of transparency in artificial intelligence systems and should be taken into account in policymaking. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719860542",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Heike Felzmann",
        "Eduard Fosch Villaronga",
        "Christoph Lutz",
        "Aurelia Tamò-Larrieux"
      ],
      "url": "https://doi.org/10.1177/2053951719860542",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 96,
      "is_referenced_by_count": 205,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e126b938-8d54-4a95-8cd0-d409254b11b9",
    "title": "From rules to examples: Machine learning's type of authority",
    "abstract": "<jats:p> This paper analyzes the effects of a perceived transition from a rule-based computer programming paradigm to an example-based paradigm associated with machine learning. While both paradigms coexist in practice, we critically discuss the distinctive epistemological and ethical implications of machine learning's “exemplary” type of authority. To capture its logic, we compare it to computer programming rules that date to the middle of the 20th century, showing how rules and examples have regulated human conduct in significantly different ways. In contrast to the highly constructed, explicit, and prescriptive form of authority imposed by programming rules, machine learning models are trained using data that has been made into examples. These examples elicit norms in an implicit, emergent manner to make prediction and classification possible. We analyze three ways that examples are produced in machine learning: labeling, feature engineering, and scaling. We use the phrase “artificial naturalism” to characterize the tensions of this type of authority, in which examples sit ambiguously between data and norm. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231188725",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Alexander Campolo",
        "Katia Schwerzmann"
      ],
      "url": "https://doi.org/10.1177/20539517231188725",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 54,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "cabfcdc7-7cee-4860-9967-3b2a45711cc2",
    "title": "‘I started seeing shadows everywhere’: The diverse chilling effects of surveillance in Zimbabwe",
    "abstract": "<jats:p> Recent years have witnessed growing ubiquity and potency of state surveillance measures with heightened implications for human rights and social justice. While impacts of surveillance are routinely framed through ‘privacy’ narratives, emphasising ‘chilling effects’ surfaces a more complex range of harms and rights implications for those who are, or believe they are, subjected to surveillance. Although first emphasised during the McCarthy era, surveillance ‘chilling effects’ remain under-researched, particularly in Africa. Drawing on rare interview data from participants subjected to state-sponsored surveillance in Zimbabwe, the paper reveals complex assemblages of state and non-state actors involved in diverse and expansive hybrid online–offline monitoring. While scholarship has recently emphasised the importance of large-scale digital mass surveillance, the Zimbabwean context reveals complex assemblages of ‘big data’, social media and other digital monitoring combining with more traditional human surveillance practices. Such inseparable online–offline imbrications compound the scale, scope and impact of surveillance and invite analyses as an integrated ensemble. The paper evidences how these surveillance activities exert chilling effects that vary in form, scope and intensity, and implicate rights essential to the development of personal identity and effective functioning of participatory democracy. Moreover, the data reveals impacts beyond the individual to the vicarious and collective. These include gendered dimensions, eroded interpersonal trust and the depleted ability of human rights defenders to organise and particulate in democratic processes. Overall, surveillance chilling effects exert a wide spectrum of outcomes which consequently interfere with enjoyment of multiple rights and hold both short- and long-term implications for democratic participation. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231158631",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Amy Stevens",
        "Pete Fussey",
        "Daragh Murray",
        "Kuda Hove",
        "Otto Saki"
      ],
      "url": "https://doi.org/10.1177/20539517231158631",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 54,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "eab3be52-9676-4b73-9609-3acc33f38aaa",
    "title": "Understanding ‘passivity’ in digital health through imaginaries and experiences of coronavirus disease 2019 contact tracing apps",
    "abstract": "<jats:p> Growing interest is being directed to the health applications of so-called ‘passive data’ collected through wearables and sensors without active input by users. High promises are attached to passive data and their potential to unlock new insights into health and illness, but as researchers and commentators have noted, this mode of data gathering also raises fundamental questions regarding the subject's agency, autonomy and privacy. To explore how these tensions are negotiated in practice, we present and discuss findings from an interview study with 30 members of the public in the UK and Italy, which examined their views and experiences of the coronavirus disease 2019 contact tracing apps as a large-scale, high-impact example of digital health technology using passive data. We argue that, contrary to what the phrasing ‘passive data’ suggests, passivity is not a quality of specific modes of data collection but is contingent on the very practices that the technology is supposed to unobtrusively capture. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221091138",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Alessia Costa",
        "Richard Milne"
      ],
      "url": "https://doi.org/10.1177/20539517221091138",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 65,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "cb4a14df-168b-4d80-afd9-a9c7cc032bf3",
    "title": "One size does not fit all: Constructing complementary digital reskilling strategies using online labour market data",
    "abstract": "<jats:p> Digital technologies are radically transforming our work environments and demand for skills, with certain jobs being automated away and others demanding mastery of new digital techniques. This global challenge of rapidly changing skill requirements due to task automation overwhelms workers. The digital skill gap widens further as technological and social transformation outpaces national education systems and precise skill requirements for mastering emerging technologies, such as Artificial Intelligence, remain opaque. Online labour platforms could help us to understand this grand challenge of reskilling en masse. Online labour platforms build a globally integrated market that mediates between millions of buyers and sellers of remotely deliverable cognitive work. This commentary argues that, over the last decade, online labour platforms have become the ‘laboratories’ of skill rebundling; the combination of skills from different occupational domains. Online labour platform data allows us to establish a new taxonomy on the individual complementarity of skills. For policy makers, education providers and recruiters, a continuous analysis of complementary reskilling trajectories enables automated, individual and far-sighted suggestions on the value of learning a new skill in a future of technological disruption. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211003120",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Fabian Stephany"
      ],
      "url": "https://doi.org/10.1177/20539517211003120",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 26,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b74930f3-8fb3-438f-b8b2-45bd1d0b3e75",
    "title": "Big Data and Small: Collaborations between ethnographers and data scientists",
    "abstract": "<jats:p> In the past three years, Heather Ford—an ethnographer and now a PhD student—has worked on ad hoc collaborative projects around Wikipedia sources with two data scientists from Minnesota, Dave Musicant and Shilad Sen. In this essay, she talks about how the three met, how they worked together, and what they gained from the experience. Three themes became apparent through their collaboration: that data scientists and ethnographers have much in common, that their skills are complementary, and that discovering the data together rather than compartmentalizing research activities was key to their success. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714544337",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "Heather Ford"
      ],
      "url": "https://doi.org/10.1177/2053951714544337",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 3,
      "is_referenced_by_count": 28,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "40f5ca5d-0c90-4b1a-9627-112d616ca17b",
    "title": "From human-centered to social-centered artificial intelligence: Assessing ChatGPT's impact through disruptive events",
    "abstract": "<jats:p> Large language models (LLMs) and dialogue agents represent a significant shift in artificial intelligence (AI) research, particularly with the recent release of the GPT family of models. ChatGPT's generative capabilities and versatility across technical and creative domains led to its widespread adoption, marking a departure from more limited deployments of previous AI systems. While society grapples with the emerging cultural impacts of this new societal-scale technology, critiques of ChatGPT's impact within machine learning research communities have coalesced around its performance or other conventional safety evaluations relating to bias, toxicity, and “hallucination.” We argue that these critiques draw heavily on a particular conceptualization of the “human-centered” framework, which tends to cast atomized individuals as the key recipients of technology's benefits and detriments. In this article, we direct attention to another dimension of LLMs and dialogue agents’ impact: their effects on social groups, institutions, and accompanying norms and practices. By analyzing ChatGPT's social impact through a social-centered framework, we challenge individualistic approaches in AI development and contribute to ongoing debates around the ethical and responsible deployment of AI systems. We hope this effort will call attention to more comprehensive and longitudinal evaluation tools (e.g., including more ethnographic analyses and participatory approaches) and compel technologists to complement human-centered thinking with social-centered approaches. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241290220",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Skyler Wang",
        "Ned Cooper",
        "Margaret Eby"
      ],
      "url": "https://doi.org/10.1177/20539517241290220",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 109,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5ebcb514-02ed-43d5-8d5f-f29eb930d9f9",
    "title": "Privacy cynicism and diminishing utility of state surveillance: A natural experiment of mandatory location disclosure on China's Weibo",
    "abstract": "<jats:p> This article examines the public response to mandatory location disclosure (MLD), a new surveillance technology implemented on China's Sina Weibo. Initially introduced to geo-tag posts related to the Ukraine War, the MLD eventually expanded to encompass all posts and comments on the platform. Drawing on a large-scale dataset comprising over 0.6 million posts and 24 million comments, this study uncovers political asymmetry observed during the initial implementation of MLD. Users with different political orientations were subjected to different levels of geo-tagging. Pro-Ukraine users were most frequently geo-tagged, followed by Pro-Russia and liberal-leaning users, while conservative-leaning users are least likely to be tagged. This selective surveillance approach, however, backfired among Pro-Ukraine and Pro-Russia users, pushing them to publish more war-related content, while its impact on liberal- and conservative-leaning users appeared to be minimal. When selective surveillance was replaced by universal surveillance, the backfire effects ceased to exist and people's interest in war-related topics declined. Furthermore, privacy cynicism prevails among commenters across opinion groups. Neither the introduction nor the expansion of MLD deterred audiences from engaging with the geo-tagged posts. These findings suggest that prolonged surveillance makes people less sensitive to privacy threats and more experienced in neutralizing surveillance's influence on themselves. Privacy cynicism, though widely considered toxic to democracy, can function as a source of resilience that shields people from the fear of coercion and undercuts the marginal utility of state surveillance in an authoritarian context. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241242450",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Yuner Zhu"
      ],
      "url": "https://doi.org/10.1177/20539517241242450",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 99,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e482957c-78f0-4370-8118-126680bce8ab",
    "title": "Big Web data, small focus: An ethnosemiotic approach to culturally themed selective Web archiving",
    "abstract": "<jats:p> This paper proposes a multimodal ethnosemiotic conceptual framework for culturally themed selective Web archiving, taking as a practical example the curation of the London French Special Collection (LFSC) in the UK Web Archive. Its focus on a particular ‘community’ is presented as advantageous in overcoming the sheer scale of data available on the Web; yet, it is argued that these ethnographic boundaries may be flawed if they do not map onto the collective self-perception of the London French. The approach establishes several theoretical meeting points between Pierre Bourdieu’s ethnography and Gunther Kress’s multimodal social semiotics, notably, the foregrounding of practice and the meaning-making potentialities of the everyday; the implications of language and categorisation; the interplay between (curating/researcher) subject and (curated/research) object; evolving notions of agency, authorship and audience; together with social engagement, and the archive as dynamic process and product. The curation rationale proposed stems from Bourdieu’s three-stage field analysis model, which places a strong emphasis on habitus, considered to be most accurately (re)presented through blogs, yet necessitates its contextualisation within the broader (diasporic) field(s), through institutional websites, for example, whilst advocating a reflexive awareness of the researcher/curator’s (subjective) role. This, alongside the Kressian acknowledgement of the inherent multimodality of on-line resources, lends itself convincingly to selection and valuation strategies, whilst the discussion of language, genre, authorship and audience is relevant to the potential cataloguing of Web objects. By conceptualising the culturally themed selective Web-archiving process within the ethnosemiotic framework constructed, concrete recommendations emerge regarding curation, classification and crowd-sourcing. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715595823",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Saskia Huc-Hepher"
      ],
      "url": "https://doi.org/10.1177/2053951715595823",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 72,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8ea913a3-c67d-4030-a83b-378fa30649d9",
    "title": "The place of conditionality and individual responsibility in a “data-driven economy”",
    "abstract": "Advances in information and communication technologies enable more decentralized and individualized mechanisms for coordination and for managing societal complexity. This has important consequences for the role of conditionality and the idea of individual responsibility in two seemingly unrelated policy areas. First, the changing information infrastructure enables an extension of conditionality in the area of welfare through greater activation, enhanced self-management, and a personalization of risks. Second, conditionality and personal responsibility also form an important ideational template and a legitimatory basis for facilitating value creation that is based on data as a raw material. This argument is illustrated looking at the trajectories of the digital strategies in the United Kingdom and Germany. In both cases, data protection is depicted as a question of individual responsibility and tied to certain forms of individual conduct.",
    "metadata": {
      "doi": "10.1177/2053951717742419",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Pascal D König"
      ],
      "url": "https://doi.org/10.1177/2053951717742419",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171774241",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 73,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f8c3c71b-fbe0-4c77-98e2-ace941817c2b",
    "title": "The conundrum of police officer-involved homicides: Counter-data in Los Angeles County",
    "abstract": "<jats:p> This paper draws from critical data studies and related fields to investigate police officer-involved homicide data for Los Angeles County. We frame police officer-involved homicide data as a rhetorical tool that can reify certain assumptions about the world and extend regimes of power. We highlight the possibility that this type of sensitive civic data can be investigated and employed within local communities through creative practice. Community involvement with data can create a countervailing force to powerful dominant narratives and supplement activist projects that hold local officials accountable for their actions. Our analysis examines four Los Angeles County police officer-involved homicide data sets. First, we provide accounts of the semantics, granularity, scale and transparency of this local data. Then, we describe a “counter data action,” an event that invited members of the community to identify the limits and challenges present in police officer-involved homicide data and to propose new methods for deriving meaning from these indicators and statistics. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716663566",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Morgan Currie",
        "Britt S Paris",
        "Irene Pasquetto",
        "Jennifer Pierre"
      ],
      "url": "https://doi.org/10.1177/2053951716663566",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 45,
      "is_referenced_by_count": 40,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "303f2fd1-e335-4c35-a584-62bc10947e6e",
    "title": "The problem of researching a recursive society: Algorithms, data coils and the looping of the social",
    "abstract": "<jats:p> This commentary article outlines and explores the key problem that faces anyone interested in researching and understanding what might be thought of as a recursive society. It reflects on the problem that is posed by the layering of multiple feedback loops as a result of algorithmic sorting and data processes. This article is concerned with the difficulties of understanding the social where recursive algorithmic processes have repeatedly shaped outcomes, practices, relations and actions over time. This is not just about the sinking of algorithms into the everyday, it is about the way that loop-upon-loop of data processes lead to the social world itself being recursive. This repeated looping is described here as a kind of data coiling. The article argues for a focus on recursivity and for an engagement with the conceptual problems and questions that this notion implies. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221104997",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "David Beer"
      ],
      "url": "https://doi.org/10.1177/20539517221104997",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 16,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9129d35c-9da5-4668-bfb2-0dac36f16dde",
    "title": "Connected or informed?: Local Twitter networking in a London neighbourhood",
    "abstract": "<jats:p> This paper asks whether geographically localised, or ‘hyperlocal’, uses of Twitter succeed in creating peer-to-peer neighbourhood networks or simply act as broadcast media at a reduced scale. Literature drawn from the smart cities discourse and from a UK research project into hyperlocal media, respectively, take on these two opposing interpretations. Evidence gathered in the case study presented here is consistent with the latter, and on this basis we criticise the notion that hyperlocal social media can be seen as a community in itself. We demonstrate this by creating a network map of Twitter followers of a popular hyperlocal blog in Brockley, southeast London. We describe various attributes of this network including its average degree and clustering coefficient to suggest that a small and highly connected cluster of visible local entities such as businesses form a clique at the centre of this network, with individual residents following these but not one another. We then plot the locations of these entities and demonstrate that sub-communities in the network are formed due to close geographical proximity between smaller sets of businesses. These observations are illustrated with qualitative evidence from interviews with users who suggest instead that rather than being connected to one another they benefit from what has been described as ‘neighbourhood storytelling’. Despite the limitations of working with Twitter data, we propose that this multi-modal approach offers a valuable way to investigate the experience of using social media as a communication tool in urban neighbourhoods. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715597457",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "John Bingham-Hall",
        "Stephen Law"
      ],
      "url": "https://doi.org/10.1177/2053951715597457",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 26,
      "is_referenced_by_count": 20,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4c8d6586-af9b-45bf-ba0f-6dd8d0e0c883",
    "title": "Data associations in global law and policy",
    "abstract": "Social phenomena—or the condition of society—may be ‘‘seized indirectly when there is a slight change in one older association mutating into a slightly newer or different one’’ (Latour, 2005: 36). The aim of this special issue is to trace mutations underway in those associations rendered or experienced in data and to probe some patterns that these changing ties draw. In particular, contributors to this issue reflect upon associations traceable in data that are of a juridical nature (or could be so understood), or that have salience for legal institutions and norms. This is something other than inviting consideration of ‘‘problems’’ that technology makes for law. It is something other, too, than thinking about whether law does or does not determine or reflect socio-technical practice, or vice versa, and how such law-technology correspondence might ‘‘properly’’ be maintained. Instead, contributors engage here in a collective experiment of envisioning data as vectors of lawful relations on the global plane, and at other scales. This is unfinished business for Big Data & Society. In this journal’s opening issue, Rob Kitchin argued that ‘‘the development of digital humanities and computational social sciences. . . propose radically different ways to make sense of culture, history, economy and society’’ (Kitchin, 2014: 1). But what ‘‘sense’’ could ‘‘Big Data empiricism,’’ as Kitchin described it, make in, of and for global law and policy? This is among the questions that the contributors to this special issue take up. Neither digital technology nor law is pivotal to this inquiry, so much as their irrepressible leaking and morphing into would-be or could-be versions of the other. As paradigmatic a shift as the turn to epistemologies of Big Data might seem, making connections between these emergent epistemologies and ‘‘older association[s],’’ in Latour’s words, is also an important task of this collection. Sheila Jasanoff traces, for instance, the history of the production of ‘‘a panoptic viewpoint from which the entire diversity of human experience can be seen, catalogued, aggregated, and mined’’ from the mid-20th-century, especially in the emergence of the ‘‘global environment’’ as an ‘‘actionable object for law and policy.’’ Naveen Thayyil likewise draws an analogy between change in weather and climatological studies from the 1960s onwards (from instrument reading techniques to computer modeling) and parallel shifts in approaches to risk regulation (from conventional risk assessment to precautionary approaches, the latter increasingly advanced through ‘‘Big Data’’ automation). Ben Hurlbut similarly connects ‘‘scientifically authorized imaginations of future risk’’ on the global plane to earlier incarnations of the ‘‘republic of science’’ assembled around pandemic risk since the 19th-century. Other contributions to this volume re-frame contemporary phenomena by reference to associations of more recent provenance: Sarah Logan analyses ‘‘post 9-11 mass surveillance’’ and the ‘‘anxious information state’’ it enshrines. Likewise, Gavin Smith, Kath Albury, Jean Burgess, Ben Light, Kane Race, Rowan Wilken, and Daniel Joyce focus on ‘‘data cultures’’ ascendant during the past decade and the legal, social, and political conflicts and connections that surface amid them. The protagonists and environs of the stories told in these pages vary greatly. Not all are of a kind that one",
    "metadata": {
      "doi": "10.1177/2053951718783438",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Lyria B Moses",
        "Fleur Johns",
        "Daniel Joyce"
      ],
      "url": "https://doi.org/10.1177/2053951718783438",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 4,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "81eca167-fcd7-4cbc-99b9-7c9fa61db30e",
    "title": "Data access and regime competition: A case study of car data sharing in China",
    "abstract": "<jats:p> We study the case of a Chinese industrial policy, implemented in Shanghai that makes it mandatory for car manufacturers to share electro-mechanical performance and real time navigation data from their entire fleet of electric and hybrid vehicles with local and central government authorities. This policy seeks to prevent fraud in state subsidies, reduce emissions, assess the performance of New Energy Vehicles and strengthen the competitiveness of Chinese manufacturers of these vehicles. We argue that economies of scope in data aggregation may provide traditional market failure arguments in favor of government intervention and mandatory data pooling. Our paper illustrates how data access regimes could be used for economic competition. The EU and China pursue similar data sharing and pooling policy goals that hinge on economies of scope in data aggregation. However, they follow very different political processes to achieve these goals. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211046374",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Bertin Martens",
        "Bo Zhao"
      ],
      "url": "https://doi.org/10.1177/20539517211046374",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 15,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "751cf027-270f-40e6-bb17-622405370696",
    "title": "“You Social Scientists Love Mind Games”: Experimenting in the “divide” between data science and critical algorithm studies",
    "abstract": "<jats:p> In recent years, many qualitative sociologists, anthropologists, and social theorists have critiqued the use of algorithms and other automated processes involved in data science on both epistemological and political grounds. Yet, it has proven difficult to bring these important insights into the practice of data science itself. We suggest that part of this problem has to do with under-examined or unacknowledged assumptions about the relationship between the two fields—ideas about how data science and its critics can and should relate. Inspired by recent work in Science and Technology Studies on interventions, we attempted to stage an encounter in which practicing data scientists were asked to analyze a corpus of critical social science literature about their work, using tools of textual analysis such as co-word and topic modelling. The idea was to provoke discussion both about the content of these texts and the possible limits of such analyses. In this commentary, we reflect on the planning stages of the experiment and how responses to the exercise, from both data scientists and qualitative social scientists, revealed some of the tensions and interactions between the normative positions of the different fields. We argue for further studies which can help us understand what these interdisciplinary tensions turn on—which do not paper over them but also do not take them as given. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719833404",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "David Moats",
        "Nick Seaver"
      ],
      "url": "https://doi.org/10.1177/2053951719833404",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 44,
      "is_referenced_by_count": 39,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "41721b5e-ee4c-4af0-9345-765dc05f04fd",
    "title": "Critical data ethics pedagogies:  Three (non-rival) approaches",
    "abstract": "<jats:p> In a moment of heightened ethical questioning concerning data-intensive analytics, “data ethics” has become a site of dispute over its very definition in teaching, research, and practice. In this paper, we contextualize this dispute based on the experience of teaching data ethics. We describe how the field of computer ethics has historically informed the training of computer experts and how, in recent years, the scholarship on science and technology studies has created opportunities for transforming the way we teach with the inclusion of critical scholarship on relational ethics and sociotechnical systems. The emergent literature on “critical data ethics” has created a space for interdisciplinary collaboration that integrates technical and social science research to examine digital systems in their design, implementation, and use through a hands-on approach. As a contribution to the recent efforts to reimagine and transform the field of data science, we conclude with a discussion of the approach we devised to bridge technology/society divides and engage students with questions of social justice, accountability, and openness in their data practices. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231203666",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Luis Felipe R Murillo",
        "Caitlin Wylie",
        "Phil Bourne"
      ],
      "url": "https://doi.org/10.1177/20539517231203666",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 71,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5d60a148-5356-4356-aa5a-c280651dd5ca",
    "title": "“We called that a behavior”: The making of institutional data",
    "abstract": "<jats:p>Predictive uses of data are becoming widespread in institutional settings as actors seek to anticipate people and their activities. Predictive modeling is increasingly the subject of scholarly and public criticism. Less common, however, is scrutiny directed at the data that inform predictive models beyond concerns about homogenous training data or general epistemological critiques of data. In this paper, I draw from a qualitative case study set in higher education in the United States to investigate the making of data. Data analytics projects at universities have become more pervasive and intensive to better understand and anticipate undergraduate student bodies. Drawing from 12 months of ethnographic research at a large public university, I analyze the ways data personnel at the institution—data scientists, administrators, and programmers—sort student data into “attributes” and “behaviors,” where “attributes” are demographic data that students “can’t change.” “Behaviors,” in contrast, are data defined as reflective of what students can choose: attending and paying attention in class, studying on campus, among other data which personnel categorize as what students have control over. This discursive split enables the institution nudge students to make responsible choices according to behavior data that correlate with success in the predictive model. In discussing how personnel type, sort, stabilize, and nudge on behavior data, this paper examines the contingencies of data making processes and implications for the application of student data.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720932200",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Madisson Whitman"
      ],
      "url": "https://doi.org/10.1177/2053951720932200",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172093220",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 69,
      "is_referenced_by_count": 20,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fe708ff4-2070-4696-bd4a-50c944060757",
    "title": "Educating the smart city: Schooling smart citizens through computational urbanism",
    "abstract": "<jats:p> Coupled with the ‘smart city’, the idea of the ‘smart school’ is emerging in imaginings of the future of education. Various commercial, governmental and civil society organizations now envisage education as a highly coded, software-mediated and data-driven social institution. Such spaces are to be governed through computational processes written in computer code and tracked through big data. In an original analysis of developments from commercial, governmental and civil society sectors, the article examines two interrelated dimensions of an emerging smart schools imaginary: (1) the constant flows of digital data that smart schools depend on and the mobilization of analytics that enable student data to be used to anticipate and shape their behaviours; and (2) the ways that young people are educated to become ‘computational operatives’ who must ‘learn to code’ in order to become ‘smart citizens’ in the governance of the smart city. These developments constitute an emerging educational space fabricated from intersecting standards, technologies, discourses and social actors, all infused with the aspirations of technical experts to govern the city at a distance through both monitoring young people as ‘data objects’ and schooling them as active ‘computational citizens’ with the responsibility to compute the future of the city. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715617783",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Ben Williamson"
      ],
      "url": "https://doi.org/10.1177/2053951715617783",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 39,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b5e7771a-a56d-4fa7-8f4f-5001ffb30cf6",
    "title": "The right to information or data sovereignty? Sending unsolicited messages to Russians about the war in Ukraine",
    "abstract": "<jats:p> The Russian government's narrative about the Russia-Ukraine war has raised concerns about disinformation, fake news and freedom of information. In response, websites have been developed that allow people across the world to call or send emails and texts with information about the war to individuals based in Russia. To facilitate this person-to-person communication between strangers, automated data processing has been used to collect personal data from the internet and compile it into publicly accessible mailing lists. This side-stepping of consent coupled with the nature of information being transmitted and the motivation behind its transmission poses important questions of an ethical nature: What is an appropriate balance between the data subjects’ right to freedom of information and their right to privacy? Can data processing without the consent of the data subject be justified in certain circumstances? This commentary does not seek to provide definitive answers to these questions, rather it canvases some key issues in the hope of starting further dialogue on the topic. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231156123",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Yao-Tai Li",
        "Katherine Whitworth"
      ],
      "url": "https://doi.org/10.1177/20539517231156123",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 24,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1a4807f2-9747-4e80-95ad-d594144777e6",
    "title": "Can we trust Big Data? Applying philosophy of science to software",
    "abstract": "<jats:p> We address some of the epistemological challenges highlighted by the Critical Data Studies literature by reference to some of the key debates in the philosophy of science concerning computational modeling and simulation. We provide a brief overview of these debates focusing particularly on what Paul Humphreys calls epistemic opacity. We argue that debates in Critical Data Studies and philosophy of science have neglected the problem of error management and error detection. This is an especially important feature of the epistemology of Big Data. In “Error” section we explain the main characteristics of error detection and correction along with the relationship between error and path complexity in software. In this section we provide an overview of conventional statistical methods for error detection and review their limitations when faced with the high degree of conditionality inherent to modern software systems. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716664747",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "John Symons",
        "Ramón Alvarado"
      ],
      "url": "https://doi.org/10.1177/2053951716664747",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 62,
      "is_referenced_by_count": 41,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "17fb89a6-e92e-4e4f-9c94-cb37398e3260",
    "title": "Big Data is not only about data: The two cultures of modelling",
    "abstract": "<jats:p> The contribution of Big Data to social science is not limited to data availability but includes the introduction of analytical approaches that have been developed in computer science, and in particular in machine learning. This brings about a new ‘culture’ of statistical modelling that bears considerable potential for the social scientist. This argument is illustrated with a brief discussion of model-based recursive partitioning which can bridge the theory and data-driven approach. Such a method is an example of how this new approach can help revise models that work for the full dataset: it can be used for evaluating different models, a traditional weakness of the ‘traditional’ statistical approach used in social science. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717703997",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Giuseppe Alessandro Veltri"
      ],
      "url": "https://doi.org/10.1177/2053951717703997",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 26,
      "is_referenced_by_count": 27,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "72413ced-dae7-4659-9550-dfcfe77791d9",
    "title": "Reluctant activists? The impact of legislative and structural attempts of surveillance on investigative journalism",
    "abstract": "<jats:p> If we accept that surveillance by the State and ‘sousveillance’ by the media in Western democracies tend towards a relative equilibrium, or ‘equiveillance’ supported by the function of journalism as a watchdog and that the rule of law largely protects fundamental freedoms, this paper argues that the act of ‘mutual watching’ is undesired by the State and comes at a very high cost to journalists. The combination of technological capacity, legislative change and antidemocratic sentiments of the State, in the context of its willingness and ability to collect and process Big Data on an unprecedented scale, disrupt the preconditions for a strong democracy based on free media and free citizens. This paper examines the politics of investigative journalism under the conditions of dominance of the State by investigating the experiences of journalists with surveillance. Our interviews with 48 journalists show that journalists are acutely aware of surveillance and its noxious impact. Well beyond simple ‘watching’ these experiences are remarkably similar in non-Western and Western countries. Journalists are engaging increasingly with technological and other communities, as they aim to defend journalism and their lives. Their activism is operationalised in three areas: (a) in reluctant often-fraught cooperation with hacktivists, (b) in self-directed protection of communications and sources and (c) in not always willingly acting as dissenters vis-a-vis the State. This paper explores the extent to which journalists consider equilibrium to be distorted, and how they are countering any slide into subdued democracy. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716669381",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Anthony Mills",
        "Katharine Sarikakis"
      ],
      "url": "https://doi.org/10.1177/2053951716669381",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 45,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7c9ec399-b03a-4ab2-a67c-1126be6f36c1",
    "title": "The Thick Machine: Anthropological AI between explanation and explication",
    "abstract": "<jats:p> According to Clifford Geertz, the purpose of anthropology is not to explain culture but to explicate it. That should cause us to rethink our relationship with machine learning. It is, we contend, perfectly possible that machine learning algorithms, which are unable to explain, and could even be unexplainable themselves, can still be of critical use in a process of explication. Thus, we report on an experiment with anthropological AI. From a dataset of 175K Facebook comments, we trained a neural network to predict the emoji reaction associated with a comment and asked a group of human players to compete against the machine. We show that a) the machine can reach the same (poor) accuracy as the players (51%), b) it fails in roughly the same ways as the players, and c) easily predictable emoji reactions tend to reflect unambiguous situations where interpretation is easy. We therefore repurpose the failures of the neural network to point us to deeper and more ambiguous situations where interpretation is hard and explication becomes both necessary and interesting. We use this experiment as a point of departure for discussing how experiences from anthropology, and in particular the tension between formalist ethnoscience and interpretive thick description, might contribute to debates about explainable AI. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211069891",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Anders Kristian Munk",
        "Asger Gehrt Olesen",
        "Mathieu Jacomy"
      ],
      "url": "https://doi.org/10.1177/20539517211069891",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 43,
      "is_referenced_by_count": 26,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3bdacce0-20f6-412b-85ca-8a8957327b99",
    "title": "Sharing precision medicine data with private industry: Outcomes of a citizens’ jury in Singapore",
    "abstract": "<jats:p> Precision medicine is an emerging approach to treatment and disease prevention that relies on linkages between very large datasets of health information that is shared amongst researchers and health professionals. While studies suggest broad support for sharing precision medicine data with researchers at publicly funded institutions, there is reluctance to share health information with private industry for research and development. As the private sector is likely to play an important role in generating public benefits from precision medicine initiatives, it is important to understand what the concerns are and how they might be mitigated. This study reports outcomes of a deliberative method of citizen engagement in Singapore that asked whether sharing precision medicine data with private industry would be permissible, and if so, under what circumstances. Findings from this citizens’ jury suggest sharing with industry would be permissible under certain conditions that are set out in nine recommendations. Implications of the recommendations and their underlying assumptions for policy decision makers are discussed. This study aligns with prior international studies which found conditional acceptance for data sharing with private industry, a public benefit requirement, specific reluctance to share with insurance companies and an emphasis on accountability and transparency to demonstrate trustworthiness. However, our results differ from prior studies in that opt-in consent did not dominate the deliberations as jurors were able to set it aside as an assumed prerequisite for participation in a precision medicine programme. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221108988",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Angela Ballantyne",
        "Tamra Lysaght",
        "Hui Jin Toh",
        "Serene Ong",
        "Andrew Lau",
        "G Owen Schaefer",
        "Vicki Xafis",
        "E Shyong Tai",
        "Ainsley J Newson",
        "Stacy Carter",
        "Chris Degeling",
        "Annette Braunack-Mayer"
      ],
      "url": "https://doi.org/10.1177/20539517221108988",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 61,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d6589483-3055-492e-b7bd-d1d10f74522e",
    "title": "Privacy at risk? Understanding the perceived privacy protection of health  code apps in China",
    "abstract": "<jats:p> As a key constituent of China's approach to fighting COVID-19, Health Code apps (HCAs) not only serve the pandemic control imperatives but also exercise the agency of digital surveillance. As such, HCAs pave a new avenue for ongoing discussions on contact tracing solutions and privacy amid the global pandemic. This article attends to the perceived privacy protection among HCA users via the lens of the contextual integrity theory. Drawing on an online survey of adult HCA users in Wuhan and Hangzhou (N = 1551), we find users’ perceived convenience, attention towards privacy policy, trust in government, and acceptance of government purposes regarding HCA data management are significant contributors to users’ perceived privacy protection in using the apps. By contrast, users’ frequency of mobile privacy protection behaviors has limited influence, and their degrees of perceived protection do not vary by sociodemographic status. These findings shed new light on China's distinctive approach to pandemic control with respect to the state's expansion of big data-driven surveillance capacity. Also, the findings foreground the heuristic value of contextual integrity theory to examine controversial digital surveillance in non-Western contexts. Put tougher, our findings contribute to the thriving scholarly conversations around digital privacy and surveillance in China, as well as contact tracing solutions and privacy amid the global pandemic. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221135132",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Gejun Huang",
        "An Hu",
        "Wenhong Chen"
      ],
      "url": "https://doi.org/10.1177/20539517221135132",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 59,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9da84a5c-2553-497b-9329-99e001420f96",
    "title": "Data cultures of mobile dating and hook-up apps: Emerging issues for critical social science research",
    "abstract": "The ethical and social implications of data mining, algorithmic curation and automation in the context of social media have been of heightened concern for a range of researchers with interests in digital media in recent years, with particular concerns about privacy arising in the context of mobile and locative media. Despite their wide adoption and economic importance, mobile dating apps have received little scholarly attention from this perspective – but they are intense sites of data generation, algorithmic processing, and cross-platform data-sharing; bound up with competing cultures of production, exploitation and use. In this paper, we describe the ways various forms of data are incorporated into, and emerge from, hook-up apps’ business logics, socio-technical arrangements, and cultures of use to produce multiple and intersecting data cultures. We propose a multi-layered research agenda for critical and empirical inquiry into this field, and suggest appropriate conceptual and methodological frameworks for exploring the social and political challenges of data cultures.",
    "metadata": {
      "doi": "10.1177/2053951717720950",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Kath Albury",
        "Jean Burgess",
        "Ben Light",
        "Kane Race",
        "Rowan Wilken"
      ],
      "url": "https://doi.org/10.1177/2053951717720950",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171772095",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 93,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "20b2decd-ea21-4b10-97bf-683657e1e966",
    "title": "Smart corruption: Satirical strategies for gaming accountability",
    "abstract": "<jats:p> Although new forms of data can be used to hold power to account, they also grant the powerful new resources to game accountability. We dub the latter behavior “smart corruption.” The concept highlights the possibility of appropriating algorithms, infrastructures, and data publics to accumulate benefits and obscure responsibility while leaning into the positive associations of transparency. Unlike conventional forms of corruption, smart corruption is disguised as progressive, and is thus difficult to spot or analyze through existing legal or ethical frameworks. To illustrate, we outline a satirical strategy for gaming accountability. Identifying the particular mechanisms and outcomes of transgressive activities carried out under the veneer of data-driven transparency, as well as the key actors and organizations most active in gaming accountability, is an important research and political project. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231164119",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Ritwick Ghosh",
        "Hilary Oliva Faxon"
      ],
      "url": "https://doi.org/10.1177/20539517231164119",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 34,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b70d6216-cea2-4d29-9db8-fc4c19b93ed6",
    "title": "Digital phenotyping and data inheritance",
    "abstract": "<jats:p> Proponents of precision medicine envision that digital phenotyping can enable more individualized strategies to manage current and future health conditions. We problematize the interpretation of digital phenotypes as straightforward representations of individuals through examples of what we call data inheritance. Rather than being a digital copy of a presumed original, digital phenotypes are shaped by larger data collectives that precede and continuously change how the individual is represented. We contend that looking beyond the individual is crucial for understanding the factors that can ‘bend’ digital mirrors in specific directions. Since algorithms used for digital profiling are based on historical data, their predictions often inherit and increase the values and perspectives of past data practices. Moreover, the data legacies we leave behind today may return as so-called ‘data phantoms’ that conflict with the interests of the individual and contest who and what the ‘original’ is. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211036799",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Sara Green",
        "Mette N. Svendsen"
      ],
      "url": "https://doi.org/10.1177/20539517211036799",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 25,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "cad89c30-424c-454a-8b3b-6c4ce8bf9497",
    "title": "Data as performance – Showcasing cities through open data maps",
    "abstract": "This article describes how the City of Los Angeles is showcasing data-driven services to the public through dynamic visualisations of open data. I frame an analysis of this aspect of datafication in local government through linguistics and cultural theory; drawing on this set of literature I theorise the use of public data as both a performative tool and a performance of data-driven city services. I then discuss examples of interactive maps on the City of Los Angeles’ open data websites, produced by the Bureau of Sanitation, the Controller’s Office, and the Department of Transportation. The article concludes with some general thoughts on how open data maps are a new form of impression management; they set up a relationship in which government and citizens are in alignment, sharing an orientation towards administrative problems that begins at the same point, framed by an administration’s datasets.",
    "metadata": {
      "doi": "10.1177/2053951720907953",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Morgan Currie"
      ],
      "url": "https://doi.org/10.1177/2053951720907953",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172090795",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 37,
      "is_referenced_by_count": 21,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3eded8e7-ca0e-4a69-8c40-9bba879e520e",
    "title": "After the crisis? Big Data and the methodological challenges of empirical sociology",
    "abstract": "<jats:p> Google Trends reveals that at the time we were writing our article on ‘The Coming Crisis of Empirical Sociology’ in 2007 almost nobody was searching the internet for ‘Big Data’. It was only towards the very end of 2010 that the term began to register, just ahead of an explosion of interest from 2011 onwards. In this commentary we take the opportunity to reflect back on the claims we made in that original paper in light of more recent discussions about the social scientific implications of the inundation of digital data. Did our paper, with its emphasis on the emergence of, what we termed, ‘social transactional data’ and ‘digital byproduct data’ prefigure contemporary debates that now form the basis and rationale for this excellent new journal? Or was the paper more concerned with broader methodological, theoretical and political debates that have somehow been lost in all of the loud babble that has come to surround Big Data. Using recent work on the BBC Great British Class Survey as an example this brief paper offers a reflexive and critical reflection on what has become – much to the surprise of its authors – one of the most cited papers in the discipline of sociology in the last decade. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714540280",
      "type": "journal-article",
      "published": [
        2014,
        4,
        1
      ],
      "authors": [
        "Roger Burrows",
        "Mike Savage"
      ],
      "url": "https://doi.org/10.1177/2053951714540280",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 24,
      "is_referenced_by_count": 160,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e1f5a9c2-3aa1-47ac-872b-5f34f9d117a7",
    "title": "(Tar)getting you: The use of online political targeted messages on Facebook",
    "abstract": "<jats:p> This study examines how mainstream political actors and other organizations use political targeted messages. For this purpose, a data set from ProPublica is used. The study examines 55,918 sponsored Facebook ads that were posted by 236 political actors (i.e., political elites and other organizations) in the United States. (1) Topic classification was used to identify policy issues, (2) network analysis to identify the main policy issues from the various political actors, and (3) Sankey diagrams to visualize microtargeted messages. Our findings indicate that actors focus on traditionally owned issues (i.e., the Democratic Party: environmental policy, social issues, and social welfare; the Republican Party: foreign affairs, law, and government finances). No clear evidence for a focus on wedge issues can be found, however, some first indications (e.g., a focus on reproductive rights, LGBTQ+) are present in a targeted media environment. All in all, the current study helps us to understand in what way political actors deploy targeted messages. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221089626",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Sanne Kruikemeier",
        "Susan Vermeer",
        "Nadia Metoui",
        "Tom Dobber",
        "Brahim Zarouali"
      ],
      "url": "https://doi.org/10.1177/20539517221089626",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a5fca951-82b7-4a4b-8062-f5551c1ec39c",
    "title": "Fact signalling and fact nostalgia in the data-driven society",
    "abstract": "<jats:p> Post-truth tells the story of a public descending into unreason, aided and abetted by platforms and other data-driven systems. But this apparent collapse of epistemic consensus is, I argue, also dominated by loud and aggressive commitment to the idea of facts and Reason – a site where an imagined modern past is being pillaged for vestigial legitimacy. This article identifies two common practices of such reappropriation and mythologisation. (1) Fact signalling involves performative invocations of facts and Reason, which are then weaponised to discredit communicative rivals and establish affective solidarity. This is often closely tied to (2) fact nostalgia: the cultivation of an imagined past when ‘facts were facts’ and we, the good liberal subjects, could recognise facts when we saw them. Both tendencies are underwritten by a myth of connection: the still enduring narrative that maximising the circulation of information regardless of provenance or meaning will eventually yield a more rational public – even as data-driven systems tend to undermine the very conditions for such a public. Drawing on examples from YouTube-amplified ‘alternative influencers’ in the American right, and the normative discourses around fact-checking practices, I argue that this continued reliance on the vestigial authority of the modern past is a pernicious obstacle in normative debates around data-driven publics, keeping us stuck on the same dead-end scripts of heroically suspicious individuals and ignorant, irrational masses. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231164118",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Sun-ha Hong"
      ],
      "url": "https://doi.org/10.1177/20539517231164118",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 96,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8404864d-2b48-406d-854b-b39fd8cb8079",
    "title": "Toward a computational hermeneutics",
    "abstract": "<jats:p> We describe some of the ways that the field of content analysis is being transformed in an Era of Big Data. We argue that content analysis, from its beginning, has been concerned with extracting the main meanings of a text and mapping those meanings onto the space of a textual corpus. In contrast, we suggest that the emergence of new styles of text mining tools is creating an opportunity to develop a different kind of content analysis that we describe as a computational hermeneutics. Here the goal is to go beyond a mapping of the main meaning of a text to mimic the kinds of questions and concerns that have traditionally been the focus of a hermeneutically grounded close reading, a reading that focuses on what Kenneth Burke described as the poetic meanings of a text. We illustrate this approach by referring to our own work concerning the rhetorical character of US National Security Strategy documents. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715613809",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "John W Mohr",
        "Robin Wagner-Pacifici",
        "Ronald L Breiger"
      ],
      "url": "https://doi.org/10.1177/2053951715613809",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 34,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "67c44eb9-7021-429a-8e15-543f2854641b",
    "title": "The ‘doings’ behind data: An ethnography of police data construction",
    "abstract": "<jats:p> Public organisations, like the Netherlands Police, increasingly rely on data. Despite its importance, there has been limited empirical attention to how data is created and how its situated context impacts algorithmic interpretation of data. Using the Netherlands Police as a research focus, this study aims to fill this gap by studying datafication from an interpretivist perspective, emphasising the importance of material factors and human actors engaging in ‘data work’. The main research question is: How do material factors and human actors interact in ‘data work’ to enable datafication of street-level situated contexts at the Netherlands Police? The study builds on nearly 200 h of ethnographic fieldwork with street-level employees at the Netherlands Police. It finds that data work is deeply embedded in daily policing and is shaped by personal values, organisational context, and practical considerations. The findings highlight challenges posed by structured and unstructured data entry in the registration software for police reports. Structured data limit discretion with predefined labels, often conflicting with employees’ own perceptions. Unstructured data offer more flexibility but pose challenges such as linguistic nuance, inconsistencies, and the presence of ‘voice’ in police reports that complicate data interpretation. The study unearths various patterns of the interplay between human actors and material factors in relation to their situated contexts, which impact how police reports are constructed through a registration system. This approach, emphasising the interplay between material factors, human actors, organisational dynamics, and contextual factors, can help public sector organisations take steps towards responsible algorithmic interpretation of data. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241270695",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Isabelle Donatz-Fest"
      ],
      "url": "https://doi.org/10.1177/20539517241270695",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 63,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "efac635f-686b-4838-9aae-f5cd1442e9ef",
    "title": "Digital platforms in the agricultural sector: Dynamics of oligopolistic platformisation",
    "abstract": "<jats:p> This paper introduces the concept of ‘oligopolistic platformisation’ to capture the specific dynamics of collaboration and competition between multinational upstream agribusinesses and Big Tech companies in the agricultural (ag) sector. We examine this phenomenon through the lens of Van Dijck et al.’s platform mechanisms: datafication, selection and commodification. Multinational agribusinesses operate sectoral ag platforms that analyse spatial, weather and agronomic data to optimise farming operations, whilst Big Tech companies provide the digital infrastructure, including cloud computing, data analytics and artificial intelligence. We explore how these pre-existing oligopolistic market structures influence the process and outcomes of platformisation in the ag sector. Using expert interviews, field observations, economic relationship mapping and an extensive literature review, we investigate relationships amongst multinational agribusinesses and between agribusinesses and Big Tech companies. Our findings reveal that Big Tech and multinational agribusinesses are collaboratively establishing digital platforms as the core organisational form of digital agriculture, aiming to consolidate most services. This collaboration blurs the lines between traditionally distinct industries, fostering overlapping ecosystems and mutually beneficial economic relationships in an already highly concentrated market. This dynamic has the potential to reinforce the market position of established companies, increase farmers’ dependency on agribusinesses and contribute to fragmented and siloed data systems. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241306365",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Monja Sauvagerd",
        "Maximilian Mayer",
        "Monika Hartmann"
      ],
      "url": "https://doi.org/10.1177/20539517241306365",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 99,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "28cb381b-146a-4f63-96de-3ac95fdd9774",
    "title": "Consumers are willing to pay a price for explainable, but not for green AI. Evidence from a choice-based conjoint analysis",
    "abstract": "<jats:p> A major challenge with the increasing use of Artificial Intelligence (AI) applications is to manage the long-term societal impacts of this technology. Two central concerns that have emerged in this respect are that the optimized goals behind the data processing of AI applications usually remain opaque and the energy footprint of their data processing is growing quickly. This study thus explores how much people value the transparency and environmental sustainability of AI using the example of personal AI assistants. The results from a choice-based conjoint analysis with a sample of more than 1.000 respondents from Germany indicate that people hardly care about the energy efficiency of AI; and while they do value transparency through explainable AI, this added value of an application is offset by minor costs. The findings shed light on what kinds of AI people are likely to demand and have important implications for policy and regulation. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211069632",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Pascal D König",
        "Stefan Wurster",
        "Markus B Siewert"
      ],
      "url": "https://doi.org/10.1177/20539517211069632",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 71,
      "is_referenced_by_count": 28,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3f9903c1-24f4-4da0-ab69-55eed56c8c03",
    "title": "A view from data science",
    "abstract": "<jats:p> For better and worse, our world has been transformed by Big Data. To understand digital traces generated by individuals, we need to design multidisciplinary approaches that combine social and data science. Data and social scientists face the challenge of effectively building upon each other’s approaches to overcome the limitations inherent in each side. Here, we offer a “data science perspective” on the challenges that arise when working to establish this interdisciplinary environment. We discuss how we perceive the differences and commonalities of the questions we ask to understand digital behaviors (including how we answer them), and how our methods may complement each other. Finally, we describe what a path toward common ground between these fields looks like when viewed from data science. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211040198",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Anna Sapienza",
        "Sune Lehmann"
      ],
      "url": "https://doi.org/10.1177/20539517211040198",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 17,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "41e631d3-9ead-46df-8bf6-b62657be5d40",
    "title": "Artificial intelligence and skills in the workplace: An integrative research agenda",
    "abstract": "<jats:p> The development and diffusion of artificial intelligence (AI) technologies in workplaces are transforming the nature of work practices and their constituent skill requirements. This dual transformation is challenging for workers, organisations and societies, who are faced with the need to develop and enhance extant and new skills required to succeed in increasingly AI-mediated work settings. Although literature has recognised skills as a key factor in the development and uptake of AI technologies, there has been paucity of empirical research on the precise nature of skill requirements in AI-mediated workplaces. This commentary argues that to advance our understanding of skill requirements in AI-mediated workplaces, an integrative, multidisciplinary, multimethod and multistakeholder approach is required. The commentary proposes an agenda for future research in this societally important but poorly understood area. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231206804",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Anoush Margaryan"
      ],
      "url": "https://doi.org/10.1177/20539517231206804",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 29,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5ea15568-11c3-476c-99b9-a1360b08a07a",
    "title": "Governing algorithmic decisions: The role of decision importance and governance on perceived legitimacy of algorithmic decisions",
    "abstract": "<jats:p> The algorithmic accountability literature to date has primarily focused on procedural tools to govern automated decision-making systems. That prescriptive literature elides a fundamentally empirical question: whether and under what circumstances, if any, is the use of algorithmic systems to make public policy decisions perceived as legitimate? The present study begins to answer this question. Using factorial vignette survey methodology, we explore the relative importance of the type of decision, the procedural governance, the input data used, and outcome errors on perceptions of the legitimacy of algorithmic public policy decisions as compared to similar human decisions. Among other findings, we find that the type of decision—low importance versus high importance—impacts the perceived legitimacy of automated decisions. We find that human governance of algorithmic systems (aka human-in-the-loop) increases perceptions of the legitimacy of algorithmic decision-making systems, even when those decisions are likely to result in significant errors. Notably, we also find the penalty to perceived legitimacy is greater when human decision-makers make mistakes than when algorithmic systems make the same errors. The positive impact on perceived legitimacy from governance—such as human-in-the-loop—is greatest for highly pivotal decisions such as parole, policing, and healthcare. After discussing the study’s limitations, we outline avenues for future research. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221100449",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Ari Waldman",
        "Kirsten Martin"
      ],
      "url": "https://doi.org/10.1177/20539517221100449",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 108,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8e0c52a0-5974-4c6a-b305-28be26ec8fe0",
    "title": "Administrative social science data: The challenge of reproducible research",
    "abstract": "<jats:p> Powerful new social science data resources are emerging. One particularly important source is administrative data, which were originally collected for organisational purposes but often contain information that is suitable for social science research. In this paper we outline the concept of reproducible research in relation to micro-level administrative social science data. Our central claim is that a planned and organised workflow is essential for high quality research using micro-level administrative social science data. We argue that it is essential for researchers to share research code, because code sharing enables the elements of reproducible research. First, it enables results to be duplicated and therefore allows the accuracy and validity of analyses to be evaluated. Second, it facilitates further tests of the robustness of the original piece of research. Drawing on insights from computer science and other disciplines that have been engaged in e-Research we discuss and advocate the use of Git repositories to provide a useable and effective solution to research code sharing and rendering social science research using micro-level administrative data reproducible. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716684143",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Christopher J Playford",
        "Vernon Gayle",
        "Roxanne Connelly",
        "Alasdair JG Gray"
      ],
      "url": "https://doi.org/10.1177/2053951716684143",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 66,
      "is_referenced_by_count": 16,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b4ba6dbe-32f2-4187-864b-5b12111f80c7",
    "title": "Aestheticizing Google critique: A 20-year retrospective",
    "abstract": "<jats:p> With Google marking its 20th year online, the piece provides a retrospective of cultural commentary and select works of Google art that have transformed the search engine into an object of critical interest. Taken up are artistic and cultural responses to Google by independent artists but also by cultural critics and technology writers, including the development of such evocative notions as the deep web, flickering man and filter bubble. Among the critiques that have taken shape in the works to be discussed here are objects and subjects brought into being by Google (such as ‘spammy neighbourhoods’), Googlization, Google’s information politics, its licensing (or what one is agreeing to when searching) as well as issues surrounding specific products such as Google Street View, as Google leaves the web, capturing more spaces to search. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718768626",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Richard Rogers"
      ],
      "url": "https://doi.org/10.1177/2053951718768626",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 64,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5f251ef5-0409-4b0e-84ce-fc7ba598e311",
    "title": "Algorithmic reparation",
    "abstract": "<jats:p> Machine learning algorithms pervade contemporary society. They are integral to social institutions, inform processes of governance, and animate the mundane technologies of daily life. Consistently, the outcomes of machine learning reflect, reproduce, and amplify structural inequalities. The field of fair machine learning has emerged in response, developing mathematical techniques that increase fairness based on anti-classification, classification parity, and calibration standards. In practice, these computational correctives invariably fall short, operating from an algorithmic idealism that does not, and cannot, address systemic, Intersectional stratifications. Taking present fair machine learning methods as our point of departure, we suggest instead the notion and practice of algorithmic reparation. Rooted in theories of Intersectionality, reparative algorithms name, unmask, and undo allocative and representational harms as they materialize in sociotechnical form. We propose algorithmic reparation as a foundation for building, evaluating, adjusting, and when necessary, omitting and eradicating machine learning systems. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211044808",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Jenny L. Davis",
        "Apryl Williams",
        "Michael W. Yang"
      ],
      "url": "https://doi.org/10.1177/20539517211044808",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 111,
      "is_referenced_by_count": 75,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7e1ce706-10f1-476a-9f55-a7614e10ece9",
    "title": "Advancing search engine studies: The evolution of Google critique and intervention",
    "abstract": "<jats:p> In this piece, which frames the special issue, “The State of Google Critique and Intervention,” we provide an overview of research focusing on Google as an object of critical study, fleshing out the European interventions that actively attempt to address its dominance. The article begins by mapping out key areas of articulating a Google critique, from the initial focus on ranking and profiling to the subsequent scrutiny of user exploitation and competitive imbalance. As such, it situates the contributions to this special issue concerning search engine bias and discrimination, the ethics of Google Autocomplete, Google's content moderation, the commodification of engine audiences and the political economy of technical systems in a broader history of Google criticism. It then proceeds to contextualize the European developments that put forward alternatives and draws attention to legislative efforts to curb the influence of big tech. We conclude by identifying a few avenues for continued critical study, such as Google's infrastructural bundling of generative artificial intelligence with existing products, to emphasize the importance of intervention in the future. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231191528",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Astrid Mager",
        "Ov Cristian Norocel",
        "Richard Rogers"
      ],
      "url": "https://doi.org/10.1177/20539517231191528",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 75,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "db0abc11-1f37-40c9-8085-ba0a2957f6dc",
    "title": "World Heritage sites on Wikipedia: Cultural heritage activism in a context of constrained agency",
    "abstract": "<jats:p> UNESCO World Heritage sites are places of outstanding significance and often key sources of information that influence how people interact with the past today. The process of inscription on the UNESCO list is complicated and intersects with political and commercial controversies. But how well are these controversies known to the public? Wikipedia pages on these sites offer a unique dataset for insights into public understanding of heritage controversies. The unique technicity of Wikipedia, with its bot ecosystem and editing mechanics, shapes how knowledge about cultural heritage is constructed and how controversies are negotiated and communicated. In this article, we investigate the patterns of production, consumption, and spatial and temporal distributions of Wikipedia pages for World Heritage cultural sites. We find that Wikipedia provides a distinctive context for investigating how people experience and relate to the past in the present. The agency of participants is highly constrained, but distinctive, behind-the-scenes expressions of cultural heritage activism are evident. Concerns about state-like actors, violence and destruction, deal-making, etc. in the World Heritage inscription process are present, but rare on Wikipedia’s World Heritage pages. Instead, hyper-local and process issues dominate controversies on Wikipedia. We describe how this kind of research, drawing on Big Data and data science methods, contributes to digital heritage studies and also reveals its limitations. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211017304",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Ben Marwick",
        "Prema Smith"
      ],
      "url": "https://doi.org/10.1177/20539517211017304",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 68,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d4cc21d8-9ea5-48ff-9a9a-410a965573b3",
    "title": "The ethics of algorithms: Mapping the debate",
    "abstract": "<jats:p> In information societies, operations, decisions and choices previously left to humans are increasingly delegated to algorithms, which may advise, if not decide, about how data should be interpreted and what actions should be taken as a result. More and more often, algorithms mediate social processes, business transactions, governmental decisions, and how we perceive, understand, and interact among ourselves and with the environment. Gaps between the design and operation of algorithms and our understanding of their ethical implications can have severe consequences affecting individuals as well as groups and whole societies. This paper makes three contributions to clarify the ethical importance of algorithmic mediation. It provides a prescriptive map to organise the debate. It reviews the current discussion of ethical aspects of algorithms. And it assesses the available literature in order to identify areas requiring further work to develop the ethics of algorithms. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716679679",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Brent Daniel Mittelstadt",
        "Patrick Allo",
        "Mariarosaria Taddeo",
        "Sandra Wachter",
        "Luciano Floridi"
      ],
      "url": "https://doi.org/10.1177/2053951716679679",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 136,
      "is_referenced_by_count": 1307,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7f7f5ed0-6e3a-43fd-aee2-7c49e21dc92f",
    "title": "What makes Big Data, Big Data? Exploring the ontological characteristics of 26 datasets",
    "abstract": "<jats:p> Big Data has been variously defined in the literature. In the main, definitions suggest that Big Data possess a suite of key traits: volume, velocity and variety (the 3Vs), but also exhaustivity, resolution, indexicality, relationality, extensionality and scalability. However, these definitions lack ontological clarity, with the term acting as an amorphous, catch-all label for a wide selection of data. In this paper, we consider the question ‘what makes Big Data, Big Data?’, applying Kitchin’s taxonomy of seven Big Data traits to 26 datasets drawn from seven domains, each of which is considered in the literature to constitute Big Data. The results demonstrate that only a handful of datasets possess all seven traits, and some do not possess either volume and/or variety. Instead, there are multiple forms of Big Data. Our analysis reveals that the key definitional boundary markers are the traits of velocity and exhaustivity. We contend that Big Data as an analytical category needs to be unpacked, with the genus of Big Data further delineated and its various species identified. It is only through such ontological work that we will gain conceptual clarity about what constitutes Big Data, formulate how best to make sense of it, and identify how it might be best used to make sense of the world. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716631130",
      "type": "journal-article",
      "published": [
        2016,
        6,
        1
      ],
      "authors": [
        "Rob Kitchin",
        "Gavin McArdle"
      ],
      "url": "https://doi.org/10.1177/2053951716631130",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 23,
      "is_referenced_by_count": 357,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "32987d1a-713f-4dce-bf3c-13ab7713449c",
    "title": "Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management",
    "abstract": "<jats:p> Algorithms increasingly make managerial decisions that people used to make. Perceptions of algorithms, regardless of the algorithms' actual performance, can significantly influence their adoption, yet we do not fully understand how people perceive decisions made by algorithms as compared with decisions made by humans. To explore perceptions of algorithmic management, we conducted an online experiment using four managerial decisions that required either mechanical or human skills. We manipulated the decision-maker (algorithmic or human), and measured perceived fairness, trust, and emotional response. With the mechanical tasks, algorithmic and human-made decisions were perceived as equally fair and trustworthy and evoked similar emotions; however, human managers' fairness and trustworthiness were attributed to the manager's authority, whereas algorithms' fairness and trustworthiness were attributed to their perceived efficiency and objectivity. Human decisions evoked some positive emotion due to the possibility of social recognition, whereas algorithmic decisions generated a more mixed response – algorithms were seen as helpful tools but also possible tracking mechanisms. With the human tasks, algorithmic decisions were perceived as less fair and trustworthy and evoked more negative emotion than human decisions. Algorithms' perceived lack of intuition and subjective judgment capabilities contributed to the lower fairness and trustworthiness judgments. Positive emotion from human decisions was attributed to social recognition, while negative emotion from algorithmic decisions was attributed to the dehumanizing experience of being evaluated by machines. This work reveals people's lay concepts of algorithmic versus human decisions in a management context and suggests that task characteristics matter in understanding people's experiences with algorithmic technologies. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718756684",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Min Kyung Lee"
      ],
      "url": "https://doi.org/10.1177/2053951718756684",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 65,
      "is_referenced_by_count": 602,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "60bae516-290e-4cc1-ab30-46c32a469125",
    "title": "The value of mass-digitised cultural heritage content in creative contexts",
    "abstract": "<jats:p> How can digitised assets of Galleries, Libraries, Archives and Museums be reused to unlock new value? What are the implications of viewing large-scale cultural heritage data as an economic resource, to build new products and services upon? Drawing upon valuation studies, we reflect on both the theory and practicalities of using mass-digitised heritage content as an economic driver, stressing the need to consider the complexity of commercial-based outcomes within the context of cultural and creative industries. However, we also problematise the act of considering such heritage content as a resource to be exploited for economic growth, in order to inform how we consider, develop, deliver and value mass-digitisation. Our research will be of interest to those wishing to understand a rapidly changing research and innovation landscape, those considering how to engage memory institutions in data-driven activities and those critically evaluating years of mass-digitisation across the heritage sector. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211006165",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Melissa Terras",
        "Stephen Coleman",
        "Steven Drost",
        "Chris Elsden",
        "Ingi Helgason",
        "Susan Lechelt",
        "Nicola Osborne",
        "Inge Panneels",
        "Briana Pegado",
        "Burkhard Schafer",
        "Michael Smyth",
        "Pip Thornton",
        "Chris Speed"
      ],
      "url": "https://doi.org/10.1177/20539517211006165",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 106,
      "is_referenced_by_count": 19,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a716fecc-4f8e-461e-9a27-1eed0fc48bc6",
    "title": "Discovering needs for digital capitalism: The hybrid profession of data science",
    "abstract": "<jats:p> Over the last decade, ‘data scientists’ have burst into society as a novel expert role. They hold increasing responsibility for generating and analysing digitally captured human experiences. The article considers their professionalization not as a functionally necessary development but as the outcome of classification practices and struggles. The rise of data scientists is examined across their discursive classification in the academic and economic fields in both the USA and Germany. Despite notable differences across these fields and nations, the article identifies two common subjectivation patterns. Firstly, data scientists are constructed as hybrids, who combine generally conflictive roles as both generalists and specialists; technicians and communicators; data exploiters and data ethicists. This finding is interpreted as demonstrating a discursive distinction between data scientists and other competing and supposedly more one-dimensional professionals, such as statisticians or computer scientists. Secondly, the article uncovers a discursive construction that interpellates data scientists as discoverers of needs. They are imagined as explorative work subjects who can establish growth for digital capitalism by generating behavioural patterns that allow for personalization, customization and optimization practices. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211040760",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Robert Dorschel"
      ],
      "url": "https://doi.org/10.1177/20539517211040760",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 65,
      "is_referenced_by_count": 22,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2659e633-1035-4484-9cce-321484a6b417",
    "title": "Data diaries: A situated approach to the study of data",
    "abstract": "<jats:p> This article adapts the ethnographic medium of the diary to develop a method for studying data and related data practices. The article focuses on the creation of one data diary, developed iteratively over three years in the context of a national centre for monitoring disasters and natural hazards in Brazil (Cemaden). We describe four points of focus involved in the creation of a data diary – spaces, interfaces, types and situations – before reflecting on the value of this method. We suggest data diaries (1) are able to capture the informal dimension of data-intensive organisations; (2) enable empirical analysis of the specific ways that data intervene in the unfolding of situations; and (3) as a document, data diaries can foster interdisciplinary and inter-expert dialogue by bridging different ways of knowing data. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951721996036",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Nathaniel Tkacz",
        "Mário Henrique da Mata Martins",
        "João Porto de Albuquerque",
        "Flávio Horita",
        "Giovanni Dolif Neto"
      ],
      "url": "https://doi.org/10.1177/2053951721996036",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 63,
      "is_referenced_by_count": 15,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "54a7336d-46cb-442d-a2df-f3eaeef1ecaa",
    "title": "Productive measures: Culture and measurement in the context of everyday neoliberalism",
    "abstract": "<jats:p> This article reflects on how data circulations and data analysis have become a central and routine part of contemporary life; it does this through the lens of a particular cultural form: the game of football. More specifically, the article focuses upon the role of data in the production and playing of football, with the suggestion that forms of measurement and pattern recognition are now central to the performance of footballers and the recruitment and organization of squads. The article reflects on what this case study reveals about the implications of data, metrics and analytics for contemporary culture and suggests that we can use examples like football to see how embedded these data-processes are in the social world. This article presents the concept of productive measures as one means for analysing such developments. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715578951",
      "type": "journal-article",
      "published": [
        2015,
        5,
        1
      ],
      "authors": [
        "David Beer"
      ],
      "url": "https://doi.org/10.1177/2053951715578951",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 46,
      "is_referenced_by_count": 59,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "37e46f9f-8dc7-4e15-89f0-10b147156e4c",
    "title": "Data flows and water woes: The Utah Data Center",
    "abstract": "<jats:p> Using a new materialist line of questioning that looks at the agential potentialities of water and its entanglements with Big Data and surveillance, this article explores how the recent Snowden revelations about the National Security Agency (NSA) have reignited media scholars to engage with the infrastructures that enable intercepting, hosting, and processing immeasurable amounts of data. Focusing on the expansive architecture, location, and resource dependence of the NSA’s Utah Data Center, I demonstrate how surveillance and privacy can never be disconnected from the material infrastructures that allow and render natural the epistemological state of mass surveillance. Specifically, I explore the NSA’s infrastructure and the million of gallons of water it requires daily to cool its servers, while located in one of the driest states in the US. Complicating surveillance beyond the NSA, as also already imbricated with various social media companies, this article questions the emplacement and impact of corporate data centers more generally, and the changes they are causing to the landscape and local economies. I look at how water is an intriguing and politically relevant part of the surveillance infrastructure and how it has been constructed as the main tool for activism in this case, and how it may eventually help transform the public’s conceptualization of Big Data, as deeply material. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715592429",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Mél Hogan"
      ],
      "url": "https://doi.org/10.1177/2053951715592429",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 81,
      "is_referenced_by_count": 120,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d993241c-8e89-4e25-944c-b4094d14d9e0",
    "title": "The chat-chamber effect: Trusting the AI hallucination",
    "abstract": "<jats:p>This study investigates the potential for ChatGPT to trigger a media effect that sits at the intersection of echo-chamber communication and filter bubbles. We devised a two-phase, two-stage experimental design with ChatGPT 3.5 (treatment group) and Google search engine (control group) by asking participants to find out how many LGBTQIA+ individuals served as elected representatives in India (first phase) and Ireland (second phase). The similar trajectories of legal reforms observed in these countries, and their small number of LGBTQIA+ elected representatives, allowed us to identify the fault lines in ChatGPT's creation of knowledge and information around LGBTQ issues. We followed the experimental study with semi-structured interviews to identify whether the chatbot reinforced previously held beliefs and whether users cross-checked the information provided by ChatGPT. Our results show that Large Language Models may provide incorrect but proattitudinal information that remains unchecked and unverified by the users, an effect we refer to as Chat-Chamber. We conclude with a discussion of our findings and recommendations for future research in the area.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241306345",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Christo Jacob",
        "Páraic Kerrigan",
        "Marco Bastos"
      ],
      "url": "https://doi.org/10.1177/20539517241306345",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 52,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3d455b6a-47f1-4ea6-aaeb-525514c8a238",
    "title": "Official statistics and big data in Latin America: Data enclosures and counter-movements",
    "abstract": "<jats:p> With the rise of the data-driven economy, the state-owned sector of official statistics has been pressurised to ‘modernise’ and engage with big data. However, most of these data sources are controlled by tech corporations. We address the conflicts this brings about from a Latin American perspective through three case studies involving national statistical offices, international organisations, and the private sector. We investigate strategies for enabling data markets for official statistics and analyse how the statistical field has acted in this context. In doing so, we contribute to understanding the political economy of big data in Latin America and debates on how digitalisation encompasses the reshaping of state-business relations. Supported by secondary data and semi-structured interviews, we appraise Bourdieu's theory of fields, Marxian readings on the enclosure of commons, and Polanyi's double movement to analyse how data commodification challenges data as public goods – a fundamental principle for official statistics. The findings demonstrate that data enclosures have prevented the state's access to compiling official statistics and show that the initiatives for introducing big data in Latin American national statistical offices have involved testing data markets through public–private partnerships supported by international organisations and big tech. As a result, the statistical field has reacted to the data market with a ‘double movement’: mobilising symbolic capital such as ‘trust’ for partnering with businesses to access data and technologies and, conversely, defending the public value of data in counter-movements protective of the relative autonomy of the national statistical offices and the state's control over informational capital. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241229696",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Oscar Arruda d’Alva",
        "Edemilson Paraná"
      ],
      "url": "https://doi.org/10.1177/20539517241229696",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 79,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2d57774d-cc6c-449c-9cbf-9bf926f9e163",
    "title": "The world wide web of carbon: Toward a relational footprinting of information and communications technology's climate impacts",
    "abstract": "<jats:p> The climate impacts of the information and communications technology sector—and Big Data especially—is a topic of growing public and industry concern, though attempts to quantify its carbon footprint have produced contradictory results. Some studies argue that information and communications technology's global carbon footprint is set to rise dramatically in the coming years, requiring urgent regulation and sectoral degrowth. Others argue that information and communications technology's growth is largely decoupled from its carbon emissions, and so provides valuable climate solutions and a model for other industries. This article assesses these debates, arguing that, due to data frictions and incommensurate study designs, the question is likely to remain irresolvable at the global scale. We present six methodological factors that drive this impasse: fraught access to industry data, bottom-up vs. top-down assessments, system boundaries, geographic averaging, functional units, and energy efficiencies. In response, we propose an alternative approach that reframes the question in spatial and situated terms: A relational footprinting that demarcates particular relationships between elements—geographic, technical, and social—within broader information and communications technology infrastructures. Illustrating this model with one of the global Internet's most overlooked components—subsea telecommunication cables—we propose that information and communications technology futures would be best charted not only in terms of quantified total energy use, but in specifying the geographical and technical parts of the network that are the least carbon-intensive, and which can therefore provide opportunities for both carbon reductions and a renewed infrastructural politics. In parallel to the politics of (de)growth, we must also consider different network forms. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231158994",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Anne Pasek",
        "Hunter Vaughan",
        "Nicole Starosielski"
      ],
      "url": "https://doi.org/10.1177/20539517231158994",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 80,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9038c80b-4333-4176-99b4-7d43c7dea065",
    "title": "The promises and challenges of addressing artificial intelligence with human rights",
    "abstract": "<jats:p> This paper examines the potential promises and limitations of the human rights framework in the age of AI. It addresses the question: what, if anything, makes human rights well suited to face the challenges arising from new and emerging technologies like AI? It argues that the historical evolution of human rights as a series of legal norms and concrete practices has made it well placed to address AI-related challenges. The human rights framework should be understood comprehensively as a combination of legal remedies, moral justification, and political analysis that inform one another. Over time, the framework has evolved in ways that accommodate the balancing of contending rights claims, using multiple ex ante and ex post facto mechanisms, involving government and/or business actors, and in situations of diffuse responsibility that may or may not result from malicious intent. However, the widespread adoption of AI technologies pushes the moral, sociological, and political boundaries of the human rights framework in other ways. AI reproduces long-term, structural problems going beyond issue-by-issue regulation, is embedded within economic structures that produce cumulative negative effects, and introduces additional challenges that require a discussion about the relationship between human rights and science &amp; technology. Some of the reasons for why AI produces problematic outcomes are deep rooted in technical intricacies that human rights practitioners should be more willing than before to get involved in. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231205476",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Onur Bakiner"
      ],
      "url": "https://doi.org/10.1177/20539517231205476",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 99,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "eea46b99-2606-4786-bc92-5fb2b9868c3b",
    "title": "Repair work, resistance and the invisible data labour of Lebanon's digital humanitarian infrastructures",
    "abstract": "<jats:p>This article draws upon a multi-sited ethnography of everyday labour in Lebanon's digital cash assistance for Syrian refugees. The datafication of humanitarian infrastructures generates technological breakdown, gaps in data and incredibly strict and cumbersome rules. In response to impediments related to biometric identification and automated poverty targeting, this article argues that humanitarian staff, refugee recipients and community members engage in ‘repair work’ – the subtle and quotidian labour that goes into addressing fragility and maintaining functionality. Inspired by feminist studies of labour, repair work is found to be invisible in being undervalued, unpaid and reproductive, which is reminiscent of labour that has historically fallen to disenfranchised people. Repair work also enables data workers to assert their autonomy and contest infrastructures that they framed as being unreasonable and unjust. In doing so, findings suggest that repair work is fundamental to the ability of data-driven aid programmes to cater to the needs of populations in crisis. This paper marks two contributions to understanding the promise and perils of ‘Technology for Good’: it introduces repair work as a novel conceptual framework to analyse labour involved in the datafication of aid, and it applies new empirical evidence to critical studies of data work.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517251318268",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Jenna Imad Harb"
      ],
      "url": "https://doi.org/10.1177/20539517251318268",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 80,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bea6e4bd-9fb0-4e60-9fdb-9a34ece78d0e",
    "title": "How do data come to matter? Living and becoming with personal data",
    "abstract": "<jats:p> Humans have become increasingly datafied with the use of digital technologies that generate information with and about their bodies and everyday lives. The onto-epistemological dimensions of human–data assemblages and their relationship to bodies and selves have yet to be thoroughly theorised. In this essay, I draw on key perspectives espoused in feminist materialism, vital materialism and the anthropology of material culture to examine the ways in which these assemblages operate as part of knowing, perceiving and sensing human bodies. I draw particularly on scholarship that employs organic metaphors and concepts of vitality, growth, making, articulation, composition and decomposition. I show how these metaphors and concepts relate to and build on each other, and how they can be applied to think through humans’ encounters with their digital data. I argue that these theoretical perspectives work to highlight the material and embodied dimensions of human–data assemblages as they grow and are enacted, articulated and incorporated into everyday lives. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718786314",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Deborah Lupton"
      ],
      "url": "https://doi.org/10.1177/2053951718786314",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 57,
      "is_referenced_by_count": 133,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "99676685-4ab7-46cf-bfc7-3710ba91734c",
    "title": "Conceptualising the right to data protection in an era of Big Data",
    "abstract": "<jats:p> In 2009, with the enactment of the Lisbon Treaty, the Charter of Fundamental Rights of the European Union entered into force. Under Article 8 of the Charter, for the first time, a stand-alone fundamental right to data protection was declared. The creation of this right, standing as a distinct right to the right to privacy, is undoubtedly significant, and it is unique to the European legal order, being absent from other international human rights instruments. This commentary examines the parameters of this new right to data protection, asking what are the principles underpinning the right. It argues that the right reflects some key values inherent in the European legal order, namely: privacy, transparency, autonomy and nondiscrimination. It also analyses some of the challenges in implementing this right in an era of ubiquitous veillance practices and Big Data. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716686994",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Yvonne McDermott"
      ],
      "url": "https://doi.org/10.1177/2053951716686994",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 44,
      "is_referenced_by_count": 45,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "752fa2db-9ed6-484c-bbfe-abecb66d26a3",
    "title": "Datafication and empowerment: How the open data movement re-articulates notions of democracy, participation, and journalism",
    "abstract": "<jats:p> This article shows how activists in the open data movement re-articulate notions of democracy, participation, and journalism by applying practices and values from open source culture to the creation and use of data. Focusing on the Open Knowledge Foundation Germany and drawing from a combination of interviews and content analysis, it argues that this process leads activists to develop new rationalities around datafication that can support the agency of datafied publics. Three modulations of open source are identified: First, by regarding data as a prerequisite for generating knowledge, activists transform the sharing of source code to include the sharing of raw data. Sharing raw data should break the interpretative monopoly of governments and would allow people to make their own interpretation of data about public issues. Second, activists connect this idea to an open and flexible form of representative democracy by applying the open source model of participation to political participation. Third, activists acknowledge that intermediaries are necessary to make raw data accessible to the public. This leads them to an interest in transforming journalism to become an intermediary in this sense. At the same time, they try to act as intermediaries themselves and develop civic technologies to put their ideas into practice. The article concludes with suggesting that the practices and ideas of open data activists are relevant because they illustrate the connection between datafication and open source culture and help to understand how datafication might support the agency of publics and actors outside big government and big business. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715594634",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Stefan Baack"
      ],
      "url": "https://doi.org/10.1177/2053951715594634",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 50,
      "is_referenced_by_count": 175,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "15e18e71-3cbe-45a3-b195-a3534a053b9d",
    "title": "Sharing digital trace data: Researchers’ challenges and needs",
    "abstract": "<jats:p>Over the past decade, research has made rapid progress in the collection and analysis of digital trace data. However, when it comes to sharing data, researchers still face major barriers that often limit or prevent the reproducibility of research results and the reuse of data. Against this backdrop, we identify three broader categories of user challenges, namely researchers’ capacities &amp; incentives, legal &amp; ethical challenges, and technical hurdles. We describe in detail the problems researchers face in each category and why these often prevent researchers from sharing data, thus limiting both the reproducibility of research outputs and data reuse in other research projects. We conclude each category with specific needs of researchers for sharing digital trace data and making it reusable for others. These are intended to provide researchers as well as research institutes and repositories with approaches to improve the situation of data sharing.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517251325211",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Jan Schwalbach",
        "Reiner Mauer"
      ],
      "url": "https://doi.org/10.1177/20539517251325211",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 17,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "961fc223-127e-4018-b506-df9ecfcfe0b7",
    "title": "Outsourcing accountability: Extractive data practice and inequities of power in humanitarian third-party monitoring",
    "abstract": "<jats:p>Since the early 2010s, humanitarian donors have increasingly contracted private firms to monitor and evaluate humanitarian activities, accompanied by a promise of improving accountability through their data and data analytics. This article contributes to scholarship on data practices in the humanitarian sector by interrogating the implications of this new set of actors on humanitarian accountability relations. Drawing on insights from 60 interviews with humanitarian donors, implementing agencies, third-party monitors and data enumerators in Somalia, this article interrogates data narratives and data practices around third-party monitoring. We find that, while humanitarian donors are highly aware of challenges to accountability within the sector, there is a less critical view of data challenges and limitations by these external firms. This fuels donor optimism about third-party monitoring data, while obscuring the ways that third-party monitoring data practices are complicating accountability relations in practice. Resultant data practices, which are aimed at separating data from the people involved, reproduce power asymmetries around the well-being and expertise of the Global North versus Global South. This challenges accountability to donors and to crisis-affected communities, by providing a partial view of reality that is, at the same time, assumed to be reflective of crisis-affected communities’ experiences. This article contributes to critical data studies by showing how monitoring data practices intended to improve accountability relations are imbued with, and reproduce, power asymmetries that silence local actors.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517251328250",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Stephanie Diepeveen",
        "John Bryant",
        "Mahad Wasuge"
      ],
      "url": "https://doi.org/10.1177/20539517251328250",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "464a73aa-7c56-4abc-9a1a-91247c7ad2fc",
    "title": "Researching data discomfort: The case of Statistics Norway’s quest for billing data",
    "abstract": "<jats:p>National statistics offices are increasingly exploring the possibilities of utilizing new data sources to position themselves in emerging data markets. In 2022, Statistics Norway announced that the national agency will require the biggest grocers in Norway to hand over all collected billing data to produce consumer behavior statistics which had previously been produced by other sampling methods. An online article discussing this proposal sparked a surprisingly (at least to Statistics Norway) high level of interest among readers, many of whom expressed concerns about this intended change in data practice. This paper focuses on the multifaceted online discussions of the proposal, as these enable us to study citizens’ reactions and feelings towards increased data collection and emerging public-private data flows in a Nordic context. Through an explorative empirical analysis of comment sections, this paper investigates what is discussed by commenters and reflects upon why this case sparked so much interest among citizens in the first place. It therefore contributes to the growing literature of citizens’ voices in data-driven administration and to a wider discussion on how to research public feeling towards datafication. I argue that this presents an interesting case of discomfort voiced by citizens, which demonstrates the contested nature of data practices among citizens–and their ability to regard data as deeply intertwined with power and politics. This case also reminds researchers to pay attention to seemingly benign and small changes in administration beyond artificial intelligence.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517251320008",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Lisa Reutter"
      ],
      "url": "https://doi.org/10.1177/20539517251320008",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f88a6126-902f-4d9c-bb50-b1638a1eb4e9",
    "title": "Electricity as (Big) Data: Metering, spatiotemporal granularity and value",
    "abstract": "<jats:p> Electricity is hidden within wires and networks only revealing its quantity and flow when metered. The making of its properties into data is therefore particularly important to the relations that are formed around electricity as a produced and managed phenomenon. We propose approaching all metering as a situated activity, a form of quantification work in which data is made and becomes mobile in particular spatial and temporal terms, enabling its entry into data infrastructures and schemes of evaluation and value production. We interrogate the transition from the pre-digital into the making of bigger, more spatiotemporally granular electricity data, through focusing on those actors selling and materialising new metering technologies, data infrastructures and services for larger businesses and public sector organisations in the UK. We examine the claims of truth and visibility that accompany these shifts and their enrolment into management techniques that serve to more precisely apportion responsibility for, and evaluate the status of, particular patterns and instances of electricity use. We argue that whilst through becoming Big Data electricity flow is now able to be known and given identity in significantly new terms, enabling new relations to be formed with the many heterogeneous entities implicated in making and managing energy demand, it is necessary to sustain some ambivalence as to the performative consequences that follow for energy governance. We consider the wider application of our conceptualisation of metering, reflecting on comparisons with the introduction of new metering systems in domestic settings and as part of other infrastructural networks. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718757254",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Mette Kragh-Furbo",
        "Gordon Walker"
      ],
      "url": "https://doi.org/10.1177/2053951718757254",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 66,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ff912f3b-5ce0-4a1e-84f4-4c926d9041d2",
    "title": "Algorithms in practice: Comparing web journalism and criminal justice",
    "abstract": "Big Data evangelists often argue that algorithms make decision-making more informed and objective—a promise hotly contested by critics of these technologies. Yet, to date, most of the debate has focused on the instruments themselves, rather than on how they are used. This article addresses this lack by examining the actual practices surrounding algorithmic technologies. Specifically, drawing on multi-sited ethnographic data, I compare how algorithms are used and interpreted in two institutional contexts with markedly different characteristics: web journalism and criminal justice. I find that there are surprising similarities in how web journalists and legal professionals use algorithms in their work. In both cases, I document a gap between the intended and actual effects of algorithms—a process I analyze as “decoupling.” Second, I identify a gamut of buffering strategies used by both web journalists and legal professionals to minimize the impact of algorithms in their daily work. Those include foot-dragging, gaming, and open critique. Of course, these similarities do not exhaust the differences between the two cases, which are explored in the discussion section. I conclude with a call for further ethnographic work on algorithms in practice as an important empirical check against the dominant rhetoric of algorithmic power.",
    "metadata": {
      "doi": "10.1177/2053951717718855",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Angèle Christin"
      ],
      "url": "https://doi.org/10.1177/2053951717718855",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171771885",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 57,
      "is_referenced_by_count": 208,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9e7bf4c8-95ab-4c6a-ad41-ff3970a64475",
    "title": "Algorithmic constructions of risk: Anticipating uncertain futures in child protection services",
    "abstract": "<jats:p> This paper examines how predictive algorithms construct risk by calculating and anticipating children's uncertain futures. Theoretically, we analyze algorithmic risk construction by attending to (a) the problematizations justifying algorithmic prediction, (b) their underpinning data infrastructures, and (c) the configurations of agencies across humans and machines. Empirically, we examine two experiments in Danish child protection services that developed algorithmic models to predict children's maltreatment. Our analysis highlights how algorithmic predictions can create different notions of risk. The first case used predictive algorithms to supplement human risk assessments with data from child protection services, while the second case aimed to detect risk early by constructing parents as risk factors, requiring data from other welfare sectors. By comparing these cases, we highlight two distinct risk constructions: one that uses algorithmic prediction to manage uncertainty and another that seeks to eliminate undesired futures by preempting risk. These different constructions have implications for how the present is viewed as a moment of intervention and for how families are constructed as “risk objects.” </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231186120",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Helene Friis Ratner",
        "Kasper Elmholdt"
      ],
      "url": "https://doi.org/10.1177/20539517231186120",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 43,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9aeda27d-77d5-4bb8-9d3b-5ecab6160a2c",
    "title": "Doing social media analytics",
    "abstract": "<jats:p> In the few years since the advent of ‘Big Data’ research, social media analytics has begun to accumulate studies drawing on social media as a resource and tool for research work. Yet, there has been relatively little attention paid to the development of methodologies for handling this kind of data. The few works that exist in this area often reflect upon the implications of ‘grand’ social science methodological concepts for new social media research (i.e. they focus on general issues such as sampling, data validity, ethics, etc.). By contrast, we advance an abductively oriented methodological suite designed to explore the construction of phenomena played out through social media. To do this, we use a software tool – Chorus – to illustrate a visual analytic approach to data. Informed by visual analytic principles, we posit a two-by-two methodological model of social media analytics, combining two data collection strategies with two analytic modes. We go on to demonstrate each of these four approaches ‘in action’, to help clarify how and why they might be used to address various research questions. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716658060",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Phillip Brooker",
        "Julie Barnett",
        "Timothy Cribbin"
      ],
      "url": "https://doi.org/10.1177/2053951716658060",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 33,
      "is_referenced_by_count": 70,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "36f8af6e-5efc-48b9-9476-8d7431e9f695",
    "title": "The fictionality of topic modeling: Machine reading Anthony Trollope's Barsetshire series",
    "abstract": "<jats:p> This essay describes how using unsupervised topic modeling (specifically the latent Dirichlet allocation topic modeling algorithm in MALLET) on relatively small corpuses can help scholars of literature circumvent the limitations of some existing theories of the novel. Using an example drawn from work on Victorian novelist Anthony Trollope's Barsetshire series, it argues that unsupervised topic modeling's counter-factual and retrospective reconstruction of the topics out of which a given set of novels have been created allows for a denaturalizing and unfamiliar (though crucially not “objective” or “unbiased”) view. In other words, topic models are fictions, and scholars of literature should consider reading them as such. Drawing on one aspect of Stephen Ramsay's idea of algorithmic criticism, the essay emphasizes the continuities between “big data” methods and techniques and longer-standing methods of literary study. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715610591",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Rachel Sagner Buurma"
      ],
      "url": "https://doi.org/10.1177/2053951715610591",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 16,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "384757f5-45ed-47d0-a0cd-9c3763cf0232",
    "title": "Redress and worldmaking: Differing approaches to algorithmic reparations for housing justice",
    "abstract": "<jats:p> A reparative approach to algorithmic justice provides a compelling alternative to existing fairness-based frameworks, which are often inadequate for challenging the technological perpetuation of unjust social hierarchies. The definition of “reparations,” however, is philosophically contested. I discuss two interrelated but distinct notions of reparations: reparations as accountability and redress for past injustice, and reparations as a constructive worldmaking project focused on present and future justice. Each of these perspectives offers different recommendations and provocations for how to implement algorithmic reparations. I apply this to a case study of housing injustice in the US and offer three interpretations of “algorithmic reparations” in context: first, we can litigate instances of algorithmic discrimination in housing. Second, we can use computational methods to compute damages and demand redress for structural housing injustice in the past. Finally, we can repurpose algorithmic methods to imagine more radical resistance efforts that connect incremental reform to large-scale structural change for the future. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231202983",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Aurora Zhang"
      ],
      "url": "https://doi.org/10.1177/20539517231202983",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 28,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b6dad4bc-61c0-44fe-b252-036b127633bf",
    "title": "Small moments in Spatial Big Data: Calculability, authority and interoperability in everyday mobile mapping",
    "abstract": "<jats:p> This article considers how Spatial Big Data is situated and produced through embodied spatial experiences as data processes appear and act in small moments on mobile phone applications and other digital spatial technologies. Locating Spatial Big Data in the historical and geographical contexts of Sydney and Hong Kong, it traces how situated knowledges mediate and moderate the rising potency of discourses of cartographic reason and data logics as colonial cartographic imaginations expressed in land divisions and urban planning continue on, in a world that increasingly values models of calculability, interoperability and authority. It draws on ethnographic material gathered through walking interviews in both cities, and in doing so, it argues that by using ethnographic ‘moments’, it is possible to decentre the focus on data processes to consider the critical potential of a politics of everyday experiences that produce and reflect the structures of data logics. Through these ethnographic moments, this article examines how mobile technologies are complicit in the production of Spatial Big Data, and the impact this has on the increasing regimentation and surveillance of modes of being and expression via mobile media. At the same time, it will argue that while spatial calculability has expanded from cartographic reason into data logics, the epistemological universality of Spatial Big Data is constantly being resisted – in moments of experimentation, failure, intuition, memory and desire, the ghosts of the incalculable epistemes, experiences and people, forgotten by the emphasis on calculation, continue to speak. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716661364",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Clancy Wilmott"
      ],
      "url": "https://doi.org/10.1177/2053951716661364",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 67,
      "is_referenced_by_count": 27,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e337b69f-b680-4bb0-a8c8-c3ad03483842",
    "title": "Digital payments and relational embedding: Turning relations into data and data into relations",
    "abstract": "<jats:p> Research on the digital economy has highlighted the assetization of data. This article argues for expanding existing research on data and datafication processes by focusing on how relationships are made and unmade through and from data. We introduce a general analytic model of “relationing” and show how relationships between users, companies, and products are created in three different moments—entanglement, dissection, and matching—first in the digital economy, then in physical stores. We show how payments with mobile phones connect the digital to the brick-and-mortar economy. Applying our model, we illustrate how a mobile phone's various data streams, money's record-keeping function, and retailers’ loyalty programs produce qualitatively and quantitatively new relations between customers, retailers, banks, app providers, and payment intermediaries. We argue that “relational embedding” captures the inherent relationality between users, their data points, and other economic actors: algorithmically relating users’ data profiles to other users’ profiles yields personalized recommendations, ads, or rebates, continuing the relationship between retailers and customers. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241266432",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Sophie Mützel",
        "Markus Unternährer"
      ],
      "url": "https://doi.org/10.1177/20539517241266432",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 62,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e46d9527-272c-4572-87a4-49023a3d7bb9",
    "title": "Smart campus communication, Internet of Things, and data governance: Understanding student tensions and imaginaries",
    "abstract": "<jats:p> In recent years, universities have been urged to restructure and re-evaluate their ability to trace and monitor their students as the “smart campus” is being built upon datafication, while networked apps and sensors serve as the means through which its constituents are connected and governed. This paper advances a dialectical and communication-centered approach to the Internet of Things campus ecosystem and provides an empirical investigation into (a) the tensions experienced by students and (b) the ways that these students envision alternative practices that support their digital engagement. Drawing upon student focus group interviews in a large American research and innovation intensive university, dialectical tensions identified include convenience–annoyance, integration–independence, and safety–insecurity, brought upon by students’ ongoing and prospective negotiations with Internet of Things. Furthermore, in a bid to understand students’ alternative data imaginaries, this project examined students’ preferred Internet of Things-related communication practices with campus digital application platforms, analog and older forms of digital media, as well as in-person interactions with traditional authorities within classroom and group settings. Finally, this contribution presents a discussion of the findings for theory and praxis, particularly for smart campus innovation and social data governance, in terms of potential growing challenges involving complexifying student privacy concerns, data normalization and coercion, and tertiary digital divides and inequalities. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221092656",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Pauline Hope Cheong",
        "Pratik Nyaupane"
      ],
      "url": "https://doi.org/10.1177/20539517221092656",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 57,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a54c47a0-a344-4485-b37c-8a69cc8e7a36",
    "title": "Computational text analysis: Thoughts on the contingencies of an evolving method",
    "abstract": "<jats:p> Mapping a public discourse with the tools of computational text analysis comes with many contingencies in the areas of corpus curation, data processing and analysis, and visualisation. However, the complexity of algorithmic assemblies and the beauty of resulting images give the impression of ‘objectivity’. Instead of concealing uncertainties and artefacts in order to tell a coherent and all-encompassing story, retaining the variety of alternative assemblies may actually strengthen the method. By utilising the mobility of digital devices, we could create mutable mobiles that allow access to our laboratories and enable challenging rearrangements and interpretations. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716670190",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Daniel Marciniak"
      ],
      "url": "https://doi.org/10.1177/2053951716670190",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 12,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "725541a0-972c-4f66-98e4-8ddc164e7fac",
    "title": "Digital identity as platform-mediated surveillance",
    "abstract": "<jats:p> Digital identity systems are usually viewed as datafiers of existing populations. Yet a platform view finds limited space in the digital identity discourse, with the result that the platform features of digital identity systems are not seen in relation to their surveillance outcomes. In this commentary I illuminate how the core platform properties of digital identity systems afford the undue surveillance of vulnerable groups, leading users into the binary condition of either registering and being profiled, or giving up essential benefits from providers of development programmes. By doing so I contest the “dark side” narrative often applied to digital identity, arguing that, rather than just a side, it is the very inner matter of digital identity platforms that enables surveillance outcomes. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221135176",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Silvia Masiero"
      ],
      "url": "https://doi.org/10.1177/20539517221135176",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 30,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bf2b1bb7-45fd-45e8-a78d-fb3c22feaa64",
    "title": "Data, anecdotes, anecdotal data: Feminist data activism against gendered violence post #Metoo",
    "abstract": "<jats:p> From critiques of baked-in sexism in data science, to the use of data in the service of feminism, feminist data activism has emerged as a new form of feminist activism. This paper approaches feminist data activism from a data imaginary perspective, focusing on a prominent feminist initiative from Australia called She's A Crowd, an organization that claims to have crowdsourced the world's largest dataset of gendered violence. Through interviews with 11 participants who volunteered their “datafied stories” to the organization, I explore the grassroots imaginaries about what data is and what it can do for the collective struggle against gendered violence. I show that participants’ experiences with not being believed led them to see data-driven stories as having superior epistemic value over qualitative narratives. Paradoxically, even when data is viewed as superior due to its detachment from the personal, concerns about its authenticity and quality persist. Consequently, participants advocated for increased data collection as the ultimate solution to address these limitations. Thus, if the imaginary of a binary between “data” and “stories” privileges data as a superior epistemic solution, the imaginary of limitation reinforces more data collection as the only solution imaginable. I argue that at stake is how these imaginaries locate the legitimacy of marginalized experiences within the dataset, obscuring how data collected from the grassroots might circulate within and be interpreted by hegemonic knowledge practices. This paper opens a conversation about feminist data activism and the power relations it is enmeshed within, an area that remains under explored. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241306347",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Trang Le"
      ],
      "url": "https://doi.org/10.1177/20539517241306347",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 67,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "98132585-a7a4-4f70-940a-0d102b5b2620",
    "title": "Short-circuiting biology: Digital phenotypes, digital biomarkers, and shifting gazes in psychiatry",
    "abstract": "<jats:p> Digital phenotyping is a rapidly growing research field promising to transform how psychiatry measures, classifies, predicts, and explains human behavior. This article advances the social-scientific examination of digital phenotyping's epistemology and knowledge claims. Drawing on the notion of a “neuromolecular gaze” in psychiatry since the 1960s, it suggests that digital phenotyping concerns a new psychiatric gaze—the “digital gaze.” Rather than privileging neuromolecular explanations, the digital gaze privileges the “deep” physiological, behavioral, and social “truths” afforded by digital technologies and big data. The article interrogates two concepts directing the digital gaze: “digital phenotype” and “digital biomarkers.” Both concepts make explicit an epistemic link between “the digital” and “the biological.” The article examines the soundness and construction of this link to, first, offer a “reality check” of digital phenotyping's claims and, second, more clearly delineate and demarcate the digital gaze. It argues there is evidence of significant mis- and overstatements about digital phenotyping's basis in biology, including in much-hyped psychiatric digital biomarker research. Rather than driving the biologization of digital traces, as some have suggested, digital mental health phenotyping so far seems mainly concerned with physiological, behavioral, and social processes that can be surveilled by means of digital devices. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221145680",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Shai Mulinari"
      ],
      "url": "https://doi.org/10.1177/20539517221145680",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 97,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d2973d32-09c4-4244-8a7b-9be4f4bc3999",
    "title": "After the algorithms: A study of meta-algorithmic judgments and diversity in the hiring process at a large multisite company",
    "abstract": "<jats:p> In recent years, both private and public organizations across contexts have begun implementing AI technologies in their recruitment processes. This transition is typically justified by improved efficiency as well as more objective, performance-based ranking, and inclusive selection of job candidates. However, this rapid development has also raised concerns that the use of these emerging technologies will instead increase discrimination or enhance the already existing inequality. In the present study, we first develop the concept of meta-algorithmic judgment to understand how recruiting managers may respond to automation of the hiring process. Second, we draw on this concept in the empirical assessment of the actual consequences of this type of transition by drawing on two large and unique datasets on employment records and job applications from one of Sweden's largest food retail companies. By comparing the outcomes of traditional and algorithmic job recruitment during this technological transition, we find that, contrary to the company's intentions, algorithmic recruitment decreases diversity. However, in contrast to what is often assumed, this is primarily not because the algorithms are biased, but because of what we identify as an unintended human–algorithmic interaction effect. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231221758",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Moa Bursell",
        "Lambros Roumbanis"
      ],
      "url": "https://doi.org/10.1177/20539517231221758",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "062e301e-2834-4fe5-814f-fe3f38d4b574",
    "title": "How biased is the sample? Reverse engineering the ranking algorithm of Facebook’s Graph application programming interface",
    "abstract": "Facebook research has proliferated during recent years. However, since November 2017, Facebook has introduced a new limitation on the maximum amount of page posts retrievable through their Graph application programming interface, while there is limited documentation on how these posts are selected. This paper compares two datasets of the same Facebook page, a full dataset obtained before the introduction of the limitation and a partial dataset obtained after, and employs bootstrapping technique to assess the bias caused by the new limitation. This paper demonstrates that posts with high user engagement, Photo posts and Video posts, are over-represented, while Link posts are under-represented. Top-term analysis reveals that there are significant differences in the most prominent terms between the full and partial dataset. This paper also reverse engineered the new application programming interface’s ranking algorithm to identify the features of a post that would affect its odds of being selected. Sentiment analysis reveals that there are significant differences in the sentiment word usage between the selected and non-selected posts. This paper has significant implications for the representativeness of research that use Facebook page data collected after the introduction of the limitation.",
    "metadata": {
      "doi": "10.1177/2053951720905874",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Justin Chun-Ting Ho"
      ],
      "url": "https://doi.org/10.1177/2053951720905874",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172090587",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 34,
      "is_referenced_by_count": 18,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3e2187d3-8a0f-405a-91cc-4bab26c8df61",
    "title": "Introduction to the Special Theme: The expansion of the health data ecosystem – Rethinking data ethics and governance",
    "abstract": "As in other domains, digital data are taking on an ever more central role in health and medicine today. And as it has in other domains, ‘datafication’ is contributing to a re-configuration of health and medicine, prompting its expansion to include new spaces, new practices, new techniques and new actors. Indeed, possibilities to quantify and ‘datafy’ areas of life that have not traditionally been considered the remit of biomedicine – such as sleep, ageing and emotions – and activities that have not traditionally been considered markers of health and disease – such as a person’s consumption patterns, her social media activity or her dietary habits – coupled with the promise of linking these heterogeneous datasets to glean medical insights, have contributed to a redefinition of almost any data as health-related data (Lucivero and Prainsack, 2015; Weber et al., 2014). Increasingly, these new types of data are being generated outside the traditional spaces of medicine, as people go about their daily lives interacting with consumer mobile devices. Similarly, the technological tools needed to capture, store, analyze and manage the flow of these data, from wearables and smart phones to cloud platforms and machine learning, increasingly rely on infrastructure and know-how that lie beyond the scope of traditional medical systems and scientists, amongst data scientists and information and communication technologies specialists. Moreover, new stakeholders are cropping up in these quasi-medical yet still undomesticated territories. On one end of the spectrum, individuals who generate health data as they track and monitor medical conditions, well-being, physical activity, or air quality, are both solicited as research participants and are making demands on researchers to utilize their personal health data (Health Data Exploration Project, 2014). On the other end of the spectrum, consumer technology corporations such as Apple and Google are reinventing themselves as obligatory passage points for dataintensive precision medicine (Sharon, 2016). And somewhere in between, not-for-profit organizations, such as Sage Bionetworks and OpenHumans.org, are positioning themselves as mediators in this ecosystem in formation, between the medical research community, individual and collective generators of data and technology developers. As proponents uphold, this expansion and decentralization of the health data ecosystem is promising, both in terms of the potential to advance data-driven research and healthcare, and in terms of rendering research more inclusive and more meaningful for participants (Shen, 2015; Topol, 2015). But, as critical scholars of science and technology have consistently shown, a fuller grasp of our technological present must always include the far-reaching, unexpected and sometimes deleterious social, political and cultural effects of discourses of scientific progress and technologically enabled democratization and participation. In recent years, such critical scholarship has been particularly wary of the new power asymmetries that datafication contributes to. Rather than levelling power relations, critics observe, these are being redrawn along new digital divides based on data ownership or access, control over digital infrastructures and new types of computational expertise, where those who generate data, especially citizens, patients and consumers, are positioned on the losing side of the on-going extraction and scramble for the world’s data driven by state",
    "metadata": {
      "doi": "10.1177/2053951719852969",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Tamar Sharon",
        "Federica Lucivero"
      ],
      "url": "https://doi.org/10.1177/2053951719852969",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171985296",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 18,
      "is_referenced_by_count": 20,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5f68e951-e053-4a68-86f9-44a7597b3fea",
    "title": "The birth of sensory power: How a pandemic made it visible?",
    "abstract": "<jats:p> Much has been written about data politics in the last decade, which has generated myriad concepts such as ‘surveillance capitalism’, ‘gig economy’, ‘quantified self’, ‘algorithmic governmentality’, ‘data colonialism’, ‘data subjects’ and ‘digital citizens’. Yet, it has been difficult to plot these concepts into an historical series to discern specific continuities and discontinuities since the origins of modern power in its three major forms: sovereign, disciplinary and regulatory. This article argues that the coronavirus pandemic in 2020 brought these three forms of power into sharp relief but made particularly visible a fourth form of power that we name ‘sensory power’, which has been emerging since the 1980s. The article draws on early studies of power by Michel Foucault, subsequent studies on biopower and biopolitics that expanded on them, and studies in the past decade that focused on data produced from apps, devices and platforms. Yet, despite its ambition, the article is inevitably an outline of a much larger project. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720969208",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Engin Isin",
        "Evelyn Ruppert"
      ],
      "url": "https://doi.org/10.1177/2053951720969208",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 106,
      "is_referenced_by_count": 57,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "694ddfe0-69ca-4094-ad54-4073bfae0e9e",
    "title": "Rethinking the filter bubble? Developing a research agenda for the protective filter bubble",
    "abstract": "<jats:p> Filter bubbles and echo chambers have received global attention from scholars, media organizations, and the general public. Filter bubbles have primarily been regarded as intrinsically negative, and many studies have sought to minimize their influence. The detrimental influence of filter bubbles is well-studied. Filter bubbles may, for example, create information silos, amplify misinformation, and promote hatred and extremism. However, comparatively few studies have considered the other side of the filter bubble; its protective benefits, particularly to marginalized communities and those living in countries with low levels of press freedom. Through a review of the literature on digital safe spaces and protective filter bubbles, this commentary suggests that there may be a need to rethink the filter bubble, and it proposes several areas for future research. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241231276",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Jacob Erickson"
      ],
      "url": "https://doi.org/10.1177/20539517241231276",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 28,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "cc1d0e49-2f49-47d6-9037-ae76014df66b",
    "title": "How web tracking changes user agency in the age of Big Data: The used user",
    "abstract": "<jats:p> Big Data enhances the possibilities for storing personal data extracted from social media and web search on an unprecedented scale. This paper draws on the political economy of information which explains why the online industry fails to self-regulate, resulting in increasingly insidious web-tracking technologies. Content analysis of historical blogs and request for comments on HTTP cookies published by the Internet Engineering Task Force illustrates how cookie technology was introduced in the mid-1990s, amid stark warnings about increased system vulnerabilities and deceptive personal data extractions. In conclusion, online users today are left with few alternatives but to enter into unconscionable contracts about the extraction of their personal data when using the Internet for private purposes. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714564228",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "Sylvia E Peacock"
      ],
      "url": "https://doi.org/10.1177/2053951714564228",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 73,
      "is_referenced_by_count": 25,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "afe4375a-b3a2-4072-8859-0c86f81cdf5e",
    "title": "Feeling fixes: Mess and emotion in algorithmic audits",
    "abstract": "<jats:p> Efforts to address algorithmic harms have gathered particular steam over the last few years. One area of proposed opportunity is the notion of an “algorithmic audit,” specifically an “internal audit,” a process in which a system’s developers evaluate its construction and likely consequences. These processes are broadly endorsed in theory—but how do they work in practice? In this paper, we conduct not only an audit but an autoethnography of our experiences doing so. Exploring the history and legacy of a facial recognition dataset, we find paradigmatic examples of algorithmic injustices. But we also find that the process of discovery is interwoven with questions of affect and infrastructural brittleness that internal audit processes fail to articulate. For auditing to not only address existing harms but avoid producing new ones in turn, we argue that these processes must attend to the “mess” of engaging with algorithmic systems in practice. Doing so not only reduces the risks of audit processes but—through a more nuanced consideration of the emotive parts of that mess—may enhance the benefits of a form of governance premised entirely on altering future practices. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221113772",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Os Keyes",
        "Jeanie Austin"
      ],
      "url": "https://doi.org/10.1177/20539517221113772",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 74,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b29821e3-2dfb-490f-add3-6635abecbd32",
    "title": "Algorithms as culture: Some tactics for the ethnography of algorithmic systems",
    "abstract": "This article responds to recent debates in critical algorithm studies about the significance of the term “algorithm.” Where some have suggested that critical scholars should align their use of the term with its common definition in professional computer science, I argue that we should instead approach algorithms as “multiples”—unstable objects that are enacted through the varied practices that people use to engage with them, including the practices of “outsider” researchers. This approach builds on the work of Laura Devendorf, Elizabeth Goodman, and Annemarie Mol. Different ways of enacting algorithms foreground certain issues while occluding others: computer scientists enact algorithms as conceptual objects indifferent to implementation details, while calls for accountability enact algorithms as closed boxes to be opened. I propose that critical researchers might seek to enact algorithms ethnographically, seeing them as heterogeneous and diffuse sociotechnical systems, rather than rigidly constrained and procedural formulas. To do so, I suggest thinking of algorithms not “in” culture, as the event occasioning this essay was titled, but “as” culture: part of broad patterns of meaning and practice that can be engaged with empirically. I offer a set of practical tactics for the ethnographic enactment of algorithmic systems, which do not depend on pinning down a singular “algorithm” or achieving “access,” but which rather work from the partial and mobile position of an outsider.",
    "metadata": {
      "doi": "10.1177/2053951717738104",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Nick Seaver"
      ],
      "url": "https://doi.org/10.1177/2053951717738104",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171773810",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 31,
      "is_referenced_by_count": 476,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d5a845f6-7d09-41fc-8a8a-db41b7c2cc34",
    "title": "Machine learning, meaning making: On reading computer science texts",
    "abstract": "<jats:p> Computer science tends to foreclose the reading of its texts by social science and humanities scholars – via code and scale, mathematics, black box opacities, secret or proprietary models. Yet, when computer science papers are read in order to better understand what machine learning means for societies, a form of reading is brought to bear that is not primarily about excavating the hidden meaning of a text or exposing underlying truths about science. Not strictly reading to make sense or to discern definitive meaning of computer science texts, reading is an engagement with the sense-making and meaning-making that takes place. We propose a strategy for reading computer science that is attentive to the act of reading itself, that stays close to the difficulty involved in all forms of reading, and that works with the text as already properly belonging to the ethico-politics that this difficulty engenders. Addressing a series of three “reading problems” – genre, readability, and meaning – we discuss machine learning textbooks and papers as sites where today's algorithmic models are actively giving accounts of their paradigmatic worldview. Much more than matters of technical definition or proof of concept, texts are sites where concepts are forged and contested. In our times, when the political application of AI and machine learning is so commonly geared to settle or predict difficult societal problems in advance, a reading strategy must open the gaps and difficulties of that which cannot be settled or resolved. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231166887",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Louise Amoore",
        "Alexander Campolo",
        "Benjamin Jacobsen",
        "Ludovico Rella"
      ],
      "url": "https://doi.org/10.1177/20539517231166887",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 37,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "99808c88-6597-4fd7-ae10-dc4049dd3491",
    "title": "Producing and projecting data: Aesthetic practices of government data portals",
    "abstract": "<jats:p> We develop the concept of ‘aesthetic practices’ to capture the work needed for population data to be disseminated via government data portals. Specifically, we look at the Census Hub of the European Statistical System and the Danish Ministry of Education’s Data Warehouse. These portals form part of open government data initiatives, which we understand as governing technologies. We argue that to function as such, aesthetic practices are required so that data produced at dispersed sites can be brought into relation and projected as populations in forms such as bar charts, heat maps and tables. Two examples of aesthetic practices are analysed based on ethnographic studies we have conducted on the production of data for the Hub and Warehouse: metadata and data cleaning. Metadata enables data to come into relation by containing and accounting for (some of) the differences between data. Data cleaning deals with the indeterminacies and absences of data and involves algorithms to determine what values data can obtain so they can be brought into relation. We attend to how both aesthetic practices involve normative decisions that make absent what exceeds them: embodied knowledge that cannot or has not been documented as well as data that cannot meet the forms required of data portals. While these aesthetic practices are necessary to sustain data portals as ‘sites of projection,’ we also bring critical attention to their performative effects for knowing, enacting and governing populations. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719853316",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Helene Ratner",
        "Evelyn Ruppert"
      ],
      "url": "https://doi.org/10.1177/2053951719853316",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171985331",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 40,
      "is_referenced_by_count": 30,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "75d5562b-d4ea-42af-a0bb-71c52e748f8e",
    "title": "The material consequences of “chipification”: The case of software-embedded cars",
    "abstract": "<jats:p> Today's modern car is an assemblage of mechanical and digital components, of metal panels that comprise its structure and silicon chips that run its functions. Communication and information studies scholars have interrogated the problematic aspects of the programs that run those functions, revealing serious issues surrounding privacy and security, worker surveillance, and racial, gendered, and class-based bias. This article contributes to that work by taking a step back and asking about the issues inherent not in the software running on these chips, but on the microchips themselves. Using the lens of “chipification”—the process by which a device is rendered capable of reading and processing data through the embedding of microchips—this article explores how the integration of microchips also involves processes that are often borne from, replicate, or create troubling power dynamics of their own. It takes light-duty passenger vehicles as a case study into how chipification is radically reshaping such processes as resource allocation, labor flows, and cultural practices around car manufacture, use, repair, and modification. By naming the process of chipification, this article allows researchers to identify and analyze the ways that integrating data processing capabilities into everyday devices is not a frictionless practice, but rather one that implicates a variety of power dynamics within these massive industries. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221095429",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "MC Forelle"
      ],
      "url": "https://doi.org/10.1177/20539517221095429",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 63,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ab2b0f8c-c760-4439-a503-9fc53cbcb6f4",
    "title": "Doing place through data: Proliferation, profiling and the perils of portrayal in local climate action",
    "abstract": "<jats:p> Building on work which has shown the role of digital technologies in reframing environmental relations, this paper explores ethnographically how environmental data is reconfiguring the concept of place. The paper takes as its focus an action-research project within a UK based, citizen-oriented initiative called Newtown Energy Futures, in which we sought to enfold climate and energy data into a social-justice informed attempt at climate action. By exploring how the project used data as an invitation for citizens to engage with and participate in local infrastructural and environmental dynamics, the paper sheds light on how environmental data came to participate in the making of place and in doing so raised questions about how to rebuild the socio-material relations through which ‘a sense of place’ might be reproduced. As climate and energy data increasingly demand that places become enrolled into environmental projects our findings suggest that data enables place to emerge as a ‘socio-technical potentiality’ an observation that has implications both for both engagement with, and the study of data and place. In practical terms, we suggest that this refiguration of place has the effect of creating hopeful trajectories for change, whilst also posing difficult questions about the limits of participation in a data-infused form of place-based politics. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241266404",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Hannah Knox"
      ],
      "url": "https://doi.org/10.1177/20539517241266404",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 62,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a32f2a2b-3e70-4ce7-9745-3a0b763297af",
    "title": "Small decisions with big impact on data analytics",
    "abstract": "<jats:p> Big social data have enabled new opportunities for evaluating the applicability of social science theories that were formulated decades ago and were often based on small- to medium-sized samples. Big Data coupled with powerful computing has the potential to replace the statistical practice of sampling and estimating effects by measuring phenomena based on full populations. Preparing these data for analysis and conducting analytics involves a plethora of decisions, some of which are already embedded in previously collected data and built tools. These decisions refer to the recording, indexing and representation of data and the settings for analysis methods. While these choices can have tremendous impact on research outcomes, they are not often obvious, not considered or not being made explicit. Consequently, our awareness and understanding of the impact of these decisions on analysis results and derived implications are highly underdeveloped. This might be attributable to occasional high levels of over-confidence in computational solutions as well as the possible yet questionable assumption that Big Data can wash out minor data quality issues, among other reasons. This article provides examples for how to address this issue. It argues that checking, ensuring and validating the quality of big social data and related auxiliary material is a key ingredient for empowering users to gain reliable insights from their work. Scrutinizing data for accuracy issues, systematically fixing them and diligently documenting these processes can have another positive side effect: Closely interacting with the data, thereby forcing ourselves to understand their idiosyncrasies and patterns, can help us to move from being able to precisely model and formally describe effects in society to also understand and explain them. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715617185",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Jana Diesner"
      ],
      "url": "https://doi.org/10.1177/2053951715617185",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 34,
      "is_referenced_by_count": 19,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f54da06f-a096-44b0-827d-c13e1157b8ee",
    "title": "The trustification of AI. Disclosing the bridging pillars that tie trust and AI together",
    "abstract": "<jats:p> Trustworthy artificial intelligence (TAI) is trending high on the political agenda. However, what is actually implied when talking about TAI, and why it is so difficult to achieve, remains insufficiently understood by both academic discourse and current AI policy frameworks. This paper offers an analytical scheme with four different dimensions that constitute TAI: a) A user perspective of AI as a quasi-other; b) AI's embedding in a network of actors from programmers to platform gatekeepers; c) The regulatory role of governance in bridging trust insecurities and deciding on AI value trade-offs; and d) The role of narratives and rhetoric in mediating AI and its conflictual governance processes. It is through the analytical scheme that overlooked aspects and missed regulatory demands around TAI are revealed and can be tackled. Conceptually, this work is situated in disciplinary transgression, dictated by the complexity of the phenomenon of TAI. The paper borrows from multiple inspirations such as phenomenology to reveal AI as a quasi-other we (dis-)trust; Science &amp; Technology Studies (STS) to deconstruct AI's social and rhetorical embedding; as well as political science for pinpointing hegemonial conflicts within regulatory bargaining. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241249430",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Jascha Bareis"
      ],
      "url": "https://doi.org/10.1177/20539517241249430",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 114,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8d7b7c04-eb67-4e2e-b7ad-7545db1d4269",
    "title": "Data out of place: Toxic traces and the politics of recycling",
    "abstract": "<jats:p> It has become increasingly common to talk about “digital traces”. The idea that we leak, drop and leave traces wherever we go has given rise to a culture of traceability, and this culture of traceability, I argue, is intimately entangled with a socio-economics of data disposability and recycling. While the culture of traceability has often been theorised in terms of, and in relation to, privacy, I offer another approach, framing digital traces instead as a question of waste. This perspective, I argue, allows us to connect to, extend and nuance existing discussions of digital traces. It shows us that data traces raise questions about not only how data capitalism tracks individual and multiple data behaviours, but also how it links to social and environmental toxicities in the form of abuse and environmental pollution, which follow gendered and colonial structures of violence. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719875479",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Nanna Bonde Thylstrup"
      ],
      "url": "https://doi.org/10.1177/2053951719875479",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171987547",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 50,
      "is_referenced_by_count": 33,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d8d111f8-ac61-4623-9270-3585037bbfdc",
    "title": "Big Data, epistemology and causality: Knowledge in and knowledge out in EXPOsOMICS",
    "abstract": "<jats:p> Recently, it has been argued that the use of Big Data transforms the sciences, making data-driven research possible and studying causality redundant. In this paper, I focus on the claim on causal knowledge by examining the Big Data project EXPOsOMICS, whose research is funded by the European Commission and considered capable of improving our understanding of the relation between exposure and disease. While EXPOsOMICS may seem the perfect exemplification of the data-driven view, I show how causal knowledge is necessary for the project, both as a source for handling complexity and as an output for meeting the project’s goals. Consequently, I argue that data-driven claims about causality are fundamentally flawed and causal knowledge should be considered a necessary aspect of Big Data science. In addition, I present the consequences of this result on other data-driven claims, concerning the role of theoretical considerations. I argue that the importance of causal knowledge and other kinds of theoretical engagement in EXPOsOMICS undermine theory-free accounts and suggest alternative ways of framing science based on Big Data. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716669530",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Stefano Canali"
      ],
      "url": "https://doi.org/10.1177/2053951716669530",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 44,
      "is_referenced_by_count": 17,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d8ec32f7-ce79-441b-8d42-eb95bfdb142a",
    "title": "Meaningful disinformation: Narrative rituals and affective folktales",
    "abstract": "<jats:p> In this article, we review the epistemological boundaries of disinformation studies and argue that they are informed by network and transmission models where the unit of analysis (i.e., disinformation) is assumed to follow contagion growth patterns typical of population models. This framework reduces disinformation to a behavioral problem that downplays the participatory and ritualistic dimension of disinformation, which we argue cannot be reduced, and therefore cannot be corrected, by targeting individual behavior. We review seminal contributions to information and communication studies to foreground disinformation as de facto alternative social contracts that organize the overflow of information in meaningful narratives. We conclude by arguing that disinformation studies would benefit from tracing the resonance of narratives informed by lived experiences to achieve a higher-level principle that can negotiate conflicting realities. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231215361",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Marco Bastos",
        "Marc Tuters"
      ],
      "url": "https://doi.org/10.1177/20539517231215361",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 31,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0f8b4d95-df4b-4db3-8acc-690fb4163f9c",
    "title": "Beyond high-tech versus low-tech: A tentative framework for sustainable urban data governance",
    "abstract": "<jats:p> Technological imaginaries have been increasingly shaping the future perceptions of cities. From artificial intelligence and distributed ledger technology to three-dimensional printing, high-tech artifacts are very often the premises of such imaginaries. However, technology does not only refer to artifacts. Technology also encompasses the processes around the artifacts: how the artifacts are designed, manufactured, used, maintained, and disposed. From this perspective, high-tech visions often disregard problems that pertain to resource extraction, labor exploitation, energy use, and material flows. On the contrary, low-tech and localized alternatives incite lower impact and higher resilience visions. However, they fail to offer solutions of the desired scale and intensity. To address this tension, we provide an alternative vision for mid-tech: a balance between the opposite extreme qualities of low-tech and high-tech. Through a case of open-source prosthetics, we illustrate how to synergistically combine the efficiency and versatility of high-tech solutions with the potential for autonomy and resilience that low-tech offers. Then we discuss a mid-tech approach for distributed ledger technology from a city as a license lens. We provide connections with existing or conceptual applications to show how distributed ledger technology could support more socially and ecologically responsible data practices for city governance. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231180583",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Vasilis Kostakis",
        "Alex Pazaitis",
        "Minas Liarokapis"
      ],
      "url": "https://doi.org/10.1177/20539517231180583",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 27,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "27057eab-a387-45f6-9394-07536883d47d",
    "title": "Networks of digital humanities scholars: The informational and social uses and gratifications of Twitter",
    "abstract": "<jats:p> Big Data research is currently split on whether and to what extent Twitter can be characterized as an informational or social network. We contribute to this line of inquiry through an investigation of digital humanities (DH) scholars’ uses and gratifications of Twitter. We conducted a thematic analysis of 25 semi-structured interview transcripts to learn about these scholars’ professional use of Twitter. Our findings show that Twitter is considered a critical tool for informal communication within DH invisible colleges, functioning at varying levels as both an information network (learning to ‘Twitter’ and maintaining awareness) and a social network (imagining audiences and engaging other digital humanists). We find that Twitter follow relationships reflect common academic interests and are closely tied to scholars’ pre-existing social ties and conference or event co-attendance. The concept of the invisible college continues to be relevant but requires revisiting. The invisible college formed on Twitter is messy, consisting of overlapping social contexts (professional, personal and public), scholars with different habits of engagement, and both formal and informal ties. Our research illustrates the value of using multiple methods to explore the complex questions arising from Big Data studies and points toward future research that could implement Big Data techniques on a small scale, focusing on sub-topics or emerging fields, to expose the nature of scholars’ invisible colleges made visible on Twitter. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715589417",
      "type": "journal-article",
      "published": [
        2015,
        5,
        1
      ],
      "authors": [
        "Anabel Quan-Haase",
        "Kim Martin",
        "Lori McCay-Peet"
      ],
      "url": "https://doi.org/10.1177/2053951715589417",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 44,
      "is_referenced_by_count": 38,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ebfef9c5-5c80-40a5-b085-a404e5a6f3eb",
    "title": "The optical unconscious of Big Data: Datafication of vision and care for unknown futures",
    "abstract": "<jats:p> Ever since Big Data became a mot du jour across social fields, optical metaphors such as the microscope began to surface in popular discourse to describe and qualify its epistemological impact. While the persistence of optics seems to be at odds with the datafication of vision, this article suggests that the optical metaphor offers an opportunity to reflect about the material consequences of the modes of seeing and knowing that currently shape datafied worlds. Drawing on feminist new materialism, the article investigates the optical metaphor as a material-discursive practice that actively constitutes the world, as metaphors imply modes of thinking, knowing and doing that have material enactions. Expanding visual culture theories, the notion of ‘optical unconscious’ is taken up to discuss the tensions between displacement and persistence of optics within datafied worlds, that is, how optical vision is displaced but also mobilised and repurposed by data-driven knowledge. In dialogue with feminist science and technology studies and speculative ethics, I suggest that the datafication of vision offers a chance to reconceptualize the sense of sight towards a sensorial engagement with Big Data premised on responsibility, care, and an ethics of unknowability. Within this framework, vision may be conceived differently, perhaps not only as enhancement and control, but as generator of new possibilities. Ultimately, the article proposes that the visual theories after which Big Data is being imagined matter not only for our understanding of Big Data's epistemic potential, but also for the possibility of shaping emerging data worlds. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719826859",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Daniela Agostinho"
      ],
      "url": "https://doi.org/10.1177/2053951719826859",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 68,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "57eeb92f-ff29-4b33-bef6-5ece9364c6dd",
    "title": "Stabilizing translucencies: Governing AI transparency by standardization",
    "abstract": "<jats:p>Standards are put forward as important means to turn the ideals of ethical and responsible artificial intelligence into practice. One principle targeted for standardization is transparency. This article attends to the tension between standardization and transparency, by combining a theoretical exploration of these concepts with an empirical analysis of standardizations of artificial intelligence transparency. Conceptually, standards are underpinned by goals of stability and solidification, while transparency is considered a flexible see-through quality. In addition, artificial intelligence-technologies are depicted as ‘black boxed’, complex and in flux. Transparency as a solution for ethical artificial intelligence has, however, been problematized. In the empirical sample of standardizations, transparency is largely presented as a static, measurable, and straightforward information transfer, or as a window to artificial intelligence use. The standards are furthermore described as pioneering and able to shape technological futures, while their similarities suggest that artificial intelligence translucencies are already stabilizing into similar arrangements. To rely heavily upon standardization to govern artificial intelligence transparency still risks allocating rule-making to non-democratic processes, and while intended to bring clarity, the standardizations could also create new distributions of uncertainty and accountability. This article stresses the complexity of governing sociotechnical artificial intelligence principles by standardization. Overall, there is a risk that the governance of artificial intelligence is let to be too shaped by technological solutionism, allowing the standardization of social values (or even human rights) to be carried out in the same manner as that of any other technical product or procedure.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241234298",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Charlotte Högberg"
      ],
      "url": "https://doi.org/10.1177/20539517241234298",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 71,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0f70dd69-b97c-4666-b616-25ec2641ee57",
    "title": "Taking stock of COVID-19 health status certificates: Legal implications for data privacy and human rights",
    "abstract": "<jats:p> The technological solutions adopted during the current pandemic will have a lasting impact on our societies. Currently, COVID-19 health status certificates are being deployed around the world, including in Europe, the United States and China. When combined with identity verification, these digital and paper-based certificates allow individuals to prove their health status by showing recent COVID-19 tests results, full vaccination records or evidence of recovery from COVID-19. Most countries in the Global South, where vaccination rates are low, have not yet fully implemented such certificates, although several initiatives are currently underway. That is, for instance, the case in the African Union. Yet, it is not sufficient to develop technical solutions for the verification of COVID-19 health status. Because technologies do not evolve in a legal vacuum, the existing laws and regulations must be respected. The risks of implementing such technologies must be anticipated and mitigated as much as possible before any large-scale deployment. Risk mitigation should also underpin strategies throughout the deployment of these certificates. This article evaluates the key legal implications of COVID-19 health status certificates for data privacy and human rights. In doing so, it contributes to the current debates, thus informing policymakers in this area of vital national and international interest </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211069300",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Ana Beduschi"
      ],
      "url": "https://doi.org/10.1177/20539517211069300",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 32,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "848667d1-8066-4a73-9deb-0a41b322751a",
    "title": "Data in the smart city: How incongruent frames challenge the transition from ideal to practice",
    "abstract": "<jats:p> This paper presents an analysis of interviews, focus groups and workshops with employees in the technical administration in the municipality of Copenhagen in the year after it won a prestigious Smart City award. The administration is interpreted as a ‘most likely’ to succeed in translating the idealised version of the smart city into a workable bureaucratic practice. Drawing on the work of Orlikowski and Gash, the empirical analysis identifies and describes two incongruent ‘technological frames’ that illustrates different ways of making sense of data and the smart city within this single organisational unit. One is called the experimentalist’s credo and it is characterised by inspiration from the development of an Internet of Things as well as a readiness to learn from the open source community in software development. The other is called the data-owners vocation and it is characterised by a more situated approach that interprets data as strategic and political. It is argued that the existence of these frames provides two insights relevant for the literature on smart cities. First, they illustrate that one should be careful not to reify the smart city as a phenomenon that can be criticised in generic terms. Second, they suggest that even if there exists a transition toward the implementation of a technocratic smart city paradigm across public administrations, this paradigm is not unique in its focus on markets and evidence in governance. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718802321",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Anders Koed Madsen"
      ],
      "url": "https://doi.org/10.1177/2053951718802321",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 42,
      "is_referenced_by_count": 26,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5239ab54-f6b7-4faf-a57f-d21816018560",
    "title": "The cloud, the crowd, and the city: How new data practices reconfigure urban governance?",
    "abstract": "The urban archetype of the flâneur, so central to the concept of modernity, can now experience the city in ways unimaginable one hundred years ago. Strolling around Paris, the contemporary flâneur might stop to post pictures of her discoveries on Instagram, simultaneously identifying points of interest to the rest of her social network and broadcasting her location (perhaps unknowingly). The café she visits might be in the middle of a fundraising campaign through a crowdfunding site such as Kickstarter, and she might be invited to tweet to her followers in exchange for a discount on her pain au chocolate. As she ambles about Paris, the route of her stroll is captured by movement sensors positioned on top of street lights, and this data—aggregated with that of thousands of other pedestrians—could be used by the City of Paris to sync up transit schedules. And if those schedules were not convenient, she might tap Uber to whisk her home to her threadbare pension booked on AirBnB. This vignette attests to the transformation of the urban experience through technology-enabled platforms that allow for the quick mobilization and exchange of information, public services, surplus capacity, entrepreneurial energy, and money. However, these changes have implicated more than just consumers, as multiple technologies have been taken up in urban governance processes through platforms variously labeled as Big Data, crowd sourcing, or the sharing economy. These systems combine inexpensive data collection and cloud-based storage, distributed social networks, geotagged locational sensing, mobile access (often through ‘‘app’’ platforms), and new collaborative entrepreneurship models to radically alter how the needs of urban residents are identified and how services are delivered and consumed in so-called ‘‘smart cities’’ (Townsend, 2013). Backed by Big Data, smart city initiatives have made inroads into urban service provision and policy in areas such as e-government and transparency, new forms of public-private partnerships through ‘‘urban lab’’ arrangements, or models such as impact investing, civic hacking, or tactical urbanism (cf. Karvonen and van Heur, 2014; Kitchin, 2014; Swyngedouw, 2005). In the rhetoric used by their boosters, the vision and practice of these technologies ‘‘disrupts’’ existing markets by harnessing the power of ‘‘the crowd’’—a process fully evident in sectors such as taxi (Uber/Lyft), hoteling (AirBnB), and finance (peer-to-peer lending). However, the notion of disruption has also targeted government bureaucracies and public services, with new initiatives seeking to insert crowd mechanisms or characteristics—at once self-organizing and collectively rational (Brabham, 2008)—into public policy. These mechanisms envision reconfiguring the traditional relationship of public powers with planning and governance by vesting data collection and problem-solving in crowd-like institutional arrangements that are partially or wholly outside the purview of government agencies. While scholars are used to talking about ‘‘governance beyond-the-state’’ (Swyngedouw, 2005) in terms of privatization and a growing scope for civil society organizations, technological intermediation potentially changes the scale and techniques of governance as well as its relationship to sovereign authority. For instance, civic crowdfunding models have emerged as new means of organizing public service provision and funding community economic development by embracing both market-like bidding",
    "metadata": {
      "doi": "10.1177/2053951717706718",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Philip Ashton",
        "Rachel Weber",
        "Matthew Zook"
      ],
      "url": "https://doi.org/10.1177/2053951717706718",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 20,
      "is_referenced_by_count": 20,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8cc26ecf-3d53-406a-939f-31979853b399",
    "title": "Navigating the ethical landscape behind ChatGPT",
    "abstract": "<jats:p> In this commentary, we examine the key ethical concerns arising from the rapid penetration and proliferation of generative artificial intelligence (AI), with ChatGPT as a prominent case study. Our analysis is structured around four pivotal themes: the debates on plagiarism and authorship in AI-generated content; the underlying power dynamics that shape biases in AI development; the dynamic, complex relationships between humans and machines; and the growing concerns over unchecked progress and the absence of accountability in the rapidly intensifying AI “Arms Race.” Recognizing the necessity for ethical alignment in AI, yet without a clear consensus of “human interests,” gives room for further exacerbating global inequalities, we advocate for enhanced transparency and increased public involvement in AI development and deployment processes. This article underscores the importance of engaging a diverse range of voices, especially those from communities traditionally uninvolved or excluded from the dialogue on AI development. By doing so, we aim to foster a more inclusive and multidisciplinary approach to understanding and shaping the trajectory of AI technologies, ensuring that their benefits are equitably shared, and their risks carefully managed. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241237488",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Lizhi Peng",
        "Bo Zhao"
      ],
      "url": "https://doi.org/10.1177/20539517241237488",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 9,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5bc6affc-96b3-402e-96c0-5de65efa87ae",
    "title": "Snails, time, data: On the politics of mass-digitization and the possibility of data drift",
    "abstract": "<jats:p> In natural history museums around the globe, museum staff are working on making collections of specimens (such as insects on pins, snail shells, dried plants, mounted birds) digitally available through online databases en masse. The mass-digitization of specimens is urgent especially now, so museum actors and biodiversity scientists stress, as natural history collections could provide the biodiversity sciences with crucial data for research into the effects of climate-change induced biodiversity loss. This paper investigates the processes and practices through which these biodiversity data are produced. It argues that the work of data production requires the negotiation of- and grappling with different temporalities, and that attending to these temporalities contributes to a further understanding of the politics of mass-digitization. Building on ethnographic fieldwork in the Museum für Naturkunde Berlin's collection of snail shells, the paper brings into view the work required to make snail specimens and their metadata digital. Following steps in a mollusk digitization workflow—meant to streamline and scale up digitization processes—it attends to the misalignment of rhythms; the importance of informal cleaning labor; the negotiation of social, biological, and colonial temporalities in practices of label transcription; and the anticipatory and expansive logics of mass-digitization. Drawing on snails’ ability to “drift,” it raises data drift as a way of engaging with natural history collections and their data. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241267760",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Roos Hopman"
      ],
      "url": "https://doi.org/10.1177/20539517241267760",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 59,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5f21c22c-7618-4e01-be39-735b50d4e32a",
    "title": "Complementary social science? Quali-quantitative experiments in a Big Data world",
    "abstract": "<jats:p> The rise of Big Data in the social realm poses significant questions at the intersection of science, technology, and society, including in terms of how new large-scale social databases are currently changing the methods, epistemologies, and politics of social science. In this commentary, we address such epochal (“large-scale”) questions by way of a (situated) experiment: at the Danish Technical University in Copenhagen, an interdisciplinary group of computer scientists, physicists, economists, sociologists, and anthropologists (including the authors) is setting up a large-scale data infrastructure, meant to continually record the digital traces of social relations among an entire freshman class of students ( N &gt; 1000). At the same time, fieldwork is carried out on friendship (and other) relations amongst the same group of students. On this basis, the question we pose is the following: what kind of knowledge is obtained on this social micro-cosmos via the Big (computational, quantitative) and Small (embodied, qualitative) Data, respectively? How do the two relate? Invoking Bohr’s principle of complementarity as analogy, we hypothesize that social relations, as objects of knowledge, depend crucially on the type of measurement device deployed. At the same time, however, we also expect new interferences and polyphonies to arise at the intersection of Big and Small Data, provided that these are, so to speak, mixed with care. These questions, we stress, are important not only for the future of social science methods but also for the type of societal (self-)knowledge that may be expected from new large-scale social databases. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714543908",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "Anders Blok",
        "Morten Axel Pedersen"
      ],
      "url": "https://doi.org/10.1177/2053951714543908",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 18,
      "is_referenced_by_count": 42,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5577b0ba-2284-4b3b-a42d-6f8a85fe1ee7",
    "title": "Structured like a language model: Analysing AI as an automated subject",
    "abstract": "<jats:p>Drawing from the resources of psychoanalysis and critical media studies, in this article we develop an analysis of large language models (LLMs) as ‘automated subjects’. We argue the intentional fictional projection of subjectivity onto LLMs can yield an alternate frame through which artificial intelligence (AI) behaviour, including its productions of bias and harm, can be analysed. First, we introduce language models, discuss their significance and risks, and outline our case for interpreting model design and outputs with support from psychoanalytic concepts. We trace a brief history of language models, culminating with the releases, in 2022, of systems that realise ‘state-of-the-art’ natural language processing performance. We engage with one such system, OpenAI's InstructGPT, as a case study, detailing the layers of its construction and conducting exploratory and semi-structured interviews with chatbots. These interviews probe the model's moral imperatives to be ‘helpful’, ‘truthful’ and ‘harmless’ by design. The model acts, we argue, as the condensation of often competing social desires, articulated through the internet and harvested into training data, which must then be regulated and repressed. This foundational structure can however be redirected via prompting, so that the model comes to identify with, and transfer , its commitments to the immediate human subject before it. In turn, these automated productions of language can lead to the human subject projecting agency upon the model, effecting occasionally further forms of countertransference. We conclude that critical media methods and psychoanalytic theory together offer a productive frame for grasping the powerful new capacities of AI-driven language systems.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231210273",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Liam Magee",
        "Vanicka Arora",
        "Luke Munn"
      ],
      "url": "https://doi.org/10.1177/20539517231210273",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 40,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "06fba0cd-7a6a-47e8-80f5-e3827e4dc091",
    "title": "Deconstructing the algorithmic sublime",
    "abstract": "<jats:p> This special theme contextualizes, examines, and ultimately works to dispel the feelings of “sublime”—of awe and terror that overrides rational thought—that much of the contemporary public discourse on algorithms encourages. Employing critical, reflexive, and ethnographic techniques, these authors show that while algorithms can take on a multiplicity of different cultural meanings, they ultimately remain closely connected to the people who define and deploy them, and the institutions and power relations in which they are embedded. Building on a conversation we began at the Algorithms in Culture conference at U.C. Berkeley in December 2016, we collectively study algorithms as culture (Seaver, this special theme), fetish (Thomas et al.), imaginary (Christin), bureaucratic logic (Caplan and boyd), method of governance (Coletta and Kitchin; Lee; Geiger), mode of inquiry (Baumer), and mode of power (Kubler). </jats:p><jats:sec><jats:title/><jats:p> [Box: see text] </jats:p></jats:sec>",
    "metadata": {
      "doi": "10.1177/2053951718779194",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Morgan G Ames"
      ],
      "url": "https://doi.org/10.1177/2053951718779194",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 12,
      "is_referenced_by_count": 41,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c975ae75-7ad5-4a2d-8f50-7c1448147154",
    "title": "Facing Big Data: Making sociology relevant",
    "abstract": "<jats:p> Working with computational methods and large textual analysis has been challenging and very rewarding—with all the ups and downs that doing empirical social research entails. In my contribution, I relate some research experiences and reflect upon data construction and the links between theory, data, and methods. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715599179",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Sophie Mützel"
      ],
      "url": "https://doi.org/10.1177/2053951715599179",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 35,
      "is_referenced_by_count": 33,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1c57bd7a-131c-4c92-8990-70c84a7932a3",
    "title": "Adjusting expectations actionable: Personalised treatment plan in anticipation of data-driven healthcare",
    "abstract": "<jats:p> Our paper is a case study of the making of data-driven healthcare and anticipation work done by developer-experts in a project for implementation of an integrated patient data management platform in Finland. We focus on ‘personalised treatment plan’, a trope that experts regularly use when talking about the objectives of data management reform and their wishes for datafication of healthcare. We conceive of the personalised plan not primarily as a future vision or an outcome, but rather a tool of anticipation of work. Our analysis demonstrates two purposes for which the developer-experts used this tool. First, the plan enabled them to reconfigure the general expectations of datafication actionable and adoptable in the actual world of healthcare and to articulate datafication technology-to-come as concrete hopes and wishes, plans and assessments in the contexts of clinical practices and administration. Second, experts used the idea of a personalised plan for reasoning over and management of their own work. Among the fuzziness and commotion of the complex project, the plan helped them to create and maintain a workable order between the expectations, tasks and functions that the datafication technology should accomplish in healthcare in the future. Furthermore, we discuss the limitations of anticipation to take the specific political and economic contexts into account, which made the developers unprepared for the political interruption of the project. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241285384",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Ilpo Helén",
        "Heta Tarkkala"
      ],
      "url": "https://doi.org/10.1177/20539517241285384",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 43,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "323d5742-6dc8-4032-ace4-ea193eb1c5fc",
    "title": "Designing privacy in personalized  health: An empirical analysis",
    "abstract": "<jats:p> A crucial challenge for personalized health is the handling of individuals’ data and specifically the protection of their privacy. Secure storage of personal health data is of paramount importance to convince citizens to collect personal health data. In this survey experiment, we test individuals’ willingness to produce and store personal health data, based on different storage options and whether this data is presented as common good or private good. In this paper, we focus on the nonmedical context with two means to self-produce data: connected devices that record physical activity and genetic tests that appraise risks of diseases. We use data from a survey experiment fielded in Switzerland in March 2020 and perform regression analyses on a representative sample of Swiss citizens in the French- and German-speaking cantons. Our analysis shows that respondents are more likely to use both apps and tests when their data is framed as a private good to be stored by individuals themselves. Our results demonstrate that concerns regarding the privacy of personal heath data storage trumps any other variable when it comes to the willingness to use personalized health technologies. Individuals prefer a data storage format where they retain control over the data. Ultimately, this study presents results susceptible to inform decision-makers in designing privacy in personalized health initiatives. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231158636",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Thibaud Deruelle",
        "Veronika Kalouguina",
        "Philipp Trein",
        "Joël Wagner"
      ],
      "url": "https://doi.org/10.1177/20539517231158636",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 42,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3b2079d5-443b-456e-b382-747dfdf6470b",
    "title": "Not so fast! Data temporalities in law enforcement and border control",
    "abstract": "<jats:p> In this paper, we investigate the temporal implications of data in law enforcement and border control. We start from the assumption that the velocity of knowledge and action is defined by heterogeneous formations and interactions of various actors, sites, and materials. To analyze these formations and interactions, we introduce and unpack the concept of “data temporality.” Data temporality explicates how the speed of knowledge and action in datafied environments unfolds in close correspondence with (1) variegated social rhythms, (2) technological inscriptions, and (3) the balancing of speed with other priorities. Specifically, we use the notion of data temporality as a heuristic tool to explore the entanglements of data and time within two case studies: Frontex’ Joint Operation Reporting Application and the predictive policing software PRECOBS. The analysis identifies two key themes in the empirical constitution of data temporalities. The first one pertains to the creation of events as reference points for temporally situated knowledge and action. And the second one pertains to timing and actionability, that is, the question of when interventions based on data analysis should be triggered. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231164120",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Matthias Leese",
        "Silvan Pollozek"
      ],
      "url": "https://doi.org/10.1177/20539517231164120",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 63,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bca528c4-5b76-47f3-b7dc-42c79a56c7bf",
    "title": "Epistemic clashes in network science: Mapping the tensions between idiographic and nomothetic subcultures",
    "abstract": "<jats:p> This article maps a controversy in network science over the last 15 years, dividing the field about the epistemic status of a central notion, scale-freeness. The article accounts for the two main disputes, in 2005 and in 2018, as they unfolded in academic publications and on social media. This article analyzes the conflict, and the reasons why it reignited in 2018, to the surprise of many. It is argued that (1) the concept of complex networks is shared by the distinct subcultures of theorists and experimentalists; and that (2) these subcultures have incompatible approaches to knowledge: nomothetic (scale-freeness is the sign of a universal law) and idiographic (scale-freeness is an empirical characterization). Following Galison, this article contends that network science is a trading zone where theorists and experimentalists can trade knowledge across the epistemic divide. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720949577",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Mathieu Jacomy"
      ],
      "url": "https://doi.org/10.1177/2053951720949577",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 78,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "503a5dea-8efb-4fc4-9fc4-8cf760bc2016",
    "title": "Role-based privacy cynicism and local privacy activism: How data stewards navigate privacy in higher education",
    "abstract": "<jats:p> This study examines the impact of role-based constraints on privacy cynicism within higher education, a workplace increasingly subjected to surveillance. Using a thematic analysis of 15 in-depth interviews conducted between 2017 and 2023 with data stewards in the California State University System, the research explores the reasons behind data stewards’ privacy cynicism, despite their knowledge of privacy and their own ability to protect it. We investigate how academic data custodians navigate four role-based tensions: the conflict between the institutional and personal definitions of privacy; the mutual reinforcement between their privacy-cynical attitudes and their perceptions of student privacy attitudes; the influence of role constraints on data stewards’ privacy-protective behaviors; and the contrast between the negatively valued societal surveillance and the positively valued university surveillance. The findings underscore the significance of considering organizational privacy cultures and role-based expectations in studying privacy cynicism. The study contributes to the theoretical understanding of privacy cynicism and offers practical implications for organizations, emphasizing the importance of aligning organizational definitions of privacy with employees’ understanding. Future research should further explore the mutual reinforcement of privacy cynicism in the relationship between data providers and data consumers (which we call the “spiral of resignation”) and consider the impact of role-based constraints in other organizational contexts. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241240664",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Mihaela Popescu",
        "Lemi Baruh",
        "Samuel Sudhakar"
      ],
      "url": "https://doi.org/10.1177/20539517241240664",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "dfe11a8c-e7f5-4300-93b6-3d983db9effc",
    "title": "Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation",
    "abstract": "<jats:p> Misinformation about the novel coronavirus (COVID-19) is a pressing societal challenge. Across two studies, one preregistered ( n<jats:sub>1</jats:sub> = 1771 and n<jats:sub>2</jats:sub> = 1777), we assess the efficacy of two ‘prebunking’ interventions aimed at improving people’s ability to spot manipulation techniques commonly used in COVID-19 misinformation across three different languages (English, French and German). We find that Go Viral!, a novel five-minute browser game, (a) increases the perceived manipulativeness of misinformation about COVID-19, (b) improves people’s attitudinal certainty (confidence) in their ability to spot misinformation and (c) reduces self-reported willingness to share misinformation with others. The first two effects remain significant for at least one week after gameplay. We also find that reading real-world infographics from UNESCO improves people’s ability and confidence in spotting COVID-19 misinformation (albeit with descriptively smaller effect sizes than the game). Limitations and implications for fake news interventions are discussed. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211013868",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Melisa Basol",
        "Jon Roozenbeek",
        "Manon Berriche",
        "Fatih Uenal",
        "William P. McClanahan",
        "Sander van der Linden"
      ],
      "url": "https://doi.org/10.1177/20539517211013868",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 67,
      "is_referenced_by_count": 148,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "719aee53-1883-425a-bffd-f22bab0d6881",
    "title": "Carceral algorithms and the history of control: An analysis of the Pennsylvania additive classification tool",
    "abstract": "<jats:p> Scholars have focused on algorithms used during sentencing, bail, and parole, but little work explores what we term “carceral algorithms” that are used during incarceration. This paper is focused on the Pennsylvania Additive Classification Tool (PACT) used to classify prisoners’ custody levels while they are incarcerated. Algorithms that are used during incarceration warrant deeper attention by scholars because they have the power to enact the lived reality of the prisoner. The algorithm in this case determines the likelihood a person would endure additional disciplinary actions, can complete required programming, and gain experiences that, among other things, are distilled into variables feeding into the parole algorithm. Given such power, examining algorithms used on people currently incarcerated offers a unique analytic view to think about the dialectic relationship between data and algorithms. Our examination of the PACT is two-fold and complementary. First, our qualitative overview of the historical context surrounding PACT reveals that it is designed to prioritize incapacitation and control over rehabilitation. While it closely informs prisoner rehabilitation plans and parole considerations, it is rooted in population management for prison securitization. Second, on analyzing data for 146,793 incarcerated people in PA, along with associated metadata related to the PACT, we find it is replete with racial bias as well as errors, omissions, and inaccuracies. Our findings to date further caution against data-driven criminal justice reforms that rely on pre-existing data infrastructures and expansive, uncritical, data-collection routines. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221094002",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Vanessa A. Massaro",
        "Swarup Dhar",
        "Darakhshan Mir",
        "Nathan C. Ryan"
      ],
      "url": "https://doi.org/10.1177/20539517221094002",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 37,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7b91f9eb-e6e0-44b0-b020-c5bb9721d12d",
    "title": "Scaffolding decision spaces in decision support systems: Using plagiarism screening software in editorial offices",
    "abstract": "<jats:p> This paper explores the dynamics of algorithmic governance, decision support systems and human involvement in the context of plagiarism screening in academic publishing. While automated plagiarism screening is widespread in editorial work, critical investigations about these decision support systems remain scarce. Focusing on the issue of human autonomy and discretion in algorithmic governance, the paper investigates the complexities of the human-in-the-loop within these screening tools. Revisiting Wanda Orlikowski's conceptual metaphor of ‘scaffolding’, the study empirically analyses interactions between editors and plagiarism screening software. It traces how these tools act as scaffolds, defining plagiarism as a manageable problem while allowing editors considerable flexibility in decision-making. The software, which is both non-deterministic and powerful, transforms issues into potential decisions, shaping the decision space for human editors. Based on this investigation of screening software as scaffolding, the paper argues that the question of human involvement in systems for automated decision-making is somewhat beside the point, and that analytical attention should shift towards understanding how algorithmic systems configure decision spaces by establishing issues as decidable problems. The implications of this shift are discussed, emphasizing the need for advancing our understanding of power dynamics inherent in algorithm–human interactions within automated decision-making systems. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241306371",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Felicitas Hesselmann"
      ],
      "url": "https://doi.org/10.1177/20539517241306371",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 47,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4c98e6f8-9c9e-4040-9826-f375ecdd0fbe",
    "title": "The old in the new: Voter surveillance in political clientelism and datafied campaigning",
    "abstract": "This article compares political clientelism and datafied campaigning as two modes of relating politicians/parties and voters that are centred around voter surveillance. It contributes to the discussion on consequences of Big Data by showing similarities of datafied campaigns with a type of electoral politics that pre-dates the advent of mass media and is usually regarded as deficient. It thus departs from the predominant perspective on datafication and surveillance, which draws on Foucault, in order to identify the particular challenges that datafication poses in the realm of democratic electoral politics. They are related to four major aspects in which datafied campaigning resembles political clientelism, as opposed to the combination of ideology, issue-based campaigning and media appeal that characterized Western European party politics in the second half of the 20th century. It personalizes the relationship between politicians and voters with the help of intermediaries; it is based on an asymmetric and iterative monitoring of voters; it implies a strong particularism and an affinity with populist appeals; and it is ambivalent with regard to the volition of voters. The identification of these similarities renders general concerns about the consequences of datafied campaigning for democracy more concrete. It offers a mirror in which seemingly novel practices are revealed to have implications that are well known to be problematic for the quality of democracy.",
    "metadata": {
      "doi": "10.1177/2053951720908290",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Isabel Kusche"
      ],
      "url": "https://doi.org/10.1177/2053951720908290",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172090829",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 82,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "844c67d7-dcd6-4dc7-b821-7dae7bfd0ef6",
    "title": "Individual benefits and collective challenges: Experts’ views on data-driven approaches in medical research and healthcare in the German context",
    "abstract": "<jats:p> Healthcare provision, like many other sectors of society, is undergoing major changes due to the increased use of data-driven methods and technologies. This increased reliance on big data in medicine can lead to shifts in the norms that guide healthcare providers and patients. Continuous critical normative reflection is called for to track such potential changes. This article presents the results of an interview-based study with 20 German and Swiss experts from the fields of medicine, life science research, informatics and humanities of digitalisation. The aim of the study was to explore expert opinions regarding current challenges and opportunities related to data-driven medicine and medical research and to provide a methodological framework for empirically grounded, continuous normative reflection. To this end, we developed a heuristic tool to map and structure empirical findings for normative analysis. Using this tool, our interview material points to a polarisation between individualistic and collectivistic orientated argumentations among experts. The study shows that a multilevel analysis is required to deal with complex normative implications of data-driven approaches in medical research and healthcare. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221092653",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Lorina Buhr",
        "Silke Schicktanz"
      ],
      "url": "https://doi.org/10.1177/20539517221092653",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 55,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f3158128-2a13-43f8-bff9-07410826f85c",
    "title": "Understanding game data work",
    "abstract": "<jats:p> The game industry's content production, maintenance of live games, and processes of acquiring production funding increasingly rely on various kinds of data and its rigorous analysis. These new needs and functions have generated emerging forms of work, such as those of the data analyst, data engineer, and data scientist. Through in-depth interviews with 20 Finnish game industry professionals and an analysis of game industry job advertisements, this paper examines the work and identity of game industry data workers. Drawing from scholarship focused on game production, game work, and data labour, this article argues that organisational practices surrounding data professionals reveal the centrality of high-level data work in game studios focused on live service games and that data work is now performed not just by data analysts, but by the entire staff and management. As a precursor to the wider creative industries, we argue that creative work and data work in game companies are gradually converging, due to the datafied work environment facilitating datafied game work and the work of data professionals increasingly intertwining with creative tasks. Complicating the previous game studio hierarchy is the data analyst's dual role as both a subservient support function and a central broker of data. Adding nuance to this, the article argues that an important aspect of the work of bespoke data professionals in game companies is communication, in contrast to the high-level quantitative tasks often associated with analysis. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241309892",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Heikki Tyni",
        "Olli Sotamaa",
        "Taina Myöhänen"
      ],
      "url": "https://doi.org/10.1177/20539517241309892",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "aeca2930-b5d3-4f39-8723-a2ff430fbcfd",
    "title": "Big data and the New Transparency: Measuring and representing police killings",
    "abstract": "<jats:p> Controversies about recent killings by police officers in the United States have prompted widespread questioning about the scale and changes in police use of force. A perceived lack of transparency about the frequency of police killings amplifies concerns that many such killings are unjustified. This commentary considers efforts by journalists and activists to comprise databases that document and measure police violence, particularly in terms of how these endeavors exemplify the New Transparency. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717696332",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Ben Brucato"
      ],
      "url": "https://doi.org/10.1177/2053951717696332",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 26,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "551ad145-6f84-4e5e-b873-52818a3254cf",
    "title": "Big Data, data integrity, and the fracturing of the control zone",
    "abstract": "<jats:p> Despite all the attention to Big Data and the claims that it represents a “paradigm shift” in science, we lack understanding about what are the qualities of Big Data that may contribute to this revolutionary impact. In this paper, we look beyond the quantitative aspects of Big Data (i.e. lots of data) and examine it from a sociotechnical perspective. We argue that a key factor that distinguishes “Big Data” from “lots of data” lies in changes to the traditional, well-established “control zones” that facilitated clear provenance of scientific data, thereby ensuring data integrity and providing the foundation for credible science. The breakdown of these control zones is a consequence of the manner in which our network technology and culture enable and encourage open, anonymous sharing of information, participation regardless of expertise, and collaboration across geographic, disciplinary, and institutional barriers. We are left with the conundrum—how to reap the benefits of Big Data while re-creating a trust fabric and an accountable chain of responsibility that make credible science possible. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714558281",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "Carl Lagoze"
      ],
      "url": "https://doi.org/10.1177/2053951714558281",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 78,
      "is_referenced_by_count": 45,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e3f376e2-f4d7-437a-b62e-393c00b770b5",
    "title": "The role of evidence-based misogyny in antifeminist online communities of the ‘manosphere’",
    "abstract": "<jats:p> In recent years, there have been a growing number of online and offline attacks linked to a loosely connected network of misogynist and antifeminist online communities called ‘the manosphere’. Since 2016, the ideas spread among and by groups of the manosphere have also become more closely aligned with those of other Far-Right online networks. In this commentary, I explore the role of what I term ‘evidence-based misogyny’ for mobilization and radicalization into the antifeminist and misogynist subcultures of the manosphere. Evidence-based misogyny is a discursive strategy, whereby members of the manosphere refer to (and misinterpret) knowledge in the form of statistics, studies, news items and pop-culture and mimic accepted methods of knowledge presentation to support their essentializing, polarizing views about gender relations in society. Evidence-based misogyny is a core aspect for manosphere-related mobilization as it provides a false sense of authority and forges a collective identity, which is framed as a supposed ‘alternative’ to mainstream gender knowledge. Due to its core function to justify and confirm the misogynist sentiments of users, evidence-based misogyny serves as connector between the manosphere and both mainstream conservative as well as other Far-Right and conspiratorial discourses. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221145671",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Ann-Kathrin Rothermel"
      ],
      "url": "https://doi.org/10.1177/20539517221145671",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 33,
      "is_referenced_by_count": 15,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b14e7185-6e35-4e52-b8a0-da811cacd386",
    "title": "Adoption of geodemographic and ethno-cultural taxonomies for analysing Big Data",
    "abstract": "<jats:p> This paper is intended to contribute to the discussion of the differential level of adoption of Big Data among research communities. Recognising the impracticality of conducting an audit across all forms and uses of Big Data, we have restricted our enquiry to one very specific form of Big Data, namely general purpose taxonomies, of which Mosaic, Acorn and Origins are examples, that rely on data from a variety of Big Data feeds. The intention of these taxonomies is to enable the records of consumers and citizens held on Big Data datasets to be coded according to type of residential neighbourhood or ethno-cultural heritage without any use of questionnaires. Based on our respective experience in the academic social sciences, in government and in the design and marketing of these taxonomies, we identify the features of these classifications which appear to render them attractive or problematic to different categories of potential user or researcher depending on how the relationship is conceived. We conclude by identifying seven classifications of user or potential user who, on account of their background, current position and future career expectations, tend to respond in different ways to the opportunity to adopt these generic systems as aids for understanding social processes. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715583914",
      "type": "journal-article",
      "published": [
        2015,
        5
      ],
      "authors": [
        "Richard James Webber",
        "Tim Butler",
        "Trevor Phillips"
      ],
      "url": "https://doi.org/10.1177/2053951715583914",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 15,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e8311638-991f-4c91-8664-94e3152e8b76",
    "title": "The value of Big Data in government: The case of ‘smart cities’",
    "abstract": "The emergence of Big Data has added a new aspect to conceptualizing the use of digital technologies in the delivery of public services and for realizing digital governance. This article explores, via the ‘value-chain’ approach, the evolution of digital governance research, and aligns it with current developments associated with data analytics, often referred to as ‘Big Data’. In many ways, the current discourse around Big Data reiterates and repeats established commentaries within the eGovernment research community. This body of knowledge provides an opportunity to reflect on the ‘promise’ of Big Data, both in relation to service delivery and policy formulation. This includes, issues associated with the quality and reliability of data, from mixing public and private sector data, issues associated with the ownership of raw and manipulated data, and ethical issues concerning surveillance and privacy. These insights and the issues raised help assess the value of Big Data in government and smart city environments.",
    "metadata": {
      "doi": "10.1177/2053951720912775",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Karl Löfgren",
        "C William R Webster"
      ],
      "url": "https://doi.org/10.1177/2053951720912775",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172091277",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 88,
      "is_referenced_by_count": 69,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a2e92469-740d-4c82-b775-1cf8d88cd1f9",
    "title": "Squeaky wheels: Missing data, disability,  and power in the smart city",
    "abstract": "<jats:p> Data about the accessibility of United States municipalities is infrastructure in the smart city. What is counted and how, reflects the sociotechnical imaginary (norms and values) of a time or place. In this paper we focus on features identified by people with disabilities as promoting or hindering safe pedestrian travel. We use a regionally stratified sample of 178 cities across the United States. The municipalities were scored on two factors: their open data practices (or lack thereof), and the degree to which they cataloged the environmental features that persons with disabilities deemed critical for safe movement through urban spaces. In contradiction to the dominating narrative of too much data and not enough analyses, we find that when it comes to data points that might be useful to persons with disabilities, data are lacking. This data gap has consequences both politically and materially—on one hand data could help enforce compliance with the Americans with Disabilities Act, on the other they would allow for safe route planning. We find that reading these data formats and collection patterns from the perspective of critical disability studies—particularly those whose work disrupts notions of “normal” —helps answer questions about potential benefits and harms of data practices. This lens has the potential to promote analysis that is as disruptive to injustices as it is practical. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211047735",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Shiloh Deitz",
        "Amy Lobben",
        "Arielle Alferez"
      ],
      "url": "https://doi.org/10.1177/20539517211047735",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 73,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e29c31ff-20b9-4733-8e90-a636329f63cf",
    "title": "Techno-solutionism and the standard human in the making of the COVID-19 pandemic",
    "abstract": "<jats:p> Quantification is particularly seductive in times of global uncertainty. Not surprisingly, numbers, indicators, categorizations, and comparisons are central to governmental and popular response to the COVID-19 pandemic. This essay draws insights from critical data studies, sociology of quantification and decolonial thinking, with occasional excursion into the biomedical domain, to investigate the role and social consequences of counting broadly defined as a way of knowing about the virus. It takes a critical look at two domains of human activity that play a central role in the fight against the virus outbreak, namely medical sciences and technological innovation. It analyzes their efforts to craft solutions for their user base and explores the unwanted social costs of these operations. The essay argues that the over-reliance of biomedical research on “whiteness” for lab testing and the techno-solutionism of the consumer infrastructure devised to curb the social costs of the pandemic are rooted in a distorted idea of a “standard human” based on a partial and exclusive vision of society and its components, which tends to overlook alterity and inequality. It contends that to design our way out of the pandemic, we ought to make space for distinct ways of being and knowing, acknowledging plurality and thinking in terms of social relations, alterity, and interdependence. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720966781",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Stefania Milan"
      ],
      "url": "https://doi.org/10.1177/2053951720966781",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 54,
      "is_referenced_by_count": 56,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "81b3fccb-baa2-479c-9eff-6ec39a06ae6d",
    "title": "Shareveillance: Subjectivity between open and closed data",
    "abstract": "<jats:p> This article attempts to question modes of sharing and watching to rethink political subjectivity beyond that which is enabled and enforced by the current data regime. It identifies and examines a ‘shareveillant’ subjectivity: a form configured by the sharing and watching that subjects have to withstand and enact in the contemporary data assemblage. Looking at government open and closed data as case studies, this article demonstrates how ‘shareveillance’ produces an anti-political role for the public. In describing shareveillance as, after Jacques Rancière, a distribution of the (digital) sensible, this article posits a politico-ethical injunction to cut into the share and flow of data in order to arrange a more enabling assemblage of data and its affects. In order to interrupt shareveillance, this article borrows a concept from Édouard Glissant and his concern with raced otherness to imagine what a ‘right to opacity’ might mean in the digital context. To assert this right is not to endorse the individual subject in her sovereignty and solitude, but rather to imagine a collective political subjectivity and relationality according to the important question of what it means to ‘share well’ beyond the veillant expectations of the state. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716663965",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Clare Birchall"
      ],
      "url": "https://doi.org/10.1177/2053951716663965",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 30,
      "is_referenced_by_count": 24,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d7f3d43c-aff2-4f67-acfe-694fb0cd198c",
    "title": "Intentionality and design in the data sonification of social issues",
    "abstract": "<jats:p> Data sonification is a practice for conducting scientific analysis through the use of sound to represent data. It is now transitioning to a practice for communicating and reaching wider publics by expanding the range of languages and senses for understanding complexity in data-intensive societies. Communicating to wider publics, though, requires that authors intentionally shape sonification in ways that consider the goals and contexts in which publics relate. It requires a specific set of knowledge and skills that design as a discipline could provide. In this article, we interpret five recent sonification projects and locate them on a scale of intentionality in how authors communicate socially relevant issues to publics. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720944603",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Sara Lenzi",
        "Paolo Ciuccarelli"
      ],
      "url": "https://doi.org/10.1177/2053951720944603",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 27,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9e033aa2-4c26-491c-b5ef-a5a725439536",
    "title": "A practical role-based approach for autonomous vehicle moral dilemmas",
    "abstract": "<jats:p> Autonomous vehicle moral dilemmas matter less for the particular outcomes of potential accidents than for their role in defining the values of the society we wish to live in. Different approaches have been suggested to determine the ethical settings that autonomous vehicles should be implemented in and identify the legitimate agents for making such decisions. Most of these, however, fail on theoretical grounds, facing severe issues related to moral justifications and compliance to the law, or on practical grounds, being insufficiently universal, action-guiding, or technically viable to be implemented. The analogy with the “trolley problem” has been extensively discussed. However, researchers have rarely tried to adapt this framework to autonomous vehicle cases or investigate how it could be used to address these issues. In doing so, this paper aims to answer the two key problems of autonomous vehicle dilemmas. With regards to the decision-maker, it rejects autonomous vehicle users’ choice-based models, showing the absurdity of both switch of control and adaptative preferences and arguing for common legislator-determined ethical settings. With regards to the decisions themselves, it criticizes both utilitarian views and those based on individuals’ criteria to suggest a deontologist rights-based approach. This allows for the defence of a morally coherent, regulatory compliant, explainable, and easily implementable framework capable of addressing all autonomous vehicle moral dilemma scenarios present in the literature. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221123305",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Hubert Etienne"
      ],
      "url": "https://doi.org/10.1177/20539517221123305",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f18fdb01-0a5f-46c4-b5b3-638d4220b16a",
    "title": "Ethical assessments and mitigation strategies for biases in AI-systems used during the COVID-19 pandemic",
    "abstract": "<jats:p> The main aim of this article is to reflect on the impact of biases related to artificial intelligence (AI) systems developed to tackle issues arising from the COVID-19 pandemic, with special focus on those developed for triage and risk prediction. A secondary aim is to review assessment tools that have been developed to prevent biases in AI systems. In addition, we provide a conceptual clarification for some terms related to biases in this particular context. We focus mainly on non-racial biases that may be less considered when addressing biases in AI systems in the existing literature. In the manuscript, we found that the existence of bias in AI systems used for COVID-19 can result in algorithmic justice and that the legal frameworks and strategies developed to prevent the apparition of bias have failed to adequately consider social determinants of health. Finally, we make some recommendations on how to include more diverse professional profiles in order to develop AI systems that increase the epistemic diversity needed to tackle AI biases during the COVID-19 pandemic and beyond. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231179199",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Alicia de Manuel",
        "Janet Delgado",
        "Iris Parra Jounou",
        "Txetxu Ausín",
        "David Casacuberta",
        "Maite Cruz",
        "Ariel Guersenzvaig",
        "Cristian Moyano",
        "David Rodríguez-Arias",
        "Jon Rueda",
        "Angel Puyol"
      ],
      "url": "https://doi.org/10.1177/20539517231179199",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 72,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f2929c44-6eee-4539-a952-f083946e7be8",
    "title": "The EU Settlement Scheme: Footprints in quicksand",
    "abstract": "<jats:p> Part of an accelerated trend to integrate algorithms in immigration decision-making, the UK's EU Settlement Scheme relies on automated data checks as an essential and mandatory step in the application for UK residence. In this article, I engage with the literature on datafication and algorithmic accuracy to showcase algorithmic inaccuracy within borders in regard to the allocation of residence statuses and rights. I argue that, while the EUSS uses big data to create a data double of the ‘desirable’ migrant, even applicants within this category experience mismatches. Some EU+ Citizens on linear residence and career trajectories were initially offered pre-settled status and had difficulty proving their entitlement to the full status, while others, who did not qualify for settled status, obtained it nevertheless. The analysis is based on in-depth interviews with high skilled applicants, and experts on the EUSS, exposing that footprints are not evidence per se. Instead, the outcomes are decided by an opaque algorithm that is not retained and disappears as easily as footprints in quicksand. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241242537",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Cristina Juverdeanu"
      ],
      "url": "https://doi.org/10.1177/20539517241242537",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 69,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e8966c0a-23ed-478f-ae40-c2c8e7824537",
    "title": "A post-truth pandemic?",
    "abstract": "<jats:p> As the coronavirus pandemic continues apace in the United States, the dizzying amount of data being generated, analyzed and consumed about the virus has led to calls to proclaim this the first ‘data-driven pandemic’. But at the same time, it seems that this plethora of data has not meant a better grasp on the reality of the pandemic and its effects. Even as we have the potential to digitally track and trace nearly every single individual who has contracted the virus, we have no idea exactly how many people have had the virus, been hospitalized, or died because of it, largely due to a confluence of factors, particularly active obfuscation and mismanagement by public authorities and misinformation spread through social media and right-wing media channels. But beyond these dynamics, there also lies the less nefarious ways that the everyday, subjective practices of data collection, analysis and visualization have the potential to themselves (re)produce these very same dynamics where data is at once valorized and ignored, preeminent and completely useless. That is, the pandemic has revealed only the general inadequacy of our data infrastructures and assemblages to solving pressing social issues, but also the more general shift towards a ‘post-truth’ disposition in contemporary social life. But, as this paper argues, it would be a mistake to see the centrality of data as being somehow the opposite from the larger post-truth apparatus, as the two are instead fundamentally intertwined and co-produced. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720965612",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Taylor Shelton"
      ],
      "url": "https://doi.org/10.1177/2053951720965612",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 28,
      "is_referenced_by_count": 30,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1c591ffe-3b54-4e8b-a8ca-501accc4e24a",
    "title": "With great (statistical) power comes  great responsibility: A comment on the ethics of using administrative data to investigate marginalised populations",
    "abstract": "<jats:p> As health data infrastructure improves, we have the opportunity to link increasing volumes of data in order to investigate important health problems. This is perhaps most pertinent when looking at the experiences and outcomes of our most disadvantaged groups, who are often invisible in data obtained through primary research. Whilst these data offer enormous opportunity, there are also ethical implications in their use, which are less frequently discussed than in relation to their qualitative counterparts. As a diverse group of clinicians and academics working across public health, we share our experience and understanding of how we can improve our reflexivity in health data science and ensure that research in this area is ethically conducted in co-production with the people whose data we are using. We discuss the potential opportunities, challenges and impacts of using administrative data to investigate marginalised populations. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241296058",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Louise Marryat",
        "Ruchika Gajwani",
        "Sharon Graham",
        "Marion Henderson",
        "Christine Puckering",
        "Lucy Thompson",
        "Philip Wilson",
        "Helen Minnis"
      ],
      "url": "https://doi.org/10.1177/20539517241296058",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 19,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f228d45e-dd26-4e22-bf2e-1c58200c1a0e",
    "title": "Mapping materials, drawing Europe: Sample and data quality and accessibility in the biobanking infrastructure BBMRI-ERIC",
    "abstract": "<jats:p> The European biobanking infrastructure BBMRI-ERIC was established in the context of European Union science policy to facilitate collaboration between European repositories of biological samples and associated data, or so-called biobanks. To allow the exchange of research materials, the infrastructure has created several platforms for quality management and making materials visible and accessible. In this article, I develop the metaphor of mapping to explore the workings of these platforms. I consider maps as devices for giving directions, as representations of science, and as (symbolic) outlines of the territory of Europe to explore how BBMRI-ERIC's activities in quality management and IT-platforms for making materials visible and accessible (aim to) facilitate circulation. Across the different platforms, efforts to harmonize and integrate European biobanking activities confront both scientific and European tendencies toward fragmentation. The map of a European biobanking community drawn by BBMRI-ERIC consequently both makes and unmakes Europe sketching a Europe of both harmonization and fragmentation. In laying bare these paradoxical effects of the construction of a European biobanking infrastructure, using mapping as a lens shows how, rather than realizing its much-cited role as a “facilitator” for research, BBMRI-ERIC embodies key tensions at the center of efforts to advance “data-based” (big) science. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241303128",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Erik Aarden"
      ],
      "url": "https://doi.org/10.1177/20539517241303128",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 86,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8700b948-12c4-40bc-ab43-49a216e32253",
    "title": "Quantifying the self with others",
    "abstract": "<jats:p> Self-trackers collect personal data for many reasons, including generating insight about their bodies, habits, productivity, and wellbeing. Self-tracking may expose intimate facets of daily life, raising important questions about surveillance, privacy, and data ownership. In this study, we investigated an online community of self-trackers and their weekly “show-and-tell” presentations through observations of their meetings and interviews with members. Making sense of their personal data in community with others involved practical and philosophical difficulties that participants navigated by integrating competing priorities for their interactions in specific communication moves and by transcending interactional difficulties through a shared focus on an open science data imaginary. The findings contribute to the study of the datafication of health by revealing how their interactions helped them generate meaning, how they navigated the tensions inherent to making sense of personal data in community with others, and how they deliberated about the broader social issues implicated in their practice. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241247831",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Shelbey R. Call",
        "Jared T. Jensen",
        "Joshua B. Barbour"
      ],
      "url": "https://doi.org/10.1177/20539517241247831",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 35,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "462eb478-e3c3-4465-9cc2-712ab3972a83",
    "title": "How partners mediate platform power: Mapping business and data partnerships in the social media ecosystem",
    "abstract": "<jats:p> Social media platforms’ digital advertising revenues depend considerably on partnerships. Business partnerships are endemic and essential to the business of platforms, yet their role remains relatively underexplored in the literature on platformisation and platform power. This article considers the significance of partnerships in the social media ecosystem to better understand how industry platforms, and the infrastructure they build, mediate and shape platform power and governance. We argue that partners contribute to ‘platformisation’ through their collective development of business-to-business platform infrastructures. Specifically, we examine how partners have integrated social media platforms with what we call the audience economy – an exceptionally complex global and interconnected marketplace of intermediaries involved in the creation, commodification, analysis, and circulation of data audiences for purposes including but not limited to digital advertising and marketing. We determined which relationships are involved, which are exclusive or shared, and identified key ecosystem partners. Further, we found that partners build and integrate extensive infrastructures for data-sourcing and media distribution, surfacing infrastructural and strategic sources and locations, or ‘nodes’, of power in this ecosystem. The empirical findings thus highlight the significance of partnerships and partner integrations and draw attention to the powerful industry players and intermediaries that remain largely invisible. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211025061",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Fernando N van der Vlist",
        "Anne Helmond"
      ],
      "url": "https://doi.org/10.1177/20539517211025061",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 50,
      "is_referenced_by_count": 41,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "274afd52-37d2-415e-8535-a3ec0c24f5a4",
    "title": "Big Data in the 1800s in surgical science: A social history of early large data set development in urologic surgery in Paris and Glasgow",
    "abstract": "<jats:p> “Big Data” in health and medicine in the 21st century differs from “Big Data” used in health and medicine in the 1700s and 1800s. However, the old data sets share one key component: large numbers. The term “Big Data” is not synonymous with large numbers. Large numbers are a key component of Big Data in health and medicine, both for understanding the full range of how a disease presents in a human for diagnosis, and for understanding if one treatment of a disease is better than another treatment or better than just leaving the patient on his or her own without therapy. In this paper, we examine the first considerations of Big Data in medicine in Paris in the early 1800s when urologic surgeon Jean Civiale collected the first large numbers. Civiale collected the large numbers to defend the efficacy of his urologic instrument, the lithotrite, and the surgical procedure he developed, lithotrity, for the removal of bladder stones compared with earlier, more invasive surgical approaches. We examine how large numbers were adjudicated in social decision-making in the Académie des sciences, Paris, when a dispute arose among French urologic surgeons about the importance of large numbers in surgical science. After Civiale’s successful defense of his instrument and procedure in Paris, we examine how his approach to Big Data (large numbers) impacted data collection by George Buchanan in his use of the procedure at the Royal Hospital Infirmary in Glasgow. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714543701",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "Dennis J Mazur"
      ],
      "url": "https://doi.org/10.1177/2053951714543701",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 27,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fda63b16-5d28-4820-b138-eea27c977696",
    "title": "Surveillance experiences of extinction rebellion activists and police: Unpacking the technologization of Dutch protest policing",
    "abstract": "<jats:p> Recent years have witnessed an intensifying debate on the deployment of emerging surveillance technologies in protests. Often discussed in terms of “chilling effects”—where activists self-censor due to fear of surveillance repercussions—there's limited research on its effects on both activists and law enforcement. This study explores the technologization of protest policing, moving beyond the oversimplified cat-and-mouse game analogy, to examine its effects on surveillance experiences in more nuanced ways. By analyzing observations and interview data from 2023 road blockades by Extinction Rebellion in The Hague, Netherlands, this paper highlights the intricate consequences of surveillance technologies for both sides. Moving beyond the narrow legal interpretation of “chilling effects,” it uncovers two further socio-psychological sub-manifestations, showing how both groups adapt through hyper-transparency (extreme openness) and hyper-alertness (extreme caution). The study demonstrates how these experiences can be self-reinforcing, where reciprocal suspicion might contribute to a cycle of mutual distrust beyond protest contexts, but also introduces new forms of resilience. This cycle, despite lacking clear causality, bears important implications for society at large. Pervasive suspicion erodes institutional trust among activists and threatens the traditionally communicative and de-escalation-focused approach of Dutch law enforcement. Overall, this extended impact indicates that the technologization of protest policing has resulted in a hybridization of screens and streets, causing its human impacts to stretch beyond the specific times and places of demonstrations. Protest policing now encompasses a multifaceted spectrum of surveillance experiences, affecting a plethora of public values, beyond the right to protest alone. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241307892",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Majsa Storbeck",
        "Gabriele Jacobs",
        "Marc Schuilenburg",
        "Robin van den Akker"
      ],
      "url": "https://doi.org/10.1177/20539517241307892",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 102,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "95754e99-d92a-4447-bae4-bd253db3055e",
    "title": "Wikipedia, sociology, and the promise and pitfalls of Big Data",
    "abstract": "<jats:p> Wikipedia is an important instance of “Big Data,” both because it shapes people's frames of reference and because it is a window into the construction—including via crowd-sourcing—of new bodies of knowledge. Based on our own research as well as others' critical and ethnographic work, we take as an instance Wikipedia's evolving representation of the field of sociology and sociologists, including such gendered aspects as male and female scholars and topics associated with masculinity and femininity. Both the gender-specific dynamics surrounding what counts as “notability” on the online encyclopedia and Wikipedia's relative categorical incoherence are discussed. If “Big Data” can be said to construct its own object, it is, in this instance, a curious and lop-sided one, exemplifying pitfalls as well as promise with respect to more accurate and democratic forms of knowledge. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715614332",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Julia Adams",
        "Hannah Brückner"
      ],
      "url": "https://doi.org/10.1177/2053951715614332",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 18,
      "is_referenced_by_count": 21,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "24b06790-a599-4be1-b3d2-fbf0552e8f22",
    "title": "In data we (don't) trust: The public adrift in data-driven public opinion models",
    "abstract": "<jats:p> This article seeks to address current debates comparing polls and opinion mining as empirically based figuration models of public opinion in the light of in-depth intellectual debates on the role and nature of public opinion that began after the French Revolution and the controversy over public opinion spurred by the invention of polls. Issues of historical quantification and re-conceptualisation of public opinion are addressed in four parts. The first summarises the history of the rise and fall of the concept of public opinion. The second re-examines the key controversies in the debates on the theoretical, empirical and social implications and consequences of the invention of polling. The third part scrutinises the datafication of public opinion that started with polling industry and continues in the age of big data and data mining. The final section discusses the controversial potentials of opinion-mining technology and suggests ways in which social scientists could critically respond to the big data and opinion-mining challenges in order to reintegrate the ideas of publicness, the public and public sphere into public opinion research. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221097319",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Slavko Splichal"
      ],
      "url": "https://doi.org/10.1177/20539517221097319",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 65,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "dc2ccc31-5d07-45e0-a231-595b81fb13be",
    "title": "Introduction to Articles from the 2014 Conference on Social Media &amp; Society",
    "abstract": "Data, data everywhere. With faster computers and cheaper storage, bigger data sets are becoming abundant. Social media is a key source of Big Data in the form of user and system generated content. What do we do with all of the social data and how do we make sense of it? How does the use of social",
    "metadata": {
      "doi": "10.1177/2053951715621570",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Anatoliy Gruzd"
      ],
      "url": "https://doi.org/10.1177/2053951715621570",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f2e45daf-b9f1-4b35-81c5-e137b2dc4c35",
    "title": "Automated analysis of the US presidential elections using Big Data and network analysis",
    "abstract": "<jats:p> The automated parsing of 130,213 news articles about the 2012 US presidential elections produces a network formed by the key political actors and issues, which were linked by relations of support and opposition. The nodes are formed by noun phrases and links by verbs, directly expressing the action of one node upon the other. This network is studied by applying insights from several theories and techniques, and by combining existing tools in an innovative way, including: graph partitioning, centrality, assortativity, hierarchy and structural balance. The analysis yields various patterns. First, we observe that the fundamental split between the Republican and Democrat camps can be easily detected by network partitioning, which provides a strong validation check of the approach adopted, as well as a sound way to assign actors and topics to one of the two camps. Second, we identify the most central nodes of the political camps. We also learnt that Clinton played a more central role than Biden in the Democrat camp; the overall campaign was much focused on economy and rights; the Republican Party (Grand Old Party or GOP) is the most divisive subject in the campaign, and is portrayed more negatively than the Democrats; and, overall, the media reported positive statements more frequently for the Democrats than the Republicans. This is the first study in which political positions are automatically extracted and derived from a very large corpus of online news, generating a network that goes well beyond traditional word-association networks by means of richer linguistic analysis of texts. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715572916",
      "type": "journal-article",
      "published": [
        2015,
        5
      ],
      "authors": [
        "Saatviga Sudhahar",
        "Giuseppe A Veltri",
        "Nello Cristianini"
      ],
      "url": "https://doi.org/10.1177/2053951715572916",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 42,
      "is_referenced_by_count": 23,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e0dccac5-7f4b-4753-9d02-b9bdc2991d31",
    "title": "COVID-19: What does it mean for digital social protection?",
    "abstract": "<jats:p> COVID-19 has hit a world in which social protection schemes are increasingly augmented with digital measures. Digital identity schemes are especially being adopted to match citizens’ data with social protection entitlements, enabling authentication through demographic and, increasingly, biometric data at the point of access. In this commentary, I discuss three sets of implications that COVID-19 has yielded on digital social protection, whose central trade-off – increasing the probabilities of accurate user identification, at the cost of greater exclusions – has become even more problematic during the crisis. I argue that three forms of data injustice – legal, informational and design-related, previously identified in datafied social protection schemes, will need to be monitored in the post-pandemic scenario. I finally observe that the crisis exposes the long-term need to place digitality within social protection schemes that expand user entitlements rather than constraining them. Implications of such reflections are drawn for the study of data-based social welfare interventions. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720978995",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Silvia Masiero"
      ],
      "url": "https://doi.org/10.1177/2053951720978995",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 39,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "81ed123a-cef1-4e67-85b2-6e019f1d8e56",
    "title": "A view from anthropology: Should anthropologists fear the data  machines?",
    "abstract": "<jats:p> If you are an anthropologist wanting to use digital methods or programming as part of your research, where do you start? In this commentary, we discuss three ways in which anthropologists can use computational tools to enhance, support, and complement ethnographic methods. By presenting our reflections, we hope to contribute to the stirring conversations about the potential future role(s) of (social) data science vis-a-vis anthropology and ethnography, and to inspire other anthropologists to take up the use of digital methods, programming, and computational tools in their own research. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211043655",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Kristoffer Albris",
        "Eva I Otto",
        "Sofie L Astrupgaard",
        "Emilie Munch Gregersen",
        "Laura Skousgaard Jørgensen",
        "Olivia Jørgensen",
        "Clara Rosa Sandbye",
        "Signe Schønning"
      ],
      "url": "https://doi.org/10.1177/20539517211043655",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 20,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "33c27217-433a-4bc0-982b-a29e0bd2918c",
    "title": "At close quarters: Combatting Facebook design, features and temporalities in social research",
    "abstract": "<jats:p> As researchers we often find ourselves grappling with social media platforms and data ‘at close quarters’. Although social media platforms were created for purposes other than academic research – which are apparent in their architecture and temporalities – they offer opportunities for researchers to repurpose them for the collection, generation and analysis of rich datasets. At the same time, this repurposing raises an evolving range of practical and methodological challenges at the small and large scale. We draw on our experiences and empirical data from two research projects, one using Facebook Community Pages and the other repurposing Facebook Activity Logs. This article reflects critically on the specific challenges we faced using these platform features, on their common roots, and the tactics we adopted in response. De Certeau’s distinction between strategy and tactics provides a useful framework for exploring these struggles as located in the practice of doing social research – which often ends up being tactical. This article argues that we have to collectively discuss, demystify and devise tactics to mitigate the strategies and temporalities deeply embedded in platforms, corresponding as far as possible to the temporalities and the aims of our research. Although combat at close quarters is inevitable in social media research, dialogue between researchers is more than ever needed to tip the scales in our favour. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718802316",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Justine Gangneux",
        "Stevie Docherty"
      ],
      "url": "https://doi.org/10.1177/2053951718802316",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 54,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "32bda7ee-a293-4914-b436-8c5398b847c6",
    "title": "Bridging awareness and resistance: Using algorithmic knowledge against controversial content",
    "abstract": "<jats:p> Political and moral/religious contents are increasingly popular on TikTok, and the concerns associated with them create the premises for a re-exploration of the user–machine agency negotiation. Using algorithmic awareness as a process, this research examines the relationship between users’ awareness of the TikTok algorithm and the main concerns associated with content that conveys political or moral/religious tenets. A survey of 329 Romanian students showed that greater algorithm awareness influences positive attitudes toward algorithms, but significantly stronger positive effects are observed between awareness and the two mediators related to political and moral/religious content perceived as contentious. Using Foucauldian insights on productive resistance, I argue that in-depth knowledge about the functionality of algorithms empower users to identify and subvert different forms of power, algorithmically mediated through political or religious content. When users perceive that they have enhanced agency over what they watch on TikTok, they feel that they can control potential concerns and consequently adopt positive attitudes toward algorithms and the overall platform. Foucault discusses pastoral power as a subtle form of power, designed to empty individuals of their deepest secrets. Similarly, such power is increasingly algorithmically mediated, given that digital machines enhance their agency in often nontransparent ways. Therefore, users’ awareness regarding the functionalities of algorithms allow them to combat the various mutations specific to pastoral power while encouraging them to adopt more positive attitudes toward algorithms in general. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241296046",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Dragoș M Obreja"
      ],
      "url": "https://doi.org/10.1177/20539517241296046",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 63,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "30e72ac4-d029-49a6-ad78-7664ba77a38e",
    "title": "Data infrastructure studies on an unequal planet",
    "abstract": "<jats:p> In this article, I take the case of data centers as a powerful tool and infrastructure of multinational digital capitalism, analyzing the ways in which understanding these and other data infrastructures through their energy frameworks allows us to theorize the implications of planetary environmental impacts of digital data for contemporary subjects beyond individual data technologies themselves. This is especially true in data centers’ function as energy vacuums and in their carbon and extractive footprints and other environmental externalities. I demonstrate that data centers organize an assemblage of environmental relations whose operations reproduce uneven systems of capitalism enacted through energy and environmental politics. While this article is by no means comprehensive, and by necessity must be selective in its engagement with key texts in a number of overlapping fields, it broadly draws from media studies, geographical, and sociological approaches to data infrastructures to unravel the entanglements of digital systems and the environment. Data centers and their energy connections represent multivalent sites and indications into the global supply chain of data infrastructure, and their extractive dynamic as networked infrastructure fundamentally changes how we need to see their impacts and the impacts of datafication more broadly. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231182402",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Patrick Brodie"
      ],
      "url": "https://doi.org/10.1177/20539517231182402",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 115,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "baacb2e4-9881-4d22-abd2-3af974089ba7",
    "title": "Corrigendum to Leveraging blockchain for energy transition in urban contexts",
    "abstract": "",
    "metadata": {
      "doi": "10.1177/20539517231223863",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [],
      "url": "https://doi.org/10.1177/20539517231223863",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "not available"
    }
  },
  {
    "id": "d116f1c3-3570-463d-b84d-f956e6493803",
    "title": "It’s time to scale the science in the social sciences",
    "abstract": "<jats:p> The social sciences are at a remarkable confluence of events. Advances in computing have made it feasible to analyze data at the scale of the population of the world. How can we combine the depth of inquiry in the social sciences with the scale and robustness of statistics and computer science? Can we decompose complex questions in the social sciences into simpler, more robustly testable hypotheses? We discuss these questions and the role of machine learning in the social sciences. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714532240",
      "type": "journal-article",
      "published": [
        2014,
        4,
        1
      ],
      "authors": [
        "Prabhakar Raghavan"
      ],
      "url": "https://doi.org/10.1177/2053951714532240",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 2,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7a7af469-c747-4e1b-82d8-f7af7a4c068c",
    "title": "Living on the block: How equitable is tokenized equity?",
    "abstract": "<jats:p> Recently blockchain has become a tool for spatial coordination and appropriation. Globally, the tokenization of land and housing has led to new forms of datafication and increased financialization. In the case of land non-fungible tokens), security token offerings, and blockchain-based real estate investment trusts, blockchains act as exclusionary digital platforms, with new socio-technical assemblages emerging as complex predatory formations of speculation that are intentionally obfuscatory and difficult to regulate. With the security token offering, crowdfunding and venture capital are combined with cryptocurrency to create a “tokenized venture capital fund” tied to tangible assets, such as ownership rights in housing, real estate, or land. Distributed ledgers are proposed to be used as the digital technology underlying new forms of land/property documentation, ownership, and inhabitation – from conducting and recording land surveys and title creation to transference of land/property rights. This paper addresses the question: how equitable is tokenized equity – does it prioritize the right to the city for all or to all but a very few? This paper looks toward the means of contestation against extractive crypto-settlements, speculation, and housing financialization, critically comparing a range of proposed distributed ledger technology projects that claim to inject equity in the system, pose alternative housing economies, or leverage distributed ledgers for land rights and data sovereignty. I question the utility and limits of datafication and explore how engaging with digital technology – with or without distributed ledgers – can raise awareness and enact alternative forms of housing and land stewardship, from cooperativism to Community Land Trusts and to counter-hegemonic commoning practices. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231208455",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Jillian Crandall"
      ],
      "url": "https://doi.org/10.1177/20539517231208455",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 73,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "391cdfb8-0e69-427a-8de7-89a7f31d96ae",
    "title": "Failing the market, failing deliberative democracy: How scaling up corporate carbon reporting proliferates information asymmetries",
    "abstract": "<jats:p> Corporate carbon footprint data has become ubiquitous. This data is also highly promissory. But as this paper argues, such data fails both consumers and citizens. The governance of climate change seemingly requires a strong foundation of data on emission sources. Economists approach climate change as a market failure, where the optimisation of the atmosphere is to be evidence based and data driven. Citizens or consumers, state or private agents of control, all require deep access to information to judge emission realities. Whether we are interested in state-led or in neoliberal ‘solutions’ for either democratic participatory decision-making or for preventing market failure, companies’ emissions need to be known. This paper draws on 20 months of ethnographic fieldwork in a Fortune 50 company’s environmental accounting unit to show how carbon reporting interferes with information symmetry requirements, which further troubles possibilities for contesting data. A material-semiotic analysis of the data practices and infrastructures employed in the context of corporate emissions disclosure details the situated political economies of data labour along the data processing chain. The explicit consideration of how information asymmetries are socially and computationally shaped, how contexts are shifted and how data is systematically straightened out informs a reflexive engagement with Big Data. The paper argues that attempts to automatise environmental accounting’s veracity management by means of computing metadata or to ensure that data quality meets requirements through third-party control are not satisfactory. The crossover of Big Data with corporate environmental governance does not promise to trouble the political economy that hitherto sustained unsustainability. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716673390",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Ingmar Lippert"
      ],
      "url": "https://doi.org/10.1177/2053951716673390",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 45,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c8290e7f-e678-43f2-9203-f24e2fddaa15",
    "title": "Heritage transformations",
    "abstract": "<jats:p> This special theme examines the dynamic relationships between production, availability, and usage of Big Data, laying out a research agenda for digital heritage at the time of the ‘data turn’. Over the past 15 years, a proliferation of heritage data has been generated by ‘ecosystems of distributed practices’ enacted by the co-working of bodies, cultural identities, organisational workflows, software, application programming interfaces, etc. The authors of research articles and commentaries in this collection explore the three macro-dimensions along which we can map transformations of and by heritage in Big Data ecologies: (a) ontologies or heritage as datified resources, (b) interactions and (c) methodologies and epistemologies. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211034302",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Chiara Bonacchi"
      ],
      "url": "https://doi.org/10.1177/20539517211034302",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 22,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2cc4c4e8-e6e1-4e0f-a0c2-ce5424cfd9a0",
    "title": "Medical research, Big Data and the need for privacy by design",
    "abstract": "<jats:p> Medical research data is sensitive personal data that needs to be protected from unauthorized access and unintentional disclosure. In a research setting, sharing of (big) data within the scientific community is necessary in order to make progress and maximize scientific benefits derived from valuable and costly data. At the same time, convincingly protecting the privacy of people (patients) participating in medical research is a prerequisite for maintaining trust and willingness to share. In this commentary, we will address this issue and the pitfalls involved in the context of the PEP project<jats:sup> 1 </jats:sup> that provides the infrastructure for the Personalized Parkinson’s Project,<jats:sup> 2 </jats:sup> a large cohort study on Parkinson’s disease from Radboud University Medical Center (Radboudumc), in cooperation with Verily life Sciences, an Alphabet subsidiary. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718824352",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Bart Jacobs",
        "Jean Popma"
      ],
      "url": "https://doi.org/10.1177/2053951718824352",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 9,
      "is_referenced_by_count": 20,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6a50966d-a6e2-4e08-9ba5-b3f01efa3094",
    "title": "The datafication revolution in  criminal justice: An empirical  exploration of frames portraying  data-driven technologies for crime prevention and control",
    "abstract": "<jats:p> The proliferation of big data analytics in criminal justice suggests that there are positive frames and imaginaries legitimising them and depicting them as the panacea for efficient crime control. Criminological and criminal justice scholarship has paid insufficient attention to these frames and their accompanying narratives. To address the gap created by the lack of theoretical and empirical insight in this area, this article draws on a study that systematically reviewed and compared multidisciplinary academic abstracts on the data-driven tools now shaping decision-making across several justice systems. Using insights distilled from the study, the article proposes three frames (optimistic, neutral, oppositional) for understanding how the technologies are portrayed. Inherent in the frames are a set of narratives emphasising their ostensible status as vital crime control mechanisms. These narratives obfuscate the harms of data-driven technologies and evince idealistic imaginaries of their capabilities. The narratives are bolstered by unequal structural arrangements, specifically the unevenly distributed digital capital with which some are empowered to participate in technology development for criminal justice application and other forms of penal governance. In unravelling these issues, the article advances current understanding of the dynamics that sustain the depiction of data-driven technologies as prime crime prevention and law enforcement tools. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211049670",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Anita Lavorgna",
        "Pamela Ugwudike"
      ],
      "url": "https://doi.org/10.1177/20539517211049670",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 78,
      "is_referenced_by_count": 18,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "64d9256a-a307-4b1f-848c-e38cef95d45d",
    "title": "Bot, or not? Comparing three methods for detecting social bots  in five political discourses",
    "abstract": "<jats:p> Social bots – partially or fully automated accounts on social media platforms – have not only been widely discussed, but have also entered political, media and research agendas. However, bot detection is not an exact science. Quantitative estimates of bot prevalence vary considerably and comparative research is rare. We show that findings on the prevalence and activity of bots on Twitter depend strongly on the methods used to identify automated accounts. We search for bots in political discourses on Twitter, using three different bot detection methods: Botometer, Tweetbotornot and “heavy automation”. We drew a sample of 122,884 unique user Twitter accounts that had produced 263,821 tweets contributing to five political discourses in five Western democracies. While all three bot detection methods classified accounts as bots in all our cases, the comparison shows that the three approaches produce very different results. We discuss why neither manual validation nor triangulation resolves the basic problems, and conclude that social scientists studying the influence of social bots on (political) communication and discourse dynamics should be careful with easy-to-use methods, and consider interdisciplinary research. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211033566",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Franziska Martini",
        "Paul Samula",
        "Tobias R Keller",
        "Ulrike Klinger"
      ],
      "url": "https://doi.org/10.1177/20539517211033566",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 61,
      "is_referenced_by_count": 51,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "faa07b1a-1690-4e0c-9b03-cae6793f5cca",
    "title": "Virtual state, where are you? A literature review, framework and agenda for failed digital transformation",
    "abstract": "<jats:p> The users, sensors and networks of the Internet of Things generate huge amounts of data. Given the sophisticated (artificially intelligent) algorithms, computing power and software available, we would expect governments to have successfully completed their digital transformation into Jane Fountain's (2001) ‘Virtual State’. In practice, despite heavy investments, governments often fail to enact new digital technologies in an efficient, appropriate or fair way. This article provides an overview of techno-rational and socio-political failures and solutions at the macro-, meso- and micro-level to support digital transformation. The reviewed articles suggest a modest approach to digital transformation, with an emphasis on high-quality in-house IT infrastructure and expertise, but also better collaborative networks and strong leadership ensuring human oversight. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231160528",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Shirley Kempeneer",
        "Frederik Heylen"
      ],
      "url": "https://doi.org/10.1177/20539517231160528",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 133,
      "is_referenced_by_count": 15,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a5850f82-bda4-4a64-a4a4-e3e918ed5fb4",
    "title": "From pool to profile: Social consequences of algorithmic prediction in insurance",
    "abstract": "<jats:p> The use of algorithmic prediction in insurance is regarded as the beginning of a new era, because it promises to personalise insurance policies and premiums on the basis of individual behaviour and level of risk. The core idea is that the price of the policy would no longer refer to the calculated uncertainty of a pool of policyholders, with the consequence that everyone would have to pay only for her real exposure to risk. For insurance, however, uncertainty is not only a problem – shared uncertainty is a resource. The availability of individual risk information could undermine the principle of risk-pooling and risk-spreading on which insurance is based. The article examines this disruptive change first by exploring the possible consequences of the use of predictive algorithms to set insurance premiums. Will it endanger the principle of mutualisation of risks, producing new forms of discrimination and exclusion from coverage? In a second step, we analyse how the relationship between the insurer and the policyholder changes when the customer knows that the company has voluminous, and continuously updated, data about her real behaviour. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720939228",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Alberto Cevolini",
        "Elena Esposito"
      ],
      "url": "https://doi.org/10.1177/2053951720939228",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 94,
      "is_referenced_by_count": 58,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "880e4302-b835-45be-b4b5-38e951ad50a4",
    "title": "Between surveillance and recognition: Rethinking digital identity in aid",
    "abstract": "<jats:p> Identification technologies like biometrics have long been associated with securitisation, coercion and surveillance but have also, in recent years, become constitutive of a politics of empowerment, particularly in contexts of international aid. Aid organisations tend to see digital identification technologies as tools of recognition and inclusion rather than oppressive forms of monitoring, tracking and top-down control. In addition, practices that many critical scholars describe as aiding surveillance are often experienced differently by humanitarian subjects. This commentary examines the fraught questions this raises for scholars of international aid, surveillance studies and critical data studies. We put forward a research agenda that tackles head-on how critical theories of data and society can better account for the ambivalent dynamics of ‘power over’ and ‘power to’ that digital aid interventions instantiate. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211006744",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Keren Weitzberg",
        "Margie Cheesman",
        "Aaron Martin",
        "Emrys Schoemaker"
      ],
      "url": "https://doi.org/10.1177/20539517211006744",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 66,
      "is_referenced_by_count": 45,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "70ae4953-24a6-45e9-bd98-72ae2307de1f",
    "title": "Big Data, precision medicine and private insurance: A delicate balancing act",
    "abstract": "<jats:p> In this paper, we discuss how access to health-related data by private insurers, other than affecting the interests of prospective policy-holders, can also influence their propensity to make personal data available for research purposes. We take the case of national precision medicine initiatives as an illustrative example of this possible tendency. Precision medicine pools together unprecedented amounts of genetic as well as phenotypic data. The possibility that private insurers could claim access to such rapidly accumulating biomedical Big Data or to health-related information derived from it would discourage people from enrolling in precision medicine studies. Should that be the case, the economic value of personal data for the insurance industry would end up affecting the public value of data as a scientific resource. In what follows we articulate three principles – trustworthiness, openness and evidence – to address this problem and tame its potentially harmful effects on the development of precision medicine and, more generally, on the advancement of medical science. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719830111",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Alessandro Blasimme",
        "Effy Vayena",
        "Ine Van Hoyweghen"
      ],
      "url": "https://doi.org/10.1177/2053951719830111",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 25,
      "is_referenced_by_count": 21,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2e665ad8-b1e6-4b86-a334-f88a3aae0f69",
    "title": "Fairness perceptions of algorithmic decision-making: A systematic review  of the empirical literature",
    "abstract": "<jats:p> Algorithmic decision-making increasingly shapes people's daily lives. Given that such autonomous systems can cause severe harm to individuals and social groups, fairness concerns have arisen. A human-centric approach demanded by scholars and policymakers requires considering people's fairness perceptions when designing and implementing algorithmic decision-making. We provide a comprehensive, systematic literature review synthesizing the existing empirical insights on perceptions of algorithmic fairness from 58 empirical studies spanning multiple domains and scientific disciplines. Through thorough coding, we systemize the current empirical literature along four dimensions: (1) algorithmic predictors, (2) human predictors, (3) comparative effects (human decision-making vs. algorithmic decision-making), and (4) consequences of algorithmic decision-making. While we identify much heterogeneity around the theoretical concepts and empirical measurements of algorithmic fairness, the insights come almost exclusively from Western-democratic contexts. By advocating for more interdisciplinary research adopting a society-in-the-loop framework, we hope our work will contribute to fairer and more responsible algorithmic decision-making. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221115189",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Christopher Starke",
        "Janine Baleis",
        "Birte Keller",
        "Frank Marcinkowski"
      ],
      "url": "https://doi.org/10.1177/20539517221115189",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 106,
      "is_referenced_by_count": 89,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0e0d40bd-16e6-44d3-a07a-70e81e0880b8",
    "title": "Big Data in the workplace: Privacy Due Diligence as a human rights-based approach to employee privacy protection",
    "abstract": "<jats:p> Data-driven technologies have come to pervade almost every aspect of business life, extending to employee monitoring and algorithmic management. How can employee privacy be protected in the age of datafication? This article surveys the potential and shortcomings of a number of legal and technical solutions to show the advantages of human rights-based approaches in addressing corporate responsibility to respect privacy and strengthen human agency. Based on this notion, we develop a process-oriented model of Privacy Due Diligence to complement existing frameworks for safeguarding employee privacy in an era of Big Data surveillance. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211013051",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Isabel Ebert",
        "Isabelle Wildhaber",
        "Jeremias Adams-Prassl"
      ],
      "url": "https://doi.org/10.1177/20539517211013051",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 97,
      "is_referenced_by_count": 22,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "32af7085-4b50-48b1-ae43-2c0a44fdfc34",
    "title": "Social data governance: Towards a definition and model",
    "abstract": "<jats:p> With the surge in the number of data and datafied governance initiatives, arrangements, and practices across the globe, understanding various types of such initiatives, arrangements, and their structural causes has become a daunting task for scholars, policy makers, and the public. This complexity additionally generates substantial difficulties in considering different data(fied) governances commensurable with each other. To advance the discussion, this study argues that existing scholarship is inclined to embrace an organization-centric perspective that primarily concerns factors and dynamics regarding data and datafication at the organizational level at the expense of macro-level social, political, and cultural factors of both data and governance. To explicate the macro, societal dimension of data governance, this study then suggests the term “social data governance” to bring forth the consideration that data governance not only reflects the society from which it emerges but also (re)produces the policies and practices of the society in question. Drawing on theories of political science and public management, a model of social data governance is proposed to elucidate the ideological and conceptual groundings of various modes of governance from a comparative perspective. This preliminary model, consisting of a two-dimensional continuum, state intervention and societal autonomy for the one, and national cultures for the other, accounts for variations in social data governance across societies as a complementary way of conceptualizing and categorizing data governance beyond the European standpoint. Finally, we conduct an extreme case study of governing digital contact-tracing techniques during the pandemic to exemplify the explanatory power of the proposed model of social data governance. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221111352",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Jun Liu"
      ],
      "url": "https://doi.org/10.1177/20539517221111352",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 142,
      "is_referenced_by_count": 18,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9f35cfce-70dc-44b0-bb61-731c6465f5a9",
    "title": "Synthetic data protection: Towards a paradigm change in data regulation?",
    "abstract": "<jats:p> Synthetic data generated through machine learning algorithms from original real-world data is gaining prominence across sectors due to their potential to provide privacy-preserving alternatives to traditional data sources. However, recent studies have raised concerns about the re-identification risks of synthetic data. This article examines the legal challenges surrounding synthetic data protection, with a focus on the European Union's General Data Protection Regulation (GDPR). After briefly explaining the methods of synthetic data generation and discussing their potential for privacy preservation, the article analyses the shortcomings of the personal/non-personal dualist approach under the GDPR. It then assesses the possibility of a paradigm change in data protection legislation, moving beyond this binary categorisation. The article argues in favour of establishing clear guidelines for the generation and processing of synthetic data, prioritising the principles of transparency, accountability and fairness. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241231277",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Ana Beduschi"
      ],
      "url": "https://doi.org/10.1177/20539517241231277",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 17,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c29dbc02-587f-437d-a8d9-74bd6f339ae4",
    "title": "Big Data in food and agriculture",
    "abstract": "<jats:p> Farming is undergoing a digital revolution. Our existing review of current Big Data applications in the agri-food sector has revealed several collection and analytics tools that may have implications for relationships of power between players in the food system (e.g. between farmers and large corporations). For example, Who retains ownership of the data generated by applications like Monsanto Corproation's Weed I.D. “app”? Are there privacy implications with the data gathered by John Deere's precision agricultural equipment? Systematically tracing the digital revolution in agriculture, and charting the affordances as well as the limitations of Big Data applied to food and agriculture, should be a broad research goal for Big Data scholarship. Such a goal brings data scholarship into conversation with food studies and it allows for a focus on the material consequences of big data in society. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716648174",
      "type": "journal-article",
      "published": [
        2016,
        6
      ],
      "authors": [
        "Kelly Bronson",
        "Irena Knezevic"
      ],
      "url": "https://doi.org/10.1177/2053951716648174",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 37,
      "is_referenced_by_count": 261,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "895e2c46-8776-400c-9033-eae6b20cb2c9",
    "title": "Data journeys: Capturing the socio-material constitution of data objects and flows",
    "abstract": "<jats:p> In this paper, we discuss the development and piloting of a new methodology for illuminating the socio-material constitution of data objects and flows as data move between different sites of practice. The data journeys approach contributes to the development of critical, qualitative methodologies that can address the geographic and temporal scale of emerging knowledge infrastructures, and capture the ‘life of data’ from their initial generation through to re-use in different contexts. We discuss the theoretical development of the data journeys methodology and the application of the approach on a project examining meteorological data on their journey from initial production through to being re-used in climate science and financial markets. We then discuss three key conceptual findings from this project about: (1) the socio-material constitution of digital data objects, (2) ‘friction’ in the movement of data through space and time and (3) the mutability of digital data as a material property that contributes to driving the movement of data between different sites of practice. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716654502",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Jo Bates",
        "Yu-Wei Lin",
        "Paula Goodale"
      ],
      "url": "https://doi.org/10.1177/2053951716654502",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 46,
      "is_referenced_by_count": 115,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6df2fb8c-720a-4df0-a9e7-d092af145974",
    "title": "Surveillance, Snowden, and Big Data: Capacities, consequences, critique",
    "abstract": "<jats:p> The Snowden revelations about National Security Agency surveillance, starting in 2013, along with the ambiguous complicity of internet companies and the international controversies that followed provide a perfect segue into contemporary conundrums of surveillance and Big Data. Attention has shifted from late C20th information technologies and networks to a C21st focus on data, currently crystallized in “Big Data.” Big Data intensifies certain surveillance trends associated with information technology and networks, and is thus implicated in fresh but fluid configurations. This is considered in three main ways: One, the capacities of Big Data (including metadata) intensify surveillance by expanding interconnected datasets and analytical tools. Existing dynamics of influence, risk-management, and control increase their speed and scope through new techniques, especially predictive analytics. Two, while Big Data appears to be about size, qualitative change in surveillance practices is also perceptible, accenting consequences. Important trends persist – the control motif, faith in technology, public-private synergies, and user-involvement – but the future-orientation increasingly severs surveillance from history and memory and the quest for pattern-discovery is used to justify unprecedented access to data. Three, the ethical turn becomes more urgent as a mode of critique. Modernity's predilection for certain definitions of privacy betrays the subjects of surveillance who, so far from conforming to the abstract, disembodied image of both computing and legal practices, are engaged and embodied users-in-relation whose activities both fuel and foreclose surveillance. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714541861",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "David Lyon"
      ],
      "url": "https://doi.org/10.1177/2053951714541861",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 392,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4305a0d6-63d6-4420-b5a1-28d59a11984c",
    "title": "Algorithmic affordances for productive resistance",
    "abstract": "<jats:p> Although overarching if not foundational conceptualizations of digital governance in the field of critical data studies aptly account for and explain subjection, calculated resistance is left conceptually unattended despite case studies that document instances of resistance. I ask at the outset why conceptualizations of digital governance are so bleak, and I argue that all are underscored implicitly by a Deleuzian theory of desire that overlooks agency, defined here in Foucauldian terms. I subsequently conceptualize digital governance as encompassing subjection as well as resistance, and I cast the two in relational perspective by making use of the concepts “affordance” and “assemblage” in conjunction with multiple subjectivities and Foucault's view of power as productive as well as his view of resistance as an “antagonism of strategies” in his late scholarship on resistance, ethics, and subjectivity. I offer examples of salient modes of what I call “productive” resistance (as opposed to resistance by way of avoidance, disruption or obfuscation), and from a Foucauldian perspective I explain how each mode targets and subverts technologies of repressive power to produce new elements of the digital environment and construct new truths. I conclude by recognizing the agency embodied in resistance as an end in itself, but I also consider that modes of productive resistance can have extrinsic value as they affect the fluid interaction among elements of the digital environment, potentially disrupting the presumed structure of dominance and dependence, and opening our conceptualization of algorithmic life to hopeful possibilities for change. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718771399",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Nancy Ettlinger"
      ],
      "url": "https://doi.org/10.1177/2053951718771399",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 96,
      "is_referenced_by_count": 54,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e76a834c-77a4-4012-89bc-fa07438411a0",
    "title": "Perspectives on algorithmic normativities: engineers, objects, activities",
    "abstract": "<jats:p>This contribution aims at proposing a framework for articulating different kinds of “normativities” that are and can be attributed to “algorithmic systems.” The technical normativity manifests itself through the lineage of technical objects. The norm expresses a technical scheme’s becoming as it mutates through, but also resists, inventions. The genealogy of neural networks shall provide a powerful illustration of this dynamic by engaging with their concrete functioning as well as their unsuspected potentialities. The socio-technical normativity accounts for the manners in which engineers, as actors folded into socio-technical networks, willingly or unwittingly, infuse technical objects with values materialized in the system. Surveillance systems’ design will serve here to instantiate the ongoing mediation through which algorithmic systems are endowed with specific capacities. The behavioral normativity is the normative activity, in which both organic and mechanical behaviors are actively participating, undoing the identification of machines with “norm following,” and organisms with “norminstitution”. This proposition productively accounts for the singularity of machine learning algorithms, explored here through the case of recommender systems. The paper will provide substantial discussions of the notions of “normative” by cutting across history and philosophy of science, legal, and critical theory, as well as “algorithmics,” and by confronting our studies led in engineering laboratories with critical algorithm studies.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719858742",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Jérémy Grosman",
        "Tyler Reigeluth"
      ],
      "url": "https://doi.org/10.1177/2053951719858742",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171985874",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 42,
      "is_referenced_by_count": 27,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "35720881-6099-4a41-8ff6-595c6026ef97",
    "title": "Disambiguating the benefits and risks from public health data in the digital economy",
    "abstract": "<jats:p>This article focuses on key roles that the ill-defined concept of ‘public benefit’ plays in accessing the public health data held by the UK’s National Health Service. Using the concept of the ‘trade-off fallacy’, this article argues that current data access and governance structures, based on particular construals of public benefit in the context of public health data, largely negate the possibility of effective control by individuals over future uses of personal health data. This generates a health data version of the trade-off fallacy that enables widespread involvement of commercial actors in personal data, despite public concerns over commercial involvement in, and potential exploitation of, public health data. The article suggests that, despite ostensibly robust regulatory and governance structures, this publicly held data is potentially subject to similar logics of accumulation as seen elsewhere in the digital economy, highlighting the inadequacies of current data regulatory frameworks in the digital era.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720933924",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Sarah Cheung"
      ],
      "url": "https://doi.org/10.1177/2053951720933924",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172093392",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 72,
      "is_referenced_by_count": 20,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "02c68938-c35e-4894-936c-408e0ca8fc74",
    "title": "Engaging with ethics in Internet of Things: Imaginaries in the social milieu of technology developers",
    "abstract": "<jats:p> Discussions about ethics of Big Data often focus on the ethics of data processing: collecting, storing, handling, analysing and sharing data. Data-based systems, however, do not come from nowhere. They are designed and brought into being within social spaces – or social milieu. This paper connects philosophical considerations of individual and collective capacity to enact practical reason to the influence of social spaces. Building a deeper engagement with the social imaginaries of technology development through analysis of two years of fieldwork with start-ups working on Internet of Things, this paper suggests that different action positions can emerge, with consequences for how data is understood and valued. The Disengaged, Pragmatist and Idealist ethical action positions identified in the paper reveal the ways individuals and groups negotiate possibilities for ethical action, through justifications, explanations and structuring of system features. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719879468",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Funda Ustek-Spilda",
        "Alison Powell",
        "Selena Nemorin"
      ],
      "url": "https://doi.org/10.1177/2053951719879468",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171987946",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 28,
      "is_referenced_by_count": 19,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "1fea2d08-e523-442d-baab-4065ff806d09",
    "title": "From data politics to the contentious politics of data",
    "abstract": "<jats:p>This article approaches the paradigm shift of datafication from the perspective of civil society. Looking at how individuals and groups engage with datafication, it complements the notion of “data politics” by exploring what we call the “contentious politics of data”. By contentious politics of data we indicate the bottom-up, transformative initiatives interfering with and/or hijacking dominant processes of datafication, contesting existing power relations or re-appropriating data practices and infrastructure for purposes distinct from the intended. Said contentious politics of data is articulated in an array of practices of data activism taking a critical stance towards datafication. In data activism, data as mediators take a central role, both as part of an action repertoire or as objects of struggle in their own right. Leveraging social movement studies and science and technology studies, this theoretical essay argues that data activism can be mapped along two analytical dimensions: “data as stakes” (as issues and/or objects of political struggle in their own right) vs. “data as repertoires” (or modular tools for political struggle), and “individual practice vs. collective action”. Mapping action repertoires and tactics along these axes allows us to chart the potential emergence of a political ( contentious) data subject at the intersection of these two dimensions. This furthers our understanding of people’s engagement with data in relation to other forms of activism and existing work in social movement studies. It also helps us interpreting potential trajectories of contemporary social movements, as they increasingly interface with data, devices and platforms.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719885967",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Davide Beraldo",
        "Stefania Milan"
      ],
      "url": "https://doi.org/10.1177/2053951719885967",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171988596",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 72,
      "is_referenced_by_count": 79,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "831fdafe-333c-42ad-8b05-2047e9c7ffef",
    "title": "Big Tech platforms in health research: Re-purposing big data governance in light of the General Data Protection Regulation’s research exemption",
    "abstract": "<jats:p> The emergence of a global industry of digital health platforms operated by Big Tech corporations, and its growing entanglements with academic and pharmaceutical research networks, raise pressing questions on the capacity of current data governance models, regulatory and legal frameworks to safeguard the sustainability of the health research ecosystem. In this article, we direct our attention toward the challenges faced by the European General Data Protection Regulation in regulating the potentially disruptive engagement of Big Tech platforms in health research. The General Data Protection Regulation upholds a rather flexible regime for scientific research through a number of derogations to otherwise stricter data protection requirements, while providing a very broad interpretation of the notion of “scientific research”. Precisely the breadth of these exemptions combined with the ample scope of this notion could provide unintended leeway to the health data processing activities of Big Tech platforms, which have not been immune from carrying out privacy-infringing and socially disruptive practices in the health domain. We thus discuss further finer-grained demarcations to be traced within the broadly construed notion of scientific research, geared to implementing use-based data governance frameworks that distinguish health research activities that should benefit from a facilitated data protection regime from those that should not. We conclude that a “re-purposing” of big data governance approaches in health research is needed if European nations are to promote research activities within a framework of high safeguards for both individual citizens and society. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211018783",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Luca Marelli",
        "Giuseppe Testa",
        "Ine Van Hoyweghen"
      ],
      "url": "https://doi.org/10.1177/20539517211018783",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 91,
      "is_referenced_by_count": 19,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "aa79948b-55f6-48aa-93ff-208923bb4a34",
    "title": "Content moderation, AI, and the question of scale",
    "abstract": "<jats:p> AI seems like the perfect response to the growing challenges of content moderation on social media platforms: the immense scale of the data, the relentlessness of the violations, and the need for human judgments without wanting humans to have to make them. The push toward automated content moderation is often justified as a necessary response to the scale: the enormity of social media platforms like Facebook and YouTube stands as the reason why AI approaches are desirable, even inevitable. But even if we could effectively automate content moderation, it is not clear that we should. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720943234",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Tarleton Gillespie"
      ],
      "url": "https://doi.org/10.1177/2053951720943234",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 27,
      "is_referenced_by_count": 188,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "160d36e5-d118-49ce-9515-9715d82ca71b",
    "title": "Designing for human rights in AI",
    "abstract": "<jats:p> In the age of Big Data, companies and governments are increasingly using algorithms to inform hiring decisions, employee management, policing, credit scoring, insurance pricing, and many more aspects of our lives. Artificial intelligence (AI) systems can help us make evidence-driven, efficient decisions, but can also confront us with unjustified, discriminatory decisions wrongly assumed to be accurate because they are made automatically and quantitatively. It is becoming evident that these technological developments are consequential to people’s fundamental human rights. Despite increasing attention to these urgent challenges in recent years, technical solutions to these complex socio-ethical problems are often developed without empirical study of societal context and the critical input of societal stakeholders who are impacted by the technology. On the other hand, calls for more ethically and socially aware AI often fail to provide answers for how to proceed beyond stressing the importance of transparency, explainability, and fairness. Bridging these socio-technical gaps and the deep divide between abstract value language and design requirements is essential to facilitate nuanced, context-dependent design choices that will support moral and social values. In this paper, we bridge this divide through the framework of Design for Values, drawing on methodologies of Value Sensitive Design and Participatory Design to present a roadmap for proactively engaging societal stakeholders to translate fundamental human rights into context-dependent design requirements through a structured, inclusive, and transparent process. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720949566",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Evgeni Aizenberg",
        "Jeroen van den Hoven"
      ],
      "url": "https://doi.org/10.1177/2053951720949566",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 73,
      "is_referenced_by_count": 109,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f9e6bb33-42a0-4cc7-80e4-bb9a07f3e483",
    "title": "Shall AI moderators be made visible? Perception of accountability and trust in moderation systems on social media platforms",
    "abstract": "<jats:p> This study examines how visibility of a content moderator and ambiguity of moderated content influence perception of the moderation system in a social media environment. In the course of a two-day pre-registered experiment conducted in a realistic social media simulation, participants encountered moderated comments that were either unequivocally harsh or ambiguously worded, and the source of moderation was either unidentified, or attributed to other users or an automated system (AI). The results show that when comments were moderated by an AI versus other users, users perceived less accountability in the moderation system and had less trust in the moderation decision, especially for ambiguously worded harassments, as opposed to clear harassment cases. However, no differences emerged in the perceived moderation fairness, objectivity, and participants confidence in their understanding of the moderation process. Overall, our study demonstrates that users tend to question the moderation decision and system more when an AI moderator is visible, which highlights the complexity of effectively managing the visibility of automatic content moderation in the social media environment. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221115666",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Marie Ozanne",
        "Aparajita Bhandari",
        "Natalya N Bazarova",
        "Dominic DiFranzo"
      ],
      "url": "https://doi.org/10.1177/20539517221115666",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 64,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6b1718a9-a60e-424b-9f33-8f33c06799d7",
    "title": "Dislocated accountabilities in the  “AI supply chain”: Modularity and developers’ notions of responsibility",
    "abstract": "<jats:p> Responsible artificial intelligence guidelines ask engineers to consider how their systems might harm. However, contemporary artificial intelligence systems are built by composing many preexisting software modules that pass through many hands before becoming a finished product or service. How does this shape responsible artificial intelligence practice? In interviews with 27 artificial intelligence engineers across industry, open source, and academia, our participants often did not see the questions posed in responsible artificial intelligence guidelines to be within their agency, capability, or responsibility to address. We use Suchman's “located accountability” to show how responsible artificial intelligence labor is currently organized and to explore how it could be done differently. We identify cross-cutting social logics, like modularizability, scale, reputation, and customer orientation, that organize which responsible artificial intelligence actions do take place and which are relegated to low status staff or believed to be the work of the next or previous person in the imagined “supply chain.” We argue that current responsible artificial intelligence interventions, like ethics checklists and guidelines that assume panoptical knowledge and control over systems, could be improved by taking a located accountability approach, recognizing where relations and obligations might intertwine inside and outside of this supply chain. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231177620",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "David Gray Widder",
        "Dawn Nafus"
      ],
      "url": "https://doi.org/10.1177/20539517231177620",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 64,
      "is_referenced_by_count": 41,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "14f8142b-90a1-4b7d-96be-c004fbfa3e5d",
    "title": "Clinical algorithms, racism, and “fairness” in healthcare: A case of bounded justice",
    "abstract": "<jats:p> To date, attempts to address racially discriminatory clinical algorithms have largely focused on fairness and the development of models that “do no harm.” While the push for fairness is rooted in a desire to avoid or ameliorate health disparities, it generally neglects the role of racism in shaping health outcomes and does little to repair harm to patients. These limitations necessitate reconceptualizing how clinical algorithms should be designed and employed in pursuit of racial justice and health equity. A useful lens for this work is bounded justice, a concept and research analytic proposed by Melissa Creary to guide multidisciplinary health equity interventions. We describe how bounded justice offers a lens for (1) articulating the deep injustices embedded in the datasets, methodologies, and sociotechnical infrastructure underlying design and implementation of clinical algorithms and (2) envisioning how these algorithms can be redesigned to contribute to larger efforts that not only address current inequities, but to redress the historical mistreatment of communities of color by biomedical institutions. Thus, the aim of this article is two-fold. First, we apply the bounded justice analytic to fairness and clinical algorithms by describing structural constraints on health equity efforts such as medical device regulatory frameworks, race-based medicine, and racism in data. We then reimagine how clinical algorithms could function as a reparative technology to support justice and empower patients in the healthcare system. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231213820",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Sarah El-Azab",
        "Paige Nong"
      ],
      "url": "https://doi.org/10.1177/20539517231213820",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 115,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "503cbb17-3cc0-4e73-8f33-54934d9881bd",
    "title": "Terms-we-serve-with: Five dimensions for anticipating and repairing algorithmic harm",
    "abstract": "<jats:p> Power and information asymmetries between people and digital technology companies are further legitimized through contractual agreements that fail to provide meaningful consent and contestability. In particular, the Terms-of-Service (ToS) agreement, is a contract of adhesion where companies effectively set the terms and conditions of the contract. Whereas, ToS reinforce existing structural inequalities, we seek to enable an intersectional accountability mechanism grounded in the practice of algorithmic reparation. Building on existing critiques of ToS in the context of algorithmic systems, we return to the roots of contract theory by recentering notions of agency and mutual assent. We evolve a multipronged intervention we frame as the Terms-we-Serve-with (TwSw) social, computational, and legal framework. The TwSw is a new social imaginary centered on: (1) co-constitution of user agreements, through participatory mechanisms; (2) addressing friction, leveraging the fields of design justice and critical design in the production and resolution of conflict; (3) enabling refusal mechanisms, reflecting the need for a sufficient level of human oversight and agency including opting out; (4) complaint and algorithmic harms reporting, through a feminist studies lens and open-sourced computational tools; and (5) disclosure-centered mediation, to disclose, acknowledge, and take responsibility for harm, drawing on the field of medical law. We further inform our analysis through an exploratory design workshop with a South African gender-based violence reporting AI startup. We derive practical strategies for communities, technologists, and policy-makers to leverage a relational approach to algorithmic reparation and propose there's a need for a radical restructuring of the “take-it-or-leave-it” ToS agreement. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231211553",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Bogdana Rakova",
        "Renee Shelby",
        "Megan Ma"
      ],
      "url": "https://doi.org/10.1177/20539517231211553",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 145,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b25f53a7-b89d-451b-9094-de760066d063",
    "title": "Agreements ‘in the wild’: Standards and alignment in machine learning benchmark dataset construction",
    "abstract": "<jats:p>This article presents an ethnographic case study of a corporate-academic group constructing a benchmark dataset of daily activities for a variety of machine learning and computer vision tasks. Using a socio-technical perspective, the article conceptualizes the dataset as a knowledge object that is stabilized by both practical standards (for daily activities, datafication, annotation and benchmarks) and alignment work – that is, efforts including forging agreements to make these standards effective in practice. By attending to alignment work, the article highlights the informal, communicative and supportive efforts that underlie the success of standards and the smoothing of tensions between actors and factors. Emphasizing these efforts constitutes a contribution in several ways. This article's ethnographic mode of analysis challenges and supplements quantitative metrics on datasets. It advances the field of dataset analysis by offering a detailed empirical examination of the development of a new benchmark dataset as a collective accomplishment. By showing the importance of alignment efforts and their close ties to standards and their limitations, it adds to our understanding of how machine learning datasets are built. And, most importantly, it calls into question a key characterization of the dataset: that it captures unscripted activities occurring naturally ‘in the wild’, as alignment work bleeds into moments of data capture.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241242457",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Isak Engdahl"
      ],
      "url": "https://doi.org/10.1177/20539517241242457",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 63,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f893e33d-4c1e-4e21-9df6-7e319d741396",
    "title": "Generative AI and the politics of visibility",
    "abstract": "<jats:p> Proponents of generative AI tools claim they will supplement, even replace, the work of cultural production. This raises questions about the politics of visibility: what kinds of stories do these tools tend to generate, and what do they generally not? Do these tools match the kind of diversity of representation that marginalized populations and non-normative communities have fought to secure in publishing and broadcast media? I tested three widely available generative AI tools with prompts designed to reveal these normative assumptions; I prompted the tools multiple times with each, to track the diversity of the outputs to the same query. I demonstrate that, as currently designed and trained, generative AI tools tend to reproduce normative identities and narratives, rarely representing less common arrangements and perspectives. When they do generate variety, it is often narrow, maintaining deeper normative assumptions in what remains absent. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241252131",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Tarleton Gillespie"
      ],
      "url": "https://doi.org/10.1177/20539517241252131",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 50,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "13387456-7505-4352-a65e-9208c169b24c",
    "title": "Making sense of decision support systems: Rationales, translations and potentials for critical reflections on the reality of child protection",
    "abstract": "<jats:p> Decision support systems, which incorporate artificial intelligence and big data, are receiving significant attention in the public sector. Decision support systems are sociocultural artefacts that are subject to a mix of technical and political choices, and critical investigation of these choices and the rationales they reflect are paramount since they are inscribed into and may cause harm, violate fundamental rights and reproduce negative social patterns. Applying and merging the concepts of sense-making and translation, this article investigates the rationales, translations and critical reflections that shape the development of a decision support system to support social workers assessing referrals concerning child neglect. It presents findings from a qualitative case study conducted in 2019–2020 at the Citizen Centre Children and Young People, Copenhagen Municipality, Denmark. The analysis shows how key actors through processes of translation construct, negotiate and readjust problem definitions, roles, interests, responsibilities and ideas of ambiguity and accountability. Although technological solutionism is present in these processes, it is not the only rationale invested. Rather, technological and data-driven rationales are adjusted to and merged with rationales of efficiency, return on investment and child welfare. Through continuous renegotiation of roles, responsibilities and problems according to these rationales, the key actors attempt to orchestrate ways of managing the complexity facing child welfare services by projecting images of future potentials of the decision support system that are yet to be realised. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221125163",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Andreas Møller Jørgensen",
        "Maria Appel Nissen"
      ],
      "url": "https://doi.org/10.1177/20539517221125163",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 67,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f7509abb-12ac-4416-9e8a-f3cde0e6570f",
    "title": "Contextualizing realism: An analysis of acts of seeing and recording in Digital Twin datafication",
    "abstract": "<jats:p> Digital Twins are conceptualized as real-time digital representations of real-life physical entities or systems. They are explored for a wide array of societal implementations, and in particular to help address fundamental societal challenges. As accurate digital equivalents of their real-life twin, Digital Twins substitute their physical twin in knowledge production and decision-making processes. They raise high expectations: they are expected to produce new knowledge, expose issues early, predict future behavior, and help to optimize the physical twin. Data play a key role here because they form the building blocks from which the Digital Twin representation is created. However, data are not neutral phenomena but products of human-technology interaction. In this article, we therefore raise the question of how a Digital Twin data collection is created, and what implications does this have for Digital Twins? To answer this question, we explore the data collection process in three cases of Digital Twin development at a university. Connecting to Jasanoff's theoretical framework of regimes of sight, we approach the creation of a data collection as acts of seeing and recording that influence how reality is represented in data, as well as give a certain legitimacy and authority to the data collection. By examining the acts of seeing and recording and their respective roles in producing the data collection, we provide insight into the struggles of representation in Digital Twins and their implications. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231155061",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Paulan Korenhof",
        "Else Giesbers",
        "Janita Sanderse"
      ],
      "url": "https://doi.org/10.1177/20539517231155061",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 27,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "027043d5-55da-414d-96ce-7a83e216abe5",
    "title": "Aiming at the good life in the datafied world: A co-productionist framework of ethics",
    "abstract": "<jats:p> This article proposes an ethical framework to navigate life in the datafied world that combines the relational ethics approach of the philosopher Paul Ricoeur with the idiom of co-production from the field of Science and Technology Studies (STS). Mainstream data and computing ethics approaches, which tend to view ethics itself as a technology to produce particular outcomes, fail to adequately consider the context of the datafied world for ethics. The datafied world is a condition in which data and computing technologies form the ineluctable infrastructure for daily life, structuring social order, forming power relations, and supporting visions of desirable futures. I argue that the datafied world is not just a background upon which ethics unfolds, rather it demands a novel framework for ethics that understands the contexts of data and computing technologies and their consequences for human action. The idiom of co-production suggests how action gets tied to visions of the good in the datafied world. In particular, it draws attention to the evolution of these actions in the identities, institutions, representations, and discourses of the social world, creating specific forms of life and meaning in datafied societies. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221139782",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Margarita Boenig-Liptsin"
      ],
      "url": "https://doi.org/10.1177/20539517221139782",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 61,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2237a1f7-b0ca-4cb6-9153-ef69554df423",
    "title": "A place for Big Data: Close and distant readings of accessions data from the Arnold Arboretum",
    "abstract": "<jats:p> Place is a key concept in environmental studies and criticism. However, it is often overlooked as a dimension of situatedness in social studies of information. Rather, situatedness has been defined primarily as embodiment or social context. This paper explores place attachments in Big Data by adapting close and distant approaches for reading texts to examine the accessions data of the Arnold Arboretum, a living collection of trees, vines and shrubs established by Harvard University in 1872 (The original interactive data visualizations can be found online: http://www.lifeanddeathofdata.org ). Although it is an early and unconventional example of the phenomenon, there are several reasons that the Arboretum is a useful site for investigating the relationship between Big Data and place. First, the category of place is embedded in a range of data fields used in the Arboretum’s records. Second, the Arboretum has long sought to be a place in which scientists and citizens alike can encounter large collections of data firsthand. Third, the place has shaped fluctuations in the daily production of data over the course of the Arboretum’s 144 year history. Furthermore, Arboretum data can help us see place in ways not necessarily tied to geolocation. Each of these place attachments suggests a different way in which data can be environmental: by being about, in, from, or generative of place. Taken together, these attachments offer a model for examining other data in relation to their environments. Moreover, the paper contends that rather than being detached from place, as prevailing discourses suggest, Big Data bring together more and further reaching place attachments than data sets of smaller sizes. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716661365",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Yanni Alexander Loukissas"
      ],
      "url": "https://doi.org/10.1177/2053951716661365",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 52,
      "is_referenced_by_count": 22,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7699cafc-f73e-4970-af06-007c64924d1c",
    "title": "Make data sing: The automation of storytelling",
    "abstract": "<jats:p> With slogans such as ‘Tell the stories hidden in your data’ ( www.narrativescience.com ) and ‘From data to clear, insightful content – Wordsmith automatically generates narratives on a massive scale that sound like a person crafted each one’ ( www.automatedinsights.com ), a series of companies currently market themselves on the ability to turn data into stories through Natural Language Generation (NLG) techniques. The data interpretation and knowledge production process is here automated, while at the same time hailing narrativity as a fundamental human ability of meaning-making. Reading both the marketing rhetoric and the functionality of the automated narrative services through narrative theory allows for a contextualization of the rhetoric flourishing in Big Data discourse. Building upon case material obtained from companies such as Arria NLG, Automated Insights, Narrativa, Narrative Science, and Yseop, this article argues that what might be seen as a ‘re-turn’ of narrative as a form of knowledge production that can make sense of large data sets inscribes itself in – but also rearticulates – an ongoing debate about what narrative entails. Methodological considerations are thus raised on the one hand about the insights to be gained for critical data studies by turning to literary theory, and on the other hand about how automated technologies may inform our understanding of narrative as a faculty of human meaning-making. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718756686",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Kristin Veel"
      ],
      "url": "https://doi.org/10.1177/2053951718756686",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 35,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "564e783e-b20a-4a5a-a6f3-163b7ac4183f",
    "title": "Revisiting the Black Box Society by rethinking the political economy of big data",
    "abstract": "<jats:p> The Black Box Society was one of first scholarly accounts to propose a social theory of the use of data in constructing personal reputations, new media audiences, and financial power, by illuminating recurrent patterns of power and exploitation in the digital economy. While many corporations have a direct window into our lives through constant, ubiquitous data collection, our knowledge of their inner workings is often partial and incomplete. Closely guarded by private companies and inaccessible to most researchers or the broader public, too much algorithmic decision-making remains a black box to this day. Much has happened since 2015 that vindicates and challenges the book’s main themes. To answer many of the concerns raised in the volume in light of the most recent developments, we have brought together leading thinkers who have explored the interplay of politics, economics, and culture in domains ordered algorithmically by managers, bureaucrats, and technology workers. While the contributions are diverse, a unifying theme animates them. Each offers a sophisticated critique of the interplay between state and market forces in building or eroding the many layers of our common lives, as well as the privatization of spheres of reputation, search, and finance. Unsatisfied with narrow methodologies of economics or political science, they advance politico-economic analysis. They therefore succeed in unveiling the foundational role that the turn to big data has in organizing economic and social relations. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720935146",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Benedetta Brevini",
        "Frank Pasquale"
      ],
      "url": "https://doi.org/10.1177/2053951720935146",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 2,
      "is_referenced_by_count": 20,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9ede5452-c72d-4598-9cfa-7e1ccb26d2d5",
    "title": "Cyborgs for strategic communication on social media",
    "abstract": "<jats:p> Social media platforms are a key ground of information consumption and dissemination. Key figures like politicians, celebrities, and activists have leveraged on its wide user base for strategic communication. Strategic communications, or StratCom, is the deliberate act of information creation and distribution. Its techniques are used by key figures for establishing brand and amplifying messages. Automated scripts are used on top of personal touches to effectively perform these tasks. The combination of automation and manual online posting creates a Cyborg social media profile, which is a hybrid between bot and human. In this study, we establish a quantitative definition for a Cyborg account, an account that is detected as bot in one time window, and identified as human in another. This definition makes use of frequent changes in bot classification labels and large differences in bot likelihood scores to identify Cyborgs. We perform a large-scale analysis across over 3.1 million users from Twitter collected from two key events, the 2020 Coronavirus pandemic and the 2020 US Elections. We extract Cyborgs from two datasets and employ tools from network science, natural language processing, and manual annotation to characterize Cyborg accounts. Our analyses identify Cyborg accounts are constructed for strategic communication uses, have a strong duality in their bot/human classification and are tactically positioned in the social media network, aiding these accounts to promote their desired content. Cyborgs are also discovered to have long online lives, indicating their ability to evade bot detectors, or the graciousness of platforms to allow their operations. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241231275",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Lynnette Hui Xian Ng",
        "Dawn C Robertson",
        "Kathleen M Carley"
      ],
      "url": "https://doi.org/10.1177/20539517241231275",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 28,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "479fa013-30a4-458a-a09a-b685b6ac97ae",
    "title": "Surfeit and surface",
    "abstract": "<jats:p> “Would you like another EXTRA BIG ASS FRIES?” (Carl's Jr computer, Idiocracy) </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715604334",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Monica Lee",
        "John Levi Martin"
      ],
      "url": "https://doi.org/10.1177/2053951715604334",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7c1a2246-dfe9-4008-b7f4-495d69cd9439",
    "title": "Assessing biases, relaxing moralism: On ground-truthing practices in machine learning design and application",
    "abstract": "<jats:p> This theoretical paper considers the morality of machine learning algorithms and systems in the light of the biases that ground their correctness. It begins by presenting biases not as a priori negative entities but as contingent external referents—often gathered in benchmarked repositories called ground-truth datasets—that define what needs to be learned and allow for performance measures. I then argue that ground-truth datasets and their concomitant practices—that fundamentally involve establishing biases to enable learning procedures—can be described by their respective morality, here defined as the more or less accounted experience of hesitation when faced with what pragmatist philosopher William James called “genuine options”—that is, choices to be made in the heat of the moment that engage different possible futures. I then stress three constitutive dimensions of this pragmatist morality, as far as ground-truthing practices are concerned: (I) the definition of the problem to be solved (problematization), (II) the identification of the data to be collected and set up (databasing), and (III) the qualification of the targets to be learned (labeling). I finally suggest that this three-dimensional conceptual space can be used to map machine learning algorithmic projects in terms of the morality of their respective and constitutive ground-truthing practices. Such techno-moral graphs may, in turn, serve as equipment for greater governance of machine learning algorithms and systems. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211013569",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Florian Jaton"
      ],
      "url": "https://doi.org/10.1177/20539517211013569",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 82,
      "is_referenced_by_count": 31,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "edf43345-e277-4bd6-b384-f2efc1a5f0fe",
    "title": "Algorithmic precarity and metric power: Managing the affective measures and customers in the gig economy",
    "abstract": "<jats:p> Drawing on a qualitative, multi-case study of three kinds of geographically tethered gig work—ride-hailing, delivery, and domestic services platforms—in the United States, I examine how workers anticipate the influences of metrics, live with metrics, and cope with algorithmic precarity. Data for this project include in-depth interviews with 50 gig workers about their efforts to interpret and manage metrics as part of their everyday work practices. The analysis reveals that participants were anxious about metrics primarily because of the disciplinary outcomes, that are, the threat of job loss and the valued job features. It also directs attention to how workers felt and experienced customer-sourced ratings and system-generated behavioral metrics variously across platforms. Information asymmetries and the perceived lack of control also intensified a sense of powerlessness among participants. While participants articulated strategies that aimed at managing the uncertainty of customer-sourced ratings—and more precisely, the work-related uncertainty created by “difficult customers”—throughout service interactions, their feelings of anxiety could not be resolved. Furthermore, the (in)visibility of metrics, the settings of platform-mediated worker–customer interactions, and workers’ platform dependence contributed to the varying disciplinary power of metrics. The study contributes to understanding how metrics as affective measures mediate the trilateral relationship between platforms, workers, and customers in the gig economy. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221133779",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Ngai Keung Chan"
      ],
      "url": "https://doi.org/10.1177/20539517221133779",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 58,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e232c890-187e-474d-9a0b-7f999cd54760",
    "title": "Asserting the public interest in health data: On the ethics of data governance for biobanks and insurers",
    "abstract": "<jats:p> Recent reporting has revealed that the UK Biobank (UKB)—a large, publicly-funded research database containing highly-sensitive health records of over half a million participants—has shared its data with private insurance companies seeking to develop actuarial AI systems for analyzing risk and predicting health. While news reports have characterized this as a significant breach of public trust, the UKB contends that insurance research is “in the public interest,” and that all research participants are adequately protected from the possibility of insurance discrimination via data de-identification. Here, we contest both of these claims. Insurers use population data to identify novel categories of risk, which become fodder in the production of black-boxed actuarial algorithms. The deployment of these algorithms, as we argue, has the potential to increase inequality in health and decrease access to insurance. Importantly, these types of harms are not limited just to UKB participants: instead, they are likely to proliferate unevenly across various populations within global insurance markets via practices of profiling and sorting based on the synthesis of multiple data sources, alongside advances in data analysis capabilities, over space/time. This necessitates a significantly expanded understanding of the publics who must be involved in biobank governance and data-sharing decisions involving insurers. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241290215",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Kathryne Metcalf",
        "Jathan Sadowski"
      ],
      "url": "https://doi.org/10.1177/20539517241290215",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 79,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "04b85fcd-4f21-4720-a535-2c4c47f47d3e",
    "title": "The power and promise of transparency: Perspectives from citizens’ juries of pandemic health data sharing",
    "abstract": "<jats:p> The COVID-19 pandemic response in the UK, as in other countries, drew heavily on health and social care data, making its utility extremely visible as necessary for timely government decision-making and planning. The urgency created by the crisis, however, meant that additional data collection and sharing under emergency legislation was implemented with minimal public consultation. To understand the public perception of these new data measures and initiatives, three citizens’ juries took place in the spring of 2021. This article reports on qualitative observations of the small group deliberations from these juries. The analysis shows that jurors frequently drew on normative discourses of transparency and trust in discussions, and the different roles they were assumed to fulfil. Transparency was expected to offer greater visibility into the organisations involved in health and social care data sharing, but this was made difficult by the increased complexity of the health data economy. Transparency into the political justifications for additional health data collection was important for jurors. The utilitarian narratives used by the government were considered problematic, restricting opportunities for individuals to express concerns and leading to cynicism. The findings will be situated with the critical literature on visibility practices to highlight the need to unpick what the promise of transparency and trust offers to the public and how it links to power and control. Lastly, it will examine what the deliberations around transparency mean for wider policy on health and social care data-sharing. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241299729",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Louise Laverty",
        "Elisa Jones",
        "Niels Peek",
        "Malcolm Oswald",
        "Kyle Bozentko",
        "Sarah Atwood",
        "Sabine van der Veer"
      ],
      "url": "https://doi.org/10.1177/20539517241299729",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 55,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "56b79d88-0dd5-44e2-b3fb-36574c9aaea4",
    "title": "Big Data Dreams and Reality in Shenzhen: An Investigation of Smart City Implementation in China",
    "abstract": "<jats:p> Chinese cities are increasingly using digital technologies to address urban problems and govern society. However, little is known about how this digital transition has been implemented. This study explores the introduction of digital governance in Shenzhen, one of China's most advanced smart cities. We show that, at the local level, the successful implementation of digital systems faces numerous hurdles in long-standing data management and bureaucratic practices that are at least as challenging as the technical problems. Furthermore, the study finds that the digital systems in Shenzhen entail a creeping centralisation of data that potentially turns lower administrative government units into mere users of the city-level smart platforms rather than being in control of their own data resources. Smart city development and big data ambitions thereby imply shifting stakeholder relations at the local level and also pull non-governmental stakeholders, such as information technology companies and research institutions, closer to new data flows and smart governance systems. The findings add to the discussion of big data-driven smart systems and their implications for governance processes in an authoritarian context. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211045171",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Jelena Große-Bley",
        "Genia Kostka"
      ],
      "url": "https://doi.org/10.1177/20539517211045171",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 61,
      "is_referenced_by_count": 27,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8b2d39a8-1848-4508-a879-917513450b4c",
    "title": "Everyday curation? Attending to data, records and record keeping in the practices of self-monitoring",
    "abstract": "<jats:p>This paper is concerned with everyday data practices, considering how people record data produced through self-monitoring. The analysis unpacks the relationships between taking a measure, and making and reviewing records. The paper is based on an interview study with people who monitor their blood pressure and/or body mass index/weight. Animated by discussions of ‘data power’ which are, in part, predicated on the flow and aggregation of data, we aim to extend important work concerning the everyday constitution of digital data. In the paper, we adopt and develop the idea of curation as a theory of attention. We introduce the idea of discerning work to characterise the skilful judgements people make about which readings they record, how readings are presented, and about the records they retain and those they discard. We suggest self-monitoring produces partial data, both in the sense that it embodies these judgements, and also because monitoring might be conducted intermittently. We also extend previous analyses by exploring the broad set of materials, digital and analogue, networked and not networked, involved in record keeping to consider the different ways these contributed to regulating attention to self-monitoring. By paying attention to which data is recorded and the occasions when data is not recorded, as well as the ways data is recorded, the research provides specificity to the different ways in which self-monitoring data may or may not flow or contribute to big data sets. We argue that ultimately our analysis contributes to nuancing our understanding of ‘data power’.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720918275",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Kate Weiner",
        "Catherine Will",
        "Flis Henwood",
        "Rosalind Williams"
      ],
      "url": "https://doi.org/10.1177/2053951720918275",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172091827",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 52,
      "is_referenced_by_count": 13,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5793b29f-2ada-4535-b660-bebda0eb8ec9",
    "title": "Broken data: Conceptualising data in an emerging world",
    "abstract": "<jats:p> In this article, we introduce and demonstrate the concept-metaphor of broken data. In doing so, we advance critical discussions of digital data by accounting for how data might be in processes of decay, making, repair, re-making and growth, which are inextricable from the ongoing forms of creativity that stem from everyday contingencies and improvisatory human activity. We build and demonstrate our argument through three examples drawn from mundane everyday activity: the incompleteness, inaccuracy and dispersed nature of personal self-tracking data; the data cleaning and repair processes of Big Data analysis and how data can turn into noise and vice versa when they are transduced into sound within practices of music production and sound art. This, we argue is a necessary step for considering the meaning and implications of data as it is increasingly mobilised in ways that impact society and our everyday worlds. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717753228",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Sarah Pink",
        "Minna Ruckenstein",
        "Robert Willim",
        "Melisa Duque"
      ],
      "url": "https://doi.org/10.1177/2053951717753228",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 48,
      "is_referenced_by_count": 112,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "46a04dbe-faee-4c5f-a390-58c2acd26327",
    "title": "Lifting the curtain: Strategic visibility of human labour in AI-as-a-Service",
    "abstract": "<jats:p> Artificial Intelligence-as-a-Service (AIaaS) empowers individuals and organisations to access AI on-demand, in either tailored or ‘off-the-shelf’ forms. However, institutional separation between development, training and deployment can lead to critical opacities, such as obscuring the level of human effort necessary to produce and train AI services. Information about how, where, and for whom AI services have been produced are valuable secrets, which vendors strategically disclose to clients depending on commercial interests. This article provides a critical analysis of how AIaaS vendors manipulate the visibility of human labour in AI production based on whether the vendor relies on paid or unpaid labour to fill interstitial gaps. Where vendors are able to occlude human labour in the organisational ‘backstage,’ such as in data preparation, validation or impersonation, they do so regularly, further contributing to ongoing techno-utopian narratives of AI hype. Yet, when vendors must co-produce the AI service with the client, such as through localised AI training, they must ‘lift the curtain’, resulting in a paradoxical situation of needing to both perpetuate dominant AI hype narratives while emphasising AI’s mundane limitations. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211016026",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Gemma Newlands"
      ],
      "url": "https://doi.org/10.1177/20539517211016026",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 121,
      "is_referenced_by_count": 32,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fc7a5315-5ce3-4959-9583-73fa78f5b8e6",
    "title": "Questioning Big Data: Crowdsourcing crisis data towards an inclusive humanitarian response",
    "abstract": "<jats:p> The aim of this paper is to critically explore whether crowdsourced Big Data enables an inclusive humanitarian response at times of crisis. We argue that all data, including Big Data, are socially constructed artefacts that reflect the contexts and processes of their creation. To support our argument, we qualitatively analysed the process of ‘Big Data making’ that occurred by way of crowdsourcing through open data platforms, in the context of two specific humanitarian crises, namely the 2010 earthquake in Haiti and the 2015 earthquake in Nepal. We show that the process of creating Big Data from local and global sources of knowledge entails the transformation of information as it moves from one distinct group of contributors to the next. The implication of this transformation is that locally based, affected people and often the original ‘crowd’ are excluded from the information flow, and from the interpretation process of crowdsourced crisis knowledge, as used by formal responding organizations, and are marginalized in their ability to benefit from Big Data in support of their own means. Our paper contributes a critical perspective to the debate on participatory Big Data, by explaining the process of in and exclusion during data making, towards more responsive humanitarian relief. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716662054",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Femke Mulder",
        "Julie Ferguson",
        "Peter Groenewegen",
        "Kees Boersma",
        "Jeroen Wolbers"
      ],
      "url": "https://doi.org/10.1177/2053951716662054",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 61,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "789333f4-e69d-44b6-b93a-7f801214a800",
    "title": "<i>AI ethics should not remain toothless!</i> A call to bring back the teeth of ethics",
    "abstract": "<jats:p> Ethics has powerful teeth, but these are barely being used in the ethics of AI today – it is no wonder the ethics of AI is then blamed for having no teeth. This article argues that ‘ethics’ in the current AI ethics field is largely ineffective, trapped in an ‘ethical principles’ approach and as such particularly prone to manipulation, especially by industry actors. Using ethics as a substitute for law risks its abuse and misuse. This significantly limits what ethics can achieve and is a great loss to the AI field and its impacts on individuals and society. This article discusses these risks and then highlights the teeth of ethics and the essential value they can – and should – bring to AI ethics now. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720942541",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Anaïs Rességuier",
        "Rowena Rodrigues"
      ],
      "url": "https://doi.org/10.1177/2053951720942541",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 20,
      "is_referenced_by_count": 127,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "70e54c6e-72db-4590-b12b-79b4e66fcf93",
    "title": "Data sovereignty: A review",
    "abstract": "<jats:p> New data-driven technologies yield benefits and potentials, but also confront different agents and stakeholders with challenges in retaining control over their data. Our goal in this study is to arrive at a clear picture of what is meant by data sovereignty in such problem settings. To this end, we review 341 publications and analyze the frequency of different notions such as data sovereignty, digital sovereignty, and cyber sovereignty. We go on to map agents they concern, in which context they appear, and which values they allude to. While our sample reveals a considerable degree of divergence and an occasional lack of clarity about intended meanings of data sovereignty, we propose a conceptual grid to systematize different dimensions and connotations. Each of them relates in some way to meaningful control, ownership, and other claims to data articulated by a variety of agents ranging from individuals to countries. Data sovereignty alludes to a nuanced mixture of normative concepts such as inclusive deliberation and recognition of the fundamental rights of data subjects. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720982012",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Patrik Hummel",
        "Matthias Braun",
        "Max Tretter",
        "Peter Dabrock"
      ],
      "url": "https://doi.org/10.1177/2053951720982012",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 69,
      "is_referenced_by_count": 182,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3dd611b5-2658-43e3-9889-9e4242cac65e",
    "title": "Datafication and data fiction: Narrating data and narrating with           data",
    "abstract": "<jats:p> Data do not speak for themselves. Data must be narrated—put to work in particular contexts, sunk into narratives that give them shape and meaning, and mobilized as part of broader processes of interpretation and meaning-making. We examine these processes through the lens of ethnographic practice and, in particular, ethnography’s attention to narrative processes. We draw on a particular case in which digital data must be animated and narrated by different groups in order to examine broader questions of how we might come to understand data ethnographically. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718784083",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Paul Dourish",
        "Edgar Gómez Cruz"
      ],
      "url": "https://doi.org/10.1177/2053951718784083",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 46,
      "is_referenced_by_count": 116,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9f6a19d4-7875-4c6c-b3a4-e1ff02c7588f",
    "title": "Prediction and explainability in AI: Striking a new balance?",
    "abstract": "<jats:p> The debate regarding prediction and explainability in artificial intelligence (AI) centers around the trade-off between achieving high-performance accurate models and the ability to understand and interpret the decisionmaking process of those models. In recent years, this debate has gained significant attention due to the increasing adoption of AI systems in various domains, including healthcare, finance, and criminal justice. While prediction and explainability are desirable goals in principle, the recent spread of high accuracy yet opaque machine learning (ML) algorithms has highlighted the trade-off between the two, marking this debate as an inter-disciplinary, inter-professional arena for negotiating expertise. There is no longer an agreement about what should be the “default” balance of prediction and explainability, with various positions reflecting claims for professional jurisdiction. Overall, there appears to be a growing schism between the regulatory and ethics-based call for explainability as a condition for trustworthy AI, and how it is being designed, assimilated, and negotiated. The impetus for writing this commentary comes from recent suggestions that explainability is overrated, including the argument that explainability is not guaranteed in human healthcare experts either. To shed light on this debate, its premises, and its recent twists, we provide an overview of key arguments representing different frames, focusing on AI in healthcare. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241235871",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Aviad Raz",
        "Bert Heinrichs",
        "Netta Avnoon",
        "Gil Eyal",
        "Yael Inbar"
      ],
      "url": "https://doi.org/10.1177/20539517241235871",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 30,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0d6b5974-7d7a-4771-a062-e929b44228ef",
    "title": "The affordances of extreme speech",
    "abstract": "<jats:p> New media studies invested in online political conflict, radical and antagonistic subcultures have taken an interest in the affordances that shape memes, vernaculars and online political communication. One often overlooked affordance is the ensemble of social, communication, platform and legal frameworks stipulating what users can and cannot say, which I call “speech affordances.” To explore this concept, I look at the strategic communication of 4chan, Twitter and YouTube subcultures tied to a historical meme, “Kekistan,” often perceived as a key example of the ideological cacophony of the 2015–2017 online “culture wars.” I focus on how 4chan's policy of user anonymity, YouTube's unmoderated comment sections and Twitter's more proactive moderation practices brought some influencers to alter the original connotations of the meme into “overt” messages tolerable to Twitter and YouTube out-groups and platform moderation policies. Speech affordances bear methodological implications for historical studies of speech moderation and the overall mechanisms in which problematic language adapts to spaces with distinct speech norms. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231206810",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Emillie de Keulenaar"
      ],
      "url": "https://doi.org/10.1177/20539517231206810",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 28,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "421470e1-6200-424a-a90d-51af6ebc2e10",
    "title": "Rethinking use-restricted open-source licenses for regulating abuse of generative models",
    "abstract": "<jats:p> The rapid progress of Artificial intelligence in generative modeling is marred by widespread misuse. In response, researchers turn to use-based restrictions—contractual terms prohibiting certain uses—as a “solution” for abuse. While these restrictions can be beneficial to artificial intelligence governance in API-gated settings, their failings are especially significant in open-source models: not only do they lack any means of enforcement, but they also perpetuate the current proliferation of tokenistic efforts toward ethical artificial intelligence. This observation echoes growing literature that points to useless efforts in “AI ethics,” and underscores the need to shift from this paradigm. This article provides an overview of these drawbacks and argues that researchers should divert their efforts to studying deployable, effective, and theoretically grounded solutions like watermarking and model alignment from human feedback to effect tangible changes in the current climate of artificial intelligence. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241229699",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Jonathan Cui",
        "David A Araujo"
      ],
      "url": "https://doi.org/10.1177/20539517241229699",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 43,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0ecd3844-742e-4559-b85d-7d123935a4d4",
    "title": "Covid-19 and the accelerating smart home",
    "abstract": "<jats:p> Home, digital technologies and data are intersecting in new ways as responses to the COVID-19 pandemic emerge. We consider the data practices associated with COVID-19 responses and their implications for housing and home through two overarching themes: the notion of home as a private space, and digital technology and surveillance in the home. We show that although home has never been private, the rapid adoption and acceptance of technologies in the home for quarantine, work and study, enabled by the pandemic, is rescripting privacy. The acceleration of technology adoption and surveillance in the home has implications for privacy and potential discrimination, and should be approached with a critical lens. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720938073",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Sophia Maalsen",
        "Robyn Dowling"
      ],
      "url": "https://doi.org/10.1177/2053951720938073",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 18,
      "is_referenced_by_count": 56,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "96f0409f-7af6-4bfe-9e86-a38590477c1d",
    "title": "Race-neutral vs race-conscious: Using algorithmic methods to evaluate the reparative potential of housing programs",
    "abstract": "<jats:p> The racial wealth gap in the United States remains a persistent issue; white individuals possess six times more wealth than Black individuals. Leading scholars and public figures have pointed to slavery and post-slavery discrimination as root cause factors and called for reparations. Yet the institutionalization of race-neutral ideologies in policies and practices hinders a reparative approach to closing the racial wealth gap. This study models the use of algorithmic methods in the service of reparations to Black Americans in the domain of housing, where most American wealth is built. We examine a hypothetical scenario for measuring the effectiveness of race-conscious Special Purpose Credit Programs (SPCPs) in reducing the housing racial wealth gap compared to race-neutral SPCPs. We use a predictive model to show that race-conscious, people-based lending programs, if they were nationally available, would be two to three times more effective in closing the racial housing wealth gap than other, existing forms of SPCPs. In doing so, we also demonstrate the potential for using algorithms and computational methods to support outcomes aligned with movements for reparations, another possible meaning for the emerging discourse on “algorithmic reparations.” </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231210272",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Wonyoung So",
        "Catherine D’Ignazio"
      ],
      "url": "https://doi.org/10.1177/20539517231210272",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 78,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fba05d05-1651-48e2-999f-5131d27c172a",
    "title": "Grassroots resource mobilization through counter-data action",
    "abstract": "<jats:p> In this paper, we document the counter-data action and data activism of a grassroots affordable housing advocacy group in Atlanta. Our observation and insight into these data activities and strategies are achieved through ethnographic and engaged research and participatory design. We find that counter-data action through community-collected data is rooted in a legacy of Atlanta’s black activism and black scholarship; that this data activism enabled resource mobilization and critical conscious making; and that design and media production are essential post counter-data action activities in data activism. Based on these findings, we urge the field of open government data to broaden their concept of social impact of data to include the use data to mobilize resources within oppressed communities not to influence policy and government but to build capacities within community in order to transform, not join, political structures. We also advocate that scholars within the fields of open government data, critical data studies, and data activism recognize the legacy and historic practice of data activism by black communities working towards social change. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718796862",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Amanda Meng",
        "Carl DiSalvo"
      ],
      "url": "https://doi.org/10.1177/2053951718796862",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 53,
      "is_referenced_by_count": 35,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9cb95b7a-8721-4dbb-aa01-bc339f5de313",
    "title": "Social media advertising for clinical studies: Ethical and data protection implications of online targeting",
    "abstract": "<jats:p> Social media advertising has revolutionised the advertising world by providing data-driven targeting methods. One area where social media advertising is just gaining a foothold is in the recruitment of clinical study participants. Here, as everywhere, social media advertising promises more yield per money spent because the technology can better reach highly specialised groups. In this article, we point out severe societal risks posed by advertising for clinical studies on social media. We show that social media advertising for clinical studies in many cases violates the privacy of individual users (R1), creates collective privacy risks by helping platform companies train predictive models of medical information that can be applied to all their users (R2), exploits the weaknesses of existing guidelines in (biomedical) research ethics (R3) and is detrimental to the quality of (biomedical) research (R4). We argue that the well-intentioned promises, which are often associated with the use of social media advertising for clinical studies, are untenable from a balanced point of view. Consequently, we call for updates of research ethics guidelines and better regulation of Big Data and inferential analytics. We conclude that social media advertising – especially with vulnerable patient populations – is not suitable as a recruitment tool for clinical studies as long as the processing of (even anonymised) social media usage data and the training of predictive models by data analytics and artificial intelligence companies is not sufficiently regulated. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231156127",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Rainer Mühlhoff",
        "Theresa Willem"
      ],
      "url": "https://doi.org/10.1177/20539517231156127",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 61,
      "is_referenced_by_count": 16,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "11e2f996-c3ce-4337-a3ce-e67d289bd982",
    "title": "Ghosts of white methods? The challenges of Big Data research in exploring racism in digital context",
    "abstract": "<jats:p> The paper explores the potential and limitations of big data for researching racism on social media. Informed by critical data studies and critical race studies, the paper discusses challenges of doing big data research and the problems of the so called ‘white method’. The paper introduces the following three types of approach, each with a different epistemological basis for researching racism in digital context: 1) using big data analytics to point out the dominant power relations and the dynamics of racist discourse, 2) complementing big data with qualitative research and 3) revealing new logics of racism in datafied context. The paper contributes to critical data and critical race studies by enhancing the understanding of the possibilities and limitations of big data research. This study also highlights the importance of contextualisation and mixed methods for achieving a more nuanced comprehension of racism and discrimination on social media and in large datasets. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211048964",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Kaarina Nikunen"
      ],
      "url": "https://doi.org/10.1177/20539517211048964",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 91,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c53bcec1-adb4-424d-9b0d-838a9ff6f5e2",
    "title": "Big Data is a big lie without little data: Humanistic intelligence as a human right",
    "abstract": "<jats:p> This article introduces an important concept: Transparency by way of Humanistic Intelligence as a human right, and in particular, Big/Little Data and Sur/Sous Veillance, where “Little Data” is to sousveillance (undersight) as “Big Data” is to surveillance (oversight). Veillance (Sur- and Sous-veillance) is a core concept not just in human–human interaction (e.g. people watching other people) but also in terms of Human–Computer Interaction. In this sense, veillance is the core of Human-in-the-loop Intelligence (Humanistic Intelligence rather than Artificial Intelligence), leading us to the concept of “Sousveillant Systems” which are forms of Human–Computer Interaction in which internal computational states are made visible to end users, allowing users (but not requiring them) to “jump” into the computational feedback loop whenever or wherever they want. An important special case of Sousveillant Systems is that of scientific exploration: not only is (big/little) data considered, but also due consideration must be given to how data is captured, understood, explored, and discovered, and in particular, to the use of scientific instruments to collect data and to make important new discoveries, and learn about the world. Science is a domain where bottom-up transparency is of the utmost importance, and scientists have the right and responsibility to be able to understand the instruments that they use to make their discoveries. Such instruments must be sousveillant systems! </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717691550",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Steve Mann"
      ],
      "url": "https://doi.org/10.1177/2053951717691550",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 66,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0b906657-f79d-46f2-909f-3b4fdbf0afac",
    "title": "Organic online politics: Farmers, Facebook, and Myanmar's military coup",
    "abstract": "<jats:p> Despite perennial hope in the democratic possibilities of the internet, the rise of digital authoritarianism threatens online and offline freedom across much of the world. Yet while critical data studies has expanded its geographic focus, limited work to date has examined digital mobilization in the agrarian communities that comprise much of the Global South. This article advances the concept of “organic online politics,” to demonstrate how digital mobilization grows from specific rural conditions, material concerns, and repertoires of resistance, within the constraints of authoritarian violence and internet control. To do so, we examine social media interaction in the wake of the 2021 military coup in Myanmar, an agrarian nation with recent, rapid digital connection that corresponded with a decade-long democratic turn. Analyzing an original archive of over 2000 Facebook posts collected from popular farming pages and groups, we find a massive drop-off in online activity after the military coup and analyze the shifting temporalities of digital mobilization. Crucially, we highlight the embeddedness of online interaction within the material concerns of farming communities, examining how social media become a key forum for negotiating political crisis in Myanmar's countryside. These findings call attention to rural digital subcultures as fertile sites of investigation and point toward the need for future scholarship on data practices that attends to rooted agrarian struggles. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231168101",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Hilary Oliva Faxon",
        "Kendra Kintzi",
        "Van Tran",
        "Kay Zak Wine",
        "Swan Ye Htut"
      ],
      "url": "https://doi.org/10.1177/20539517231168101",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 74,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "90920dc3-3b3f-414b-be82-c432f0068d3d",
    "title": "The object of mobile spatial data, the subject in mobile spatial research",
    "abstract": "<jats:p> With an estimated one billion smartphones producing over 5 petabytes of data a day, the spatially aware mobile device has become a near ubiquitous presence in daily life. Cogent, excellent research in a variety of fields has explored what the spatial data these devices produce can reveal of society, such as analysis of Foursquare check-ins to reveal patterns of mobility for groups through a city. In such studies, the individual intentions, motivations, and desires behind the production of said data can become lost through computational aggregation and analysis. In this commentary, I argue for a rethinking of the epistemological leap from individual to data point through a (re)seating of the reflexive, self-eliciting subject as an object for spatial big data research. To do so, I first situate current research on spatial big data within a computational turn in social sciences that relies overly on the data produced as a stand-in for the subject producing said data. Second, I argue that a recent shift within geography and cognate disciplines toward viewing spatial big data as a form of spatial media allows for study of the sociotechnical processes that produce modern assemblages of data and society. As spatial media, the spatial big data created through mobile device use can be understood as the data of everyday life and as part of the sociotechnical processes that produce individuals, data, and space. Ultimately, to understand the data of everyday life, researchers must write thick descriptions of the stories we tell ourselves about the data we give off to others. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716659092",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Jim Thatcher"
      ],
      "url": "https://doi.org/10.1177/2053951716659092",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 57,
      "is_referenced_by_count": 14,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e1583cb2-9baa-437e-ae42-8d14a727334b",
    "title": "AI incidents and ‘networked trouble’: The case for a research agenda",
    "abstract": "<jats:p> Against a backdrop of widespread interest in how publics can participate in the design of AI, I argue for a research agenda focused on AI incidents – examples of AI going wrong and sparking controversy – and how they are constructed in online environments. I take up the example of an AI incident from September 2020, when a Twitter user created a ‘horrible experiment’ to demonstrate the racist bias of Twitter's algorithm for cropping images. This resulted in Twitter not only abandoning its use of that algorithm, but also disavowing its decision to use any algorithm for the task. I argue that AI incidents like this are a significant means for participating in AI systems that require further research. That research agenda, I argue, should focus on how incidents are constructed through networked online behaviours that I refer to as ‘networked trouble’, where formats for participation enable individuals and algorithms to interact in ways that others – including technology companies – come to know and come to care about. At stake, I argue, is an important mechanism for participating in the design and deployment of AI. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231215360",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Tommy Shaffer Shane"
      ],
      "url": "https://doi.org/10.1177/20539517231215360",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 15,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "cf6450db-ab8d-4171-83d8-e9a680444623",
    "title": "Understanding the promises and premises of online health platforms",
    "abstract": "<jats:p> This article investigates the claims and complexities involved in the platform-based economics of health and fitness apps. We examine a double-edged logic inscribed in these platforms, promising to offer personal solutions to medical problems while also contributing to the public good. On the one hand, online platforms serve as personalized data-driven services to their customers. On the other hand, they allegedly serve public interests, such as medical research or health education. In doing so, many apps employ a diffuse discourse, hinging on terms like “sharing,” “open,” and “reuse” when they talk about data extraction and distribution. The analytical approach we adopt in this article is situated at the nexus of science and technology studies, political economy, and the sociology of health and illness. The analysis concentrates on two aspects: datafication (the use and reuse of data) and commodification (a platform’s deployment of governance and business models). We apply these analytical categories to three specific platforms: 23andMe, PatientsLikeMe, and Parkinson mPower. The last section will connect these individual examples to the wider implications of health apps’ data flows, governance policies, and business models. Regulatory bodies commonly focus on the (medical) safety and security of apps, but pay scarce attention to health apps’ techno-economic governance. Who owns user-generated health data and who gets to benefit? We argue that it is important to reflect on the societal implications of health data markets. Governments have the duty to provide conceptual clarity in the grand narrative of transforming health care and health research. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716654173",
      "type": "journal-article",
      "published": [
        2016,
        6
      ],
      "authors": [
        "José Van Dijck",
        "Thomas Poell"
      ],
      "url": "https://doi.org/10.1177/2053951716654173",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 51,
      "is_referenced_by_count": 59,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6a67c024-d915-4585-a451-4ce7a01f6c78",
    "title": "On minorities and outliers: The case for making Big Data small",
    "abstract": "<jats:p> In this essay, I make the case for choosing to examine small subsets of Big Data datasets—making big data small. Big Data allows us to produce summaries of human behavior at a scale never before possible. But in the push to produce these summaries, we risk losing sight of a secondary but equally important advantage of Big Data—the plentiful representation of minorities. Women, minorities and statistical outliers have historically been omitted from the scientific record, with problematic consequences. Big Data affords the opportunity to remedy those omissions. However, to do so, Big Data researchers must choose to examine very small subsets of otherwise large datasets. I encourage researchers to embrace an ethical, empirical and epistemological stance on Big Data that includes minorities and outliers as reference categories, rather than the exceptions to statistical norms. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714540613",
      "type": "journal-article",
      "published": [
        2014,
        4,
        1
      ],
      "authors": [
        "Brooke Foucault Welles"
      ],
      "url": "https://doi.org/10.1177/2053951714540613",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 7,
      "is_referenced_by_count": 33,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0be8bc00-01da-48c8-bf40-446a3b2f7497",
    "title": "Critical data studies with Latin America: Theorizing beyond data colonialism",
    "abstract": "<jats:p> The article aims to theorize about critical data studies with Latin America beyond the framework of data colonialism, arguing that the long history of social thought in the region can contribute to a more nuanced understanding of the datafication. It discusses views around dependence, oppressions, and liberation, debating how Latin American authors can be useful for current critical data studies, in a more nuanced and complex vision. It presents the theoretical contributions of Lelia Gonzalez, dependency theorists and Enrique Dussel. Dependency theorists criticize evolutionary frameworks of development and can contribute to discussions around data sovereignty and overexploitation of labor. Gonzalez contributes to a complex vision of Amefrica Ladina, articulating multiple forms of oppression. Enrique Dussel presents a theory of technology considering totality and proposes an ethics of liberation that can be related to alternatives toward data justice and data commons. All theoretical frameworks contribute to thinking about datafication with Latin America not as an isolated phenomenon, but in relation to other countries in the world, and as an analytical key for the construction of alternatives. All perspectives are related to current debates on critical data studies and can make an important contribution to the construction of critical theories about data that consider Latin America also as a site of knowledge production. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241227875",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Jonas C. L. Valente",
        "Rafael Grohmann"
      ],
      "url": "https://doi.org/10.1177/20539517241227875",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 69,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9b47c4bb-b991-41e2-8206-bd28f222c5b1",
    "title": "Privacy resignation, apathy, and cynicism: Introduction to a special theme",
    "abstract": "<jats:p> The growing trend of collecting data about individuals to track past actions and infer future attitudes and behaviors has fueled popular and scholarly interest in the erosion of privacy. Recent shifts in technologies around machine learning and artificial intelligence have intensified these concerns. This editorial introduces the articles in the special theme on digital resignation and privacy cynicism: concepts developed in the past decade to explain the growing powerlessness individuals feel in relation to their digital privacy even as they continue to experience consternation over the collection and use of their personal information. The papers in this special theme engage and extend existing research on these topics. The original articles and commentaries pose theoretical and practical questions related to the ways people confront the powerful institutional forces that increasingly shape many aspects of the information environment. They employ several methodologies and theoretical perspectives and extend the range of geographic, political, cultural, and institutional contexts in which privacy cynicism and digital resignation can be identified and examined. In addition to contextualizing these contributions, this editorial maps a range of related concepts including digital resignation, privacy cynicism, privacy apathy, surveillance realism, privacy fatigue, and privacy helplessness. It concludes by identifying key themes across the papers in this collection and provides directions for future research. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241270663",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Nora A Draper",
        "Christian Pieter Hoffmann",
        "Christoph Lutz",
        "Giulia Ranzini",
        "Joseph Turow"
      ],
      "url": "https://doi.org/10.1177/20539517241270663",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 48,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "6ab4ad1f-f732-4ca9-b9ef-2ed24526325f",
    "title": "Stream your brain! Speculative economy of the IoT and its pan-kinetic  dataveillance",
    "abstract": "<jats:p> It is now a common belief that the truths of our lives are hidden in the databases streamed from our interactions in smart environments. In this current hype of big data, the Internet of Things has been suggested as the idea to embed small sensors and actuators everywhere to unfold the truths beneath the surfaces of everything. However, remaining the technology that promises more than it can provide thus far, more important for the IoT’s actual expansion to various social domains than the actual discovery of hidden truths has been people’s speculations about the unknown problems, such as hidden security issues or lifestyle concerns, beyond the narrow human knowability but assumed to leave their traces in the IoT-collected big data. This paper discuss this speculation as the concealed cognitive labor of IoT users that projects some fictitious values to the big data IoT companies accumulate. By the term pan-kinetics, the systemic operation of smart actuators is analyzed as the process through which fictitious values of data are converted to the real values as these actuators draw some profitable correlations from physical domains of the IoT. Analyzing smart electroencephalogram (EEG) headsets as the unique IoT devices operating on human brains, it argues how the IoT translates this speculative realism of unknown problems into its big data, which the IoT developers believe to be full of machine-learnable correlations that would lead to the smart solutions of the problems. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211051973",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Sungyong Ahn"
      ],
      "url": "https://doi.org/10.1177/20539517211051973",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 76,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fe46fa1c-8ffc-4aba-88e6-af6f3e353163",
    "title": "Data ratcheting and data-driven organisational change in transport",
    "abstract": "<jats:p>This article explores the process by which intelligent transport system technologies have further advanced a data-driven culture in public transport and traffic control. Based on 12 interviews with transport engineers and fieldwork visits to three control rooms, it follows the implementation of Real-Time Passenger Information in Dublin and the various technologies on which it is dependent. It uses the concept of ‘data ratcheting’ to describe how a new data-driven rational order supplants a gradualist, conservative ethos, creating technological dependencies that pressure organisations to take control of their own data and curate accessibility to outside organisations. It is argued that the implementation of Real-Time Passenger Information forms part of a changing landscape of urban technologies as cities move from a phase of opening data silos and expanded communication across departments and with citizens towards one in which new streams of digital data are recognised for their value in stabilising novel forms of city administration.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719867359",
      "type": "journal-article",
      "published": [
        2019,
        7
      ],
      "authors": [
        "Liam Heaphy"
      ],
      "url": "https://doi.org/10.1177/2053951719867359",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "2",
      "page": "205395171986735",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 35,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "82223acb-70b5-4eac-a5e9-ffdf17d14faa",
    "title": "Small Big Data: Using multiple data-sets to explore unfolding social and economic change",
    "abstract": "<jats:p> Bold approaches to data collection and large-scale quantitative advances have long been a preoccupation for social science researchers. In this commentary we further debate over the use of large-scale survey data and official statistics with ‘Big Data’ methodologists, and emphasise the ability of these resources to incorporate the essential social and cultural heredity that is intrinsic to the human sciences. In doing so, we introduce a series of new data-sets that integrate approximately 30 years of survey data on victimisation, fear of crime and disorder and social attitudes with indicators of socio-economic conditions and policy outcomes in Britain. The data-sets that we outline below do not conform to typical conceptions of ‘Big Data’. But, we would contend, they are ‘big’ in terms of the volume, variety and complexity of data which has been collated (and to which additional data can be linked) and ‘big’ also in that they allow us to explore key questions pertaining to how social and economic policy change at the national level alters the attitudes and experiences of citizens. Importantly, they are also ‘small’ in the sense that the task of rendering the data usable, linking it and decoding it, required both manual processing and tacit knowledge of the context of the data and intentions of its creators. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715589418",
      "type": "journal-article",
      "published": [
        2015,
        5,
        1
      ],
      "authors": [
        "Emily Gray",
        "Will Jennings",
        "Stephen Farrall",
        "Colin Hay"
      ],
      "url": "https://doi.org/10.1177/2053951715589418",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 30,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e64b0f7d-b37c-4870-adba-9d61b9dfe591",
    "title": "Knowing when to act: A call for an open misinformation library to guide actionable surveillance",
    "abstract": "<jats:p> The design and reporting of data-driven studies seeking to measure misinformation are patchy and inconsistent, and these studies rarely measure associations with, or effects on, behaviour. The consequence is that data-driven misinformation studies are not yet useful as an empirical basis for guiding when to act on emerging misinformation threats, or for deciding when it is more appropriate to do nothing to avoid inadvertently amplifying misinformation. In a narrative review focused on examples of health-related misinformation, we take a critical perspective of data-driven misinformation studies. To address this problem, we propose a curated and open library of misinformation examples and describe its structure and how it might be used to support actionable surveillance. We draw on experiences with other curated repositories to speculate on the likely challenges related to achieving critical mass and maintaining data consistency. We conclude that an open library of misinformation could help improve the consistency of data-driven misinformation study design and reporting, as well as provide an empirical basis from which to make decisions about how to act on new and emerging misinformation threats. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211018788",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Adam G Dunn",
        "Maryke Steffens",
        "Amalie Dyda",
        "Kenneth D Mandl"
      ],
      "url": "https://doi.org/10.1177/20539517211018788",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 59,
      "is_referenced_by_count": 6,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8e1f0741-6c8d-4753-9332-b4b13af2e5d1",
    "title": "Techno-optimism: Framing data and digital infrastructure for public acceptance in Ghana",
    "abstract": "<jats:p> This paper examines public discourse on data and digital infrastructure in Ghana to understand how dominant actors are framing the conversation to galvanise support for the implementation of the technology in the country and its consequences. Using publicly available information on social media, this paper finds that the discourse is led by the government, contending with consistent optimism and iterations from an abstract idea of data positivism that data and digital infrastructure are prerequisites for the country's development. The government claims that building digital infrastructure would accelerate the digitalisation of the country to increase data flow. Hence, going digital with its immense data outcome would then become a means to fighting corruption, ensuring smooth and efficient governance and ensuring economic development. By carefully selecting and presenting these benefits of the technology to the public, the discourse goes unchallenged becoming the sole truth to which citizens have to believe. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231215359",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Adams Issaka"
      ],
      "url": "https://doi.org/10.1177/20539517231215359",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 64,
      "is_referenced_by_count": 1,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "cd341bf0-8293-4d17-8474-86b520d274a9",
    "title": "Emerging practices and perspectives on Big Data analysis in economics: Bigger and better or more of the same?",
    "abstract": "<jats:p> Although the terminology of Big Data has so far gained little traction in economics, the availability of unprecedentedly rich datasets and the need for new approaches – both epistemological and computational – to deal with them is an emerging issue for the discipline. Using interviews conducted with a cross-section of economists, this paper examines perspectives on Big Data across the discipline, the new types of data being used by researchers on economic issues, and the range of responses to this opportunity amongst economists. First, we outline the areas in which it is being used, including the prediction and ‘nowcasting’ of economic trends; mapping and predicting influence in the context of marketing; and acting as a cheaper or more accurate substitute for existing types of data such as censuses or labour market data. We then analyse the broader current and potential contributions of Big Data to economics, such as the ways in which econometric methodology is being used to shed light on questions beyond economics, how Big Data is improving or changing economic models, and the kinds of collaborations arising around Big Data between economists and other disciplines. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714536877",
      "type": "journal-article",
      "published": [
        2014,
        7,
        1
      ],
      "authors": [
        "Linnet Taylor",
        "Ralph Schroeder",
        "Eric Meyer"
      ],
      "url": "https://doi.org/10.1177/2053951714536877",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 22,
      "is_referenced_by_count": 64,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "67df76ed-0dd3-45a5-8e33-4628b127931c",
    "title": "Property regimes and the commodification of geographic information: An examination of Google Street View",
    "abstract": "<jats:p> The body of information on the Internet is becoming increasingly geographical. This is both due to the expansion of established categories of geographic information (e.g., digital maps and geospatial databases) and to the simultaneous enrichment of other types of information through geographic identifiers (e.g., geotags, check-ins, and global positioning system coordinates). As this repository of geographic information expands, it is also a key site for multiple processes of commodification transforming informational resources into market goods. Understanding the dynamics driving the integration of geographic information into the digital economy requires a comprehensive political economic analysis. A key component of this analysis is to explain the logics of creation and allocation of economic value from geographic information on the Internet. Addressing this need, in the present article I deploy the property regimes schema developed by Schlager and Ostrom and expand it to elucidate the differentiated commodification processes of geographic information on the Internet. Property regimes are arrangements that define rules, distribute rights, and delineate roles with respect to particular goods. These arrangements are enabled by elements such as legal frameworks, jurisdictions, type of information, and technologies of access. In this article, I explore how the legal frameworks regulating traditional categories of geographic information (such as maps) have been destabilized in the process of technological innovation, leading to the creation of new informational goods along with their respective property regimes, and rearticulating legal, economic, and sociotechnical relations. To illustrate this, I analyze the case of Google Street View images through their property regimes in various jurisdictions. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716637885",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Luis F Alvarez León"
      ],
      "url": "https://doi.org/10.1177/2053951716637885",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 66,
      "is_referenced_by_count": 25,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "eea91684-7f9e-417d-a288-76ef4353bc1e",
    "title": "Spotify as a technology for integrating health, exercise and wellness practices into financialised capitalism",
    "abstract": "<jats:p> Spotify dominates the audio streaming industry and offers an almost limitless library of music and other ‘sounds’. They have recently made various interventions into health, exercise and wellness with the development of curated and personalised playlists focused on activities such as running, weightlifting and meditation and guided workouts interspersed with algorithmically generated playlists. This article suggests that the company are developing new means of datafying health, exercise and wellness practices such as monitoring activities, heart rate, mood and broadly the rhythms and tempos of their lives. While this is presented as beneficial to users to provide a more personalised experience, analysis of patent applications, financial statements and promotional materials targeting advertisers and investors suggest other objectives. Audio consumption is combined with the newly datafied activities to ‘bundle’ users into ‘audience commodities’ to be sold to advertisers. Furthermore, such innovations, and the potential to attract advertisers, form the materials through which Spotify construct stories to potential investors about the future profitability, or at least growth in market value, of the company essential for firms integrated into ‘financialised capitalism’. This represents a further opening up of aspects of everyday lives to commercial exploitation through datafication and contributes to an attempt to reposition health-related practices as assets which can be packaged for investment portfolios. The publications analysed in this article demonstrate some of the ways in which Spotify seek to both monitor and shape practices of users to make them more amenable to financialisation. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231210278",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Chris Till"
      ],
      "url": "https://doi.org/10.1177/20539517231210278",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 119,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "52c0e457-126d-4ddd-ba29-7cdd84eb247f",
    "title": "How do politicians use Facebook? An applied Social Observatory",
    "abstract": "<jats:p> In the age of the digital generation, written public data is ubiquitous and acts as an outlet for today's society. Platforms like Facebook, Twitter, Google+ and LinkedIn have profoundly changed how we communicate and interact. They have enabled the establishment of and participation in digital communities as well as the representation, documentation and exploration of social behaviours, and had a disruptive effect on how we use the Internet. Such digital communications present scholars with a novel way to detect, observe, analyse and understand online communities over time. This article presents the formalization of a Social Observatory: a low latency method for the observation and measurement of social indicators within an online community. Our framework facilitates interdisciplinary research methodologies via tools for data acquisition and analysis in inductive and deductive settings. By focusing our Social Observatory on the public Facebook profiles of 187 federal German politicians we illustrate how we can analyse and measure sentiment, public opinion, and information discourse in advance of the federal elections. To this extent, we analysed 54,665 posts and 231,147 comments, creating a composite index of overall public sentiment and the underlying conceptual discussion themes. Our case study demonstrates the observation of communities at various resolutions: “zooming” in on specific subsets or communities as a whole. The results of the case study illustrate the ability to observe published sentiment and public dialogue as well as the difficulties associated with established methods within the field of sentiment analysis within short informal text. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715612822",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Simon Caton",
        "Margeret Hall",
        "Christof Weinhardt"
      ],
      "url": "https://doi.org/10.1177/2053951715612822",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 82,
      "is_referenced_by_count": 36,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c63915e5-b896-41d6-a916-b8cfbfc9182f",
    "title": "Tech workers’ perspectives on ethical issues in AI development: Foregrounding feminist approaches",
    "abstract": "<jats:p> While tech workers are essential stakeholders in ethical artificial intelligence (AI) development and deployment, they are rarely consulted about their understanding of the development of ethical AI. In light of this, we present the findings of our 2020 to 2021 empirical research study in which we collected data from tech workers in a major AI company to better understand what they consider to be the most pressing ethical issues when developing AI-powered products. While there is a nascent body of literature that examines how AI ethics principles are operationalised on the ground, this study differs in that we explicitly draw on feminist insights to inform our analysis, and have put a particular focus on allowing the voices and narratives of tech workers to lead the work forward. Our study generated three main findings: first, the term ‘bias’ creates real confusion among tech workers, meaning that the term is unable to do the ethical work it is intended to do; second, tech workers do not necessarily see a relationship between diversity, equality and inclusion (DEI) agendas and AI development, undermining AI ethics initiatives; and third, tech workers were particularly concerned about the monitoring and maintenance of unwieldy ‘legacy systems’ that generated serious challenges to creating and deploying new and more ethical AI products. This study thus creates a ‘thicker’ and more nuanced picture of tech workers’ perspectives on the ethical issues that arise when developing and maintaining AI systems, while simultaneously demonstrating the utility of feminist approaches in the field of AI ethics. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231221780",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Jude Browne",
        "Eleanor Drage",
        "Kerry McInerney"
      ],
      "url": "https://doi.org/10.1177/20539517231221780",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 65,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "34e18e2a-6809-40ff-9d95-2c4661fee96b",
    "title": "The politics of algorithmic governance in the black box city",
    "abstract": "<jats:p> Everyday surveillance work is increasingly performed by non-human algorithms. These entities can be conceptualised as machinic flâneurs that engage in distanciated flânerie: subjecting urban flows to a dispassionate, calculative and expansive gaze. This paper provides some theoretical reflections on the nascent forms of algorithmic practice materialising in two Australian cities, and some of their implications for urban relations and social justice. It looks at the idealisation – and operational black boxing – of automated watching programs, before considering their impacts on notions such as ‘the right to the city’ and ‘the right to the face’. It will argue that the turn to facial recognition software for the purposes of automating urban governance reconstitutes the meanings and phenomenology of the face. In particular, the fleshly and communicative physicality of the face is reduced to a measurable object that can be identified by a virtualised referent and then consequently tracked. Moreover, the asymmetrical and faceless nature of these machinic programs of recognition unsettles conventional notions of civil inattention and bodily sovereignty, and the prioritisation given to pattern recognition renders them amenable to ideas/ideals from phrenology and physiognomy. In this way, algorithmic governance may generate not only forms of facial vulnerability and estrangement, but also facial artifice, where individuals come to develop tacit and artful ways of de-facing and re-facing in order to subvert the processes of recognition which leverage these modes of biopower. Thus, the datafication of urban governance gives rise to a dynamic biopolitics of the face. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720933989",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Gavin JD Smith"
      ],
      "url": "https://doi.org/10.1177/2053951720933989",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 14,
      "is_referenced_by_count": 17,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3b3fc962-8ad5-4381-ab62-a22b272811be",
    "title": "A not quite random walk: Experimenting with the ethnomethods of the algorithm",
    "abstract": "Algorithms have become a widespread trope for making sense of social life. Science, finance, journalism, warfare, and policing—there is hardly anything these days that has not been specified as “algorithmic.” Yet, although the trope has brought together a variety of audiences, it is not quite clear what kind of work it does. Often portrayed as powerful yet inscrutable entities, algorithms maintain an air of mystery that makes them both interesting and difficult to understand. This article takes on this problem and examines the role of algorithms not as techno-scientific objects to be known, but as a figure that is used for making sense of observations. Following in the footsteps of Harold Garfinkel’s tutorial cases, I shall illustrate the implications of this view through an experiment with algorithmic navigation. Challenging participants to go on a walk, guided not by maps or GPS but by an algorithm developed on the spot, I highlight a number of dynamics typical of reasoning with running code, including the ongoing respecification of rules and observations, the stickiness of the procedure, and the selective invocation of the algorithm as an intelligible object. The materials thus provide an opportunity to rethink key issues at the intersection of the social sciences and the computational, including popular concerns with transparency, accountability, and ethics.",
    "metadata": {
      "doi": "10.1177/2053951717738105",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Malte Ziewitz"
      ],
      "url": "https://doi.org/10.1177/2053951717738105",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171773810",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 39,
      "is_referenced_by_count": 39,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "17b5be1b-5d08-4e5b-bf92-54c799362bfa",
    "title": "Introduction to Special Theme Veillance and transparency: A critical examination of mutual watching in the post-Snowden, Big Data era",
    "abstract": "<jats:p> Introducing the Special Theme on Veillance and Transparency: A Critical Examination of Mutual Watching in the Post-Snowden, Big Data Era, this article presents a series of provocations and practices on veillance and transparency in the context of Big Data in a post-Snowden period. In introducing the theoretical and empirical research papers, artistic, activist and educational provocations and commentaries in this Special Theme, it highlights three central debates. Firstly, concerning theory/practice, it queries how useful theories of veillance and transparency are in explaining mutual watching in the post-Snowden, Big Data era. Secondly, it presents a range of questions concerning norms, ethics, regulation, resistance and social change around veillance and transparency. Thirdly, it interrogates the upsurge in veillance and transparency discourses and practices post-Snowden, and asks whether they are adequate to the task of educating and engaging people on abstract and secretive surveillance practices, as well as on the possibilities and pitfalls of sousveillance. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717698996",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Vian Bakir",
        "Martina Feilzer",
        "Andrew McStay"
      ],
      "url": "https://doi.org/10.1177/2053951717698996",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 19,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "222bbd52-3dc6-4430-b421-163e3c840dbd",
    "title": "A comparative analysis of data governance: Socio-technical imaginaries of digital personal data in the USA and EU  (2008–2016)",
    "abstract": "<jats:p> Personal data are produced through our daily interactions with digital technologies like search engines, social media, and online shopping, and is often referred to as our “digital exhaust.” It has been characterized as the key resource or asset for our economies in the 21st century. This paper focuses on the socio-technical imaginaries of digital personal data as a way to understand how desired forms of data governance are co-produced with collective understandings of personal data as a political-economic asset. We examine the different socio-technical imaginaries that underpinned different developments in data regulations in the United States and EU from 2008 to 2016, focusing specifically on the mutual constitution of law, political economy, and technoscience. We do so in order to understand the “prehistories” of contemporary data governance. We analyze the institutional and legal context around the development of data privacy regulation and data commercialization in these two important jurisdictions and reflect on how this institutional and legal context configured their respective approaches to data governance. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221112925",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Rob Guay",
        "Kean Birch"
      ],
      "url": "https://doi.org/10.1177/20539517221112925",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 71,
      "is_referenced_by_count": 15,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "277711d6-bf03-49f1-81f4-ad1afaa620bb",
    "title": "Dimensionalizing privacy to advance the study of digital disempowerment",
    "abstract": "<jats:p> In this essay, we call attention to privacy as the foundational construct that underpins digital disempowerment. We argue that to better understand the processes of disempowerment, scholars must critically engage with the dimensionality of privacy conceptualizations and privacy-dependent constructs such as privacy concerns and privacy-protecting behavior, and the way in which these are measured. We focus on privacy's horizontal and vertical dimensions as a way to offer a more nuanced understanding of power in computationally mediated environments and potentially enable a more refined and meaningful understanding of privacy resignation and disengagement. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231221739",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Kelly Quinn",
        "Dmitry Epstein"
      ],
      "url": "https://doi.org/10.1177/20539517231221739",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 44,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8fa65693-6e20-4424-af5c-1bd1d6cceb1a",
    "title": "Extrapolation and AI transparency: Why machine learning models should reveal when they make decisions beyond their training",
    "abstract": "<jats:p> The right to artificial intelligence (AI) explainability has consolidated as a consensus in the research community and policy-making. However, a key component of explainability has been missing: extrapolation, which can reveal whether a model is making inferences beyond the boundaries of its training. We report that AI models extrapolate outside their range of familiar data, frequently and without notifying the users and stakeholders. Knowing whether a model has extrapolated or not is a fundamental insight that should be included in explaining AI models in favor of transparency, accountability, and fairness. Instead of dwelling on the negatives, we offer ways to clear the roadblocks in promoting AI transparency. Our commentary accompanies practical clauses useful to include in AI regulations such as the AI Bill of Rights, the National AI Initiative Act in the United States, and the AI Act by the European Commission. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231169731",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Xuenan Cao",
        "Roozbeh Yousefzadeh"
      ],
      "url": "https://doi.org/10.1177/20539517231169731",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 18,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8c5ea0fe-0c40-40cb-b16f-9a8f0b0dc84e",
    "title": "Algorithms as fetish: Faith and possibility in algorithmic work",
    "abstract": "<jats:p> Algorithms are powerful because we invest in them the power to do things. With such promise, they can transform the ordinary, say snapshots along a robotic vacuum cleaner’s route, into something much more, such as a clean home. Echoing David Graeber’s revision of fetishism, we argue that this easy slip from technical capabilities to broader claims betrays not the “magic” of algorithms but rather the dynamics of their exchange. Fetishes are not indicators of false thinking, but social contracts in material form. They mediate emerging distributions of power often too nascent, too slippery or too disconcerting to directly acknowledge. Drawing primarily on 2016 ethnographic research with computer vision professionals, we show how faith in what algorithms can do shapes the social encounters and exchanges of their production. By analyzing algorithms through the lens of fetishism, we can see the social and economic investment in some people’s labor over others. We also see everyday opportunities for social creativity and change. We conclude that what is problematic about algorithms is not their fetishization but instead their stabilization into full-fledged gods and demons – the more deserving objects of critique. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717751552",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Suzanne L Thomas",
        "Dawn Nafus",
        "Jamie Sherman"
      ],
      "url": "https://doi.org/10.1177/2053951717751552",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 29,
      "is_referenced_by_count": 43,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "393b6382-e70e-4354-9a4a-ff6c030efd94",
    "title": "Racial formation, coloniality, and climate finance organizations: Implications for emergent data projects in the Pacific",
    "abstract": "<jats:p> This commentary explores the potential consequence of latent racial formation in emergent climate finance data projects and draws from ethnographic research on climate finance governance conducted in Fiji. Climate finance data projects emerging in the Pacific aim to ease the flow of finance from the Global North to the South. These emergent data projects, such as renewable energy resource availability and investment mapping, are imbedded in the climate finance organizations that fund, develop, and use them. Thus, the commentary explores climate finance organizations through the lens of Ray’s (2019) theory of racial organizations, highlighting the ways in which important climate-related resources are mediated through racial and colonial schemas. The racial mediation of two key resources are spotlighted in this discussion: the finance itself and knowledge. Given that the Pacific region is at the coalface of climate change’s existential effects, the just allocation of resources is imperative. In interrogating the ways in which emergent data projects may deny these resources based on hidden racial schemas, the paper cautions against new and old forms of colonization that may be mobilized through even well-meaning techno-benevolent fixes ( Benjamin, 2019 ). </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211027600",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Kirsty Anantharajah"
      ],
      "url": "https://doi.org/10.1177/20539517211027600",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 29,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8c6cdd61-aa41-485c-aa64-1da025a194fe",
    "title": "The benefits of being between (many) fields: Mapping the high-dimensional space of AI research",
    "abstract": "<jats:p> This article considers how the emerging Artificial Intelligence (AI) research field is constructed, primarily in university settings. AI research is a site of significant national funding, industry investment, and media interest. As such, for researchers working across the resource-constrained science system, their relationship to the field is significant; legitimisation as an AI researcher can bring material and symbolic rewards. Through interviews (n = 90) with academics affiliated with AI-branded research organisations in the US, UK, and Australia, the article develops an empirical account of the construction of AI research as a high-dimensional field – a field that moves between multiple disciplinary and sectoral boundaries across national and international hierarchies. The article draws on the sociology of expertise and studies of research infrastructures to develop the conceptual frame of dimensionality to explain the vertical and horizontal dynamics informing the AI field's development. The article's contributions are its description of the emerging AI field, which complements critical studies of how the figure of AI is mobilised in other settings, and its extension of field theory to fluid spaces that leverage the boundary zone between several overlapping field arrangements. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241306355",
      "type": "journal-article",
      "published": [
        2025,
        3
      ],
      "authors": [
        "Glen Berman",
        "Kate Williams",
        "Eliel Cohen"
      ],
      "url": "https://doi.org/10.1177/20539517241306355",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "12",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 84,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "82bcaccd-6943-413e-9300-2ed7b898e558",
    "title": "Just public algorithms: Mapping public engagement with the use of algorithms in UK public services",
    "abstract": "<jats:p> This paper proposes and models a novel approach to public engagement with the use of algorithms in public services. Algorithms pose significant risks which need to be anticipated and mitigated through democratic governance, including public engagement. We argue that as the challenge of creating responsible algorithms within a dynamic innovation system is one that will never definitively be accomplished – and as public engagement is not singular or pre-given but is always constructed through performance and in relation to other processes and events – public engagement with algorithms needs to be conducted and conceptualised as relational, systemic, and ongoing. We use a systemic mapping approach to map and analyse 77 cases of public engagement with the use of algorithms in public services in the UK 2013–2020 and synthesise the potential benefits and risks of these approaches articulated across the cases. The mapping shows there was already a diversity of public engagement on this topic in the UK by 2020, involving a wide range of different policy areas, framings of the problem, affordances of algorithms, publics, and formats of public engagement. While many of the cases anticipate benefits from the adoption of these technologies, they also raise a range of concerns which mirror much of the critical literature and highlight how algorithmic approaches may sometimes foreclose alternative options for policy delivery. The paper concludes by considering how this approach could be adopted on an ongoing basis to ensure the responsible governance of algorithms in public services, through a ‘public engagement observatory’. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241235867",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Helen Pallett",
        "Catherine Price",
        "Jason Chilvers",
        "Simon Burall"
      ],
      "url": "https://doi.org/10.1177/20539517241235867",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 77,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "20beda58-b135-4886-bf67-7b2884d7a0f4",
    "title": "“No disease for the others”: How COVID-19 data can enact new and old alterities",
    "abstract": "<jats:p> The COVID-19 pandemic invites a question about how long-standing narratives of alterity and current narratives of disease are entwined and re-enacted in the diagnosis of COVID-19. In this commentary, we discuss two related phenomena that, we argue, should be taken into account in answering this question. First, we address the diffusion of pseudoscientific accounts of minorities’ immunity to COVID-19. While apparently praising minorities’ biological resistance, such accounts rhetorically introduce a distinction between “Us” and “Them,” and in so doing produce new and re-enact old narratives of alterity. Second, these unsubstantiated narratives thrive on fake news and scarcity of data. The second part of this commentary thus surveys the methods through which the COVID-19 test is administered in various countries. We argue that techniques used for data collection have a major role in producing COVID-19 data that render contagion rates among migrants and other minorities invisible. In the conclusion, we provide two recommendations about how COVID-19 data can instead potentially work towards inclusion. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720942542",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Annalisa Pelizza"
      ],
      "url": "https://doi.org/10.1177/2053951720942542",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "824da110-c437-410f-adaf-fd980effa454",
    "title": "Corrigendum to Low on trust, high on use: Datafied media, trust and everyday life",
    "abstract": "",
    "metadata": {
      "doi": "10.1177/20539517221080834",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [],
      "url": "https://doi.org/10.1177/20539517221080834",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "not available"
    }
  },
  {
    "id": "c32f8c7d-0d4e-4731-accb-884f02d5e435",
    "title": "Data doxa: The affective consequences of data practices",
    "abstract": "<jats:p> This paper explores the embedding of data producing technologies in people's everyday lives and practices. It traces how repeated encounters with digital data operate to naturalise these entities, while often blindsiding their agentive properties and the ways they get implicated in processes of exploitation and governance. I propose and develop the notion of ‘data doxa’ to conceptualise the way in which digital data – and the devices and platforms that stage data – have come to be perceived in Western societies as normal, necessary and enabling. The ‘data doxa’ concept also accentuates the enculturation of many individuals into a data sharing habitus which frames digital technologies in simplistic terms as (a) panaceas for the problems associated with contemporary life, (b) figures of progress and convenience, and (c) mediums of knowledge, pleasure and identity. I suggest that three types of data-based relations contribute to the formation of this doxic sensibility: fetishisation, habit and enchantment. Each of these relations come to mediate public understandings of digital devices and the data they generate, obscuring the multifaceted nature and hidden depths of data and their propensity to double up as technologies of exposure and discipline. As a result of this situation, imaginative educational programs and revamped regulatory frameworks are urgently needed to inform individuals about the contribution of data to the leveraging of value and power in today's digital economies, but also to protect them from experiencing data-based harms. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717751551",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Gavin JD Smith"
      ],
      "url": "https://doi.org/10.1177/2053951717751551",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 58,
      "is_referenced_by_count": 36,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9509c541-5106-43cc-a11c-c8c3e1e02e81",
    "title": "The Snowden Archive-in-a-Box: A year of travelling experiments in outreach and education",
    "abstract": "<jats:p> The Snowden Archive-in-a-Box is an offline wireless network and web server providing private access to a replica of the Snowden Digital Surveillance Archive. The online version is hosted by Canadian Journalists for Free Expression. A work-in-development since April 2015, the Archive-in-a-Box is both a research tool and a tool for public education on data surveillance. The original version is powered with battery packs and housed in a 1960s spy style briefcase. When it is turned on, anybody in the vicinity can access the archive by connecting their wireless device to the Snowden Archive WiFi network and browsing to a website. Open the briefcase up and one finds a wood panel with a flatscreen inset, playing back the IP traffic of the archive's current users. Thus, while an audience such as a class of students or workshop group can access the Snowden documents and learn about mass surveillance from primary materials, they are also shown what data surveillance ‘looks like’. This Commentary explores my experiences during the first year of the Snowden Archive-in-a-Box. I examine my experiences as an international traveller carrying a suspicious briefcase of Top Secret materials and this project's reception by certain audiences. The project is still a prototype, yet it is quickly gathering a following and a number of permanent installations around the world. What could this mean for the future of surveillance education and leaks-enabled research? </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716666869",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Evan Light"
      ],
      "url": "https://doi.org/10.1177/2053951716666869",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 3,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "880c972b-3b18-4e5f-88a2-fca9e985d2fb",
    "title": "Algorithmic decision-making: The right to explanation and the significance of stakes",
    "abstract": "<jats:p> The stakes associated with an algorithmic decision are often said to play a role in determining whether the decision engenders a right to an explanation. More specifically, “high stakes” decisions are often said to engender such a right to explanation whereas “low stakes” or “non-high” stakes decisions do not. While the overall gist of these ideas is clear enough, the details are lacking. In this paper, we aim to provide these details through a detailed investigation of what we will call the “Simple Stakes Thesis.” The Simple Stakes Thesis, as it will turn out, is too simple. For even if the stakes associated with a specific one-off decision are low—and hence does not engender a right to an explanation—such decisions may nevertheless form part of a high stakes pattern or aggregate of decisions. In such cases, we argue, even a low stakes decision may engender a right to explanation. Not only does this show that the right to explanation is more demanding than so far recognized but it also shows that the stakes thesis is significantly harder to apply in practice. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231222872",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Lauritz Aastrup Munch",
        "Jens Christian Bjerring",
        "Jakob Thrane Mainz"
      ],
      "url": "https://doi.org/10.1177/20539517231222872",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 43,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7812ea54-7393-4a98-bf50-f03c871daaaa",
    "title": "AI ethics and data governance in the geospatial domain of Digital Earth",
    "abstract": "<jats:p> Digital Earth applications provide a common ground for visualizing, simulating, and modeling real-world situations. The potential of Digital Earth applications has increased significantly with the evolution of artificial intelligence systems and the capacity to collect and process complex amounts of geospatial data. Yet, the widespread techno-optimism at the root of Digital Earth must now confront concerns over high-risk artificial intelligence systems and power asymmetries of a datafied society. In this commentary, we claim that not only can current debates about data governance and ethical artificial intelligence inform development in the field of Digital Earth, but that the specificities of geospatial data, together with the expectations surrounding Digital Earth applications, offer a fruitful lens through which to examine current debates on data governance and artificial intelligence ethics. In particular, we argue that for the implementation of ethical artificial intelligence and inclusive approaches to data governance, Digital Earth initiatives need to involve stakeholders and communities at the local level and be sensitive to social, legal, cultural, and institutional contexts, including conflicts that might arise within those contexts. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221138767",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Marina Micheli",
        "Caroline M Gevaert",
        "Mary Carman",
        "Max Craglia",
        "Emily Daemen",
        "Rania E Ibrahim",
        "Alexander Kotsev",
        "Zaffar Mohamed-Ghouse",
        "Sven Schade",
        "Ingrid Schneider",
        "Lea A Shanley",
        "Alessio Tartaro",
        "Michele Vespe"
      ],
      "url": "https://doi.org/10.1177/20539517221138767",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 38,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "709188bb-ca06-48b8-94b7-8b3cb51e8495",
    "title": "Understanding the meaning of emoji in mobile social payments: Exploring the use of mobile payments as hedonic versus utilitarian through skin tone modified emoji usage",
    "abstract": "<jats:p> Despite research establishing emojis as sites of critical racial discourse, there is a paucity of literature examining their importance in the increasingly popular context of mobile payments. This is particularly important as new forms of social payment platforms such as Venmo bridge the seamlessness of mobile payments with the vibrant communicative practices of social networks. As such, they provide a unique medium to examine how emojis are used within the context of digital consumption, and by extension, self-representation. This study analyzes approximately 325 million public transactions on the U.S. payment platform Venmo to understand whether emoji usage in mobile payments is more hedonic or utilitarian. We then explore how race is represented across emoji usage on Venmo via tone-modified emojis, a subset of emojis whereby users can choose a skin tone. We found that while emojis in general are used for more hedonic purposes than utilitarian ones, darker tone-modified emojis indicate a proportionately higher use in hedonic consumption as compared to lighter tone-modified emojis, and also show a higher representation of utilitarian categories in transactions. Thematic analysis revealed that subsets with darker tone-modified emojis have a greater lexical variety and engage in more playful uses of emoji in mobile payments </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720949564",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Dhiraj Murthy",
        "Sabitha Sudarshan",
        "Jung-Ah Lee",
        "Charulata Ghosh",
        "Pratik Shah",
        "Wei-Jie Xiao",
        "Ishank Arora",
        "Clive Unger",
        "Amelia Acker"
      ],
      "url": "https://doi.org/10.1177/2053951720949564",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 70,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7020e311-cb9a-49f6-9273-9d8db943556d",
    "title": "Joint-sensemaking, innovation, and communication management during crisis: Evidence from the DCT applications in China",
    "abstract": "<jats:p> As exemplified by the COVID-19 pandemic, the design and implementation of data-driven health surveillance, like digital contact tracing (DCT) apps, carry significant implications for society. However, its rushed development calls for careful consideration from all involved stakeholders to achieve a shared understanding and engage in joint-sensemaking in order to implement DCT collaboratively and effectively utilize it in the fight against the pandemic. Yet, the empirical ground truth and theoretical mechanism of joint-sensemaking are both unclear. Drawing on this gap, this article applies a multistep approach, including sentiment analysis, topic analysis coupled with regression and unique network analysis, to thoroughly explore, examine, and explain the dynamic process of joint-sensemaking in the context of a public crisis. Based on evidence from 113,264 Weibo posts, we illustrate two joint-sensemaking pathways and three key interventions using the case of China's Health Code in the context of the DCT. We reveal that the effectiveness of different interventions and contributions made by stakeholders vary significantly between different joint-sensemaking pathways. Specifically, we find that official media and opinion leaders act as crucial mediators in bridging intervention conductors and the public. However, their influence presents heterogeneity toward different network modularity, thus leading to distinct patterns. Additionally, inconsistent with previous literature, we find that within the context of the China Health Code, official media has a greater impact on opinion leaders in engaging the public. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241270714",
      "type": "journal-article",
      "published": [
        2024,
        9
      ],
      "authors": [
        "Jingjing Qu",
        "Liwei Chen",
        "Hui Zou",
        "Hui Hui",
        "Wen Zheng",
        "Jar-Der Luo",
        "Qingyuan Gong",
        "Yuwei Zhang",
        "Tianyu Wen",
        "Yang Chen"
      ],
      "url": "https://doi.org/10.1177/20539517241270714",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "3",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 60,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "213b77ae-e23e-467e-8c0b-79eff37f5a70",
    "title": "<i>Grøn Genstart</i>: A quali-quantitative micro-history of a political idea in real-time",
    "abstract": "<jats:p> In this study, we build on a recent social data scientific mapping of Danish environmentalist organizations and activists during the COVID-19 lockdown in order to sketch a distinct genre of digital social research that we dub a quali-quantitative micro-history of ideas in real-time. We define and exemplify this genre by tracing and tracking the single political idea and activist slogan of grøn genstart (‘green restart’) across Twitter and other public–political domains. Specifically, we achieve our micro-history through an iterative and mutual attuning between computational and netnographic registers and techniques, in ways that contribute to the nascent field of computational anthropology. By documenting the serial ways in and different steps through which our inquiry was continually fed and enhanced by crossing over from (n)ethnographic observation to computational exploration, and vice versa, we offer up our grøn genstart case account as exemplary of wider possibilities in this line of inquiry. In particular, we position the genre of micro-history of ideas in real-time within the increasingly wide and heterogeneous space of digital social research writ large, including its established concerns with ‘big and broad’ social data, the repurposing of computational ‘interface’ techniques for socio-cultural research, as well as diverse aspirations for deploying digital data within novel combinations of qualitative and quantitative methods. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211070300",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Annika SH Isfeldt",
        "Thyge R Enggaard",
        "Anders Blok",
        "Morten A Pedersen"
      ],
      "url": "https://doi.org/10.1177/20539517211070300",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d8467f75-4296-4cbe-9fcb-be9ad45b5303",
    "title": "Innovation under pressure: Implications for data privacy during the Covid-19 pandemic",
    "abstract": "<jats:p> The global Covid-19 pandemic has resulted in social and economic disruption unprecedented in the modern era. Many countries have introduced severe measures to contain the virus, including travel restrictions, public event bans, non-essential business closures and remote work policies. While digital technologies help governments and organizations to enforce protection measures, such as contact tracing, their rushed deployment and adoption also raises profound concerns about surveillance, privacy and data protection. This article presents two critical cases on digital surveillance technologies implemented during the Covid-19 pandemic and delineates the privacy implications thereof. We explain the contextual nature of privacy trade-offs during a pandemic and explore how regulatory and technical responses are needed to protect privacy in such circumstances. By providing a multi-disciplinary conversation on the value of privacy and data protection during a global pandemic, this article reflects on the implications digital solutions have for the future and raises the question of whether there is a way to have expedited privacy assessments that could anticipate and help mitigate adverse privacy implications these may have on society. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720976680",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Gemma Newlands",
        "Christoph Lutz",
        "Aurelia Tamò-Larrieux",
        "Eduard Fosch Villaronga",
        "Rehana Harasgama",
        "Gil Scheitlin"
      ],
      "url": "https://doi.org/10.1177/2053951720976680",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 112,
      "is_referenced_by_count": 71,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "eff1eb40-f351-45e4-ab6e-3a366c84713c",
    "title": "Institutionalizing Big Data methods in social and political research",
    "abstract": "<jats:p> We expect Big Data methods to contribute to research with results that are not inferior to those attained in other ways but possibly better, or hard or impossible to generate in other ways. Those who apply these methods may also aspire to augment the arsenal of research methods, offer surrogates for existing research designs, and re-orient research. Moreover, we can critically examine the institutional, societal and political effects of the Big Data methods and the conditions for the solid institutionalization of these methods in social and political research. To reach its primary objective, this article elaborates conclusions on how Big Data methods, not only by means of their ‘social life’ but also by their ‘political life’, may influence the institutionalization of social and political research. To reach its secondary objective, the article re-examines a study of budgetary legislation in 13 countries carried out by means of Big Data methods to draw conclusions concerning the augmentation of the arsenal of research methods, the surrogation of existing research designs, and the re-orientation of research. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715591224",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Pertti Ahonen"
      ],
      "url": "https://doi.org/10.1177/2053951715591224",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 69,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b8c8bdc7-9327-4e91-b714-81aed89f4979",
    "title": "Researching with Twitter timeline data: A demonstration via “everyday” socio-political talk around welfare provision",
    "abstract": "<jats:p> Increasingly, social media platforms are understood by researchers to be valuable sites of politically-relevant discussions. However, analyses of social media data are typically undertaken by focusing on ‘snapshots’ of issues using query-keyword search strategies. This paper develops an alternative, less issue-based, mode of analysing Twitter data. It provides a framework for working qualitatively with longitudinally-oriented Twitter data (user-timelines), and uses an empirical case to consider the value and the challenges of doing so. Exploring how Twitter users place “everyday” talk around the socio-political issue of UK welfare provision, we draw on digital ethnography and narrative analysis techniques to analyse 25 user-timelines and identify three distinctions in users’ practices: users’ engagements with welfare as TV entertainment or as a socio-political concern; the degree of sustained engagement with said issues, and; the degree to which users’ tweeting practices around welfare were congruent with or in contrast to their other tweets. With this analytic orientation, we demonstrate how a longitudinal analysis of user-timelines provides rich resources that facilitate a more nuanced understanding of user engagement in everyday socio-political discussions online. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718766624",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Phillip Brooker",
        "Julie Barnett",
        "John Vines",
        "Shaun Lawson",
        "Tom Feltwell",
        "Kiel Long",
        "Gavin Wood"
      ],
      "url": "https://doi.org/10.1177/2053951718766624",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 57,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9d19fd2b-80e8-441f-a48c-1c9977412a34",
    "title": "Google Search and the creation of ignorance: The case of the climate crisis",
    "abstract": "<jats:p> The article examines the relationship between commercial search engines, using Google Search as an example, and various forms of ignorance related to climate change. It draws on concepts from the field of agnotology to explore how environmental ignorances, and specifically related to the climate crisis, are shaped at the intersection of the logics of Google Search, everyday life and civil society/politics. Ignorance refers to a multi-facetted understanding of the culturally contingent ways in which something may not be known. Two research questions are addressed: How are environmental ignorances, and in particular related to the climate crisis, shaped at the intersection of the logics of Google Search, everyday life and civil society/politics? In what ways can we conceptualise Google's role as configured into the creation of ignorances? The argument is made through four vignettes, each of which explores and illustrates how Google Search is configured into a different kind of socially produced ignorance: (1) Ignorance through information avoidance: climate anxiety; (2) Ignorance through selective choice: gaming search terms; (3) Ignorance by design: algorithmically embodied emissions; (4) Ignorance through query suggestions: directing people to data voids. The article shows that while Google Search and its underlying algorithmic and commercial logic pre-figure these ignorances, they are also co-created and co-maintained by content producers, users and other human and non-human actors, as Google Search has become integral of social practices and ideas about them. The conclusion draws attention to a new logic of ignorance that is emerging in conjunction with a new knowledge logic. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231158997",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Jutta Haider",
        "Malte Rödl"
      ],
      "url": "https://doi.org/10.1177/20539517231158997",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 66,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "84fdef37-1c14-4e30-aa8d-e8156c31ea23",
    "title": "Materialities of digital disease  control in Taiwan during COVID-19",
    "abstract": "<jats:p> During the course of the COVID-19 pandemic, a wide range of digital technologies and data analytics have been incorporated into pandemic response models globally, in the hope of better detecting, tracking, monitoring and containing outbreaks. This increased digital involvement in disease control has offered the prospect of heightened effectiveness in all of the above, but not without raising other concerns. This paper contributes to ongoing discussions of the digital transformation in disease control by proposing a materialist analysis of how such control has become operative and what its effects may be, both now and in the future. Using Taiwan's digital pandemic response as a case study, the paper explores specific ways in which material processes and arrangements have shaped digital measures, as well as the actions that rendered such measures operable, with their ensuing consequences. This analysis illustrates the importance of historical, material and technological specificities and contingencies to our understanding of how digital disease control takes a particular shape. It also demonstrates how shifting regimes of practice continually reconfigure the ways in which digital disease control functions. The paper argues that paying greater attention to the materialities of digital disease control can provide a more nuanced understanding of the complex ways in which society may be protected or harmed by its use, possibly simultaneously. It is hoped that such increased attentiveness may inform more considered and careful preparation for subsequent pandemics. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221097315",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Sung-Yueh Perng"
      ],
      "url": "https://doi.org/10.1177/20539517221097315",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 47,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "07352bf7-30e2-4136-90ec-496e46c29b3c",
    "title": "Digital resignation and the datafied  welfare state",
    "abstract": "<jats:p> This commentary calls for further research into digital resignation within non-market contexts, particularly in relation to the datafied welfare state, as distinct from commercial big tech platforms. We aim to nuance the concept of digital resignation by relating it to the digitization of institutions and public services upholding the Danish welfare state, including health services, childcare, and news consumption. These cases illustrate that datafication stimulates citizens’ discomfort by registering privacy-intrusive information and setting new standards for being a good citizen, which resignation research can help us understand. We use the case examples to propose new avenues for digital resignation research and question whether organizations, institutions, and governments themselves can be digitally resigned. As such, the usefulness of digital resignation as a concept can be expanded. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231206806",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Christoffer Bagger",
        "Arni Már Einarsson",
        "Victoria Andelsman Alvarez",
        "Maja Klausen",
        "Stine Lomborg"
      ],
      "url": "https://doi.org/10.1177/20539517231206806",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 34,
      "is_referenced_by_count": 5,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c5652902-d497-4278-b2ad-34f007074f06",
    "title": "Precision medicine and digital phenotyping: Digital medicine's way from more data to better health",
    "abstract": "<jats:p> Precision medicine and digital phenotyping are two prominent data-based approaches within digital medicine. While precision medicine historically used primarily genetic data to find targeted treatment options, digital phenotyping relies on the usage of big data deriving from digital devices such as smartphones, wearables and other connected devices. This paper first focusses on the aspect of data type to explore differences and similarities between precision medicine and digital phenotyping. It outlines different ways of data collection and production and the consequences thereof. Second, it shows how these sorts of data influence dominant beliefs in the field: The field of precision medicine relying on the dominant understanding of ‘genetic determinism’ imported from genetics, digital phenotyping building on the logic of ‘data fundamentalism’. In the end, the analysis shows how digital data informs potentials as well as challenges of precision medicine and digital phenotyping: a better health care for (some) individuals connected with individualisation and responsibilisation for all, with a prognosed shift from reactive to preventive medicine. Additionally, data-based approaches might facilitate epistemological and ontological redirections for the whole field of medicine that will also affect knowledge production and a reassessment of the value of different types of knowledge (quantifiable vs. non-quantifiable) with all its consequences. Institutionally, it might lead to shifts in distribution of power to experts in big data related technologies, i.e. private companies. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211066452",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Renate Baumgartner"
      ],
      "url": "https://doi.org/10.1177/20539517211066452",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 62,
      "is_referenced_by_count": 25,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4e6eeab3-bafc-49d3-8e33-f9c06a6d6f39",
    "title": "Intersectional approaches to data: The importance of an articulation mindset for intersectional data science",
    "abstract": "<jats:p>Data's increasing role in society and high profile reproduction of inequalities is in tension with traditional methods of using social data for social justice. Alongside this, ‘intersectionality’ has increased in prominence as a critical social theory and praxis to address inequalities. Yet, there is not a comprehensive review of how intersectionality is operationalized in research data practice. In this study, we examined how intersectionality researchers across a range of disciplines conduct intersectional analysis as a means of unpacking how intersectional praxis may advance an intersectional data science agenda. To explore how intersectionality researchers collect and analyze data, we conducted a critical discourse analysis approach in a review of 172 articles that stated using an intersectional approach in some way. We contemplated whether and how Collins’ three frames of relationality were evident in their approach. We found an over-reliance on the additive thinking frame in quantitative research, which poses limits on the potential for this research to address structural inequality. We suggest ways in which intersectional data science could adopt an articulation mindset to improve on this tendency.</jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231203667",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Caitlin Bentley",
        "Chisenga Muyoya",
        "Sara Vannini",
        "Susan Oman",
        "Andrea Jimenez"
      ],
      "url": "https://doi.org/10.1177/20539517231203667",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 71,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "60b63f64-ebc2-451d-820b-faf19132e685",
    "title": "Judgments as bulk data",
    "abstract": "<jats:p> Should court judgments be publicly available for text and data mining purposes? This article shows that the arguments for and against access to judgments conflate different understandings of what judgments are. On one view, judgments are seen as a ‘jurisprudential’ category, whereas the other view regards them as something ‘factual’. Once it is understood that these views and the claims based on them do not fight over the same territory, it should be easier to make judgments more widely available, including for the purposes of computational analysis of judgments as bulk data. The purpose of this article is to help to clear the ground for the debate around access to judgments as bulk data and highlight some relevant considerations for the preferred licencing regime concerning judgments. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231160527",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Václav Janeček"
      ],
      "url": "https://doi.org/10.1177/20539517231160527",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 34,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2d1a86c9-e97f-4613-86dc-877c13dd3e93",
    "title": "Structure from interaction events",
    "abstract": "<jats:p> In this contribution to the colloquium, I argue why and how I lost interest in the overall structure of social networks even though Big Data techniques are increasingly simplifying the collection, organisation, and analysis of ever larger networks. The challenge that Big Data techniques pose to the social scientist, I think, is of a different nature. Big Data on social actors mainly record events, e.g. interactions between human beings that happen at a point in time. In contrast, social network analysts tend to think in terms of social relations that exist over a timespan. The challenge, then, is to rethink our conceptions and models of social relations and social structure. I conceptualize social structure and social relations as forces. I propose modelling these forces with regression models for longitudinal interaction data. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715603732",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Wouter de Nooy"
      ],
      "url": "https://doi.org/10.1177/2053951715603732",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 18,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "bde3a468-711b-423c-939e-844a58588bf1",
    "title": "Corrigendum to “Data as performance – Showcasing cities through open data maps”",
    "abstract": "",
    "metadata": {
      "doi": "10.1177/2053951720951561",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [],
      "url": "https://doi.org/10.1177/2053951720951561",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 0,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "not available"
    }
  },
  {
    "id": "ce909042-b6be-4d86-8dfd-103c5b211fdb",
    "title": "Of ‘black boxes’ and algorithmic decision-making in (higher) education – A commentary",
    "abstract": "<jats:p> Higher education institutions have access to higher volumes and a greater variety and granularity of student data, often in real-time, than ever before. As such, the collection, analysis and use of student data are increasingly crucial in operational and strategic planning, and in delivering appropriate and effective learning experiences to students. Student data – not only in what data is (not) collected, but also how the data is framed and used – has material and discursive effects, both permanent and fleeting. We have to critically engage claims that artificial intelligence and the ever expansive/expanding systems of algorithmic decision-making provide speedy, accessible, revealing, panoramic, prophetic and smart analyses of students' risks, potential and learning needs. We need to pry open the black boxes higher education institutions (and increasingly venture capital and learning management system providers) use to admit, steer, predict and prescribe students’ learning journeys. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720933994",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Paul Prinsloo"
      ],
      "url": "https://doi.org/10.1177/2053951720933994",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172093399",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 23,
      "is_referenced_by_count": 21,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "43392ca3-4e01-4f3b-abcd-6d6e024d8c13",
    "title": "Four investment areas for ethical AI: Transdisciplinary opportunities to close the publication-to-practice gap",
    "abstract": "<jats:p> Big Data and Artificial Intelligence have a symbiotic relationship. Artificial Intelligence needs to be trained on Big Data to be accurate, and Big Data's value is largely realized through its use by Artificial Intelligence. As a result, Big Data and Artificial Intelligence practices are tightly intertwined in real life settings, as are their impacts on society. Unethical uses of Artificial Intelligence are therefore a Big Data problem, at least to some degree. Efforts to address this problem have been dominated by the documentation of Ethical Artificial Intelligence principles and the creation of technical tools that address specific aspects of those principles. However, there is mounting evidence that Ethical Artificial Intelligence principles and technical tools have little impact on the Artificial Intelligence that is created in practice, sometimes in very public ways. The goal of this commentary is to highlight four interconnected areas society can invest in to close this Ethical Artificial Intelligence publication-to-practice gap, maximizing the positive impact Artificial Intelligence and Big Data have on society. For Ethical Artificial Intelligence to become a reality, I argue that these areas need to be addressed holistically in a way that acknowledges their interdependencies. Progress will require iteration, compromise, and transdisciplinary collaboration, but the result of our investments will be the realization of Artificial Intelligence's and Big Data's tremendous potential for social good, in practice rather than in just our hopes and aspirations. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211040197",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Jana Schaich Borg"
      ],
      "url": "https://doi.org/10.1177/20539517211040197",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 28,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "14a62e54-e418-4855-85fc-0654ee183a33",
    "title": "Doing data differently? Developing personal data tactics and strategies amongst young mobile media users",
    "abstract": "<jats:p> Large amounts of personal data are generated through young people’s engagements with mobile media, with these data increasingly (re)used by advertisers, content developers and other third parties to profile, predict and position individuals. This has prompted growing concerns over the ability of mobile media users to develop informed stances towards how and why their data is being used, i.e. to build ‘conscious’ and/or ‘resistant’ forms of ‘data agency’. This paper explores ways of developing the critical consciousness and resistant practices of young mobile media users towards personal data. Drawing on research with 27 young people (aged 13–17 years), the paper describes efforts to make representations of third party use of personal data openly available as a basis from which to develop data-savvy tactics and strategies. The results of these interventions – while only partially successful – offer valuable insights into the technical, social and cultural issues that shape young people’s engagement with personal data. The paper concludes by considering how concerns over data agency might be better aligned with the realities of young people’s mobile media use. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718765021",
      "type": "journal-article",
      "published": [
        2018,
        1
      ],
      "authors": [
        "Neil Selwyn",
        "Luci Pangrazio"
      ],
      "url": "https://doi.org/10.1177/2053951718765021",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 31,
      "is_referenced_by_count": 43,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ff85d59e-2f17-4f83-81d3-917321529c90",
    "title": "Big Data, urban governance, and the ontological politics of hyperindividualism",
    "abstract": "<jats:p> Big Data’s calculative ontology relies on and reproduces a form of hyperindividualism in which the ontological unit of analysis is the discrete data point, the meaning and identity of which inheres in itself, preceding, separate, and independent from its context or relation to any other data point. The practice of Big Data governed by an ontology of hyperindividualism is also constitutive of that ontology, naturalizing and diffusing it through practices of governance and, from there, throughout myriad dimensions of everyday life. In this paper, I explicate Big Data’s ontology of hyperindividualism by contrasting it to a coconstitutive ontology that prioritizes relationality, context, and interdependence. I then situate the ontology of hyperindividualism in its genealogical context, drawing from Patrick Joyce’s history of liberalism and John Dewey’s pragmatist account of individualism, liberalism, and social action. True to its genealogical provenance, Big Data’s ontological politics of hyperindividualism reduces governance to the management of atomistic behavior, undermines the contribution of urban complexity as a resource for governance, erodes the potential for urban democracy, and eviscerates the possibility of collective resistance. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716682537",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Robert W Lake"
      ],
      "url": "https://doi.org/10.1177/2053951716682537",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 62,
      "is_referenced_by_count": 37,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "27f50efe-52d7-4200-9f9e-f3a949b82451",
    "title": "Algorithmic accountability in U.S. cities: Transparency, impact, and political economy",
    "abstract": "<jats:p> This article examines how algorithmic accountability is translated into action at the municipal level in the United States. Based on a review of task forces, ordinances, and policy toolkits from New York City and Seattle, I demonstrate the ways municipalities and local publics operationalize abstract notions of accountability. Municipal interventions often prioritize revealing computational tools (transparency) and their effects on people (impact assessments). While these two forms of accountability are crucial, they may neglect to examine institutions—and how they change—as they incorporate automated decision systems. I thus propose a political-economic approach that recognizes algorithmic systems as part of municipal institutions and focuses on their role in intensifying data collection and commodification between public agencies and markets. I argue that algorithmic accountability, especially in public agencies, needs to focus on incompetence and asymmetries of power within a network of governments, tech companies, community groups, and technologies. With a mix of transparency, impact assessments, and political economic review, the paper proposes a more comprehensive assessment of automated decision systems through their development, procurement, use, impact, and decommissioning. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221115426",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Burcu Baykurt"
      ],
      "url": "https://doi.org/10.1177/20539517221115426",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 91,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "0ed49fa6-3a3c-4d77-8a2d-8d0ca358ce70",
    "title": "When open data is a Trojan Horse: The weaponization of transparency in science and governance",
    "abstract": "<jats:p> Openness and transparency are becoming hallmarks of responsible data practice in science and governance. Concerns about data falsification, erroneous analysis, and misleading presentation of research results have recently strengthened the call for new procedures that ensure public accountability for data-driven decisions. Though we generally count ourselves in favor of increased transparency in data practice, this Commentary highlights a caveat. We suggest that legislative efforts that invoke the language of data transparency can sometimes function as “Trojan Horses” through which other political goals are pursued. Framing these maneuvers in the language of transparency can be strategic, because approaches that emphasize open access to data carry tremendous appeal, particularly in current political and technological contexts. We illustrate our argument through two examples of pro-transparency policy efforts, one historical and one current: industry-backed “sound science” initiatives in the 1990s, and contemporary legislative efforts to open environmental data to public inspection. Rules that exist mainly to impede science-based policy processes weaponize the concept of data transparency. The discussion illustrates that, much as Big Data itself requires critical assessment, the processes and principles that attend it—like transparency—also carry political valence, and, as such, warrant careful analysis. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715621568",
      "type": "journal-article",
      "published": [
        2016,
        6,
        1
      ],
      "authors": [
        "Karen EC Levy",
        "David Merritt Johns"
      ],
      "url": "https://doi.org/10.1177/2053951715621568",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 43,
      "is_referenced_by_count": 29,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "02903808-575b-4bce-9b89-229b5f66e428",
    "title": "How people connect fairness and equity when they talk about data uses",
    "abstract": "<jats:p> As a mechanism for addressing data-related harms, fairness has been subjected to considerable criticism, seen as failing to acknowledge the power relationships that produce said harms, or as a ‘floating signifier’ devoid of specific meaning. In contrast to fairness, it is argued that equity does a better job of recognising data-related harms. Criticisms such as these emerge in specific cultural contexts and rarely acknowledge everyday understandings of terms and concepts. This paper engages with these criticisms, drawing on research exploring how 112 UK residents perceive data uses in specific public service organisations. We found that participants perceive fairness and equity to be interwoven with each other, a finding which shows that who gets to define what is fair matters and which challenges assumptions about what does and does not constitute thinking and talking data politics. We conclude by proposing that linking fairness with equity can be seen as a kind of everyday data solidarity. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241303162",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Helen Kennedy",
        "Hannah Ditchfield",
        "Susan Oman",
        "Jo Bates",
        "Itzelle Medina Perea",
        "Monika Fratczak",
        "Mark Taylor"
      ],
      "url": "https://doi.org/10.1177/20539517241303162",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3b380c2a-9e6f-43df-9864-1efe40314021",
    "title": "Mapping the political landscape of Persian Twitter: The case of 2013 presidential election",
    "abstract": "<jats:p> The fallacy of premature designations such as “Iran's Twitter Revolution” can be attributed to the empirical gap in our knowledge about such sociotechnical phenomena in non-Western societies. To fill this gap, we need in-depth analyses of social media use in those contexts and to create detailed maps of online public environments in such societies. This paper aims to present such cartography of the political landscape of Persian Twitter by studying the case of Iran's 2013 presidential election. The objective of this study is twofold: first, to fill the empirical gap in our knowledge about Twitter use in Iran, and second, to develop computational methods for studying Persian Twitter (e.g., effective methods for analyzing Persian text) and identify the best methods for addressing different issues (e.g., topic detection and sentiment analysis). During Iran's 2013 presidential election, three million tweets were collected and analyzed using social network analysis and machine learning. The findings provide a more nuanced view of the political landscape of Persian Twitter and identify patterns in accordance with or in contrast to those identified in the English-speaking Twittersphere around the 2013 presidential election. Persian Twitter was dominated by micro-celebrities, whereas institutional elites dominated English discourse about Iran on Twitter. The results also illustrate that Persian Twitter in 2013 was predominantly in favor of reformists. Finally, this study demonstrates that sentiment analysis toward political name entities can be used efficiently for mapping the political landscape of conversation on Twitter. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719835232",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Emad Khazraee"
      ],
      "url": "https://doi.org/10.1177/2053951719835232",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 63,
      "is_referenced_by_count": 15,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ea6d073f-7ea0-4ea9-abc8-916396005ed2",
    "title": "Influence government: Exploring practices, ethics, and power in the use of targeted advertising by the UK state",
    "abstract": "<jats:p> We have identified an emerging tool being used by the UK government across a range of public bodies in the service of public policy - the online targeted advertising infrastructure and the practices, consultancy firms, and forms of expertise which have grown up around it. This reflects an intensification and adaptation of a broader ‘behavioural turn’ in the governmentality of the UK state and the increasing sophistication of everyday government communications. Contemporary UK public policy is fusing with the powerful tools for behaviour change created by the platform economy. Operational data and associated systems of classification and profiling from public bodies are being hybridised with traditional consumer marketing profiles and then ‘projected’ onto the classification systems of the targeted advertising infrastructures. This is not simply a case of algorithms being used for sorting, surveilling, and scoring; rather this suggests that targeted interventions in the cultural and behavioural life of communities are now a core part of governmental power which is being algorithmically-driven, in combination with influencer networks, traditional forms of messaging, and frontline operational practices. We map these uses and practices of what we describe as the ‘Surveillance Influence Infrastructure’, identifying key ethical issues and implications which we believe have yet to be fully investigated or considered. What we find particularly striking is the coming-together of two separate structures of power - the governmental turn to behaviourism and prevention on one hand, and the infrastructures of targeting and influence (and their complex tertiary markets) on the other. We theorise this as a move beyond ‘nudge’ or ‘behavioural science’ approaches, towards a programme which we term ‘influence government’. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221078756",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Ben Collier",
        "Gemma Flynn",
        "James Stewart",
        "Daniel Thomas"
      ],
      "url": "https://doi.org/10.1177/20539517221078756",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a637ea3c-e820-4b2d-b635-6efd7f641506",
    "title": "Seven intersectional feminist principles for equitable and actionable COVID-19 data",
    "abstract": "<jats:p> This essay offers seven intersectional feminist principles for equitable and actionable COVID-19 data, drawing from the authors' prior work on data feminism. Our book, Data Feminism (D'Ignazio and Klein, 2020), offers seven principles which suggest possible points of entry for challenging and changing power imbalances in data science. In this essay, we offer seven sets of examples, one inspired by each of our principles, for both identifying existing power imbalances with respect to the impact of the novel coronavirus and its response, and for beginning the work of change. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720942544",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Catherine D'Ignazio",
        "Lauren F. Klein"
      ],
      "url": "https://doi.org/10.1177/2053951720942544",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 30,
      "is_referenced_by_count": 20,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e6196de8-e4d2-46ea-8532-9c5ade99bfd6",
    "title": "The Concentration-after-Personalisation Index (CAPI): Governing effects of personalisation using the example of targeted online advertising",
    "abstract": "<jats:p> Firms are increasingly personalising their offers and services, leading to an ever finer-grained segmentation of consumers online. Targeted online advertising and online price discrimination are salient examples of this development. While personalisation's overall effects on consumer welfare are expectably ambiguous, it can lead to concentration in the distribution of advertising and commercial offers. Constellations are possible in which a market is generally open to competition, but the targeted consumer is only made aware of one possible seller. For the consumer, such a market could effectively resemble a monopoly. We call such extreme cases ‘targeting pockets’. Competition-law metrics such as the Herfindahl–Hirschman Index and traditional means of public oversight of adverts would not detect this concentration. We, therefore, suggest a novel metric, the Concentration-after-Personalisation Index (CAPI). The CAPI treats every consumer as a separate ‘market’, computes a measure of concentration for personalised adverts and offers for each individual consumer separately, and then averages the result to measure the exposure experienced by an average consumer. We demonstrate how the CAPI can serve as a monitoring tool for regulators and auditors and thus help to enforce existing consumer law as well as proposed new regulations such as the European Union's Digital Services Act and its Artificial Intelligence Act. We further show how adding noise via randomly distributed non-personalised adverts can dilute the potential harm of overly concentrated personalisation. We demonstrate how the CAPI can identify the optimal degree of added noise, balancing the protection of consumer choice with the economic interests of advertisers. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221132535",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Johann Laux",
        "Fabian Stephany",
        "Chris Russell",
        "Sandra Wachter",
        "Brent Mittelstadt"
      ],
      "url": "https://doi.org/10.1177/20539517221132535",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 67,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "3c8bea95-d94c-466b-b8d2-2efe38285e9b",
    "title": "‘A mechanistic interpretation, if possible’: How does predictive modelling causality affect the regulation of chemicals?",
    "abstract": "<jats:p> The regulation of chemicals is undergoing drastic changes with the use of computational models to predict environmental toxicity. This particular issue has not attracted much attention, despite its major impacts on the regulation of chemicals. This raises the problem of causality at the crossroads between data and regulatory sciences, particularly in the case models known as quantitative structure–activity relationship models. This paper shows that models establish correlations and not scientific facts, and it engages anew the way regulators deal with uncertainties. It does so by exploring the tension and problems raised by the possibility of causal explanation afforded by quantitative structure–activity relationship models. It argues that the specificity of predictive modelling promotes rethinking of the regulation of chemicals. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716670189",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "François Thoreau"
      ],
      "url": "https://doi.org/10.1177/2053951716670189",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 32,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b59ae316-20d7-4946-a4dc-1acbff37660d",
    "title": "Affect and value in critical examinations of the production and ‘prosumption’ of Big Data",
    "abstract": "<jats:p> In this paper I explore the relationship between the production and the value of Big Data. In particular I examine the concept of social media ‘prosumption’—which has predominantly been theorized from a Marxist, political economic perspective—to consider what other forms of value Big Data have, imbricated with their often speculative economic value. I take the example of social media firms in their early stages of operation to suggest that, since these firms do not necessarily generate revenue, data collected through user contributions do not always realize economic value, at least in a Marxist sense, and that, in addition to their speculative value, these data have value beyond an economic valence. Instead I argue that in addition to their function as systems for accumulation, social media and their associated data have an affective value, related closely to their economic value, and demonstrate the efficacy of social media as systems designed for the appropriation and circulation of user attention. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716640566",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Daniel G Cockayne"
      ],
      "url": "https://doi.org/10.1177/2053951716640566",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 83,
      "is_referenced_by_count": 17,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "01007b75-b5d8-4500-9671-3a19dff0fb06",
    "title": "Examining political mobilization of online communities through e-petitioning behavior in <i>We the People</i>",
    "abstract": "<jats:p> This study aims to reveal patterns of e-petition co-signing behavior that are indicative of the political mobilization of online “communities”. We discuss the case of We the People, a US national experiment in the use of social media technology to enable users to propose and solicit support for policy suggestions to the White House. We apply Baumgartner and Jones's work on agenda setting and punctuated equilibrium, which suggests that policy issues may lie dormant for periods of time until some event triggers attention from the media, interest groups, and elected representatives. In the case study presented, we focus on 21 petitions initiated during the week after the Sandy Hook shooting (14–21 December 2012) in opposition to gun control or in support of policy proposals that are alternatives to gun control, which we view as mobilized efforts to maintain stability and equilibrium in a policy system threatening to change. Using market basket analysis and social network analysis we found a core group of petitions in the “support law-abiding gun owners” theme that were highly connected and four “communities” of e-petitioners mobilizing in opposition to change in gun control policies and in favor of alternative proposals. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715598170",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Catherine L Dumas",
        "Daniel LaManna",
        "Teresa M Harrison",
        "SS Ravi",
        "Christopher Kotfila",
        "Norman Gervais",
        "Loni Hagen",
        "Feng Chen"
      ],
      "url": "https://doi.org/10.1177/2053951715598170",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 59,
      "is_referenced_by_count": 36,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "328d8314-35d8-4ece-856e-022c800828a1",
    "title": "Social media and microtargeting: Political data processing and the consequences for Germany",
    "abstract": "<jats:p> Amongst other methods, political campaigns employ microtargeting, a specific technique used to address the individual voter. In the US, microtargeting relies on a broad set of collected data about the individual. However, due to the unavailability of comparable data in Germany, the practice of microtargeting is far more challenging. Citizens in Germany widely treat social media platforms as a means for political debate. The digital traces they leave through their interactions provide a rich information pool, which can create the necessary conditions for political microtargeting following appropriate algorithmic processing. More specifically, data mining techniques enable information gathering about a people's general opinion, party preferences and other non-political characteristics. Through the application of data-intensive algorithms, it is possible to cluster users in respect of common attributes, and through profiling identify whom and how to influence. Applying machine learning algorithms, this paper explores the possibility to identify micro groups of users, which can potentially be targeted with special campaign messages, and how this approach can be expanded to large parts of the electorate. Lastly, based on these technical capabilities, we discuss the ethical and political implications for the German political system. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718811844",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Orestis Papakyriakopoulos",
        "Simon Hegelich",
        "Morteza Shahrezaye",
        "Juan Carlos Medina Serrano"
      ],
      "url": "https://doi.org/10.1177/2053951718811844",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 67,
      "is_referenced_by_count": 52,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7efeb89f-7694-45ae-b6a7-8917f773526a",
    "title": "The “black box” at work",
    "abstract": "<jats:p> An oversized reliance on big data-driven algorithmic decision-making systems, coupled with a lack of critical inquiry regarding such systems, combine to create the paradoxical “black box” at work. The “black box” simultaneously demands a higher level of transparency from the worker in regard to data collection, while shrouding the decision-making in secrecy, making employer decisions even more opaque to the worker. To access employment, the worker is commanded to divulge highly personal information, and when hired, must submit further still to algorithmic processes of evaluations which will make authoritative claims as to the workers’ productivity. Furthermore, in and out of the workplace, the worker is governed by an invisible data-created leash deploying wearable technology to collect intimate worker data. At all stages, the worker is confronted with a lack of transparency, accountability, or explanation as to the inner workings or even the logic of the “black box” at work. This data revolution of the workplace is alarming for several reasons: (1) the “black box at work” not only serves to conceal disparities in hiring, but could also allow for a level of “data-laundering” that beggars any notion of equal opportunity in employment and (2) there exists, the danger of a “mission creep” attitude to data collection that allows for pervasive surveillance, contributing to the erosion of both the personhood and autonomy of workers. Thus, the “black box at work” not only enables worker domination in the workplace, it deprives the worker of Rawlsian justice. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720938093",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Ifeoma Ajunwa"
      ],
      "url": "https://doi.org/10.1177/2053951720938093",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 61,
      "is_referenced_by_count": 36,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7f5d7078-0e5e-412d-9145-9204817fd1fb",
    "title": "Reimagining the Big Data assemblage",
    "abstract": "<jats:p> Recent work on Big Data and analytics reveals a tension between analyzing the role of emerging objects and processes in existing systems and using those same objects and processes to create new and purposeful forms of action. While the field of science and technology studies has had considerable success in pursuing the former goal, as Halford and Savage argue, there is an ongoing need to discover or invent ways to “do Big Data analytics differently.” In this commentary, I suggest that attempts to produce new ways of working with Big Data and analytics might be hindered by how science and technology studies-influenced scholars have conceptualized assemblages. While these scholars have foregrounded objects’ relations within existing assemblages, new materialist philosophers draw attention to properties of objects that transcend those relations and might indicate opportunities for more creative or generative uses of Big Data and analytics. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951718818194",
      "type": "journal-article",
      "published": [
        2018,
        7
      ],
      "authors": [
        "Daniel Carter"
      ],
      "url": "https://doi.org/10.1177/2053951718818194",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "5",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 26,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b15b419b-ab0f-4dc0-8e1a-09a236730efa",
    "title": "Against decolonial reductionism: The impact of Latin American thinking on the data decolonization project",
    "abstract": "<jats:p> This essay argues that Latin American scholarship and movement practice are key to understanding the dynamics of the datafied society and countering its inequities. Examining the sources of inspiration of a frontrunner seeking to decolonize the datafied society – the Big Data from the South Initiative ( BigDataSur) – we review Martín-Barbero's ontological shift from media to mediations, Freire's methodology centring individual agency and empowerment as a structural task of society, Mignolo's invite to take decoloniality as a praxis rather than merely an idea, Rodríguez's first-hand engagement with technology at the margins, Escobar's autonomous design for the pluriverse, and the critical ecology of eco-social movements. We engage with a new generation of Latin American thinkers who turn their gaze to core problems of today's systems of knowledge production, be they media or academia. Learning from these scholars, we warn against decolonial reductionism, namely the trend to evoke decolonial ideas and theories without fully committing to putting them into practice. We maintain that to decolonize datafication, we ought to also change how we generate knowledge about the datafied society. We outline three practical strategies that foster an open-ended dialogue on alternative approaches to datafication and scientific practice: multilingualism, public scholarship, and mentorship. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241270694",
      "type": "journal-article",
      "published": [
        2024,
        12
      ],
      "authors": [
        "Stefania Milan",
        "Emiliano Treré"
      ],
      "url": "https://doi.org/10.1177/20539517241270694",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "4",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 39,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "8ba34c18-2f1e-40b7-818f-faef7a4a4ad0",
    "title": "Close encounters of the conceptual kind: Disambiguating social structure from text",
    "abstract": "<jats:p> Despite its empirical prominence, there is very little extant organizational research on Big Data. However, there is reason to believe this is changing as organizational theory scholars are beginning to embrace new methods and data sources. In this essay, I present a view that suggests there are several latent opportunities, many of which have been simmering unattended for some time. This research approach is not without its challenges, as the ontological terrain of Big Data is untested and potentially disruptive. However, we are observing a renewal of approaches to text and content analysis. By opening up the toolkit of computational linguistics methods for text analysis, Big Data may bring about fresh synthesis and reshape classic debates around social structure. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715608655",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Timothy Hannigan"
      ],
      "url": "https://doi.org/10.1177/2053951715608655",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 39,
      "is_referenced_by_count": 10,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7e43bf7d-de6c-4d3f-aeb2-014bdc22e6ce",
    "title": "Social learning and the complex contagion of political symbols in Twitter: The case  of the yellow ribbon in Catalonia",
    "abstract": "<jats:p> In this paper, we empirically test whether the spread of political symbols in Twitter is due to complex contagion. We analyzed behavior consisting of editing the Twitter account name to include an icon with a yellow ribbon; a symbol that represents the demand for the release of imprisoned Catalan politicians and civil leaders. To test this hypothesis, we used a behavioral, non-reactive, relational, and dynamic dataset of a large sample of potential users. First, we show that the probability of displaying a ribbon is associated with the proportion of peers who also display it (friends that share their support for the political cause). Second, we rule out alternative explanations as simple contagion and homophily. To rule out simple contagion, we run three empirically calibrated, agent-based simulations. We use our dataset to rule out homophily. And third, we suggest that adoption cannot be interpreted as the result of a compliance mechanism or as the result of normative pressures. Instead, the most plausible micro-level generative mechanism that leads to a complex contagion pattern is a peer learning process. Our study makes several contributions to the field. We show how digital data can be effectively used to identify new explananda and test the plausibility of competing behavioral explanatory mechanisms. We also contribute to the development of the theory of complex contagions. Our study widens the set of conditions for complex contagion and the set of reasons to explain why complex contagion might occur. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231180569",
      "type": "journal-article",
      "published": [
        2023,
        7
      ],
      "authors": [
        "Francisco J León-Medina"
      ],
      "url": "https://doi.org/10.1177/20539517231180569",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 41,
      "is_referenced_by_count": 0,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d6d59904-5642-4b72-8070-0cce0a87ba6c",
    "title": "Doing nothing does something: Embodiment and data in the COVID-19 pandemic",
    "abstract": "<jats:p>The COVID-19 pandemic redefines how we think about the body, physiologically and socially. But what does it mean to have and to be a body in the COVID-19 pandemic? The COVID-19 pandemic offers data scholars the unique opportunity, and perhaps obligation, to revisit and reinvent the fundamental concepts of our mediated experiences. The article critiques the data double, a longstanding concept in critical data and media studies, as incompatible with the current public health and social distancing imperative. The data double, instead, is now the presupposition of a new data entity, which will emerge out of a current data shimmer: a long-sustaining transition that blurs the older boundaries of bodies and the social, and establishes new ethical boundaries around the (in)activity and (im)mobility of doing nothing to do something. The data double faces a unique dynamic in the COVID-19 pandemic between boredom and exhaustion. Following the currently simple rule to stay home presents data scholars the opportunity to revisit the meaning of data as something given, a shimmering embodied relationship with data that contributes to the common good in a global health crisis.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720933930",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Mickey Vallee"
      ],
      "url": "https://doi.org/10.1177/2053951720933930",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172093393",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 11,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9da85824-8fed-4f3a-b45f-23667017f8d7",
    "title": "Controversies, contradiction, and “participation” in AI",
    "abstract": "<jats:p> This commentary examines the inherent contradictions between participation in artificial intelligence (AI), controversy studies, and AI narratives. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241235862",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Mona Sloane"
      ],
      "url": "https://doi.org/10.1177/20539517241235862",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 48,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4070ad82-fed0-4722-ac46-eaab8757e3c1",
    "title": "Computational challenges to test and revitalize Claude Lévi-Strauss transformational methodology",
    "abstract": "<jats:p> The ambition and proposal for data modeling of myths presented in this paper is to link contemporary technical affordances to some canonical projects developed in structural anthropology. To articulate the theoretical promise and innovation of this proposal, we present a discrete-event system specification modeling and simulation approach in order to perform a generative analysis and a dynamic visualization of selected narratives, aimed at validating and revitalizing the transformational and morphodynamic theory and methodology proposed by Claude Lévi-Strauss in his structural analysis of myth. After an analysis of Lévi-Strauss’s transformational methodology, we describe in detail how discrete-event system specification models are implemented and developed in the framework of a DEVSimPy software environment. The validation of the method involves a discrete-event system specification simulation based on the extension of discrete-event system specification models dedicated to provide a dynamic Google Earth visualization of the selected myth. Future work around the discrete-event system specification formalism in anthropology is described as well as future applications regarding the impact of computational models (discrete-event system specification formalism, Bayesian inferences, and object-oriented features) to new contemporary anthropological domains. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211037862",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Albert Doja",
        "Laurent Capocchi",
        "Jean-François Santucci"
      ],
      "url": "https://doi.org/10.1177/20539517211037862",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 87,
      "is_referenced_by_count": 2,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2bc80868-9388-4e06-9013-533af869eb32",
    "title": "Social impacts of algorithmic decision-making: A research agenda for the social sciences",
    "abstract": "<jats:p> Academic and public debates are increasingly concerned with the question whether and how algorithmic decision-making (ADM) may reinforce social inequality. Most previous research on this topic originates from computer science. The social sciences, however, have huge potentials to contribute to research on social consequences of ADM. Based on a process model of ADM systems, we demonstrate how social sciences may advance the literature on the impacts of ADM on social inequality by uncovering and mitigating biases in training data, by understanding data processing and analysis, as well as by studying social contexts of algorithms in practice. Furthermore, we show that fairness notions need to be evaluated with respect to specific outcomes of ADM systems and with respect to concrete social contexts. Social sciences may evaluate how individuals handle algorithmic decisions in practice and how single decisions aggregate to macro social outcomes. In this overview, we highlight how social sciences can apply their knowledge on social stratification and on substantive domains of ADM applications to advance the understanding of social impacts of ADM. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221089305",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Frederic Gerdon",
        "Ruben L Bach",
        "Christoph Kern",
        "Frauke Kreuter"
      ],
      "url": "https://doi.org/10.1177/20539517221089305",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 113,
      "is_referenced_by_count": 21,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f10be006-904e-47cd-bcff-8e2389c5f94e",
    "title": "Crowd-Sourced Intelligence Agency: Prototyping counterveillance",
    "abstract": "<jats:p> This paper discusses how an interactive artwork, the Crowd-Sourced Intelligence Agency (CSIA), can contribute to discussions of Big Data intelligence analytics. The CSIA is a publicly accessible Open Source Intelligence (OSINT) system that was constructed using information gathered from technical manuals, research reports, academic papers, leaked documents, and Freedom of Information Act files. Using a visceral heuristic, the CSIA demonstrates how the statistical correlations made by automated classification systems are different from human judgment and can produce false-positives, as well as how the display of information through an interface can affect the judgment of an intelligence agent. The public has the right to ask questions about how a computer program determines if they are a threat to national security and to question the practicality of using statistical pattern recognition algorithms in place of human judgment. Currently, the public’s lack of access to both Big Data and the actual datasets intelligence agencies use to train their classification algorithms keeps the possibility of performing effective sous-dataveillance out of reach. Without this data, the results returned by the CSIA will not be identical to those of intelligence agencies. Because we have replicated how OSINT is processed, however, our results will resemble the type of results and mistakes made by OSINT systems. The CSIA takes some initial steps toward contributing to an informed public debate about large-scale monitoring of open source, social media data and provides a prototype for counterveillance and sousveillance tools for citizens. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951717693259",
      "type": "journal-article",
      "published": [
        2017,
        6
      ],
      "authors": [
        "Jennifer Gradecki",
        "Derek Curry"
      ],
      "url": "https://doi.org/10.1177/2053951717693259",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 13,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5cfbad21-2ee4-4c18-8ce0-59e77a4074f8",
    "title": "When the future meets the past:  Can safety and cyber security coexist in modern critical infrastructures?",
    "abstract": "<jats:p> Big data technologies are entering the world of ageing computer systems running critical infrastructures. These innovations promise to afford rapid Internet connectivity, remote operations or predictive maintenance. As legacy critical infrastructures were traditionally disconnected from the Internet, the prospect of their modernisation necessitates an inquiry into cyber security and how it intersects with traditional engineering requirements like safety, reliability or resilience. Looking at how the adoption of big data technologies in critical infrastructures shapes understandings of risk management, we focus on a specific case study from the cyber security governance: the EU Network and Information Systems Security Directive. We argue that the implementation of Network and Information Systems Security Directive is the first step in the integration of safety and security through novel risk management practices. Therefore, it is the move towards legitimising the modernisation of critical infrastructures. But we also show that security risk management practices cannot be directly transplanted from the safety realm, as cyber security is grounded in anticipation of the future adversarial behaviours rather than the history of equipment failure rates. Our analysis offers several postulates for the emerging research agenda on big data in complex engineering systems. Building on the conceptualisations of safety and security grounded in the materialist literature across Science and Technology Studies and Organisational Sociology, we call for a better understanding of the ‘making of’ technologies, standardisation processes and engineering knowledge in a quest to build safe and secure critical infrastructures. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221108369",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Ola Michalec",
        "Sveta Milyaeva",
        "Awais Rashid"
      ],
      "url": "https://doi.org/10.1177/20539517221108369",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 73,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "38b8f940-91a8-456b-8f4a-effa993c35f6",
    "title": "A typology of artificial intelligence data work",
    "abstract": "<jats:p> This article provides a new typology for understanding human labour integrated into the production of artificial intelligence systems through data preparation and model evaluation. We call these forms of labour ‘AI data work’ and show how they are an important and necessary element of the artificial intelligence production process. We draw on fieldwork with an artificial intelligence data business process outsourcing centre specialising in computer vision data, alongside a decade of fieldwork with microwork platforms, business process outsourcing, and artificial intelligence companies to help dispel confusion around the multiple concepts and frames that encompass artificial intelligence data work including ‘ghost work’, ‘microwork’, ‘crowdwork’ and ‘cloudwork’. We argue that these different frames of reference obscure important differences between how this labour is organised in different contexts. The article provides a conceptual division between the different types of artificial intelligence data work institutions and the different stages of what we call the artificial intelligence data pipeline. This article thus contributes to our understanding of how the practices of workers become a valuable commodity integrated into global artificial intelligence production networks. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241232632",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "James Muldoon",
        "Callum Cant",
        "Boxi Wu",
        "Mark Graham"
      ],
      "url": "https://doi.org/10.1177/20539517241232632",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 59,
      "is_referenced_by_count": 12,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "49357b27-f44e-490c-8bd9-fa632a21e071",
    "title": "Manipulative tactics are the norm in political emails: Evidence from 300K emails from the 2020 US election cycle",
    "abstract": "<jats:p> We collect and analyze a corpus of more than 300,000 political emails sent during the 2020 US election cycle. These emails were sent by over 3000 political campaigns and organizations including federal and state level candidates as well as Political Action Committees. We find that in this corpus, manipulative tactics—techniques using some level of deception or clickbait—are the norm, not the exception. We measure six specific tactics senders use to nudge recipients to open emails. Three of these tactics—“dark patterns”—actively deceive recipients through the email user interface, for example, by formatting “from:” fields so that they create the false impression the message is a continuation of an ongoing conversation. The median active sender uses such tactics 5% of the time. The other three tactics, like sensationalistic clickbait—used by the median active sender 37% of the time—are not directly deceptive, but instead, exploit recipients’ curiosity gap and impose pressure to open emails. This can further expose recipients to deception in the email body, such as misleading claims of matching donations. Furthermore, by collecting emails from different locations in the US, we show that senders refine these tactics through A/B testing. Finally, we document disclosures of email addresses between senders in violation of privacy policies and recipients’ expectations. Cumulatively, these tactics undermine voters’ autonomy and welfare, exacting a particularly acute cost for those with low digital literacy. We offer the complete corpus of emails at https://electionemails2020.org for journalists and academics, which we hope will support future work. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221145371",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Arunesh Mathur",
        "Angelina Wang",
        "Carsten Schwemmer",
        "Maia Hamin",
        "Brandon M Stewart",
        "Arvind Narayanan"
      ],
      "url": "https://doi.org/10.1177/20539517221145371",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 61,
      "is_referenced_by_count": 15,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "5f9e9ac8-2ff0-4a2a-9120-bb33c4f4e2f9",
    "title": "Alternative data and sentiment analysis: Prospecting non-standard data in machine learning-driven finance",
    "abstract": "<jats:p> Social media commentary, satellite imagery and GPS data are a part of ‘alternative data’, that is, data that originate outside of the standard repertoire of market data but are considered useful for predicting stock prices, detecting different risk exposures and discovering new price movement indicators. With the availability of sophisticated machine-learning analytics tools, alternative data are gaining traction within the investment management and algorithmic trading industries. Drawing on interviews with people working in investment management and algorithmic trading firms utilizing alternative data, as well as firms providing and sourcing such data, we emphasize social media-based sentiment analytics as one manifestation of how alternative data are deployed for stock price prediction purposes. This demonstrates both how sentiment analytics are developed and subsequently utilized by investment management firms. We argue that ‘alternative data’ are an open-ended placeholder for every data source potentially relevant for investment management purposes and harnessing these disparate data sources requires certain standardization efforts by different market participants. Besides showing how market participants understand and use alternative data, we demonstrate that alternative data often undergo processes of (a) prospecting (i.e. rendering such data amenable to processing with the aid of analytics tools) and (b) assetization (i.e. the transformation of data into tradable assets). We further contend that the widespread embracement of alternative data in investment management and trading encourages a financialization process at the data level which raises new governance issues. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211070701",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Kristian Bondo Hansen",
        "Christian Borch"
      ],
      "url": "https://doi.org/10.1177/20539517211070701",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 67,
      "is_referenced_by_count": 34,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "9af44ac4-5382-4e3f-b81a-d76551a0b17a",
    "title": "Toward a sociology of machine learning explainability: Human–machine interaction in deep neural  network-based automated trading",
    "abstract": "<jats:p> Machine learning systems are making considerable inroads in society owing to their ability to recognize and predict patterns. However, the decision-making logic of some widely used machine learning models, such as deep neural networks, is characterized by opacity, thereby rendering them exceedingly difficult for humans to understand and explain and, as a result, potentially risky to use. Considering the importance of addressing this opacity, this paper calls for research that studies empirically and theoretically how machine learning experts and users seek to attain machine learning explainability. Focusing on automated trading, we take steps in this direction by analyzing a trading firm’s quest for explaining its deep neural network system’s actionable predictions. We demonstrate that this explainability effort involves a particular form of human–machine interaction that contains both anthropomorphic and technomorphic elements. We discuss this attempt to attain machine learning explainability in light of reflections on cross-species companionship and consider it an example of human–machine companionship. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221111361",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Christian Borch",
        "Bo Hee Min"
      ],
      "url": "https://doi.org/10.1177/20539517221111361",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 53,
      "is_referenced_by_count": 24,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "81e147ee-1330-4e19-b59e-4d745dd9438a",
    "title": "Ontologies, methodologies, and new uses of Big Data in the social and cultural sciences",
    "abstract": "<jats:p> In our Introduction to the Conceiving the Social with Big Data Special Issue of Big Data &amp; Society, we survey the 18 contributions from scholars in the humanities and social sciences, and highlight several questions and themes that emerge within and across them. These emergent issues reflect the challenges, problems, and promises of working with Big Data to access and assess the social. They include puzzles about the locus and nature of human life, the nature of interpretation, the categorical constructions of individual entities and agents, the nature and relevance of contexts and temporalities, and the determinations of causality. As such, the Introduction reflects on the contributions along a series of binaries that capture the dualities and dynamisms of these themes: Life/Data; Mind/Machine; and Induction/Deduction. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715613810",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Robin Wagner-Pacifici",
        "John W Mohr",
        "Ronald L Breiger"
      ],
      "url": "https://doi.org/10.1177/2053951715613810",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 35,
      "is_referenced_by_count": 39,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "cb8f4a5b-9f0e-4aa0-902a-3eba28299008",
    "title": "The ontology explorer: A method to make visible data infrastructures for population management",
    "abstract": "<jats:p> This article introduces the methodology of the ‘Ontology Explorer’, a semantic method and JavaScript-based open-source tool to analyse data models underpinning information systems. The Ontology Explorer has been devised and developed by the authors, who recognized a need to compare data models collected in different formats and used by diverse systems. The Ontology Explorer is distinctive firstly because it supports analyses of information systems that are not immediately comparable and, secondly, because it systematically and quantitatively supports discursive analysis of ‘thin’ data models – also by detecting differences and absences through comparison. When applied to data models underpinning systems for population management, the Ontology Explorer enables the apprehension of how people are ‘inscribed’ in information systems: which assumptions are made about them, and which possibilities are excluded by design. The Ontology Explorer thus constitutes a methodology to capture authorities’ own imaginaries of populations and the ‘scripts’ through which they enact actual people. Furthermore, the method allows the comparison of scripts from diverse authorities. This is exemplified by illustrating its functioning with information systems for population management deployed at the European border. Our approach integrates a number of insights from early infrastructure studies and extends their methods and analytical depth to account for contemporary data infrastructures. By doing so, we hope to trigger a systematic discussion on how to extend those early methodical innovations at the semantic level to contemporary developments in digital methods. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221104087",
      "type": "journal-article",
      "published": [
        2022,
        1
      ],
      "authors": [
        "Wouter Van Rossem",
        "Annalisa Pelizza"
      ],
      "url": "https://doi.org/10.1177/20539517221104087",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 55,
      "is_referenced_by_count": 7,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "c4ee423a-4945-4c2a-8f24-d70055fff80c",
    "title": "The combine will tell the truth: On precision agriculture and algorithmic rationality",
    "abstract": "<jats:p> Recent technological and methodological changes in farming have led to an emerging set of claims about the role of digital technology in food production. Known as precision agriculture, the integration of digital management and surveillance technologies in farming is normatively presented as a revolutionary transformation. Proponents contend that machine learning, Big Data, and automation will create more accurate, efficient, transparent, and environmentally friendly food production, staving off both food insecurity and ecological ruin. This article contributes a critique of these rhetorical and discursive claims to a growing body of critical literature on precision agriculture. It argues precision agriculture is less a revolution than an evolution, an effort to shore up and intensify the conventional farming system responsible for generating many of the social and environmental problems precision agriculture is presented as solving. While precision agriculture advocates portray it as a radical, even democratic epistemological break with the past, this paper locates truth claims surrounding datafication and algorithmic control in farming within deeper historical contexts of the capitalist rationalization of production and efforts to quantify and automate physical and mental labor. Abjuring the growing cultural tendency to treat algorithmic systems as revolutionary in favor of social and historical dimensions of precision agriculture, can help re-frame the discussion about its design and use around real, socially and ecologically oriented change in farming, and so ensure that the possibilities and benefits of precision agriculture are as evenly and effectively shared as possible. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719849444",
      "type": "journal-article",
      "published": [
        2019,
        1
      ],
      "authors": [
        "Christopher Miles"
      ],
      "url": "https://doi.org/10.1177/2053951719849444",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "6",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 76,
      "is_referenced_by_count": 117,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "d1a4283a-af18-4533-937b-7e90095f18fa",
    "title": "A Maussian bargain: Accumulation by gift in the digital economy",
    "abstract": "<jats:p>The harvesting of data about people, organizations, and things and their transformation into a form of capital is often described as a process of “accumulation by dispossession,” a pervasive loss of rights buttressed by predatory practices and legal violence. Yet this argument does not square well with the fact that enrollment into digital systems is often experienced (and presented by companies) as a much more benign process: signing up for a “free” service, responding to a “friend’s” invitation, or being encouraged to “share” content. In this paper, we focus on the centrality of gifting and reciprocity to the business model and cultural imagination of digital capitalism. Relying on historical narratives and in-depth interviews with the designers and critics of digital systems, we explain the cultural genesis of these “give-to-get” relationships and analyze the socio-technical channels that structure them in practice. We suggest that the economic relation that develops as a result of a digital gift offering not only masks the structural asymmetry between giver and gifted but also permits the creation of the new commodity of personal data, obfuscates its true value, and naturalizes its private appropriation. We call this unique regime “accumulation by gift.”</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951719897092",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Marion Fourcade",
        "Daniel N Kluttz"
      ],
      "url": "https://doi.org/10.1177/2053951719897092",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395171989709",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 79,
      "is_referenced_by_count": 63,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "239bf846-39db-4c15-a506-06affa1bbd8e",
    "title": "A dialogic analysis of Hello Barbie’s conversations with children",
    "abstract": "<jats:p>This paper analyses Hello Barbie as a commercial artefact to explore how big data practices are reshaping the enterprise of marketing. The doll uses voice recognition software to ‘listen’ to the child and ‘talk back’ by algorithmically selecting a response from 8000 predetermined lines of dialogue. As such, it is a useful example of how marketers use customer relationship management systems that rely on sophisticated data collection and analysis techniques to create a relationship between companies and customers in which both parties are positioned as active participants who are able to obtain what they wish from the interaction. I use dialogic analysis to see how Mattel ‘makes sense’ of the dialogue as a dialogic partner. I argue that, in spite of the rhetoric of instantaneity and personalization, in which the technology is positioned as an immediate response to a child’s imagination, Mattel’s dialogic communication is both asynchronous and carefully crafted to fit the child’s responses within predetermined consumer subjectivities that are crafted to encourage particular kinds of consumption. Although the dialogue spoken by Hello Barbie is able to situate Barbie as an active subject, the control exercised by the company in order to elicit data for customer relationship management purposes and steer the dialogue to brand-friendly messages relegates the child to a passive role. Accordingly, the doll fails to deliver the promises of customer relationship management.</jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720919151",
      "type": "journal-article",
      "published": [
        2020,
        1
      ],
      "authors": [
        "Valerie Steeves"
      ],
      "url": "https://doi.org/10.1177/2053951720919151",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "1",
      "page": "205395172091915",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 34,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "90b17a56-64b0-4081-9854-b09a75dc22cb",
    "title": "Contested technology: Social scientific perspectives of  behaviour-based insurance",
    "abstract": "<jats:p> In this review, I analyse how ‘behaviour-based personalisation’ in insurance – that is, insurers’ increased interest in tracking and manipulating insureds’ behaviour with, for instance, wearable devices – has been approached in recent social scientific literature. In the review, I focus on two streams of literature, critical data studies and the sociology of insurance, discussing the new (i.e. health and life) insurance schemes that utilise sensor-generated and digital data. The aim of this review is to compare these two approaches and to analyse what kinds of understandings, methodologies and theoretical perspectives they apply to so-called ‘behaviour-based insurance’. The critical data studies literature emphasises the exploitative aspects of these new technologies and mobilises behaviour-based insurance to exemplify the negative outcomes of digital health. Scholars from the field of the sociology of insurance empirically analyse the practices of behavioural-based personalisation and study how regulating and ‘doing’ insurance affect attempts to personalise it. I highlight the importance of approaching insurance as a specific financial technology and argue that more research is needed to understand the practices of developing behaviour-based insurance schemes and the insureds’ experiences. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720942536",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Maiju Tanninen"
      ],
      "url": "https://doi.org/10.1177/2053951720942536",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 114,
      "is_referenced_by_count": 22,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "894b290b-655d-42c7-a1fc-91b17e06a046",
    "title": "Emerging models of data governance in the age of datafication",
    "abstract": "<jats:p> The article examines four models of data governance emerging in the current platform society. While major attention is currently given to the dominant model of corporate platforms collecting and economically exploiting massive amounts of personal data, other actors, such as small businesses, public bodies and civic society, take also part in data governance. The article sheds light on four models emerging from the practices of these actors: data sharing pools, data cooperatives, public data trusts and personal data sovereignty. We propose a social science-informed conceptualisation of data governance. Drawing from the notion of data infrastructure we identify the models as a function of the stakeholders’ roles, their interrelationships, articulations of value, and governance principles. Addressing the politics of data, we considered the actors’ competitive struggles for governing data. This conceptualisation brings to the forefront the power relations and multifaceted economic and social interactions within data governance models emerging in an environment mainly dominated by corporate actors. These models highlight that civic society and public bodies are key actors for democratising data governance and redistributing value produced through data. Through the discussion of the models, their underpinning principles and limitations, the article wishes to inform future investigations of socio-technical imaginaries for the governance of data, particularly now that the policy debate around data governance is very active in Europe. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720948087",
      "type": "journal-article",
      "published": [
        2020,
        7
      ],
      "authors": [
        "Marina Micheli",
        "Marisa Ponti",
        "Max Craglia",
        "Anna Berti Suman"
      ],
      "url": "https://doi.org/10.1177/2053951720948087",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "7",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 78,
      "is_referenced_by_count": 140,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fd489796-825b-40c6-9ffd-027de312a6cb",
    "title": "The COVID-19 Infodemic: Twitter versus Facebook",
    "abstract": "<jats:p> The global spread of the novel coronavirus is affected by the spread of related misinformation—the so-called COVID-19 Infodemic—that makes populations more vulnerable to the disease through resistance to mitigation efforts. Here, we analyze the prevalence and diffusion of links to low-credibility content about the pandemic across two major social media platforms, Twitter and Facebook. We characterize cross-platform similarities and differences in popular sources, diffusion patterns, influencers, coordination, and automation. Comparing the two platforms, we find divergence among the prevalence of popular low-credibility sources and suspicious videos. A minority of accounts and pages exert a strong influence on each platform. These misinformation “superspreaders” are often associated with the low-credibility sources and tend to be verified by the platforms. On both platforms, there is evidence of coordinated sharing of Infodemic content. The overt nature of this manipulation points to the need for societal-level solutions in addition to mitigation strategies within the platforms. However, we highlight limits imposed by inconsistent data-access policies on our capability to study harmful manipulations of information ecosystems. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211013861",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Kai-Cheng Yang",
        "Francesco Pierri",
        "Pik-Mai Hui",
        "David Axelrod",
        "Christopher Torres-Lugo",
        "John Bryden",
        "Filippo Menczer"
      ],
      "url": "https://doi.org/10.1177/20539517211013861",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 67,
      "is_referenced_by_count": 126,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ab223a0a-41f6-4892-8730-0843363f5382",
    "title": "Encrypting human rights: The intertwining of resistant voices in the UK state surveillance debate",
    "abstract": "<jats:p> The Snowden revelations in 2013 redrew the lines of debate surrounding surveillance, exposing the extent of state surveillance across multiple nations and triggering legislative reform in many. In the UK, this was in the form of the Investigatory Powers Act (2016). As a contribution to understanding resistance to expanding state surveillance activities, this article reveals the intertwining of diverse interests and voices which speak in opposition to UK state surveillance. Through a computational topic modelling-based mixed methods analysis of the submissions made to the draft Investigatory Powers Bill consultation, the article demonstrates the diversity and intersection of discourses within different actor groups, including civil society and the technology industry. We demonstrate that encryption is a key issue for these groups, and is additionally conflated with a human rights discourse. This serves to unite seemingly disparate interests by imbuing encryption with a responsibility for the protection of human rights, but also threatens to legitimate corporate interests and distract from their own data-driven activities of surveillance capitalism. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951720985304",
      "type": "journal-article",
      "published": [
        2021,
        1
      ],
      "authors": [
        "Amy Stevens",
        "James Allen-Robertson"
      ],
      "url": "https://doi.org/10.1177/2053951720985304",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 56,
      "is_referenced_by_count": 3,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e53496f2-8b49-4374-8ce8-8fa7e3547804",
    "title": "“The revolution will not be supervised”: Consent and open secrets in data science",
    "abstract": "<jats:p> The social impacts of computer technology are often glorified in public discourse, but there is growing concern about its actual effects on society. In this article, we ask: how does “consent” as an analytical framework make visible the social dynamics and power relations in the capture, extraction, and labor of data science knowledge production? We hypothesize that a form of boundary violation in data science workplaces—gender harassment—may correlate with the ways humans’ lived experiences are extracted to produce Big Data. The concept of consent offers a useful way to draw comparisons between gender relations in data science and the means by which machines are trained to learn and reason. Inspired by how Big Tech leaders describe unsupervised machine learning, and the co-optation of “revolutionary” rhetoric they use to do so, we introduce a concept we call “techniques of invisibility.” Techniques of invisibility are the ways in which an extreme imbalance between exposure and opacity, demarcated along fault lines of power, are fabricated and maintained, closing down the possibility for bidirectional transparency in the production and applications of algorithms. Further, techniques of invisibility, which we group into two categories—epistemic injustice and the Brotherhood—include acts of subjection by powerful actors in data science designed to quell resistance to exploitative relations. These techniques may be useful in making further connections between epistemic violence, sexism, and surveillance, sussing out persistent boundary violations in data science to render the social in data science visible, and open to scrutiny and debate. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211035673",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Coleen Carrigan",
        "Madison W Green",
        "Abibat Rahman-Davies"
      ],
      "url": "https://doi.org/10.1177/20539517211035673",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 103,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "7e12bd10-be25-4328-987b-6bb955f7bfe1",
    "title": "On the genealogy of machine learning datasets: A critical history of ImageNet",
    "abstract": "<jats:p> In response to growing concerns of bias, discrimination, and unfairness perpetuated by algorithmic systems, the datasets used to train and evaluate machine learning models have come under increased scrutiny. Many of these examinations have focused on the contents of machine learning datasets, finding glaring underrepresentation of minoritized groups. In contrast, relatively little work has been done to examine the norms, values, and assumptions embedded in these datasets. In this work, we conceptualize machine learning datasets as a type of informational infrastructure, and motivate a genealogy as method in examining the histories and modes of constitution at play in their creation. We present a critical history of ImageNet as an exemplar, utilizing critical discourse analysis of major texts around ImageNet’s creation and impact. We find that assumptions around ImageNet and other large computer vision datasets more generally rely on three themes: the aggregation and accumulation of more data, the computational construction of meaning, and making certain types of data labor invisible. By tracing the discourses that surround this influential benchmark, we contribute to the ongoing development of the standards and norms around data development in machine learning and artificial intelligence research. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517211035955",
      "type": "journal-article",
      "published": [
        2021,
        7
      ],
      "authors": [
        "Emily Denton",
        "Alex Hanna",
        "Razvan Amironesei",
        "Andrew Smart",
        "Hilary Nicole"
      ],
      "url": "https://doi.org/10.1177/20539517211035955",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "8",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 75,
      "is_referenced_by_count": 122,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "86908894-07ee-40b9-aa6d-6ec19fea78bf",
    "title": "Toward human-centered algorithm design",
    "abstract": "As algorithms pervade numerous facets of daily life, they are incorporated into systems for increasingly diverse purposes. These systems’ results are often interpreted differently by the designers who created them than by the lay persons who interact with them. This paper offers a proposal for human-centered algorithm design, which incorporates human and social interpretations into the design process for algorithmically based systems. It articulates three specific strategies for doing so: theoretical, participatory, and speculative. Drawing on the author’s work designing and deploying multiple related systems, the paper provides a detailed example of using a theoretical approach. It also discusses findings pertinent to participatory and speculative design approaches. The paper addresses both strengths and challenges for each strategy in helping to center the process of designing algorithmically based systems around humans.",
    "metadata": {
      "doi": "10.1177/2053951717718854",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Eric PS Baumer"
      ],
      "url": "https://doi.org/10.1177/2053951717718854",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171771885",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 46,
      "is_referenced_by_count": 62,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "f09127ef-4811-4df5-a093-0c418e83a7bf",
    "title": "Data politics",
    "abstract": "The commentary raises political questions about the ways in which data has been constituted as an object vested with certain powers, influence, and rationalities. We place the emergence and transformation of professional practices such as ‘data science’, ‘data journalism’, ‘data brokerage’, ‘data mining’, ‘data storage’, and ‘data analysis’ as part of the reconfiguration of a series of fields of power and knowledge in the public and private accumulation of data. Data politics asks questions about the ways in which data has become such an object of power and explores how to critically intervene in its deployment as an object of knowledge. It is concerned with the conditions of possibility of data that involve things (infrastructures of servers, devices, and cables), language (code, programming, and algorithms), and people (scientists, entrepreneurs, engineers, information technologists, designers) that together create new worlds. We define ‘data politics’ as both the articulation of political questions about these worlds and the ways in which they provoke subjects to govern themselves and others by making rights claims. We contend that without understanding these conditions of possibility – of worlds, subjects and rights – it would be difficult to intervene in or shape data politics if by that it is meant the transformation of data subjects into data citizens.",
    "metadata": {
      "doi": "10.1177/2053951717717749",
      "type": "journal-article",
      "published": [
        2017,
        12
      ],
      "authors": [
        "Evelyn Ruppert",
        "Engin Isin",
        "Didier Bigo"
      ],
      "url": "https://doi.org/10.1177/2053951717717749",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "4",
      "issue": "2",
      "page": "205395171771774",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 22,
      "is_referenced_by_count": 141,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "e13cc612-7f98-4638-a88a-3c831754bfae",
    "title": "Algorithms and their others: Algorithmic culture in context",
    "abstract": "<jats:p> Algorithms, once obscure objects of technical art, have lately been subject to considerable popular and scholarly scrutiny. What does it mean to adopt the algorithm as an object of analytic attention? What is in view, and out of view, when we focus on the algorithm? Using Niklaus Wirth's 1975 formulation that “algorithms + data structures = programs” as a launching-off point, this paper examines how an algorithmic lens shapes the way in which we might inquire into contemporary digital culture. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716665128",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Paul Dourish"
      ],
      "url": "https://doi.org/10.1177/2053951716665128",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 49,
      "is_referenced_by_count": 252,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ae7735af-15de-44c9-bfc9-fa7904e82824",
    "title": "Towards data justice? The ambiguity of anti-surveillance resistance in political activism",
    "abstract": "<jats:p> The Snowden leaks, first published in June 2013, provided unprecedented insights into the operations of state-corporate surveillance, highlighting the extent to which everyday communication is integrated into an extensive regime of control that relies on the ‘datafication’ of social life. Whilst such data-driven forms of governance have significant implications for citizenship and society, resistance to surveillance in the wake of the Snowden leaks has predominantly centred on techno-legal responses relating to the development and use of encryption and policy advocacy around privacy and data protection. Based on in-depth interviews with a range of social justice activists, we argue that there is a significant level of ambiguity around this kind of anti-surveillance resistance in relation to broader activist practices, and critical responses to the Snowden leaks have been confined within particular expert communities. Introducing the notion of ‘data justice’, we therefore go on to make the case that resistance to surveillance needs to be (re)conceptualized on terms that can address the implications of this data-driven form of governance in relation to broader social justice agendas. Such an approach is needed, we suggest, in light of a shift to surveillance capitalism in which the collection, use and analysis of our data increasingly comes to shape the opportunities and possibilities available to us and the kind of society we live in. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716679678",
      "type": "journal-article",
      "published": [
        2016,
        12
      ],
      "authors": [
        "Lina Dencik",
        "Arne Hintz",
        "Jonathan Cable"
      ],
      "url": "https://doi.org/10.1177/2053951716679678",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 44,
      "is_referenced_by_count": 156,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "a5e45e19-79f0-44bb-b6d1-4d5fdb15a099",
    "title": "Search algorithms, hidden labour and information control",
    "abstract": "<jats:p> The paper examines some of the processes of the closely knit relationship between Google’s ideologies of neutrality and objectivity and global market dominance. Neutrality construction comprises an important element sustaining the company’s economic position and is reflected in constant updates, estimates and changes to utility and relevance of search results. Providing a purely technical solution to these issues proves to be increasingly difficult without a human hand in steering algorithmic solutions. Search relevance fluctuates and shifts through continuous tinkering and tweaking of the search algorithm. The company also uses third parties to hire human raters for performing quality assessments of algorithmic updates and adaptations in linguistically and culturally diverse global markets. The adaptation process contradicts the technical foundations of the company and calculations based on the initial Page Rank algorithm. Annual market reports, Google’s Search Quality Rating Guidelines, and reports from media specialising in search engine optimisation business are analysed. The Search Quality Rating Guidelines document provides a rare glimpse into the internal architecture of search algorithms and the notions of utility and relevance which are presented and structured as neutral and objective. Intertwined layers of ideology, hidden labour of human raters, advertising revenues, market dominance and control are discussed throughout the paper. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951716652159",
      "type": "journal-article",
      "published": [
        2016,
        6
      ],
      "authors": [
        "Paško Bilić"
      ],
      "url": "https://doi.org/10.1177/2053951716652159",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "3",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 38,
      "is_referenced_by_count": 42,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "81525ce6-ee8c-45dd-9919-b18379b0da5b",
    "title": "What difference does quantity make? On the epistemology of Big Data in biology",
    "abstract": "<jats:p> Is Big Data science a whole new way of doing research? And what difference does data quantity make to knowledge production strategies and their outputs? I argue that the novelty of Big Data science does not lie in the sheer quantity of data involved, but rather in (1) the prominence and status acquired by data as commodity and recognised output, both within and outside of the scientific community and (2) the methods, infrastructures, technologies, skills and knowledge developed to handle data. These developments generate the impression that data-intensive research is a new mode of doing science, with its own epistemology and norms. To assess this claim, one needs to consider the ways in which data are actually disseminated and used to generate knowledge. Accordingly, this article reviews the development of sophisticated ways to disseminate, integrate and re-use data acquired on model organisms over the last three decades of work in experimental biology. I focus on online databases as prominent infrastructures set up to organise and interpret such data and examine the wealth and diversity of expertise, resources and conceptual scaffolding that such databases draw upon. This illuminates some of the conditions under which Big Data needs to be curated to support processes of discovery across biological subfields, which in turn highlights the difficulties caused by the lack of adequate curation for the vast majority of data in the life sciences. In closing, I reflect on the difference that data quantity is making to contemporary biology, the methodological and epistemic challenges of identifying and analysing data given these developments, and the opportunities and worries associated with Big Data discourse and methods. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951714534395",
      "type": "journal-article",
      "published": [
        2014,
        4,
        1
      ],
      "authors": [
        "S Leonelli"
      ],
      "url": "https://doi.org/10.1177/2053951714534395",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "1",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 46,
      "is_referenced_by_count": 167,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "2bd60247-6ae1-4659-bb57-19f46ad78467",
    "title": "Data and agency",
    "abstract": "<jats:p> This introduction to the special issue on data and agency argues that datafication should not only be understood as the process of collecting and analysing data about Internet users, but also as feeding such data back to users, enabling them to orient themselves in the world. It is important that debates about data power recognise that data is also generated, collected and analysed by alternative actors, enhancing rather than undermining the agency of the public. Developing this argument, we first make clear why and how the question of agency should be central to our engagement with data. Subsequently, we discuss how this question has been operationalized in the five contributions to this special issue, which empirically open up the study of alternative forms of datafication. Building on these contributions, we conclude that as data acquire new power, it is vital to explore the space for citizen agency in relation to data structures and to examine the practices of data work, as well as the people involved in these practices. </jats:p>",
    "metadata": {
      "doi": "10.1177/2053951715621569",
      "type": "journal-article",
      "published": [
        2015,
        12,
        1
      ],
      "authors": [
        "Helen Kennedy",
        "Thomas Poell",
        "Jose van Dijck"
      ],
      "url": "https://doi.org/10.1177/2053951715621569",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "2",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 37,
      "is_referenced_by_count": 88,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "fdbf4727-1887-48c3-bed4-4249249d2d7b",
    "title": "Generating reality and silencing debate: Synthetic data as discursive device",
    "abstract": "<jats:p> In addition to tapping data from users’ behavioral surplus, by drawing on generative adversarial networks, data for artificial intelligence is now increasingly being generated through artificial intelligence. With this new method of producing data synthetically, the data economy is not only shifting from “data collection” to “data generation.” Synthetic data is also being employed to address some of the most pressing ethical concerns around artificial intelligence. It thereby comes with the sociotechnical imaginary that social problems can be cut out of artificial intelligence, separating training data from real persons. In response to this technical solutionism, this commentary aims to initiate a critical debate about synthetic data that goes beyond misuse scenarios such as the use of generative adversarial networks to create deep fakes or dark patterns. Instead, on a more general level, we seek to complicate the idea of “solving,” i.e., “closing” and thus “silencing” the ethico-political debates for which synthetic data is supposed to be a solution by showing how synthetic data itself is political. Drawing on the complex connections between recent uses of synthetic data and public debates about artificial intelligence, we therefore propose to consider and analyze synthetic data not only as a technical device but as a discursive one as well. To this end, we shed light on their relationship to three pillars that we see associated with them (a) algorithmic bias, (b) privacy, (c) platform economy. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241249447",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Paula Helm",
        "Benjamin Lipp",
        "Roser Pujadas"
      ],
      "url": "https://doi.org/10.1177/20539517241249447",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 32,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "cf596422-2cb5-4ce2-9214-398fb447a5fa",
    "title": "Machine learning and the politics  of synthetic data",
    "abstract": "<jats:p> Machine-learning algorithms have become deeply embedded in contemporary society. As such, ample attention has been paid to the contents, biases, and underlying assumptions of the training datasets that many algorithmic models are trained on. Yet, what happens when algorithms are trained on data that are not real, but instead data that are ‘synthetic’, not referring to real persons, objects, or events? Increasingly, synthetic data are being incorporated into the training of machine-learning algorithms for use in various societal domains. There is currently little understanding, however, of the role played by and the ethicopolitical implications of synthetic training data for machine-learning algorithms. In this article, I explore the politics of synthetic data through two central aspects: first, synthetic data promise to emerge as a rich source of exposure to variability for the algorithm. Second, the paper explores how synthetic data promise to place algorithms beyond the realm of risk. I propose that an analysis of these two areas will help us better understand the ways in which machine-learning algorithms are envisioned in the light of synthetic data, but also how synthetic training data actively reconfigure the conditions of possibility for machine learning in contemporary society. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221145372",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Benjamin N Jacobsen"
      ],
      "url": "https://doi.org/10.1177/20539517221145372",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 54,
      "is_referenced_by_count": 35,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "ac7e45ff-1976-4ae1-8468-f6526fa30552",
    "title": "Reclaiming artificial intelligence accounts: A plea for a participatory turn in artificial intelligence inquiries",
    "abstract": "<jats:p> How to participate in artificial intelligence otherwise? Put simply, when it comes to technological developments, participation is either understood as public debates with non-expert voices to anticipate risks and potential harms, or as a way to better design technical systems by involving diverse stakeholders in the design process. We advocate for a third path that considers participation as crucial to problematise what is at stake and to get a grip on the situated developments of artificial intelligence technologies. </jats:p><jats:p> This study addresses how the production of accounts shape problems that arise with artificial intelligence technologies. Taking France as a field of study, we first inspected how media narratives account for the entities and issues of artificial intelligence, as reported by the national press over the last decade. From this inspection, we identified four genres and described their performative effects. We then conducted a participatory inquiry with 25 French artificial intelligence practitioners’ to ground artificial intelligence in situated experiences and trajectories. These experiential accounts enabled a plural problematisation of artificial intelligence, playing with the geometries of artificial intelligence and its constituencies, while diversifying and thickening its problems. </jats:p><jats:p> To conclude, we discuss how participatory inquiries, through experiential and plural accounts offer a refreshing weaving of artificial intelligence problems into the fabric of its deployments. Our participatory approach seeks to re-politicise artificial intelligence from practitioners’ situated experiences, by making the ongoing relationships between past trajectories, current frictions and future developments tangible and contestable, opening avenues to contribute otherwise. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241248093",
      "type": "journal-article",
      "published": [
        2024,
        6
      ],
      "authors": [
        "Pauline Gourlet",
        "Donato Ricci",
        "Maxime Crépel"
      ],
      "url": "https://doi.org/10.1177/20539517241248093",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 68,
      "is_referenced_by_count": 8,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "b356c562-2e49-4519-8ff2-de8fc214dddc",
    "title": "Big AI: Cloud infrastructure dependence and the industrialisation of artificial intelligence",
    "abstract": "<jats:p> Critical scholars contend that ‘There is no AI without Big Tech’. This study delves into the substantial role played by major technology conglomerates, including Amazon, Microsoft, and Google (Alphabet), in the ‘industrialisation of artificial intelligence’. This concept encapsulates the shift of AI technologies from the research and development stage to practical, real-world applications across diverse industry sectors, resulting in new dependencies and associated investments. We employ the term ‘Big AI’ to encapsulate the structural convergence of AI and Big Tech, characterised by the profound interdependence of AI with the infrastructure, resources, and investments of these major technology companies. Using a ‘technographic’ approach, our study scrutinises the infrastructural support and investments of Big Tech in the AI sector, focussing on corporate partnerships, acquisitions, and financial investments. Additionally, we conduct a detailed examination of the complete spectrum of cloud platform products and services offered by Amazon, Microsoft, and Google. We demonstrate that AI is not merely an abstract idea but an actual technology stack encompassing infrastructure, models, applications, and an ecosystem of applications and companies relying on this stack. Significantly, these tech giants have seamlessly integrated all three components of the stack into their cloud offerings. Furthermore, they have developed industry-focussed solutions and marketplaces aimed at attracting third-party developers and businesses, fostering the growth of a broader AI ecosystem. This analysis underscores the intricate interdependence between AI and cloud infrastructure, emphasising the industry-specific aspects of cloud AI. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517241232630",
      "type": "journal-article",
      "published": [
        2024,
        3
      ],
      "authors": [
        "Fernando van der Vlist",
        "Anne Helmond",
        "Fabian Ferrari"
      ],
      "url": "https://doi.org/10.1177/20539517241232630",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "11",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 59,
      "is_referenced_by_count": 33,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "441d00e7-4202-469e-b304-2571b30ae186",
    "title": "Public sector information in the European Union policy: The misbalance between economy and individuals",
    "abstract": "<jats:p> Algorithmic technologies and artificial intelligence are centred on data and generate new business models, known as the data-driven economy. In the European Union context, the development of such new business is accompanied by a regulatory and political framework. An important aspect of this regulatory framework regards the legal conditions that enable the data collection, availability, sharing, use and reuse. Within the larger context, this article analyses the development of the European Union regulatory framework governing the availability, sharing and reuse of public sector data, also referred to as Public Sector Information policy. Anchored in the analytical tools provided by Discursive Institutionalism and Critical Data Studies and after studying the evolution of this policy over 25 years, this article argues that economic considerations have been overwhelmingly decisive in the European Union Public Sector Information policy and much less attention has been paid to fundamental rights and democracy issues. It also shows how European Union Public Sector Information policy contributes to the data infrastructure, enabling a thriving data-driven economy. In doing so, this article argues that the possible problematic effects of this new data-driven economy are not only affordances of the technology itself but are also the result of political and regulatory choices. More globally, the article stresses the need for policymakers to inscribe each of the policies and regulations affecting the digital transformation in the framework of fundamental rights and democracy. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517221124587",
      "type": "journal-article",
      "published": [
        2022,
        7
      ],
      "authors": [
        "Clarissa Valli Buttow",
        "Sophie Weerts"
      ],
      "url": "https://doi.org/10.1177/20539517221124587",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "9",
      "issue": "2",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 69,
      "is_referenced_by_count": 9,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "4db98537-dd45-48fb-8375-78d1d88ceb0a",
    "title": "Coloniality and frictions: Data-driven humanitarianism in North-Eastern Nigeria and South Sudan",
    "abstract": "<jats:p> It is now over a decade since the proclamation of a humanitarian ‘data revolution’, with the rise of ‘innovation’ and the proliferation of ‘data solutions’ rendering data-based humanitarianism an important area of critical investigation. This article contributes to debates within the field by exploring the role of data in the provision of humanitarian assistance within camps for internally displaced persons (IDPs) across north-eastern Nigeria and South Sudan. It draws on qualitative interviews carried out with humanitarian practitioners specialising in data and information management, as well as with camp residents and stakeholders located in each region. The analysis focuses attention on the ways in which epistemic injustices have been further perpetuated by the ‘data revolution’ due to the intensification of paternalistic dynamics associated with the coloniality of humanitarianism. It shows how a logic of extractivism structures the humanitarian data ecosystem, while also generating a series of tensions and disagreements. Data-driven humanitarianism, the article concludes, is characterised by recurring colonial dynamics as well as intensified frictions that bring epistemic injustices into sharper focus. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231163171",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Vicki Squire",
        "Modesta Alozie"
      ],
      "url": "https://doi.org/10.1177/20539517231163171",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 46,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  },
  {
    "id": "400c68c7-d8d4-49c8-9bbf-31a909ff1be0",
    "title": "Imaginaries of better administration: Renegotiating the relationship between citizens and digital public power",
    "abstract": "<jats:p> This article investigates future visions of digital public administration as they appear within a particular regulatory process that aims to enable automated decision-making (ADM) in public administration in Finland. By drawing on science and technology studies, public administration studies, and socio-legal studies we analyze law in the making and identify four imaginaries of public digital administration: understandable administration, self-monitoring administration, adaptive administration, and responsible administration. We argue that digital administration is seen from the perspective of public authorities serving their current needs of legitimizing existing automation practices. While technology is pictured as unproblematic, the citizen perspective is missing. We conclude that the absence of an in-depth understanding of the diverse needs of citizens raises the question whether the relationship between public power and citizens is becoming a one-way street despite of the public administration ideals that express values of citizen engagement. </jats:p>",
    "metadata": {
      "doi": "10.1177/20539517231164113",
      "type": "journal-article",
      "published": [
        2023,
        1
      ],
      "authors": [
        "Terhi Esko",
        "Riikka Koulu"
      ],
      "url": "https://doi.org/10.1177/20539517231164113",
      "publisher": "SAGE Publications",
      "container_title": "Big Data &amp; Society",
      "volume": "10",
      "issue": "1",
      "page": "",
      "subject": [],
      "language": "en",
      "issn": [
        "2053-9517",
        "2053-9517"
      ],
      "isbn": [],
      "references_count": 44,
      "is_referenced_by_count": 4,
      "score": 0.0,
      "abstract_available": "yes"
    }
  }
]